[
  {
    "episode": 1,
    "avg_reward_per_step": -2.6157018570149115,
    "episode_length": 3000,
    "policy_loss": 43.39109420776367,
    "value_loss": 1.6696741580963135,
    "entropy": 1.3728387951850891,
    "total_loss": 44.51163284778595
  },
  {
    "episode": 2,
    "avg_reward_per_step": 13.268903455100629,
    "episode_length": 1254,
    "policy_loss": -227.15924072265625,
    "value_loss": 0.5087750852108002,
    "entropy": 1.3760925829410553,
    "total_loss": -227.20090267062187
  },
  {
    "episode": 3,
    "avg_reward_per_step": 36.49840817731281,
    "episode_length": 510,
    "policy_loss": -621.5436401367188,
    "value_loss": 0.5284064561128616,
    "entropy": 1.3715356886386871,
    "total_loss": -621.5638479560614
  },
  {
    "episode": 4,
    "avg_reward_per_step": -3.9334426119492916,
    "episode_length": 3000,
    "policy_loss": 65.8841724395752,
    "value_loss": 2.081011712551117,
    "entropy": 1.3729841113090515,
    "total_loss": 67.41599050760269
  },
  {
    "episode": 5,
    "avg_reward_per_step": 3.6338124096345,
    "episode_length": 2845,
    "policy_loss": -62.35694694519043,
    "value_loss": 0.5013696849346161,
    "entropy": 1.3710887730121613,
    "total_loss": -62.40401276946068
  },
  {
    "episode": 6,
    "avg_reward_per_step": 14.589673081878905,
    "episode_length": 1136,
    "policy_loss": -248.10169982910156,
    "value_loss": 0.5096717029809952,
    "entropy": 1.3621779084205627,
    "total_loss": -248.13689928948878
  },
  {
    "episode": 7,
    "avg_reward_per_step": 29.34813447282756,
    "episode_length": 616,
    "policy_loss": -502.3513641357422,
    "value_loss": 0.5217786431312561,
    "entropy": 1.3528140187263489,
    "total_loss": -502.37071110010146
  },
  {
    "episode": 8,
    "avg_reward_per_step": 31.221588495098104,
    "episode_length": 553,
    "policy_loss": -527.2837371826172,
    "value_loss": 0.5221571773290634,
    "entropy": 1.3227616250514984,
    "total_loss": -527.2906846553087
  },
  {
    "episode": 9,
    "avg_reward_per_step": 25.007327776831836,
    "episode_length": 672,
    "policy_loss": -431.4928207397461,
    "value_loss": 0.5170846581459045,
    "entropy": 1.2859071791172028,
    "total_loss": -431.49009895324707
  },
  {
    "episode": 10,
    "avg_reward_per_step": 46.582231945147086,
    "episode_length": 393,
    "policy_loss": -790.5624389648438,
    "value_loss": 0.5361308753490448,
    "entropy": 1.2416980564594269,
    "total_loss": -790.5229873120785
  },
  {
    "episode": 11,
    "avg_reward_per_step": 9.21782215812794,
    "episode_length": 1512,
    "policy_loss": -155.42483139038086,
    "value_loss": 0.504979744553566,
    "entropy": 1.205115407705307,
    "total_loss": -155.4018978089094
  },
  {
    "episode": 12,
    "avg_reward_per_step": 8.994394213368906,
    "episode_length": 1410,
    "policy_loss": -152.6418571472168,
    "value_loss": 0.5043369829654694,
    "entropy": 1.1749702990055084,
    "total_loss": -152.60750828385352
  },
  {
    "episode": 13,
    "avg_reward_per_step": 22.20414775548445,
    "episode_length": 716,
    "policy_loss": -380.3343734741211,
    "value_loss": 0.5141023397445679,
    "entropy": 1.133740484714508,
    "total_loss": -380.27376732826235
  },
  {
    "episode": 14,
    "avg_reward_per_step": 5.171147902805855,
    "episode_length": 1695,
    "policy_loss": -87.18576240539551,
    "value_loss": 0.5015691816806793,
    "entropy": 1.0703510642051697,
    "total_loss": -87.1123336493969
  },
  {
    "episode": 15,
    "avg_reward_per_step": 127.7898390218007,
    "episode_length": 153,
    "policy_loss": -2186.6253051757812,
    "value_loss": 0.6240372508764267,
    "entropy": 1.0063253492116928,
    "total_loss": -2186.4037980645894
  },
  {
    "episode": 16,
    "avg_reward_per_step": 19.622071053793885,
    "episode_length": 780,
    "policy_loss": -336.4924011230469,
    "value_loss": 0.5119022578001022,
    "entropy": 0.9554152935743332,
    "total_loss": -336.3626649826765
  },
  {
    "episode": 17,
    "avg_reward_per_step": 25.10178050148776,
    "episode_length": 619,
    "policy_loss": -422.215087890625,
    "value_loss": 0.5156295299530029,
    "entropy": 0.9097864180803299,
    "total_loss": -422.06337292790414
  },
  {
    "episode": 18,
    "avg_reward_per_step": 21.49474361305842,
    "episode_length": 742,
    "policy_loss": -362.0849609375,
    "value_loss": 0.513786256313324,
    "entropy": 0.9269919246435165,
    "total_loss": -361.9419714510441
  },
  {
    "episode": 19,
    "avg_reward_per_step": 59.46234824296485,
    "episode_length": 316,
    "policy_loss": -1012.3080596923828,
    "value_loss": 0.5491118729114532,
    "entropy": 0.8898734301328659,
    "total_loss": -1012.1148971915245
  },
  {
    "episode": 20,
    "avg_reward_per_step": 75.49806091404268,
    "episode_length": 244,
    "policy_loss": -1274.5393371582031,
    "value_loss": 0.5618775337934494,
    "entropy": 0.8517462909221649,
    "total_loss": -1274.3181581407785
  },
  {
    "episode": 21,
    "avg_reward_per_step": 30.012089364072374,
    "episode_length": 572,
    "policy_loss": -503.1943817138672,
    "value_loss": 0.5212382525205612,
    "entropy": 0.8961343169212341,
    "total_loss": -503.03159718811514
  },
  {
    "episode": 22,
    "avg_reward_per_step": 28.437286489752026,
    "episode_length": 607,
    "policy_loss": -480.4021301269531,
    "value_loss": 0.5201692581176758,
    "entropy": 0.9119249582290649,
    "total_loss": -480.2467308521271
  },
  {
    "episode": 23,
    "avg_reward_per_step": 24.65332750266364,
    "episode_length": 705,
    "policy_loss": -418.7732696533203,
    "value_loss": 0.5173702389001846,
    "entropy": 0.9415000379085541,
    "total_loss": -418.63249942958356
  },
  {
    "episode": 24,
    "avg_reward_per_step": 51.718508517550134,
    "episode_length": 355,
    "policy_loss": -880.1143646240234,
    "value_loss": 0.5406636893749237,
    "entropy": 0.9436339735984802,
    "total_loss": -879.9511545240879
  },
  {
    "episode": 25,
    "avg_reward_per_step": 23.649615282574995,
    "episode_length": 729,
    "policy_loss": -400.59788513183594,
    "value_loss": 0.5165424048900604,
    "entropy": 0.9694214016199112,
    "total_loss": -400.4691112875938
  },
  {
    "episode": 26,
    "avg_reward_per_step": 124.68953313490064,
    "episode_length": 158,
    "policy_loss": -2109.9884643554688,
    "value_loss": 0.6219136416912079,
    "entropy": 0.972246527671814,
    "total_loss": -2109.7554493248463
  },
  {
    "episode": 27,
    "avg_reward_per_step": 29.252469308442617,
    "episode_length": 625,
    "policy_loss": -493.1829528808594,
    "value_loss": 0.5220818817615509,
    "entropy": 0.9631706774234772,
    "total_loss": -493.0461392700672
  },
  {
    "episode": 28,
    "avg_reward_per_step": 13.61611894115831,
    "episode_length": 1262,
    "policy_loss": -230.5779037475586,
    "value_loss": 0.5093720555305481,
    "entropy": 0.9598439335823059,
    "total_loss": -230.45246926546096
  },
  {
    "episode": 29,
    "avg_reward_per_step": 97.87267634395923,
    "episode_length": 201,
    "policy_loss": -1656.4704284667969,
    "value_loss": 0.5907787382602692,
    "entropy": 0.9257367253303528,
    "total_loss": -1656.2499444186687
  },
  {
    "episode": 30,
    "avg_reward_per_step": 34.063607308766144,
    "episode_length": 540,
    "policy_loss": -578.3861999511719,
    "value_loss": 0.526098757982254,
    "entropy": 0.8935234844684601,
    "total_loss": -578.217510586977
  },
  {
    "episode": 31,
    "avg_reward_per_step": 129.28852758417526,
    "episode_length": 153,
    "policy_loss": -2192.855712890625,
    "value_loss": 0.6280503869056702,
    "entropy": 0.8611263334751129,
    "total_loss": -2192.5721130371094
  },
  {
    "episode": 32,
    "avg_reward_per_step": 33.409631547316074,
    "episode_length": 553,
    "policy_loss": -566.9105377197266,
    "value_loss": 0.5255441814661026,
    "entropy": 0.8446638137102127,
    "total_loss": -566.7228590637445
  },
  {
    "episode": 33,
    "avg_reward_per_step": 38.49663461676742,
    "episode_length": 471,
    "policy_loss": -655.8767242431641,
    "value_loss": 0.5290148556232452,
    "entropy": 0.805011123418808,
    "total_loss": -655.6697138369084
  },
  {
    "episode": 34,
    "avg_reward_per_step": 9.890600916422068,
    "episode_length": 1388,
    "policy_loss": -167.1924057006836,
    "value_loss": 0.5052704215049744,
    "entropy": 0.7635874152183533,
    "total_loss": -166.99257024526597
  },
  {
    "episode": 35,
    "avg_reward_per_step": 78.99937133940232,
    "episode_length": 240,
    "policy_loss": -1332.7573852539062,
    "value_loss": 0.5680069625377655,
    "entropy": 0.7071648389101028,
    "total_loss": -1332.4722442269326
  },
  {
    "episode": 36,
    "avg_reward_per_step": 33.08263767432606,
    "episode_length": 502,
    "policy_loss": -565.7583923339844,
    "value_loss": 0.5224093496799469,
    "entropy": 0.7024038136005402,
    "total_loss": -565.5169445097447
  },
  {
    "episode": 37,
    "avg_reward_per_step": -9.079042198365128,
    "episode_length": 3000,
    "policy_loss": 152.88683319091797,
    "value_loss": 2.7213048338890076,
    "entropy": 0.632603645324707,
    "total_loss": 155.3550965666771
  },
  {
    "episode": 38,
    "avg_reward_per_step": -2.7700966887533354,
    "episode_length": 2923,
    "policy_loss": 46.93174076080322,
    "value_loss": 0.5006986707448959,
    "entropy": 0.576116293668747,
    "total_loss": 47.20199291408062
  },
  {
    "episode": 39,
    "avg_reward_per_step": -10.672923344475413,
    "episode_length": 3000,
    "policy_loss": 179.014892578125,
    "value_loss": 3.5280946493148804,
    "entropy": 0.5840783566236496,
    "total_loss": 182.30935588479042
  },
  {
    "episode": 40,
    "avg_reward_per_step": 5.951064180458755,
    "episode_length": 1288,
    "policy_loss": -101.03753662109375,
    "value_loss": 0.5014809668064117,
    "entropy": 0.5827121585607529,
    "total_loss": -100.76914051771163
  },
  {
    "episode": 41,
    "avg_reward_per_step": -10.800066342130313,
    "episode_length": 3000,
    "policy_loss": 180.87933731079102,
    "value_loss": 3.623879134654999,
    "entropy": 0.5491275042295456,
    "total_loss": 184.28356544375418
  },
  {
    "episode": 42,
    "avg_reward_per_step": -0.8139361236880616,
    "episode_length": 2086,
    "policy_loss": 12.034173965454102,
    "value_loss": 0.49981118738651276,
    "entropy": 0.6070172041654587,
    "total_loss": 12.29117827117443
  },
  {
    "episode": 43,
    "avg_reward_per_step": -10.802264459633417,
    "episode_length": 3000,
    "policy_loss": 180.5916748046875,
    "value_loss": 3.5805981159210205,
    "entropy": 0.5906306952238083,
    "total_loss": 183.936020642519
  },
  {
    "episode": 44,
    "avg_reward_per_step": 11.237539953383944,
    "episode_length": 1039,
    "policy_loss": -190.77540588378906,
    "value_loss": 0.5049376040697098,
    "entropy": 0.6461455821990967,
    "total_loss": -190.52892651259899
  },
  {
    "episode": 45,
    "avg_reward_per_step": 62.22637445503099,
    "episode_length": 291,
    "policy_loss": -1050.940185546875,
    "value_loss": 0.5495057255029678,
    "entropy": 0.598775178194046,
    "total_loss": -1050.6301898926497
  },
  {
    "episode": 46,
    "avg_reward_per_step": 55.2344295174394,
    "episode_length": 317,
    "policy_loss": -934.1855926513672,
    "value_loss": 0.541334792971611,
    "entropy": 0.6546701341867447,
    "total_loss": -933.9061259120703
  },
  {
    "episode": 47,
    "avg_reward_per_step": 64.29007190051938,
    "episode_length": 280,
    "policy_loss": -1090.4154968261719,
    "value_loss": 0.550382673740387,
    "entropy": 0.6620418429374695,
    "total_loss": -1090.1299308896064
  },
  {
    "episode": 48,
    "avg_reward_per_step": 17.600791591453522,
    "episode_length": 784,
    "policy_loss": -300.55492401123047,
    "value_loss": 0.5095590353012085,
    "entropy": 0.6816444844007492,
    "total_loss": -300.31802276968955
  },
  {
    "episode": 49,
    "avg_reward_per_step": 102.47005643591308,
    "episode_length": 189,
    "policy_loss": -1727.9205932617188,
    "value_loss": 0.5946841239929199,
    "entropy": 0.6944241225719452,
    "total_loss": -1727.6036787867547
  },
  {
    "episode": 50,
    "avg_reward_per_step": 65.50988285684815,
    "episode_length": 278,
    "policy_loss": -1110.6833190917969,
    "value_loss": 0.5522045195102692,
    "entropy": 0.7019683867692947,
    "total_loss": -1110.4119019269942
  },
  {
    "episode": 51,
    "avg_reward_per_step": 76.49949246318968,
    "episode_length": 251,
    "policy_loss": -1290.3978271484375,
    "value_loss": 0.566180408000946,
    "entropy": 0.7341448962688446,
    "total_loss": -1290.125304698944
  },
  {
    "episode": 52,
    "avg_reward_per_step": 14.473512782514586,
    "episode_length": 1099,
    "policy_loss": -244.0823211669922,
    "value_loss": 0.5091703832149506,
    "entropy": 0.7720709443092346,
    "total_loss": -243.88197916150094
  },
  {
    "episode": 53,
    "avg_reward_per_step": 15.681456232931817,
    "episode_length": 973,
    "policy_loss": -265.29833221435547,
    "value_loss": 0.5094825327396393,
    "entropy": 0.7549173980951309,
    "total_loss": -265.09081664085386
  },
  {
    "episode": 54,
    "avg_reward_per_step": 163.20120459660586,
    "episode_length": 121,
    "policy_loss": -2759.7667846679688,
    "value_loss": 0.673005536198616,
    "entropy": 0.7594669312238693,
    "total_loss": -2759.39756590426
  },
  {
    "episode": 55,
    "avg_reward_per_step": 25.81240872808534,
    "episode_length": 701,
    "policy_loss": -431.7967987060547,
    "value_loss": 0.5191723704338074,
    "entropy": 0.7575441598892212,
    "total_loss": -431.5806439995766
  },
  {
    "episode": 56,
    "avg_reward_per_step": 139.432213557023,
    "episode_length": 138,
    "policy_loss": -2368.0835571289062,
    "value_loss": 0.6360230892896652,
    "entropy": 0.6913284361362457,
    "total_loss": -2367.724065414071
  },
  {
    "episode": 57,
    "avg_reward_per_step": -0.032165377322695324,
    "episode_length": 2378,
    "policy_loss": 1.2128670364618301,
    "value_loss": 0.49979565292596817,
    "entropy": 0.6212174147367477,
    "total_loss": 1.4641757234930992
  },
  {
    "episode": 58,
    "avg_reward_per_step": 61.25517000581782,
    "episode_length": 290,
    "policy_loss": -1033.2390441894531,
    "value_loss": 0.5469280183315277,
    "entropy": 0.5974628180265427,
    "total_loss": -1032.9311012983321
  },
  {
    "episode": 59,
    "avg_reward_per_step": 0.9453687965622383,
    "episode_length": 1952,
    "policy_loss": -17.228878498077393,
    "value_loss": 0.4998151361942291,
    "entropy": 0.6029926687479019,
    "total_loss": -16.970260429382325
  },
  {
    "episode": 60,
    "avg_reward_per_step": 66.48955862724466,
    "episode_length": 268,
    "policy_loss": -1130.4763488769531,
    "value_loss": 0.5519423633813858,
    "entropy": 0.6414872407913208,
    "total_loss": -1130.1810014098883
  },
  {
    "episode": 61,
    "avg_reward_per_step": 6.1509946630199455,
    "episode_length": 1338,
    "policy_loss": -105.01262664794922,
    "value_loss": 0.5017185658216476,
    "entropy": 0.6349355280399323,
    "total_loss": -104.76488229334355
  },
  {
    "episode": 62,
    "avg_reward_per_step": 135.24025155874344,
    "episode_length": 142,
    "policy_loss": -2284.5280151367188,
    "value_loss": 0.6306707412004471,
    "entropy": 0.6528747081756592,
    "total_loss": -2284.1584942787886
  },
  {
    "episode": 63,
    "avg_reward_per_step": 80.52047986803224,
    "episode_length": 233,
    "policy_loss": -1359.0911254882812,
    "value_loss": 0.5688674002885818,
    "entropy": 0.6110624223947525,
    "total_loss": -1358.7666830569506
  },
  {
    "episode": 64,
    "avg_reward_per_step": 155.33175915509057,
    "episode_length": 126,
    "policy_loss": -2626.1281127929688,
    "value_loss": 0.6600052416324615,
    "entropy": 0.6627032160758972,
    "total_loss": -2625.7331888377666
  },
  {
    "episode": 65,
    "avg_reward_per_step": 26.870382292729126,
    "episode_length": 624,
    "policy_loss": -452.9409942626953,
    "value_loss": 0.5183160752058029,
    "entropy": 0.6895464360713959,
    "total_loss": -452.6984967619181
  },
  {
    "episode": 66,
    "avg_reward_per_step": 2.7605307702614015,
    "episode_length": 2180,
    "policy_loss": -47.58572006225586,
    "value_loss": 0.5004717856645584,
    "entropy": 0.6756566166877747,
    "total_loss": -47.35551092326641
  },
  {
    "episode": 67,
    "avg_reward_per_step": 81.18468842433515,
    "episode_length": 234,
    "policy_loss": -1373.541259765625,
    "value_loss": 0.5704987794160843,
    "entropy": 0.6338232010602951,
    "total_loss": -1373.224290266633
  },
  {
    "episode": 68,
    "avg_reward_per_step": 9.205773117710512,
    "episode_length": 1423,
    "policy_loss": -156.27583694458008,
    "value_loss": 0.5046532154083252,
    "entropy": 0.7123595327138901,
    "total_loss": -156.05612754225731
  },
  {
    "episode": 69,
    "avg_reward_per_step": 17.115548547688054,
    "episode_length": 1019,
    "policy_loss": -290.48912048339844,
    "value_loss": 0.5120757818222046,
    "entropy": 0.7319810539484024,
    "total_loss": -290.2698371231556
  },
  {
    "episode": 70,
    "avg_reward_per_step": 112.11349976733334,
    "episode_length": 175,
    "policy_loss": -1900.2256469726562,
    "value_loss": 0.6059016436338425,
    "entropy": 0.706838384270668,
    "total_loss": -1899.9024806827306
  },
  {
    "episode": 71,
    "avg_reward_per_step": 27.499740523425938,
    "episode_length": 635,
    "policy_loss": -459.41285705566406,
    "value_loss": 0.519756942987442,
    "entropy": 0.6988177746534348,
    "total_loss": -459.172627222538
  },
  {
    "episode": 72,
    "avg_reward_per_step": 105.42249638763094,
    "episode_length": 182,
    "policy_loss": -1780.70703125,
    "value_loss": 0.5970786660909653,
    "entropy": 0.6448484808206558,
    "total_loss": -1780.3678919762374
  },
  {
    "episode": 73,
    "avg_reward_per_step": 156.26980375029385,
    "episode_length": 126,
    "policy_loss": -2640.292724609375,
    "value_loss": 0.6624941378831863,
    "entropy": 0.6734810620546341,
    "total_loss": -2639.8996228963138
  },
  {
    "episode": 74,
    "avg_reward_per_step": 59.59202526412227,
    "episode_length": 318,
    "policy_loss": -1011.6911010742188,
    "value_loss": 0.5495596528053284,
    "entropy": 0.6823414266109467,
    "total_loss": -1011.4144779920578
  },
  {
    "episode": 75,
    "avg_reward_per_step": 46.18101745654995,
    "episode_length": 399,
    "policy_loss": -780.2319030761719,
    "value_loss": 0.5361125767230988,
    "entropy": 0.7024744600057602,
    "total_loss": -779.976780283451
  },
  {
    "episode": 76,
    "avg_reward_per_step": 118.42419891664557,
    "episode_length": 166,
    "policy_loss": -2017.9620361328125,
    "value_loss": 0.6136350035667419,
    "entropy": 0.6715981811285019,
    "total_loss": -2017.617040401697
  },
  {
    "episode": 77,
    "avg_reward_per_step": 229.65124677808572,
    "episode_length": 87,
    "policy_loss": -3909.3975219726562,
    "value_loss": 0.7854831665754318,
    "entropy": 0.6372963637113571,
    "total_loss": -3908.8669573515654
  },
  {
    "episode": 78,
    "avg_reward_per_step": 17.55509081544408,
    "episode_length": 730,
    "policy_loss": -298.9778823852539,
    "value_loss": 0.5086475759744644,
    "entropy": 0.5237776339054108,
    "total_loss": -298.6787458628416
  },
  {
    "episode": 79,
    "avg_reward_per_step": -13.350918532233305,
    "episode_length": 3000,
    "policy_loss": 223.7467041015625,
    "value_loss": 3.2624229192733765,
    "entropy": 0.371673621237278,
    "total_loss": 226.86045757234098
  },
  {
    "episode": 80,
    "avg_reward_per_step": 208.2355192904563,
    "episode_length": 96,
    "policy_loss": -3509.8381958007812,
    "value_loss": 0.7471755743026733,
    "entropy": 0.6140380650758743,
    "total_loss": -3509.3366354525087
  },
  {
    "episode": 81,
    "avg_reward_per_step": 2.6249763360013625,
    "episode_length": 1644,
    "policy_loss": -45.180198669433594,
    "value_loss": 0.5001887679100037,
    "entropy": 0.3664604350924492,
    "total_loss": -44.82659407556057
  },
  {
    "episode": 82,
    "avg_reward_per_step": 0.43038260306487164,
    "episode_length": 1568,
    "policy_loss": -8.681847095489502,
    "value_loss": 0.49970053136348724,
    "entropy": 0.4038630425930023,
    "total_loss": -8.343691781163216
  },
  {
    "episode": 83,
    "avg_reward_per_step": -12.636872727432669,
    "episode_length": 3000,
    "policy_loss": 211.3028106689453,
    "value_loss": 2.088813602924347,
    "entropy": 0.4343153312802315,
    "total_loss": 213.21789813935757
  },
  {
    "episode": 84,
    "avg_reward_per_step": -5.726130586125644,
    "episode_length": 2961,
    "policy_loss": 94.76955986022949,
    "value_loss": 0.5034909546375275,
    "entropy": 0.4058070331811905,
    "total_loss": 95.11072800159454
  },
  {
    "episode": 85,
    "avg_reward_per_step": -14.284176735811952,
    "episode_length": 3000,
    "policy_loss": 238.85662078857422,
    "value_loss": 3.8647329807281494,
    "entropy": 0.34773751348257065,
    "total_loss": 242.58225876390935
  },
  {
    "episode": 86,
    "avg_reward_per_step": -14.030751925735501,
    "episode_length": 3000,
    "policy_loss": 234.66387939453125,
    "value_loss": 3.0936331152915955,
    "entropy": 0.33289845287799835,
    "total_loss": 237.62435312867166
  },
  {
    "episode": 87,
    "avg_reward_per_step": 14.067701200872564,
    "episode_length": 867,
    "policy_loss": -239.14960098266602,
    "value_loss": 0.5065367668867111,
    "entropy": 0.3950698897242546,
    "total_loss": -238.801092171669
  },
  {
    "episode": 88,
    "avg_reward_per_step": 0.5341342391295308,
    "episode_length": 1770,
    "policy_loss": -10.959931373596191,
    "value_loss": 0.4997623786330223,
    "entropy": 0.4783950299024582,
    "total_loss": -10.651527006924152
  },
  {
    "episode": 89,
    "avg_reward_per_step": 165.34441388678957,
    "episode_length": 118,
    "policy_loss": -2804.1502685546875,
    "value_loss": 0.6735161393880844,
    "entropy": 0.6556649655103683,
    "total_loss": -2803.7390184015035
  },
  {
    "episode": 90,
    "avg_reward_per_step": 3.1098636031310947,
    "episode_length": 1553,
    "policy_loss": -52.06608295440674,
    "value_loss": 0.5003452003002167,
    "entropy": 0.3927193731069565,
    "total_loss": -51.722825503349306
  },
  {
    "episode": 91,
    "avg_reward_per_step": -16.207539999340206,
    "episode_length": 3000,
    "policy_loss": 270.99483489990234,
    "value_loss": 3.620867609977722,
    "entropy": 0.28384262323379517,
    "total_loss": 274.5021654605865
  },
  {
    "episode": 92,
    "avg_reward_per_step": 11.913397974349001,
    "episode_length": 1097,
    "policy_loss": -203.06125259399414,
    "value_loss": 0.506113812327385,
    "entropy": 0.32954230159521103,
    "total_loss": -202.68695570230483
  },
  {
    "episode": 93,
    "avg_reward_per_step": 9.031431271852204,
    "episode_length": 1555,
    "policy_loss": -153.4527130126953,
    "value_loss": 0.5050640106201172,
    "entropy": 0.2645696625113487,
    "total_loss": -153.05347686707972
  },
  {
    "episode": 94,
    "avg_reward_per_step": -16.644608265473106,
    "episode_length": 3000,
    "policy_loss": 277.76810455322266,
    "value_loss": 3.9011279940605164,
    "entropy": 0.30312900990247726,
    "total_loss": 281.54798094332216
  },
  {
    "episode": 95,
    "avg_reward_per_step": -15.693366476721765,
    "episode_length": 3000,
    "policy_loss": 261.5409393310547,
    "value_loss": 3.9684447646141052,
    "entropy": 0.28045494109392166,
    "total_loss": 265.3972021192312
  },
  {
    "episode": 96,
    "avg_reward_per_step": 626.4318844740864,
    "episode_length": 32,
    "policy_loss": -9112.822021484375,
    "value_loss": 2.104532539844513,
    "entropy": 0.3229260817170143,
    "total_loss": -9110.846659377217
  },
  {
    "episode": 97,
    "avg_reward_per_step": 417.70054248307093,
    "episode_length": 48,
    "policy_loss": -6707.33154296875,
    "value_loss": 1.2664961218833923,
    "entropy": 0.2628006786108017,
    "total_loss": -6706.170167118311
  },
  {
    "episode": 98,
    "avg_reward_per_step": -15.30838957217438,
    "episode_length": 3000,
    "policy_loss": 255.05096054077148,
    "value_loss": 3.581674039363861,
    "entropy": 0.25916484743356705,
    "total_loss": 258.5289686411619
  },
  {
    "episode": 99,
    "avg_reward_per_step": -16.072247026224527,
    "episode_length": 3000,
    "policy_loss": 267.47684478759766,
    "value_loss": 3.8768747448921204,
    "entropy": 0.23730811849236488,
    "total_loss": 271.25879628509284
  },
  {
    "episode": 100,
    "avg_reward_per_step": 135.69583936615507,
    "episode_length": 147,
    "policy_loss": -2292.3698120117188,
    "value_loss": 0.6368220746517181,
    "entropy": 0.12754862196743488,
    "total_loss": -2291.784009385854
  },
  {
    "episode": 101,
    "avg_reward_per_step": 263.6266584103606,
    "episode_length": 76,
    "policy_loss": -4406.7203369140625,
    "value_loss": 0.854237362742424,
    "entropy": 0.18222473561763763,
    "total_loss": -4405.938989445567
  },
  {
    "episode": 102,
    "avg_reward_per_step": -17.25853598731343,
    "episode_length": 3000,
    "policy_loss": 287.2726821899414,
    "value_loss": 4.6736369132995605,
    "entropy": 0.22073007747530937,
    "total_loss": 291.8580270722508
  },
  {
    "episode": 103,
    "avg_reward_per_step": 489.10063510213183,
    "episode_length": 41,
    "policy_loss": -7584.6578369140625,
    "value_loss": 1.5176529586315155,
    "entropy": 0.1479375809431076,
    "total_loss": -7583.199358987808
  },
  {
    "episode": 104,
    "avg_reward_per_step": 541.8448356035047,
    "episode_length": 37,
    "policy_loss": -8207.914184570312,
    "value_loss": 1.7273123860359192,
    "entropy": 0.1175142303109169,
    "total_loss": -8206.2338778764
  },
  {
    "episode": 105,
    "avg_reward_per_step": -0.5510572496504108,
    "episode_length": 3000,
    "policy_loss": 5.8930158615112305,
    "value_loss": 0.9245665818452835,
    "entropy": 0.03686858341097832,
    "total_loss": 6.802835009992123
  },
  {
    "episode": 106,
    "avg_reward_per_step": 371.2338155405075,
    "episode_length": 54,
    "policy_loss": -6040.4906005859375,
    "value_loss": 1.1242390871047974,
    "entropy": 0.13299699872732162,
    "total_loss": -6039.419560298324
  },
  {
    "episode": 107,
    "avg_reward_per_step": 455.80080201879446,
    "episode_length": 44,
    "policy_loss": -7211.650390625,
    "value_loss": 1.3961546421051025,
    "entropy": 0.14636105671525002,
    "total_loss": -7210.312780405581
  },
  {
    "episode": 108,
    "avg_reward_per_step": 409.16583753443683,
    "episode_length": 49,
    "policy_loss": -6559.7186279296875,
    "value_loss": 1.2396659553050995,
    "entropy": 0.12758317217230797,
    "total_loss": -6558.5299952432515
  },
  {
    "episode": 109,
    "avg_reward_per_step": 466.328512539242,
    "episode_length": 43,
    "policy_loss": -7308.1502685546875,
    "value_loss": 1.4338306784629822,
    "entropy": 0.1231677494943142,
    "total_loss": -7306.765704976022
  },
  {
    "episode": 110,
    "avg_reward_per_step": 187.10398167464865,
    "episode_length": 107,
    "policy_loss": -3153.7182006835938,
    "value_loss": 0.7127784937620163,
    "entropy": 0.16592084988951683,
    "total_loss": -3153.0717905297874
  },
  {
    "episode": 111,
    "avg_reward_per_step": 256.8541799895821,
    "episode_length": 78,
    "policy_loss": -4298.365478515625,
    "value_loss": 0.8404895216226578,
    "entropy": 0.1338583007454872,
    "total_loss": -4297.578532314301
  },
  {
    "episode": 112,
    "avg_reward_per_step": 7.182085850083916,
    "episode_length": 2609,
    "policy_loss": -125.13622283935547,
    "value_loss": 0.5056754499673843,
    "entropy": 0.02869665389880538,
    "total_loss": -124.6420260509476
  },
  {
    "episode": 113,
    "avg_reward_per_step": 527.7533168207216,
    "episode_length": 38,
    "policy_loss": -8032.7149658203125,
    "value_loss": 1.6696106791496277,
    "entropy": 0.08386209420859814,
    "total_loss": -8031.0788999788465
  },
  {
    "episode": 114,
    "avg_reward_per_step": 357.9576078426322,
    "episode_length": 56,
    "policy_loss": -5839.808349609375,
    "value_loss": 1.0865016877651215,
    "entropy": 0.11868743598461151,
    "total_loss": -5838.769322896003
  },
  {
    "episode": 115,
    "avg_reward_per_step": 426.5984263656895,
    "episode_length": 47,
    "policy_loss": -6786.9210205078125,
    "value_loss": 1.2963460981845856,
    "entropy": 0.10242924466729164,
    "total_loss": -6785.6656461074945
  },
  {
    "episode": 116,
    "avg_reward_per_step": 334.06043398645676,
    "episode_length": 60,
    "policy_loss": -5488.8646240234375,
    "value_loss": 1.0216452479362488,
    "entropy": 0.12815913371741772,
    "total_loss": -5487.894242428988
  },
  {
    "episode": 117,
    "avg_reward_per_step": 489.10063510213183,
    "episode_length": 41,
    "policy_loss": -7573.3431396484375,
    "value_loss": 1.5179870128631592,
    "entropy": 0.08075946569442749,
    "total_loss": -7571.8574564218525
  },
  {
    "episode": 118,
    "avg_reward_per_step": 299.1063587938419,
    "episode_length": 67,
    "policy_loss": -4959.2708740234375,
    "value_loss": 0.9343383759260178,
    "entropy": 0.14894264936447144,
    "total_loss": -4958.396112707257
  },
  {
    "episode": 119,
    "avg_reward_per_step": 408.96246051291246,
    "episode_length": 49,
    "policy_loss": -6553.2430419921875,
    "value_loss": 1.2388163805007935,
    "entropy": 0.10673079639673233,
    "total_loss": -6552.046917930245
  },
  {
    "episode": 120,
    "avg_reward_per_step": -20.14747090685825,
    "episode_length": 3000,
    "policy_loss": 334.6563262939453,
    "value_loss": 46.65353012084961,
    "entropy": 0.022574351634830236,
    "total_loss": 381.300826674141
  },
  {
    "episode": 121,
    "avg_reward_per_step": 557.1007233124442,
    "episode_length": 36,
    "policy_loss": -8353.568115234375,
    "value_loss": 1.7924554646015167,
    "entropy": 0.04733453970402479,
    "total_loss": -8351.794593585655
  },
  {
    "episode": 122,
    "avg_reward_per_step": 455.7187736178956,
    "episode_length": 44,
    "policy_loss": -7160.7474365234375,
    "value_loss": 1.3962947726249695,
    "entropy": 0.1084023043513298,
    "total_loss": -7159.394502672553
  },
  {
    "episode": 123,
    "avg_reward_per_step": 501.34065097968517,
    "episode_length": 40,
    "policy_loss": -7719.3978271484375,
    "value_loss": 1.56516695022583,
    "entropy": 0.07781890965998173,
    "total_loss": -7717.863787762076
  },
  {
    "episode": 124,
    "avg_reward_per_step": 542.0304334915606,
    "episode_length": 37,
    "policy_loss": -8188.978515625,
    "value_loss": 1.728816270828247,
    "entropy": 0.06566806603223085,
    "total_loss": -8187.275966580584
  },
  {
    "episode": 125,
    "avg_reward_per_step": 607.7941969074885,
    "episode_length": 33,
    "policy_loss": -8888.746826171875,
    "value_loss": 2.019285023212433,
    "entropy": 0.03949746396392584,
    "total_loss": -8886.743340134248
  },
  {
    "episode": 126,
    "avg_reward_per_step": 477.44347712350964,
    "episode_length": 42,
    "policy_loss": -7433.15283203125,
    "value_loss": 1.4748337864875793,
    "entropy": 0.11901756934821606,
    "total_loss": -7431.7256052725015
  },
  {
    "episode": 127,
    "avg_reward_per_step": 589.9007660282444,
    "episode_length": 34,
    "policy_loss": -8707.223876953125,
    "value_loss": 1.9371225237846375,
    "entropy": 0.04370278213173151,
    "total_loss": -8705.304235542193
  },
  {
    "episode": 128,
    "avg_reward_per_step": 589.9007660282444,
    "episode_length": 34,
    "policy_loss": -8705.335693359375,
    "value_loss": 1.9371138513088226,
    "entropy": 0.045685796067118645,
    "total_loss": -8703.416853826493
  },
  {
    "episode": 129,
    "avg_reward_per_step": 514.2083599791642,
    "episode_length": 39,
    "policy_loss": -7872.9715576171875,
    "value_loss": 1.6156345307826996,
    "entropy": 0.11201047711074352,
    "total_loss": -7871.400727277249
  },
  {
    "episode": 130,
    "avg_reward_per_step": 542.0304334915606,
    "episode_length": 37,
    "policy_loss": -8187.2144775390625,
    "value_loss": 1.7288675010204315,
    "entropy": 0.07503564096987247,
    "total_loss": -8185.51562429443
  },
  {
    "episode": 131,
    "avg_reward_per_step": 607.7941969074885,
    "episode_length": 33,
    "policy_loss": -8888.756591796875,
    "value_loss": 2.0192862153053284,
    "entropy": 0.03851120173931122,
    "total_loss": -8886.752710062265
  },
  {
    "episode": 132,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9086.14697265625,
    "value_loss": 2.108091652393341,
    "entropy": 0.05119208060204983,
    "total_loss": -9084.059357836097
  },
  {
    "episode": 133,
    "avg_reward_per_step": 572.488738962225,
    "episode_length": 35,
    "policy_loss": -8520.01416015625,
    "value_loss": 1.8586127161979675,
    "entropy": 0.07281024195253849,
    "total_loss": -8518.184671536834
  },
  {
    "episode": 134,
    "avg_reward_per_step": 607.7941969074885,
    "episode_length": 33,
    "policy_loss": -8894.554931640625,
    "value_loss": 2.0193090438842773,
    "entropy": 0.07008165679872036,
    "total_loss": -8892.56365525946
  },
  {
    "episode": 135,
    "avg_reward_per_step": 607.7941969074885,
    "episode_length": 33,
    "policy_loss": -8890.796630859375,
    "value_loss": 2.019296884536743,
    "entropy": 0.05531558860093355,
    "total_loss": -8888.799460210279
  },
  {
    "episode": 136,
    "avg_reward_per_step": 607.7941969074885,
    "episode_length": 33,
    "policy_loss": -8891.36669921875,
    "value_loss": 2.0192651748657227,
    "entropy": 0.051365965977311134,
    "total_loss": -8889.367980430276
  },
  {
    "episode": 137,
    "avg_reward_per_step": 557.1007233109821,
    "episode_length": 36,
    "policy_loss": -8354.513427734375,
    "value_loss": 1.7925560176372528,
    "entropy": 0.08244726620614529,
    "total_loss": -8352.75385062322
  },
  {
    "episode": 138,
    "avg_reward_per_step": 607.7941969074885,
    "episode_length": 33,
    "policy_loss": -8889.40380859375,
    "value_loss": 2.0192448496818542,
    "entropy": 0.04212808050215244,
    "total_loss": -8887.40141497627
  },
  {
    "episode": 139,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9087.228759765625,
    "value_loss": 2.108082413673401,
    "entropy": 0.04830765724182129,
    "total_loss": -9085.140000414849
  },
  {
    "episode": 140,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9082.524169921875,
    "value_loss": 2.1080657243728638,
    "entropy": 0.05242123547941446,
    "total_loss": -9080.437072691693
  },
  {
    "episode": 141,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9076.8857421875,
    "value_loss": 2.1080897450447083,
    "entropy": 0.049416483379900455,
    "total_loss": -9074.797419035807
  },
  {
    "episode": 142,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9077.802734375,
    "value_loss": 2.1081201434135437,
    "entropy": 0.039744156412780285,
    "total_loss": -9075.71051189415
  },
  {
    "episode": 143,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9075.371337890625,
    "value_loss": 2.108126163482666,
    "entropy": 0.027690752875059843,
    "total_loss": -9073.274288028293
  },
  {
    "episode": 144,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9073.489501953125,
    "value_loss": 2.1081209778785706,
    "entropy": 0.02041947701945901,
    "total_loss": -9071.389548766054
  },
  {
    "episode": 145,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9072.966064453125,
    "value_loss": 2.108111798763275,
    "entropy": 0.015724676894024014,
    "total_loss": -9070.86424252512
  },
  {
    "episode": 146,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9072.581298828125,
    "value_loss": 2.108098566532135,
    "entropy": 0.012252394575625658,
    "total_loss": -9070.478101219423
  },
  {
    "episode": 147,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9072.24267578125,
    "value_loss": 2.1080853939056396,
    "entropy": 0.009745973395183682,
    "total_loss": -9070.138488776702
  },
  {
    "episode": 148,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.996826171875,
    "value_loss": 2.1080729961395264,
    "entropy": 0.007997842039912939,
    "total_loss": -9069.891952312551
  },
  {
    "episode": 149,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.82470703125,
    "value_loss": 2.108060359954834,
    "entropy": 0.006740808836184442,
    "total_loss": -9069.71934299483
  },
  {
    "episode": 150,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.6904296875,
    "value_loss": 2.1080475449562073,
    "entropy": 0.005796073703095317,
    "total_loss": -9069.584700572024
  },
  {
    "episode": 151,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.5693359375,
    "value_loss": 2.1080352067947388,
    "entropy": 0.005054530804045498,
    "total_loss": -9069.463322543026
  },
  {
    "episode": 152,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.44873046875,
    "value_loss": 2.108021378517151,
    "entropy": 0.004458495648577809,
    "total_loss": -9069.342492488493
  },
  {
    "episode": 153,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.327392578125,
    "value_loss": 2.1080073714256287,
    "entropy": 0.003973038692492992,
    "total_loss": -9069.220974422176
  },
  {
    "episode": 154,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.199951171875,
    "value_loss": 2.1079925298690796,
    "entropy": 0.0035753677366301417,
    "total_loss": -9069.0933887891
  },
  {
    "episode": 155,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9071.0712890625,
    "value_loss": 2.1079784631729126,
    "entropy": 0.0032468371791765094,
    "total_loss": -9068.964609334198
  },
  {
    "episode": 156,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.93701171875,
    "value_loss": 2.10796320438385,
    "entropy": 0.0029715205309912562,
    "total_loss": -9068.830237122578
  },
  {
    "episode": 157,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.80029296875,
    "value_loss": 2.107947826385498,
    "entropy": 0.002736816997639835,
    "total_loss": -9068.693439869163
  },
  {
    "episode": 158,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.65869140625,
    "value_loss": 2.1079322695732117,
    "entropy": 0.002534250554163009,
    "total_loss": -9068.551772836898
  },
  {
    "episode": 159,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.510498046875,
    "value_loss": 2.1079160571098328,
    "entropy": 0.0023581592831760645,
    "total_loss": -9068.403525253478
  },
  {
    "episode": 160,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.357666015625,
    "value_loss": 2.107900083065033,
    "entropy": 0.002203591982834041,
    "total_loss": -9068.250647369354
  },
  {
    "episode": 161,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.189453125,
    "value_loss": 2.107878804206848,
    "entropy": 0.0020654445397667587,
    "total_loss": -9068.08240049861
  },
  {
    "episode": 162,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9070.0107421875,
    "value_loss": 2.107856333255768,
    "entropy": 0.0019410926615819335,
    "total_loss": -9067.903662291308
  },
  {
    "episode": 163,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9069.8203125,
    "value_loss": 2.107832908630371,
    "entropy": 0.001829349872423336,
    "total_loss": -9067.713211331318
  },
  {
    "episode": 164,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9069.62158203125,
    "value_loss": 2.1078080534934998,
    "entropy": 0.001728147268295288,
    "total_loss": -9067.514465236663
  },
  {
    "episode": 165,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9069.408447265625,
    "value_loss": 2.1077807545661926,
    "entropy": 0.0016361144953407347,
    "total_loss": -9067.301320956856
  },
  {
    "episode": 166,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9069.185546875,
    "value_loss": 2.107752740383148,
    "entropy": 0.00155205704504624,
    "total_loss": -9067.078414957436
  },
  {
    "episode": 167,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9068.951416015625,
    "value_loss": 2.10772305727005,
    "entropy": 0.0014731372357346117,
    "total_loss": -9066.84428221325
  },
  {
    "episode": 168,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9068.70556640625,
    "value_loss": 2.1076927185058594,
    "entropy": 0.0013999928487464786,
    "total_loss": -9066.598433684883
  },
  {
    "episode": 169,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9068.4482421875,
    "value_loss": 2.107660472393036,
    "entropy": 0.0013326875632628798,
    "total_loss": -9066.341114790132
  },
  {
    "episode": 170,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9068.181884765625,
    "value_loss": 2.1076274514198303,
    "entropy": 0.0012708011199720204,
    "total_loss": -9066.074765634654
  },
  {
    "episode": 171,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9067.90625,
    "value_loss": 2.107593834400177,
    "entropy": 0.0012137541198171675,
    "total_loss": -9065.799141667248
  },
  {
    "episode": 172,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9067.620361328125,
    "value_loss": 2.107558310031891,
    "entropy": 0.0011610235669650137,
    "total_loss": -9065.51326742752
  },
  {
    "episode": 173,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9067.324462890625,
    "value_loss": 2.1075222492218018,
    "entropy": 0.0011121704301331192,
    "total_loss": -9065.217385509575
  },
  {
    "episode": 174,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9067.02001953125,
    "value_loss": 2.107485294342041,
    "entropy": 0.0010667351598385721,
    "total_loss": -9064.912960930971
  },
  {
    "episode": 175,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9066.706787109375,
    "value_loss": 2.1074461340904236,
    "entropy": 0.0010244393488392234,
    "total_loss": -9064.599750751024
  },
  {
    "episode": 176,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9066.388916015625,
    "value_loss": 2.107408046722412,
    "entropy": 0.0009849229390965775,
    "total_loss": -9064.281901938079
  },
  {
    "episode": 177,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9066.0595703125,
    "value_loss": 2.107367694377899,
    "entropy": 0.0009479515429120511,
    "total_loss": -9063.95258179874
  },
  {
    "episode": 178,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9065.721923828125,
    "value_loss": 2.1073261499404907,
    "entropy": 0.0009133298590313643,
    "total_loss": -9063.614963010128
  },
  {
    "episode": 179,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9065.380615234375,
    "value_loss": 2.1072859168052673,
    "entropy": 0.000880791645613499,
    "total_loss": -9063.273681634228
  },
  {
    "episode": 180,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9065.0302734375,
    "value_loss": 2.1072428822517395,
    "entropy": 0.000850118332891725,
    "total_loss": -9062.92337060258
  },
  {
    "episode": 181,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9064.67236328125,
    "value_loss": 2.107199788093567,
    "entropy": 0.0008211380481952801,
    "total_loss": -9062.565491948375
  },
  {
    "episode": 182,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9064.310302734375,
    "value_loss": 2.1071572303771973,
    "entropy": 0.0007937784248497337,
    "total_loss": -9062.203463015368
  },
  {
    "episode": 183,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9063.93896484375,
    "value_loss": 2.107111871242523,
    "entropy": 0.000767849269323051,
    "total_loss": -9061.832160112215
  },
  {
    "episode": 184,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9063.559814453125,
    "value_loss": 2.1070669889450073,
    "entropy": 0.0007432072306983173,
    "total_loss": -9061.453044747072
  },
  {
    "episode": 185,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9063.177001953125,
    "value_loss": 2.107021927833557,
    "entropy": 0.0007197293598437682,
    "total_loss": -9061.070267917035
  },
  {
    "episode": 186,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9062.7861328125,
    "value_loss": 2.1069750785827637,
    "entropy": 0.0006973763520363718,
    "total_loss": -9060.679436684459
  },
  {
    "episode": 187,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9062.385986328125,
    "value_loss": 2.106926381587982,
    "entropy": 0.0006761232507415116,
    "total_loss": -9060.279330395837
  },
  {
    "episode": 188,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9061.97705078125,
    "value_loss": 2.1068769693374634,
    "entropy": 0.0006558071763720363,
    "total_loss": -9059.870436134783
  },
  {
    "episode": 189,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9061.55810546875,
    "value_loss": 2.1068260073661804,
    "entropy": 0.0006363974243868142,
    "total_loss": -9059.451534020354
  },
  {
    "episode": 190,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9061.131103515625,
    "value_loss": 2.106773793697357,
    "entropy": 0.0006178088515298441,
    "total_loss": -9059.024576845468
  },
  {
    "episode": 191,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9060.697509765625,
    "value_loss": 2.1067219376564026,
    "entropy": 0.0006000155990477651,
    "total_loss": -9058.591027834209
  },
  {
    "episode": 192,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9060.2578125,
    "value_loss": 2.1066681146621704,
    "entropy": 0.0005829517758684233,
    "total_loss": -9058.151377566048
  },
  {
    "episode": 193,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9059.81201171875,
    "value_loss": 2.1066139936447144,
    "entropy": 0.0005666235229000449,
    "total_loss": -9057.705624374514
  },
  {
    "episode": 194,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9059.357666015625,
    "value_loss": 2.1065595746040344,
    "entropy": 0.0005509577022166923,
    "total_loss": -9057.251326824102
  },
  {
    "episode": 195,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9058.899658203125,
    "value_loss": 2.1065043210983276,
    "entropy": 0.0005359352653613314,
    "total_loss": -9056.793368256132
  },
  {
    "episode": 196,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9058.434326171875,
    "value_loss": 2.1064484119415283,
    "entropy": 0.0005215032724663615,
    "total_loss": -9056.328086361242
  },
  {
    "episode": 197,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9057.962890625,
    "value_loss": 2.1063912510871887,
    "entropy": 0.0005076609086245298,
    "total_loss": -9055.856702438276
  },
  {
    "episode": 198,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9057.4873046875,
    "value_loss": 2.1063345074653625,
    "entropy": 0.0004943555541103706,
    "total_loss": -9055.381167922256
  },
  {
    "episode": 199,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9057.0048828125,
    "value_loss": 2.1062763929367065,
    "entropy": 0.0004815565698663704,
    "total_loss": -9054.898799042192
  },
  {
    "episode": 200,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9056.516845703125,
    "value_loss": 2.106217384338379,
    "entropy": 0.0004692391157732345,
    "total_loss": -9054.410816014433
  },
  {
    "episode": 201,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9056.02587890625,
    "value_loss": 2.106159031391144,
    "entropy": 0.00045739727647742257,
    "total_loss": -9053.91990283377
  },
  {
    "episode": 202,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9055.52490234375,
    "value_loss": 2.106098473072052,
    "entropy": 0.00044600765977520496,
    "total_loss": -9053.418982273743
  },
  {
    "episode": 203,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9055.020751953125,
    "value_loss": 2.1060378551483154,
    "entropy": 0.00043504310451680794,
    "total_loss": -9052.914888115218
  },
  {
    "episode": 204,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9054.513671875,
    "value_loss": 2.1059776544570923,
    "entropy": 0.00042447776650078595,
    "total_loss": -9052.40786401165
  },
  {
    "episode": 205,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9053.99951171875,
    "value_loss": 2.1059154868125916,
    "entropy": 0.0004142994584981352,
    "total_loss": -9051.89376195172
  },
  {
    "episode": 206,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9053.4814453125,
    "value_loss": 2.1058537364006042,
    "entropy": 0.0004044974048156291,
    "total_loss": -9051.375753375061
  },
  {
    "episode": 207,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9052.95703125,
    "value_loss": 2.105790674686432,
    "entropy": 0.0003950454483856447,
    "total_loss": -9050.851398593493
  },
  {
    "episode": 208,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9052.428955078125,
    "value_loss": 2.105727732181549,
    "entropy": 0.00038594183570239693,
    "total_loss": -9050.323381722677
  },
  {
    "episode": 209,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9051.895751953125,
    "value_loss": 2.1056638956069946,
    "entropy": 0.0003771630290430039,
    "total_loss": -9049.79023892273
  },
  {
    "episode": 210,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9051.35546875,
    "value_loss": 2.1055997014045715,
    "entropy": 0.00036868818278890103,
    "total_loss": -9049.250016523869
  },
  {
    "episode": 211,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9050.812744140625,
    "value_loss": 2.1055344939231873,
    "entropy": 0.0003605095116654411,
    "total_loss": -9048.707353850506
  },
  {
    "episode": 212,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9050.26416015625,
    "value_loss": 2.1054691672325134,
    "entropy": 0.00035261811717646196,
    "total_loss": -9048.158832036264
  },
  {
    "episode": 213,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9049.711181640625,
    "value_loss": 2.105402648448944,
    "entropy": 0.0003450114600127563,
    "total_loss": -9047.60591699676
  },
  {
    "episode": 214,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9049.150390625,
    "value_loss": 2.105334997177124,
    "entropy": 0.0003376607273821719,
    "total_loss": -9047.045190692113
  },
  {
    "episode": 215,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9048.587646484375,
    "value_loss": 2.1052682995796204,
    "entropy": 0.00033055363019229844,
    "total_loss": -9046.482510406247
  },
  {
    "episode": 216,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9048.0166015625,
    "value_loss": 2.105199873447418,
    "entropy": 0.00032368644315283746,
    "total_loss": -9045.91153116363
  },
  {
    "episode": 217,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9047.444091796875,
    "value_loss": 2.1051313281059265,
    "entropy": 0.0003170443305862136,
    "total_loss": -9045.339087286502
  },
  {
    "episode": 218,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9046.8603515625,
    "value_loss": 2.1050614714622498,
    "entropy": 0.00031062254129210487,
    "total_loss": -9044.755414340054
  },
  {
    "episode": 219,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9046.273681640625,
    "value_loss": 2.1049908995628357,
    "entropy": 0.00030441016861004755,
    "total_loss": -9044.16881250513
  },
  {
    "episode": 220,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9045.681396484375,
    "value_loss": 2.104919970035553,
    "entropy": 0.00029839495255146176,
    "total_loss": -9043.57659587232
  },
  {
    "episode": 221,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9045.081787109375,
    "value_loss": 2.104848325252533,
    "entropy": 0.0002925700609921478,
    "total_loss": -9042.977055812147
  },
  {
    "episode": 222,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9044.475830078125,
    "value_loss": 2.1047754883766174,
    "entropy": 0.00028692674095509574,
    "total_loss": -9042.371169360445
  },
  {
    "episode": 223,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9043.8642578125,
    "value_loss": 2.1047028303146362,
    "entropy": 0.00028146303520770743,
    "total_loss": -9041.7596675674
  },
  {
    "episode": 224,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9043.247314453125,
    "value_loss": 2.1046287417411804,
    "entropy": 0.000276173472229857,
    "total_loss": -9041.142796180773
  },
  {
    "episode": 225,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9042.621826171875,
    "value_loss": 2.1045530438423157,
    "entropy": 0.00027104155742563307,
    "total_loss": -9040.517381544656
  },
  {
    "episode": 226,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9041.99169921875,
    "value_loss": 2.1044785380363464,
    "entropy": 0.0002660536702023819,
    "total_loss": -9039.887327102182
  },
  {
    "episode": 227,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9041.35498046875,
    "value_loss": 2.1044015288352966,
    "entropy": 0.0002612213502288796,
    "total_loss": -9039.250683428454
  },
  {
    "episode": 228,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9040.711669921875,
    "value_loss": 2.1043249368667603,
    "entropy": 0.0002565343747846782,
    "total_loss": -9038.607447598759
  },
  {
    "episode": 229,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9040.06103515625,
    "value_loss": 2.1042462587356567,
    "entropy": 0.0002519999325159006,
    "total_loss": -9037.956889697487
  },
  {
    "episode": 230,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9039.400146484375,
    "value_loss": 2.1041662096977234,
    "entropy": 0.00024759754160186276,
    "total_loss": -9037.296079313694
  },
  {
    "episode": 231,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9038.728759765625,
    "value_loss": 2.1040847301483154,
    "entropy": 0.00024331882741535082,
    "total_loss": -9036.624772363008
  },
  {
    "episode": 232,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9038.04931640625,
    "value_loss": 2.104002833366394,
    "entropy": 0.00023915678684716113,
    "total_loss": -9035.945409235599
  },
  {
    "episode": 233,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9037.363037109375,
    "value_loss": 2.1039199233055115,
    "entropy": 0.00023511411927756853,
    "total_loss": -9035.259211231718
  },
  {
    "episode": 234,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9036.66650390625,
    "value_loss": 2.1038355231285095,
    "entropy": 0.00023118046374293044,
    "total_loss": -9034.562760855308
  },
  {
    "episode": 235,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9035.96337890625,
    "value_loss": 2.1037506461143494,
    "entropy": 0.0002273558457090985,
    "total_loss": -9033.859719202474
  },
  {
    "episode": 236,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9035.25146484375,
    "value_loss": 2.103664815425873,
    "entropy": 0.00022363281095749699,
    "total_loss": -9033.147889481448
  },
  {
    "episode": 237,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9034.53173828125,
    "value_loss": 2.1035783290863037,
    "entropy": 0.00022000932585797273,
    "total_loss": -9032.428247955893
  },
  {
    "episode": 238,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9033.80419921875,
    "value_loss": 2.1034903526306152,
    "entropy": 0.00021649093105224892,
    "total_loss": -9031.700795462491
  },
  {
    "episode": 239,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9033.072509765625,
    "value_loss": 2.1034032106399536,
    "entropy": 0.00021304409892763942,
    "total_loss": -9030.969191772625
  },
  {
    "episode": 240,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9032.326904296875,
    "value_loss": 2.103312313556671,
    "entropy": 0.00020968973694834858,
    "total_loss": -9030.223675859213
  },
  {
    "episode": 241,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9031.57470703125,
    "value_loss": 2.10322105884552,
    "entropy": 0.00020642674644477665,
    "total_loss": -9029.471568543104
  },
  {
    "episode": 242,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9030.81494140625,
    "value_loss": 2.103129208087921,
    "entropy": 0.00020324729121057317,
    "total_loss": -9028.711893497079
  },
  {
    "episode": 243,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9030.047119140625,
    "value_loss": 2.1030367612838745,
    "entropy": 0.00020013937682961114,
    "total_loss": -9027.944162435091
  },
  {
    "episode": 244,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9029.272705078125,
    "value_loss": 2.1029428839683533,
    "entropy": 0.00019711278946488164,
    "total_loss": -9027.169841039273
  },
  {
    "episode": 245,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9028.488037109375,
    "value_loss": 2.1028483510017395,
    "entropy": 0.00019416473514866084,
    "total_loss": -9026.385266424268
  },
  {
    "episode": 246,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9027.697021484375,
    "value_loss": 2.1027532815933228,
    "entropy": 0.00019128172061755322,
    "total_loss": -9025.59434471547
  },
  {
    "episode": 247,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9026.897216796875,
    "value_loss": 2.1026562452316284,
    "entropy": 0.00018847184037440456,
    "total_loss": -9024.79463594038
  },
  {
    "episode": 248,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9026.08740234375,
    "value_loss": 2.102558434009552,
    "entropy": 0.00018572651970316656,
    "total_loss": -9023.984918200349
  },
  {
    "episode": 249,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9025.270751953125,
    "value_loss": 2.1024600863456726,
    "entropy": 0.00018304753029951826,
    "total_loss": -9023.168365085792
  },
  {
    "episode": 250,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9024.445068359375,
    "value_loss": 2.1023606061935425,
    "entropy": 0.00018042676310869865,
    "total_loss": -9022.342779923887
  },
  {
    "episode": 251,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9023.610595703125,
    "value_loss": 2.102259874343872,
    "entropy": 0.0001778811310941819,
    "total_loss": -9021.508406981233
  },
  {
    "episode": 252,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9022.765625,
    "value_loss": 2.102157473564148,
    "entropy": 0.0001753816322889179,
    "total_loss": -9020.66353767909
  },
  {
    "episode": 253,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9021.91455078125,
    "value_loss": 2.102054715156555,
    "entropy": 0.00017293935525231063,
    "total_loss": -9019.812565241835
  },
  {
    "episode": 254,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9021.0546875,
    "value_loss": 2.101951003074646,
    "entropy": 0.0001705557770037558,
    "total_loss": -9018.952804719236
  },
  {
    "episode": 255,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9020.183349609375,
    "value_loss": 2.1018455028533936,
    "entropy": 0.00016822765974211507,
    "total_loss": -9018.081571397586
  },
  {
    "episode": 256,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9019.30322265625,
    "value_loss": 2.101739525794983,
    "entropy": 0.00016595455963397399,
    "total_loss": -9017.20154951228
  },
  {
    "episode": 257,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9018.41357421875,
    "value_loss": 2.101631999015808,
    "entropy": 0.00016373247490264475,
    "total_loss": -9016.312007712724
  },
  {
    "episode": 258,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9017.517333984375,
    "value_loss": 2.1015239357948303,
    "entropy": 0.00016155155753949657,
    "total_loss": -9015.415874669203
  },
  {
    "episode": 259,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9016.607666015625,
    "value_loss": 2.101413071155548,
    "entropy": 0.0001594159984961152,
    "total_loss": -9014.50631671087
  },
  {
    "episode": 260,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9015.6904296875,
    "value_loss": 2.1013017296791077,
    "entropy": 0.00015732902829768136,
    "total_loss": -9013.589190889432
  },
  {
    "episode": 261,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9014.763671875,
    "value_loss": 2.1011893153190613,
    "entropy": 0.00015529189477092586,
    "total_loss": -9012.66254467644
  },
  {
    "episode": 262,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9013.826904296875,
    "value_loss": 2.1010759472846985,
    "entropy": 0.0001532920177851338,
    "total_loss": -9011.725889666397
  },
  {
    "episode": 263,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9012.879638671875,
    "value_loss": 2.1009603142738342,
    "entropy": 0.00015133605484152213,
    "total_loss": -9010.778738892022
  },
  {
    "episode": 264,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9011.92578125,
    "value_loss": 2.1008445620536804,
    "entropy": 0.00014941416520741768,
    "total_loss": -9009.824996453612
  },
  {
    "episode": 265,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9010.959228515625,
    "value_loss": 2.1007264256477356,
    "entropy": 0.0001475287863286212,
    "total_loss": -9008.858561101491
  },
  {
    "episode": 266,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9009.985595703125,
    "value_loss": 2.1006084084510803,
    "entropy": 0.00014568523329216987,
    "total_loss": -9007.885045568768
  },
  {
    "episode": 267,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9009.005126953125,
    "value_loss": 2.1004894375801086,
    "entropy": 0.00014388330600922927,
    "total_loss": -9006.904695068868
  },
  {
    "episode": 268,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9008.01171875,
    "value_loss": 2.100368916988373,
    "entropy": 0.00014211595407687128,
    "total_loss": -9005.911406679394
  },
  {
    "episode": 269,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9007.013427734375,
    "value_loss": 2.1002476811408997,
    "entropy": 0.00014038115841685794,
    "total_loss": -9004.913236205697
  },
  {
    "episode": 270,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9006.00537109375,
    "value_loss": 2.100124418735504,
    "entropy": 0.00013867933012079448,
    "total_loss": -9003.905302146746
  },
  {
    "episode": 271,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9004.986328125,
    "value_loss": 2.1000006198883057,
    "entropy": 0.00013701518764719367,
    "total_loss": -9002.886382311186
  },
  {
    "episode": 272,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9003.9609375,
    "value_loss": 2.099875807762146,
    "entropy": 0.00013538120765588246,
    "total_loss": -9001.86111584472
  },
  {
    "episode": 273,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9002.9267578125,
    "value_loss": 2.0997501015663147,
    "entropy": 0.00013378332369029522,
    "total_loss": -9000.827061224263
  },
  {
    "episode": 274,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9001.8828125,
    "value_loss": 2.0996225476264954,
    "entropy": 0.0001322179195994977,
    "total_loss": -8999.783242839541
  },
  {
    "episode": 275,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -9000.82958984375,
    "value_loss": 2.099494457244873,
    "entropy": 0.00013067106192465872,
    "total_loss": -8998.73014765493
  },
  {
    "episode": 276,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8999.769775390625,
    "value_loss": 2.099365711212158,
    "entropy": 0.00012915635670651682,
    "total_loss": -8997.670461341955
  },
  {
    "episode": 277,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8998.699951171875,
    "value_loss": 2.0992351174354553,
    "entropy": 0.00012767071893904358,
    "total_loss": -8996.600767122727
  },
  {
    "episode": 278,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8997.62109375,
    "value_loss": 2.099103808403015,
    "entropy": 0.00012621842688531615,
    "total_loss": -8995.522040428968
  },
  {
    "episode": 279,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8996.53564453125,
    "value_loss": 2.0989717841148376,
    "entropy": 0.0001247780237463303,
    "total_loss": -8994.436722658345
  },
  {
    "episode": 280,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8995.439453125,
    "value_loss": 2.0988372564315796,
    "entropy": 0.00012337948282947764,
    "total_loss": -8993.340665220361
  },
  {
    "episode": 281,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8994.3349609375,
    "value_loss": 2.0987029671669006,
    "entropy": 0.00012199329648865387,
    "total_loss": -8992.236306767652
  },
  {
    "episode": 282,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8993.223388671875,
    "value_loss": 2.0985677242279053,
    "entropy": 0.00012064169641234912,
    "total_loss": -8991.124869204326
  },
  {
    "episode": 283,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8992.10302734375,
    "value_loss": 2.0984301567077637,
    "entropy": 0.00011932050256291404,
    "total_loss": -8990.004644915243
  },
  {
    "episode": 284,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8990.97119140625,
    "value_loss": 2.098292052745819,
    "entropy": 0.00011800665197370108,
    "total_loss": -8988.872946556165
  },
  {
    "episode": 285,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8989.834228515625,
    "value_loss": 2.0981533527374268,
    "entropy": 0.0001167170048574917,
    "total_loss": -8987.73612184969
  },
  {
    "episode": 286,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8988.687744140625,
    "value_loss": 2.0980125665664673,
    "entropy": 0.00011545008237590082,
    "total_loss": -8986.589777754092
  },
  {
    "episode": 287,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8987.532470703125,
    "value_loss": 2.0978724360466003,
    "entropy": 0.00011420650662330445,
    "total_loss": -8985.43464394968
  },
  {
    "episode": 288,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8986.369140625,
    "value_loss": 2.097729802131653,
    "entropy": 0.0001129752563429065,
    "total_loss": -8984.271456012972
  },
  {
    "episode": 289,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8985.19677734375,
    "value_loss": 2.0975860357284546,
    "entropy": 0.00011176515181432478,
    "total_loss": -8983.099236014083
  },
  {
    "episode": 290,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8984.017578125,
    "value_loss": 2.0974430441856384,
    "entropy": 0.00011059162352466956,
    "total_loss": -8981.920179317463
  },
  {
    "episode": 291,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8982.826171875,
    "value_loss": 2.0972965955734253,
    "entropy": 0.0001094322378776269,
    "total_loss": -8980.728919052322
  },
  {
    "episode": 292,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8981.6279296875,
    "value_loss": 2.0971495509147644,
    "entropy": 0.00010829838356585242,
    "total_loss": -8979.530823455938
  },
  {
    "episode": 293,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8980.421875,
    "value_loss": 2.097002387046814,
    "entropy": 0.0001071707174560288,
    "total_loss": -8978.32491548124
  },
  {
    "episode": 294,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8979.207763671875,
    "value_loss": 2.0968536138534546,
    "entropy": 0.00010606944852042943,
    "total_loss": -8977.1109524858
  },
  {
    "episode": 295,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8977.98388671875,
    "value_loss": 2.0967032313346863,
    "entropy": 0.00010497272160137072,
    "total_loss": -8975.887225476505
  },
  {
    "episode": 296,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8976.7529296875,
    "value_loss": 2.0965532660484314,
    "entropy": 0.00010389956696599256,
    "total_loss": -8974.656417981278
  },
  {
    "episode": 297,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8975.51318359375,
    "value_loss": 2.096401035785675,
    "entropy": 0.0001028443130053347,
    "total_loss": -8973.41682369569
  },
  {
    "episode": 298,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8974.265625,
    "value_loss": 2.0962482690811157,
    "entropy": 0.00010180805111303926,
    "total_loss": -8972.169417454139
  },
  {
    "episode": 299,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8973.0068359375,
    "value_loss": 2.096093773841858,
    "entropy": 0.00010078776722366456,
    "total_loss": -8970.910782478764
  },
  {
    "episode": 300,
    "avg_reward_per_step": 626.6418180111721,
    "episode_length": 32,
    "policy_loss": -8971.743408203125,
    "value_loss": 2.095938563346863,
    "entropy": 9.978182242775802e-05,
    "total_loss": -8969.647509552507
  }
]