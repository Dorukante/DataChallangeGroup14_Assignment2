[
  {
    "episode": 1,
    "avg_reward_per_step": 17.985936236843436,
    "episode_length": 1000,
    "policy_loss": -309.3986511230469,
    "value_loss": 0.5131320208311081,
    "entropy": 1.3587729334831238,
    "total_loss": -309.429028275609
  },
  {
    "episode": 2,
    "avg_reward_per_step": 59.96523900087697,
    "episode_length": 316,
    "policy_loss": -1023.3224945068359,
    "value_loss": 0.5496142208576202,
    "entropy": 1.3554627895355225,
    "total_loss": -1023.3150654017925
  },
  {
    "episode": 3,
    "avg_reward_per_step": 73.91675117475727,
    "episode_length": 262,
    "policy_loss": -1261.6495971679688,
    "value_loss": 0.5642263889312744,
    "entropy": 1.3314329385757446,
    "total_loss": -1261.6179439544678
  },
  {
    "episode": 4,
    "avg_reward_per_step": 12.069600248586667,
    "episode_length": 1420,
    "policy_loss": -204.09458541870117,
    "value_loss": 0.5082441568374634,
    "entropy": 1.298060655593872,
    "total_loss": -204.10556552410125
  },
  {
    "episode": 5,
    "avg_reward_per_step": 4.992668096303555,
    "episode_length": 2742,
    "policy_loss": -84.81020736694336,
    "value_loss": 0.5026149153709412,
    "entropy": 1.267410784959793,
    "total_loss": -84.81455676555633
  },
  {
    "episode": 6,
    "avg_reward_per_step": -1.891568861294023,
    "episode_length": 3000,
    "policy_loss": 31.762348651885986,
    "value_loss": 1.698421448469162,
    "entropy": 1.238148421049118,
    "total_loss": 32.9655107319355
  },
  {
    "episode": 7,
    "avg_reward_per_step": 6.586299214187033,
    "episode_length": 2345,
    "policy_loss": -111.2302017211914,
    "value_loss": 0.5039625912904739,
    "entropy": 1.2199440896511078,
    "total_loss": -111.21421676576138
  },
  {
    "episode": 8,
    "avg_reward_per_step": -1.6152961407580322,
    "episode_length": 3000,
    "policy_loss": 26.970612049102783,
    "value_loss": 1.826909750699997,
    "entropy": 1.2124253511428833,
    "total_loss": 28.312551659345626
  },
  {
    "episode": 9,
    "avg_reward_per_step": 11.097975433883517,
    "episode_length": 1513,
    "policy_loss": -187.44287490844727,
    "value_loss": 0.5074176639318466,
    "entropy": 1.1999599635601044,
    "total_loss": -187.41544122993946
  },
  {
    "episode": 10,
    "avg_reward_per_step": 14.187180403793228,
    "episode_length": 1235,
    "policy_loss": -239.82728576660156,
    "value_loss": 0.509957417845726,
    "entropy": 1.1741012930870056,
    "total_loss": -239.78696886599064
  },
  {
    "episode": 11,
    "avg_reward_per_step": 31.935213561744636,
    "episode_length": 598,
    "policy_loss": -542.1180114746094,
    "value_loss": 0.5254282653331757,
    "entropy": 1.1614850759506226,
    "total_loss": -542.0571772396564
  },
  {
    "episode": 12,
    "avg_reward_per_step": 17.962131421422754,
    "episode_length": 1028,
    "policy_loss": -305.1896209716797,
    "value_loss": 0.5134172141551971,
    "entropy": 1.160688042640686,
    "total_loss": -305.1404789745808
  },
  {
    "episode": 13,
    "avg_reward_per_step": 59.810270251942455,
    "episode_length": 328,
    "policy_loss": -1016.2436065673828,
    "value_loss": 0.5513673722743988,
    "entropy": 1.1604480147361755,
    "total_loss": -1016.1564184010028
  },
  {
    "episode": 14,
    "avg_reward_per_step": 51.24482696788635,
    "episode_length": 378,
    "policy_loss": -868.9117736816406,
    "value_loss": 0.542786568403244,
    "entropy": 1.1607212722301483,
    "total_loss": -868.8332756221295
  },
  {
    "episode": 15,
    "avg_reward_per_step": 55.68994605069504,
    "episode_length": 338,
    "policy_loss": -947.1090240478516,
    "value_loss": 0.5454232841730118,
    "entropy": 1.1453595161437988,
    "total_loss": -947.0217445701361
  },
  {
    "episode": 16,
    "avg_reward_per_step": 61.96077274772608,
    "episode_length": 298,
    "policy_loss": -1053.942626953125,
    "value_loss": 0.5498660206794739,
    "entropy": 1.0809989273548126,
    "total_loss": -1053.8251605033875
  },
  {
    "episode": 17,
    "avg_reward_per_step": 12.579851445904675,
    "episode_length": 1095,
    "policy_loss": -210.87071990966797,
    "value_loss": 0.5067163705825806,
    "entropy": 1.0150709003210068,
    "total_loss": -210.7700318992138
  },
  {
    "episode": 18,
    "avg_reward_per_step": 20.349600134344907,
    "episode_length": 798,
    "policy_loss": -345.8667449951172,
    "value_loss": 0.5132252275943756,
    "entropy": 0.9693795591592789,
    "total_loss": -345.74127159118655
  },
  {
    "episode": 19,
    "avg_reward_per_step": -8.131922715226859,
    "episode_length": 3000,
    "policy_loss": 136.41833877563477,
    "value_loss": 2.2725850343704224,
    "entropy": 0.8960005044937134,
    "total_loss": 138.3325236082077
  },
  {
    "episode": 20,
    "avg_reward_per_step": 28.806252673934083,
    "episode_length": 581,
    "policy_loss": -486.3721389770508,
    "value_loss": 0.5196181833744049,
    "entropy": 0.8791578710079193,
    "total_loss": -486.20418394207957
  },
  {
    "episode": 21,
    "avg_reward_per_step": -1.6386790767807886,
    "episode_length": 2410,
    "policy_loss": 27.21723747253418,
    "value_loss": 0.5000357925891876,
    "entropy": 0.8455897718667984,
    "total_loss": 27.37903735637665
  },
  {
    "episode": 22,
    "avg_reward_per_step": -0.8489947122577345,
    "episode_length": 2315,
    "policy_loss": 13.656291723251343,
    "value_loss": 0.4998430162668228,
    "entropy": 0.8528366088867188,
    "total_loss": 13.815000095963478
  },
  {
    "episode": 23,
    "avg_reward_per_step": -8.34344751866792,
    "episode_length": 3000,
    "policy_loss": 139.66768264770508,
    "value_loss": 2.4957387447357178,
    "entropy": 0.8797722011804581,
    "total_loss": 141.8115125119686
  },
  {
    "episode": 24,
    "avg_reward_per_step": 25.496854403682864,
    "episode_length": 612,
    "policy_loss": -431.8129196166992,
    "value_loss": 0.5159430354833603,
    "entropy": 0.9113022536039352,
    "total_loss": -431.6614974826574
  },
  {
    "episode": 25,
    "avg_reward_per_step": 3.8988358785267483,
    "episode_length": 1879,
    "policy_loss": -69.29898834228516,
    "value_loss": 0.5009276568889618,
    "entropy": 0.9509452730417252,
    "total_loss": -69.17843879461289
  },
  {
    "episode": 26,
    "avg_reward_per_step": 22.407380687000963,
    "episode_length": 676,
    "policy_loss": -377.1310043334961,
    "value_loss": 0.5136100053787231,
    "entropy": 0.9698397666215897,
    "total_loss": -377.005330234766
  },
  {
    "episode": 27,
    "avg_reward_per_step": 21.407232114765137,
    "episode_length": 779,
    "policy_loss": -363.96702575683594,
    "value_loss": 0.5143676549196243,
    "entropy": 1.011708527803421,
    "total_loss": -363.8573415130377
  },
  {
    "episode": 28,
    "avg_reward_per_step": 22.403998206731345,
    "episode_length": 739,
    "policy_loss": -377.68357849121094,
    "value_loss": 0.5149211138486862,
    "entropy": 0.9960083961486816,
    "total_loss": -377.5670607358217
  },
  {
    "episode": 29,
    "avg_reward_per_step": 26.436327567448195,
    "episode_length": 692,
    "policy_loss": -451.35945892333984,
    "value_loss": 0.519902378320694,
    "entropy": 0.9886180609464645,
    "total_loss": -451.23500376939774
  },
  {
    "episode": 30,
    "avg_reward_per_step": 15.003500274524258,
    "episode_length": 1126,
    "policy_loss": -253.62177276611328,
    "value_loss": 0.5101497024297714,
    "entropy": 0.9430403262376785,
    "total_loss": -253.48883919417858
  },
  {
    "episode": 31,
    "avg_reward_per_step": 40.23828430749098,
    "episode_length": 462,
    "policy_loss": -682.1586303710938,
    "value_loss": 0.5315398126840591,
    "entropy": 0.9127011448144913,
    "total_loss": -681.9921710163355
  },
  {
    "episode": 32,
    "avg_reward_per_step": 53.57914693037478,
    "episode_length": 361,
    "policy_loss": -913.1130828857422,
    "value_loss": 0.5449091345071793,
    "entropy": 0.8708318173885345,
    "total_loss": -912.9165064781904
  },
  {
    "episode": 33,
    "avg_reward_per_step": 8.70378726425952,
    "episode_length": 2001,
    "policy_loss": -145.4840431213379,
    "value_loss": 0.5060584843158722,
    "entropy": 0.7526946663856506,
    "total_loss": -145.27906250357628
  },
  {
    "episode": 34,
    "avg_reward_per_step": -1.1902558883915828,
    "episode_length": 3000,
    "policy_loss": 19.54265308380127,
    "value_loss": 1.3149722218513489,
    "entropy": 0.6847119331359863,
    "total_loss": 20.583740532398224
  },
  {
    "episode": 35,
    "avg_reward_per_step": -0.9458064787119744,
    "episode_length": 3000,
    "policy_loss": 15.440134286880493,
    "value_loss": 1.3952246606349945,
    "entropy": 0.6374690234661102,
    "total_loss": 16.580371338129044
  },
  {
    "episode": 36,
    "avg_reward_per_step": -1.0178896263920367,
    "episode_length": 3000,
    "policy_loss": 16.55263376235962,
    "value_loss": 1.237504005432129,
    "entropy": 0.6268715113401413,
    "total_loss": 17.53938916325569
  },
  {
    "episode": 37,
    "avg_reward_per_step": -1.0900788991128978,
    "episode_length": 3000,
    "policy_loss": 17.588701725006104,
    "value_loss": 1.1631207168102264,
    "entropy": 0.6216038912534714,
    "total_loss": 18.50318088531494
  },
  {
    "episode": 38,
    "avg_reward_per_step": -0.850314263625295,
    "episode_length": 3000,
    "policy_loss": 13.516434669494629,
    "value_loss": 1.3870921432971954,
    "entropy": 0.5811553746461868,
    "total_loss": 14.67106466293335
  },
  {
    "episode": 39,
    "avg_reward_per_step": -1.0115169889291544,
    "episode_length": 3000,
    "policy_loss": 15.96690821647644,
    "value_loss": 1.2270234525203705,
    "entropy": 0.5923678874969482,
    "total_loss": 16.95698451399803
  },
  {
    "episode": 40,
    "avg_reward_per_step": -0.9700122098270384,
    "episode_length": 3000,
    "policy_loss": 15.208451509475708,
    "value_loss": 1.2852363884449005,
    "entropy": 0.565682977437973,
    "total_loss": 16.26741470694542
  },
  {
    "episode": 41,
    "avg_reward_per_step": 17.777290821480364,
    "episode_length": 1060,
    "policy_loss": -300.6885681152344,
    "value_loss": 0.5137369632720947,
    "entropy": 0.6035441309213638,
    "total_loss": -300.41624880433085
  },
  {
    "episode": 42,
    "avg_reward_per_step": -0.796857187222123,
    "episode_length": 3000,
    "policy_loss": 12.092048645019531,
    "value_loss": 1.241726964712143,
    "entropy": 0.5546278655529022,
    "total_loss": 13.111924463510514
  },
  {
    "episode": 43,
    "avg_reward_per_step": -1.1145227728093274,
    "episode_length": 3000,
    "policy_loss": 17.23610496520996,
    "value_loss": 1.247750073671341,
    "entropy": 0.6001348197460175,
    "total_loss": 18.243801110982893
  },
  {
    "episode": 44,
    "avg_reward_per_step": -0.9897442079412874,
    "episode_length": 3000,
    "policy_loss": 14.977748155593872,
    "value_loss": 1.195743888616562,
    "entropy": 0.5815644711256027,
    "total_loss": 15.940866255760193
  },
  {
    "episode": 45,
    "avg_reward_per_step": -0.8965904456729957,
    "episode_length": 3000,
    "policy_loss": 13.272457122802734,
    "value_loss": 1.3502666056156158,
    "entropy": 0.5402331054210663,
    "total_loss": 14.406630486249924
  },
  {
    "episode": 46,
    "avg_reward_per_step": -0.8228871099326889,
    "episode_length": 3000,
    "policy_loss": 11.956462621688843,
    "value_loss": 1.2734032273292542,
    "entropy": 0.53068807721138,
    "total_loss": 13.017590618133545
  },
  {
    "episode": 47,
    "avg_reward_per_step": -0.9218205472190683,
    "episode_length": 3000,
    "policy_loss": 13.42746353149414,
    "value_loss": 1.1798932552337646,
    "entropy": 0.5596279948949814,
    "total_loss": 14.383505588769912
  },
  {
    "episode": 48,
    "avg_reward_per_step": 11.125111781960022,
    "episode_length": 1682,
    "policy_loss": -192.60159301757812,
    "value_loss": 0.5085741430521011,
    "entropy": 0.5738678574562073,
    "total_loss": -192.3225660175085
  },
  {
    "episode": 49,
    "avg_reward_per_step": -0.8364229678961551,
    "episode_length": 3000,
    "policy_loss": 11.505010843276978,
    "value_loss": 1.0886348187923431,
    "entropy": 0.6048593968153,
    "total_loss": 12.351701903343201
  },
  {
    "episode": 50,
    "avg_reward_per_step": -0.9455839665639737,
    "episode_length": 3000,
    "policy_loss": 13.256732702255249,
    "value_loss": 1.1077284812927246,
    "entropy": 0.6244919449090958,
    "total_loss": 14.114664405584335
  },
  {
    "episode": 51,
    "avg_reward_per_step": -1.2804871640308824,
    "episode_length": 3000,
    "policy_loss": 18.780563354492188,
    "value_loss": 1.0800098180770874,
    "entropy": 0.6970199942588806,
    "total_loss": 19.581765174865723
  },
  {
    "episode": 52,
    "avg_reward_per_step": -1.1328774324887183,
    "episode_length": 3000,
    "policy_loss": 15.937702417373657,
    "value_loss": 1.0598284304141998,
    "entropy": 0.705096423625946,
    "total_loss": 16.71549227833748
  },
  {
    "episode": 53,
    "avg_reward_per_step": -1.0474772903084062,
    "episode_length": 3000,
    "policy_loss": 14.361764430999756,
    "value_loss": 0.9929391890764236,
    "entropy": 0.7031067460775375,
    "total_loss": 15.073460921645164
  },
  {
    "episode": 54,
    "avg_reward_per_step": -1.2151813710504658,
    "episode_length": 3000,
    "policy_loss": 17.095580577850342,
    "value_loss": 0.9249070882797241,
    "entropy": 0.7376975864171982,
    "total_loss": 17.725408631563187
  },
  {
    "episode": 55,
    "avg_reward_per_step": -1.4807051570316334,
    "episode_length": 3000,
    "policy_loss": 21.374592304229736,
    "value_loss": 1.0316562354564667,
    "entropy": 0.7629662603139877,
    "total_loss": 22.10106203556061
  },
  {
    "episode": 56,
    "avg_reward_per_step": 10.855271286599445,
    "episode_length": 1659,
    "policy_loss": -188.89446640014648,
    "value_loss": 0.5081193745136261,
    "entropy": 0.7565782815217972,
    "total_loss": -188.68897833824158
  },
  {
    "episode": 57,
    "avg_reward_per_step": 9.26261205544855,
    "episode_length": 1853,
    "policy_loss": -164.23325729370117,
    "value_loss": 0.5066069215536118,
    "entropy": 0.8008822947740555,
    "total_loss": -164.04700329005718
  },
  {
    "episode": 58,
    "avg_reward_per_step": 17.419755913629473,
    "episode_length": 1047,
    "policy_loss": -298.5667953491211,
    "value_loss": 0.5131348222494125,
    "entropy": 0.876654863357544,
    "total_loss": -298.4043224722147
  },
  {
    "episode": 59,
    "avg_reward_per_step": 21.27772996395194,
    "episode_length": 875,
    "policy_loss": -366.1006622314453,
    "value_loss": 0.516419067978859,
    "entropy": 0.9177522510290146,
    "total_loss": -365.9513440638781
  },
  {
    "episode": 60,
    "avg_reward_per_step": 20.1614743410872,
    "episode_length": 909,
    "policy_loss": -353.75736236572266,
    "value_loss": 0.5153413265943527,
    "entropy": 0.9641839116811752,
    "total_loss": -353.62769460380076
  },
  {
    "episode": 61,
    "avg_reward_per_step": 109.47914351874321,
    "episode_length": 181,
    "policy_loss": -1887.6565856933594,
    "value_loss": 0.6049274504184723,
    "entropy": 0.9789248704910278,
    "total_loss": -1887.4432281911372
  },
  {
    "episode": 62,
    "avg_reward_per_step": 89.85079166724955,
    "episode_length": 211,
    "policy_loss": -1517.6119689941406,
    "value_loss": 0.5786014497280121,
    "entropy": 0.9013627022504807,
    "total_loss": -1517.3939126253129
  },
  {
    "episode": 63,
    "avg_reward_per_step": 102.46476660210823,
    "episode_length": 186,
    "policy_loss": -1737.4639892578125,
    "value_loss": 0.5928062200546265,
    "entropy": 0.8220225721597672,
    "total_loss": -1737.1999920666217
  },
  {
    "episode": 64,
    "avg_reward_per_step": -0.1598425918453925,
    "episode_length": 2353,
    "policy_loss": -2.0295154750347137,
    "value_loss": 0.4997790902853012,
    "entropy": 0.8091448247432709,
    "total_loss": -1.8533943146467209
  },
  {
    "episode": 65,
    "avg_reward_per_step": 5.979066650626058,
    "episode_length": 1617,
    "policy_loss": -106.11553382873535,
    "value_loss": 0.5021666288375854,
    "entropy": 0.8470606058835983,
    "total_loss": -105.9521914422512
  },
  {
    "episode": 66,
    "avg_reward_per_step": 15.834700587936823,
    "episode_length": 846,
    "policy_loss": -272.72008514404297,
    "value_loss": 0.5084761828184128,
    "entropy": 0.8074333965778351,
    "total_loss": -272.5345823198557
  },
  {
    "episode": 67,
    "avg_reward_per_step": 1.6727012187314207,
    "episode_length": 1806,
    "policy_loss": -32.97859859466553,
    "value_loss": 0.49991484731435776,
    "entropy": 0.777162566781044,
    "total_loss": -32.78954877406359
  },
  {
    "episode": 68,
    "avg_reward_per_step": 18.053111384344493,
    "episode_length": 758,
    "policy_loss": -309.8658981323242,
    "value_loss": 0.509870171546936,
    "entropy": 0.8008000552654266,
    "total_loss": -309.67634798288344
  },
  {
    "episode": 69,
    "avg_reward_per_step": 116.04726010843451,
    "episode_length": 167,
    "policy_loss": -1974.7848815917969,
    "value_loss": 0.6091062873601913,
    "entropy": 0.8480578362941742,
    "total_loss": -1974.5149984389543
  },
  {
    "episode": 70,
    "avg_reward_per_step": 117.24071427588213,
    "episode_length": 168,
    "policy_loss": -1993.4273376464844,
    "value_loss": 0.6134874373674393,
    "entropy": 0.8837448358535767,
    "total_loss": -1993.1673481434584
  },
  {
    "episode": 71,
    "avg_reward_per_step": 79.57240381015193,
    "episode_length": 243,
    "policy_loss": -1363.5998229980469,
    "value_loss": 0.5705486983060837,
    "entropy": 0.8810589462518692,
    "total_loss": -1363.3816978782415
  },
  {
    "episode": 72,
    "avg_reward_per_step": 72.31126484971453,
    "episode_length": 266,
    "policy_loss": -1221.5553894042969,
    "value_loss": 0.5622573494911194,
    "entropy": 0.8227756470441818,
    "total_loss": -1221.3222423136235
  },
  {
    "episode": 73,
    "avg_reward_per_step": 30.7456322522055,
    "episode_length": 551,
    "policy_loss": -522.1853179931641,
    "value_loss": 0.5217075049877167,
    "entropy": 0.8730431646108627,
    "total_loss": -522.0128277540207
  },
  {
    "episode": 74,
    "avg_reward_per_step": 34.516114620420595,
    "episode_length": 519,
    "policy_loss": -585.8757934570312,
    "value_loss": 0.5259004384279251,
    "entropy": 0.8897833228111267,
    "total_loss": -585.7058063477277
  },
  {
    "episode": 75,
    "avg_reward_per_step": 22.274921187571643,
    "episode_length": 806,
    "policy_loss": -380.6498794555664,
    "value_loss": 0.5165474563837051,
    "entropy": 0.9001364707946777,
    "total_loss": -380.4933865875006
  },
  {
    "episode": 76,
    "avg_reward_per_step": 83.94265453336482,
    "episode_length": 231,
    "policy_loss": -1426.7339477539062,
    "value_loss": 0.5750474333763123,
    "entropy": 0.864720419049263,
    "total_loss": -1426.5047884881496
  },
  {
    "episode": 77,
    "avg_reward_per_step": 66.08074569729422,
    "episode_length": 297,
    "policy_loss": -1120.0477905273438,
    "value_loss": 0.5577691346406937,
    "entropy": 0.8623621016740799,
    "total_loss": -1119.8349662333726
  },
  {
    "episode": 78,
    "avg_reward_per_step": 44.37798656154149,
    "episode_length": 426,
    "policy_loss": -754.3487548828125,
    "value_loss": 0.5358552187681198,
    "entropy": 0.8452920466661453,
    "total_loss": -754.1510164827108
  },
  {
    "episode": 79,
    "avg_reward_per_step": 84.17977561884409,
    "episode_length": 230,
    "policy_loss": -1426.4830627441406,
    "value_loss": 0.5750122219324112,
    "entropy": 0.8302881568670273,
    "total_loss": -1426.240165784955
  },
  {
    "episode": 80,
    "avg_reward_per_step": 27.087976067869,
    "episode_length": 631,
    "policy_loss": -466.6066360473633,
    "value_loss": 0.5191387981176376,
    "entropy": 0.8008693009614944,
    "total_loss": -466.4078449696302
  },
  {
    "episode": 81,
    "avg_reward_per_step": 68.1835325443062,
    "episode_length": 277,
    "policy_loss": -1170.7255859375,
    "value_loss": 0.5578878670930862,
    "entropy": 0.7903416305780411,
    "total_loss": -1170.4838347226382
  },
  {
    "episode": 82,
    "avg_reward_per_step": 5.223790447307111,
    "episode_length": 1379,
    "policy_loss": -90.61201667785645,
    "value_loss": 0.5013247132301331,
    "entropy": 0.6721018999814987,
    "total_loss": -90.37953272461891
  },
  {
    "episode": 83,
    "avg_reward_per_step": 14.106939937755564,
    "episode_length": 868,
    "policy_loss": -240.7046356201172,
    "value_loss": 0.5067910999059677,
    "entropy": 0.6268018782138824,
    "total_loss": -240.44856527149676
  },
  {
    "episode": 84,
    "avg_reward_per_step": -10.810439529880625,
    "episode_length": 3000,
    "policy_loss": 177.51781845092773,
    "value_loss": 3.4080162048339844,
    "entropy": 0.5941336005926132,
    "total_loss": 180.68818121552468
  },
  {
    "episode": 85,
    "avg_reward_per_step": -9.662748740713958,
    "episode_length": 3000,
    "policy_loss": 157.94029235839844,
    "value_loss": 2.326343059539795,
    "entropy": 0.6014931350946426,
    "total_loss": 160.02603816390038
  },
  {
    "episode": 86,
    "avg_reward_per_step": -7.949187759180075,
    "episode_length": 3000,
    "policy_loss": 129.3382225036621,
    "value_loss": 1.5402401983737946,
    "entropy": 0.6191766709089279,
    "total_loss": 130.63079203367232
  },
  {
    "episode": 87,
    "avg_reward_per_step": -1.4537604538707491,
    "episode_length": 2204,
    "policy_loss": 19.582614421844482,
    "value_loss": 0.4998997524380684,
    "entropy": 0.5857484191656113,
    "total_loss": 19.848214806616305
  },
  {
    "episode": 88,
    "avg_reward_per_step": -10.1145103627256,
    "episode_length": 3000,
    "policy_loss": 165.37990951538086,
    "value_loss": 2.2982595562934875,
    "entropy": 0.5970609188079834,
    "total_loss": 167.43934470415115
  },
  {
    "episode": 89,
    "avg_reward_per_step": -2.0262295958197423,
    "episode_length": 2324,
    "policy_loss": 28.967681884765625,
    "value_loss": 0.5000624656677246,
    "entropy": 0.5957519263029099,
    "total_loss": 29.229443579912186
  },
  {
    "episode": 90,
    "avg_reward_per_step": 3.428307033650664,
    "episode_length": 1607,
    "policy_loss": -63.42763614654541,
    "value_loss": 0.500586524605751,
    "entropy": 0.630998894572258,
    "total_loss": -63.17944917976856
  },
  {
    "episode": 91,
    "avg_reward_per_step": 8.895505483101747,
    "episode_length": 1140,
    "policy_loss": -156.1432228088379,
    "value_loss": 0.5035126358270645,
    "entropy": 0.6305567473173141,
    "total_loss": -155.89193287193774
  },
  {
    "episode": 92,
    "avg_reward_per_step": 96.20956273322142,
    "episode_length": 197,
    "policy_loss": -1640.139892578125,
    "value_loss": 0.5846692025661469,
    "entropy": 0.6603905558586121,
    "total_loss": -1639.8193795979023
  },
  {
    "episode": 93,
    "avg_reward_per_step": 128.809044862657,
    "episode_length": 150,
    "policy_loss": -2178.3125610351562,
    "value_loss": 0.6241550743579865,
    "entropy": 0.68564672768116,
    "total_loss": -2177.962664651871
  },
  {
    "episode": 94,
    "avg_reward_per_step": 26.221745663099604,
    "episode_length": 589,
    "policy_loss": -450.58199310302734,
    "value_loss": 0.5165832042694092,
    "entropy": 0.7290391325950623,
    "total_loss": -450.35702555179597
  },
  {
    "episode": 95,
    "avg_reward_per_step": 72.40597032475331,
    "episode_length": 253,
    "policy_loss": -1233.11767578125,
    "value_loss": 0.5590423196554184,
    "entropy": 0.7775426656007767,
    "total_loss": -1232.869650527835
  },
  {
    "episode": 96,
    "avg_reward_per_step": 221.87945078163938,
    "episode_length": 90,
    "policy_loss": -3767.0697021484375,
    "value_loss": 0.7715712934732437,
    "entropy": 0.803677573800087,
    "total_loss": -3766.6196018844844
  },
  {
    "episode": 97,
    "avg_reward_per_step": 108.40621405810798,
    "episode_length": 179,
    "policy_loss": -1852.0103454589844,
    "value_loss": 0.6017318218946457,
    "entropy": 0.7026898264884949,
    "total_loss": -1851.689689567685
  },
  {
    "episode": 98,
    "avg_reward_per_step": -10.242037047717128,
    "episode_length": 3000,
    "policy_loss": 168.09389114379883,
    "value_loss": 3.279117465019226,
    "entropy": 0.5637815296649933,
    "total_loss": 171.14749599695205
  },
  {
    "episode": 99,
    "avg_reward_per_step": -9.140938336590118,
    "episode_length": 3000,
    "policy_loss": 148.77780532836914,
    "value_loss": 1.5775814652442932,
    "entropy": 0.5374317318201065,
    "total_loss": 150.14041410088538
  },
  {
    "episode": 100,
    "avg_reward_per_step": -11.406793027403335,
    "episode_length": 3000,
    "policy_loss": 186.63060760498047,
    "value_loss": 2.415730834007263,
    "entropy": 0.47003085166215897,
    "total_loss": 188.85832609832286
  },
  {
    "episode": 101,
    "avg_reward_per_step": -12.555701340660761,
    "episode_length": 3000,
    "policy_loss": 205.7232551574707,
    "value_loss": 3.6974745392799377,
    "entropy": 0.41766297072172165,
    "total_loss": 209.25366450846195
  },
  {
    "episode": 102,
    "avg_reward_per_step": -11.65312261984958,
    "episode_length": 3000,
    "policy_loss": 190.56342315673828,
    "value_loss": 3.237649440765381,
    "entropy": 0.4246351420879364,
    "total_loss": 193.6312185406685
  },
  {
    "episode": 103,
    "avg_reward_per_step": -12.780704356424009,
    "episode_length": 3000,
    "policy_loss": 209.34230422973633,
    "value_loss": 3.52577143907547,
    "entropy": 0.4144102931022644,
    "total_loss": 212.7023115515709
  },
  {
    "episode": 104,
    "avg_reward_per_step": -12.838900945924486,
    "episode_length": 3000,
    "policy_loss": 210.03220748901367,
    "value_loss": 3.1892805099487305,
    "entropy": 0.39426514506340027,
    "total_loss": 213.06378194093705
  },
  {
    "episode": 105,
    "avg_reward_per_step": -12.424723414167206,
    "episode_length": 3000,
    "policy_loss": 202.8587875366211,
    "value_loss": 3.6117385029792786,
    "entropy": 0.41140054166316986,
    "total_loss": 206.3059658229351
  },
  {
    "episode": 106,
    "avg_reward_per_step": -12.267753619157574,
    "episode_length": 3000,
    "policy_loss": 199.94525909423828,
    "value_loss": 3.385034203529358,
    "entropy": 0.41164518892765045,
    "total_loss": 203.16563522219658
  },
  {
    "episode": 107,
    "avg_reward_per_step": -8.876224554358707,
    "episode_length": 3000,
    "policy_loss": 142.66220474243164,
    "value_loss": 1.2422365844249725,
    "entropy": 0.45533479005098343,
    "total_loss": 143.7223074108362
  },
  {
    "episode": 108,
    "avg_reward_per_step": -12.368154532083302,
    "episode_length": 3000,
    "policy_loss": 201.2837028503418,
    "value_loss": 3.195332646369934,
    "entropy": 0.42132405936717987,
    "total_loss": 204.31050587296485
  },
  {
    "episode": 109,
    "avg_reward_per_step": -12.34628411830943,
    "episode_length": 3000,
    "policy_loss": 200.64776611328125,
    "value_loss": 3.473260462284088,
    "entropy": 0.42446810752153397,
    "total_loss": 203.95123933255672
  },
  {
    "episode": 110,
    "avg_reward_per_step": -12.528047733657067,
    "episode_length": 3000,
    "policy_loss": 203.62875366210938,
    "value_loss": 3.5604475140571594,
    "entropy": 0.4270789250731468,
    "total_loss": 207.01836960613727
  },
  {
    "episode": 111,
    "avg_reward_per_step": 76.89858090832058,
    "episode_length": 238,
    "policy_loss": -1305.2598876953125,
    "value_loss": 0.5638438612222672,
    "entropy": 0.40888693928718567,
    "total_loss": -1304.859598609805
  },
  {
    "episode": 112,
    "avg_reward_per_step": 61.502963348454635,
    "episode_length": 286,
    "policy_loss": -1055.1990356445312,
    "value_loss": 0.547399640083313,
    "entropy": 0.43463341891765594,
    "total_loss": -1054.825489372015
  },
  {
    "episode": 113,
    "avg_reward_per_step": 83.53404192101087,
    "episode_length": 222,
    "policy_loss": -1422.5050659179688,
    "value_loss": 0.5709934830665588,
    "entropy": 0.4992935433983803,
    "total_loss": -1422.1337898522615
  },
  {
    "episode": 114,
    "avg_reward_per_step": -10.378185621077101,
    "episode_length": 3000,
    "policy_loss": 166.66790008544922,
    "value_loss": 2.5414533615112305,
    "entropy": 0.5726403743028641,
    "total_loss": 168.9802972972393
  },
  {
    "episode": 115,
    "avg_reward_per_step": 36.66944336252552,
    "episode_length": 445,
    "policy_loss": -628.447265625,
    "value_loss": 0.5254453718662262,
    "entropy": 0.6072305887937546,
    "total_loss": -628.1647124886513
  },
  {
    "episode": 116,
    "avg_reward_per_step": -0.29211343737367207,
    "episode_length": 2115,
    "policy_loss": -3.4264565110206604,
    "value_loss": 0.4997796565294266,
    "entropy": 0.6112757176160812,
    "total_loss": -3.1711871415376662
  },
  {
    "episode": 117,
    "avg_reward_per_step": 7.482561851277368,
    "episode_length": 1372,
    "policy_loss": -134.4353141784668,
    "value_loss": 0.5031673461198807,
    "entropy": 0.6170510202646255,
    "total_loss": -134.17896724045278
  },
  {
    "episode": 118,
    "avg_reward_per_step": 0.2961129590161663,
    "episode_length": 2021,
    "policy_loss": -13.470657587051392,
    "value_loss": 0.49984631687402725,
    "entropy": 0.5962434411048889,
    "total_loss": -13.20930864661932
  },
  {
    "episode": 119,
    "avg_reward_per_step": 102.80576638839733,
    "episode_length": 181,
    "policy_loss": -1741.0715637207031,
    "value_loss": 0.5905464440584183,
    "entropy": 0.5651183873414993,
    "total_loss": -1740.7070646315813
  },
  {
    "episode": 120,
    "avg_reward_per_step": -2.758181044666551,
    "episode_length": 2656,
    "policy_loss": 37.89193916320801,
    "value_loss": 0.5003559589385986,
    "entropy": 0.56802599132061,
    "total_loss": 38.165084725618364
  },
  {
    "episode": 121,
    "avg_reward_per_step": -9.97263899669278,
    "episode_length": 3000,
    "policy_loss": 159.7215919494629,
    "value_loss": 3.3536201119422913,
    "entropy": 0.5791978240013123,
    "total_loss": 162.84353293180465
  },
  {
    "episode": 122,
    "avg_reward_per_step": 4.601789604319017,
    "episode_length": 1456,
    "policy_loss": -86.80860328674316,
    "value_loss": 0.5012569278478622,
    "entropy": 0.6100176721811295,
    "total_loss": -86.55135342776775
  },
  {
    "episode": 123,
    "avg_reward_per_step": 3.517483649306985,
    "episode_length": 1778,
    "policy_loss": -67.88948822021484,
    "value_loss": 0.5009251832962036,
    "entropy": 0.6361052989959717,
    "total_loss": -67.64300515651703
  },
  {
    "episode": 124,
    "avg_reward_per_step": -0.010538516507861334,
    "episode_length": 2759,
    "policy_loss": -8.437933683395386,
    "value_loss": 0.49985652416944504,
    "entropy": 0.6543685644865036,
    "total_loss": -8.199824585020542
  },
  {
    "episode": 125,
    "avg_reward_per_step": 163.55847237466133,
    "episode_length": 122,
    "policy_loss": -2809.1481323242188,
    "value_loss": 0.6770216524600983,
    "entropy": 0.6532596349716187,
    "total_loss": -2808.732414525747
  },
  {
    "episode": 126,
    "avg_reward_per_step": -2.2108205271589823,
    "episode_length": 2564,
    "policy_loss": 30.0643630027771,
    "value_loss": 0.5000710487365723,
    "entropy": 0.5014264807105064,
    "total_loss": 30.36386345922947
  },
  {
    "episode": 127,
    "avg_reward_per_step": -11.987873208926345,
    "episode_length": 3000,
    "policy_loss": 193.23766708374023,
    "value_loss": 3.0715759992599487,
    "entropy": 0.4155421331524849,
    "total_loss": 196.14302622973918
  },
  {
    "episode": 128,
    "avg_reward_per_step": -12.119494314923779,
    "episode_length": 3000,
    "policy_loss": 195.55392837524414,
    "value_loss": 2.7395219206809998,
    "entropy": 0.3532293885946274,
    "total_loss": 198.15215854048728
  },
  {
    "episode": 129,
    "avg_reward_per_step": -12.327440772798557,
    "episode_length": 3000,
    "policy_loss": 198.4496726989746,
    "value_loss": 3.168756127357483,
    "entropy": 0.3186327666044235,
    "total_loss": 201.4909757196903
  },
  {
    "episode": 130,
    "avg_reward_per_step": -13.906033384965207,
    "episode_length": 3000,
    "policy_loss": 224.7928924560547,
    "value_loss": 3.433950901031494,
    "entropy": 0.30265602469444275,
    "total_loss": 228.10578094720842
  },
  {
    "episode": 131,
    "avg_reward_per_step": 50.854172911803715,
    "episode_length": 355,
    "policy_loss": -867.7192687988281,
    "value_loss": 0.5401472002267838,
    "entropy": 0.2802244797348976,
    "total_loss": -867.2912113904953
  },
  {
    "episode": 132,
    "avg_reward_per_step": 42.32366351500287,
    "episode_length": 425,
    "policy_loss": -726.5682983398438,
    "value_loss": 0.5329053550958633,
    "entropy": 0.2971046715974808,
    "total_loss": -726.1542348533869
  },
  {
    "episode": 133,
    "avg_reward_per_step": -13.121630364021764,
    "episode_length": 3000,
    "policy_loss": 210.98754501342773,
    "value_loss": 3.2009612321853638,
    "entropy": 0.3562343046069145,
    "total_loss": 214.04601252377034
  },
  {
    "episode": 134,
    "avg_reward_per_step": -13.03522645769981,
    "episode_length": 3000,
    "policy_loss": 209.39407348632812,
    "value_loss": 3.4109217524528503,
    "entropy": 0.38499831408262253,
    "total_loss": 212.65099591314794
  },
  {
    "episode": 135,
    "avg_reward_per_step": -11.73031788740302,
    "episode_length": 3000,
    "policy_loss": 187.60145568847656,
    "value_loss": 2.8536065220832825,
    "entropy": 0.3998085930943489,
    "total_loss": 190.2951387733221
  },
  {
    "episode": 136,
    "avg_reward_per_step": -12.078022955879526,
    "episode_length": 3000,
    "policy_loss": 193.00830078125,
    "value_loss": 3.1003846526145935,
    "entropy": 0.4143698588013649,
    "total_loss": 195.94293749034404
  },
  {
    "episode": 137,
    "avg_reward_per_step": 58.32231678958173,
    "episode_length": 290,
    "policy_loss": -1001.3310394287109,
    "value_loss": 0.5430436283349991,
    "entropy": 0.43249423056840897,
    "total_loss": -1000.9609934926033
  },
  {
    "episode": 138,
    "avg_reward_per_step": 1.8892279561495482,
    "episode_length": 1654,
    "policy_loss": -43.667240142822266,
    "value_loss": 0.500190019607544,
    "entropy": 0.48050007969141006,
    "total_loss": -43.35925015509129
  },
  {
    "episode": 139,
    "avg_reward_per_step": -11.554742602653283,
    "episode_length": 3000,
    "policy_loss": 183.40319442749023,
    "value_loss": 3.395291745662689,
    "entropy": 0.5224300622940063,
    "total_loss": 186.5895141482353
  },
  {
    "episode": 140,
    "avg_reward_per_step": -10.689373028937743,
    "episode_length": 3000,
    "policy_loss": 168.77589416503906,
    "value_loss": 3.1574001908302307,
    "entropy": 0.5567385107278824,
    "total_loss": 171.71059895157813
  },
  {
    "episode": 141,
    "avg_reward_per_step": -10.662513407576027,
    "episode_length": 3000,
    "policy_loss": 168.22473526000977,
    "value_loss": 3.146966814994812,
    "entropy": 0.5617066919803619,
    "total_loss": 171.14701939821242
  },
  {
    "episode": 142,
    "avg_reward_per_step": 0.3599943971117793,
    "episode_length": 2251,
    "policy_loss": -19.05172824859619,
    "value_loss": 0.49997084587812424,
    "entropy": 0.6015785038471222,
    "total_loss": -18.792388804256916
  },
  {
    "episode": 143,
    "avg_reward_per_step": 35.3807353388527,
    "episode_length": 483,
    "policy_loss": -610.2504577636719,
    "value_loss": 0.5259251296520233,
    "entropy": 0.6450024396181107,
    "total_loss": -609.9825336098671
  },
  {
    "episode": 144,
    "avg_reward_per_step": 20.211375238511927,
    "episode_length": 739,
    "policy_loss": -355.55230712890625,
    "value_loss": 0.5129183083772659,
    "entropy": 0.6615714877843857,
    "total_loss": -355.30401741564276
  },
  {
    "episode": 145,
    "avg_reward_per_step": 39.51485298822224,
    "episode_length": 441,
    "policy_loss": -683.6684265136719,
    "value_loss": 0.5298193097114563,
    "entropy": 0.6902557462453842,
    "total_loss": -683.4147095024585
  },
  {
    "episode": 146,
    "avg_reward_per_step": 36.09833676589762,
    "episode_length": 484,
    "policy_loss": -622.4244384765625,
    "value_loss": 0.5273613482713699,
    "entropy": 0.7140085697174072,
    "total_loss": -622.1826805561781
  },
  {
    "episode": 147,
    "avg_reward_per_step": 95.96621293799804,
    "episode_length": 201,
    "policy_loss": -1646.7764892578125,
    "value_loss": 0.5880352109670639,
    "entropy": 0.7203436940908432,
    "total_loss": -1646.4765915244818
  },
  {
    "episode": 148,
    "avg_reward_per_step": 62.94499481837888,
    "episode_length": 310,
    "policy_loss": -1068.7056579589844,
    "value_loss": 0.5553667843341827,
    "entropy": 0.6894913762807846,
    "total_loss": -1068.4260877251625
  },
  {
    "episode": 149,
    "avg_reward_per_step": 100.15592421569785,
    "episode_length": 193,
    "policy_loss": -1719.1989440917969,
    "value_loss": 0.5927736461162567,
    "entropy": 0.7301168590784073,
    "total_loss": -1718.898217189312
  },
  {
    "episode": 150,
    "avg_reward_per_step": 19.324149704295788,
    "episode_length": 869,
    "policy_loss": -338.004638671875,
    "value_loss": 0.5141038447618484,
    "entropy": 0.7106399685144424,
    "total_loss": -337.77479081451895
  },
  {
    "episode": 151,
    "avg_reward_per_step": 97.94626853315712,
    "episode_length": 197,
    "policy_loss": -1669.80224609375,
    "value_loss": 0.5901819169521332,
    "entropy": 0.6773847341537476,
    "total_loss": -1669.4830180704594
  },
  {
    "episode": 152,
    "avg_reward_per_step": 26.779378531269447,
    "episode_length": 624,
    "policy_loss": -463.4805908203125,
    "value_loss": 0.5192785859107971,
    "entropy": 0.6632321327924728,
    "total_loss": -463.2266050875187
  },
  {
    "episode": 153,
    "avg_reward_per_step": 33.14610012485243,
    "episode_length": 499,
    "policy_loss": -573.1432952880859,
    "value_loss": 0.5234279185533524,
    "entropy": 0.6569114327430725,
    "total_loss": -572.8826319426298
  },
  {
    "episode": 154,
    "avg_reward_per_step": 27.971613434307223,
    "episode_length": 592,
    "policy_loss": -485.61549377441406,
    "value_loss": 0.5199319273233414,
    "entropy": 0.6345813721418381,
    "total_loss": -485.34939439594746
  },
  {
    "episode": 155,
    "avg_reward_per_step": 66.9178960986317,
    "episode_length": 274,
    "policy_loss": -1161.8412170410156,
    "value_loss": 0.5548955351114273,
    "entropy": 0.6244646161794662,
    "total_loss": -1161.536107352376
  },
  {
    "episode": 156,
    "avg_reward_per_step": 104.90997414830832,
    "episode_length": 178,
    "policy_loss": -1785.7111511230469,
    "value_loss": 0.5937171280384064,
    "entropy": 0.6772733926773071,
    "total_loss": -1785.3883433520793
  },
  {
    "episode": 157,
    "avg_reward_per_step": 7.76215471276822,
    "episode_length": 1749,
    "policy_loss": -142.77760314941406,
    "value_loss": 0.505055844783783,
    "entropy": 0.700153186917305,
    "total_loss": -142.5526085793972
  },
  {
    "episode": 158,
    "avg_reward_per_step": 109.51702210967461,
    "episode_length": 179,
    "policy_loss": -1887.44775390625,
    "value_loss": 0.604569286108017,
    "entropy": 0.6967611908912659,
    "total_loss": -1887.1218890964985
  },
  {
    "episode": 159,
    "avg_reward_per_step": 38.14566111859095,
    "episode_length": 463,
    "policy_loss": -661.7357177734375,
    "value_loss": 0.5291802734136581,
    "entropy": 0.6754419505596161,
    "total_loss": -661.4767142802477
  },
  {
    "episode": 160,
    "avg_reward_per_step": 63.7330879021438,
    "episode_length": 286,
    "policy_loss": -1090.0586547851562,
    "value_loss": 0.551870658993721,
    "entropy": 0.6013486832380295,
    "total_loss": -1089.7473235994578
  },
  {
    "episode": 161,
    "avg_reward_per_step": 23.381125688637596,
    "episode_length": 664,
    "policy_loss": -404.7585983276367,
    "value_loss": 0.5155128389596939,
    "entropy": 0.5881856679916382,
    "total_loss": -404.47835975587367
  },
  {
    "episode": 162,
    "avg_reward_per_step": 13.409219707825963,
    "episode_length": 876,
    "policy_loss": -239.94606399536133,
    "value_loss": 0.5066702514886856,
    "entropy": 0.5712969452142715,
    "total_loss": -239.66791252195836
  },
  {
    "episode": 163,
    "avg_reward_per_step": 5.3427532084471485,
    "episode_length": 1382,
    "policy_loss": -102.83795356750488,
    "value_loss": 0.5017463713884354,
    "entropy": 0.5915186405181885,
    "total_loss": -102.57281465232373
  },
  {
    "episode": 164,
    "avg_reward_per_step": 25.436632369337786,
    "episode_length": 593,
    "policy_loss": -443.5839538574219,
    "value_loss": 0.516383484005928,
    "entropy": 0.6058695167303085,
    "total_loss": -443.30991818010807
  },
  {
    "episode": 165,
    "avg_reward_per_step": 7.759453987068531,
    "episode_length": 1474,
    "policy_loss": -142.55380630493164,
    "value_loss": 0.5040789246559143,
    "entropy": 0.6402057111263275,
    "total_loss": -142.30580966472627
  },
  {
    "episode": 166,
    "avg_reward_per_step": 58.28168927404522,
    "episode_length": 304,
    "policy_loss": -998.2288360595703,
    "value_loss": 0.5456206351518631,
    "entropy": 0.5935753285884857,
    "total_loss": -997.9206455558539
  },
  {
    "episode": 167,
    "avg_reward_per_step": 45.263285208960646,
    "episode_length": 383,
    "policy_loss": -786.9224243164062,
    "value_loss": 0.5341708064079285,
    "entropy": 0.6207414120435715,
    "total_loss": -786.6365500748158
  },
  {
    "episode": 168,
    "avg_reward_per_step": 209.84636694562715,
    "episode_length": 95,
    "policy_loss": -3595.000244140625,
    "value_loss": 0.7510821372270584,
    "entropy": 0.688763901591301,
    "total_loss": -3594.5246675640346
  },
  {
    "episode": 169,
    "avg_reward_per_step": 159.85684240823946,
    "episode_length": 122,
    "policy_loss": -2744.56640625,
    "value_loss": 0.667599231004715,
    "entropy": 0.6688180714845657,
    "total_loss": -2744.166334247589
  },
  {
    "episode": 170,
    "avg_reward_per_step": 43.9055303262003,
    "episode_length": 382,
    "policy_loss": -746.6744537353516,
    "value_loss": 0.5317924171686172,
    "entropy": 0.6030820459127426,
    "total_loss": -746.3838941365481
  },
  {
    "episode": 171,
    "avg_reward_per_step": 27.5381717789679,
    "episode_length": 554,
    "policy_loss": -481.99832916259766,
    "value_loss": 0.517922431230545,
    "entropy": 0.5337128043174744,
    "total_loss": -481.6938918530941
  },
  {
    "episode": 172,
    "avg_reward_per_step": -10.179222446231726,
    "episode_length": 3000,
    "policy_loss": 159.2896728515625,
    "value_loss": 2.678405463695526,
    "entropy": 0.4947230815887451,
    "total_loss": 161.77018908262252
  },
  {
    "episode": 173,
    "avg_reward_per_step": -11.712410308034466,
    "episode_length": 3000,
    "policy_loss": 185.07589721679688,
    "value_loss": 3.1883381009101868,
    "entropy": 0.46670928597450256,
    "total_loss": 188.07755160331726
  },
  {
    "episode": 174,
    "avg_reward_per_step": 7.490974405133159,
    "episode_length": 1269,
    "policy_loss": -139.53739547729492,
    "value_loss": 0.5033562630414963,
    "entropy": 0.4753294438123703,
    "total_loss": -139.22417099177838
  },
  {
    "episode": 175,
    "avg_reward_per_step": 8.512781757699559,
    "episode_length": 1115,
    "policy_loss": -156.72482681274414,
    "value_loss": 0.5035607069730759,
    "entropy": 0.4483957141637802,
    "total_loss": -156.40062439143657
  },
  {
    "episode": 176,
    "avg_reward_per_step": -3.933105750074179,
    "episode_length": 2610,
    "policy_loss": 52.81085205078125,
    "value_loss": 0.5008922070264816,
    "entropy": 0.4372612461447716,
    "total_loss": 53.136839759349826
  },
  {
    "episode": 177,
    "avg_reward_per_step": -12.039570055136066,
    "episode_length": 3000,
    "policy_loss": 189.51591110229492,
    "value_loss": 3.0802043080329895,
    "entropy": 0.4390857368707657,
    "total_loss": 192.4204811155796
  },
  {
    "episode": 178,
    "avg_reward_per_step": -11.825812427506829,
    "episode_length": 3000,
    "policy_loss": 185.78359603881836,
    "value_loss": 3.3026997447013855,
    "entropy": 0.46352242678403854,
    "total_loss": 188.90088681280614
  },
  {
    "episode": 179,
    "avg_reward_per_step": 11.067072611945765,
    "episode_length": 955,
    "policy_loss": -200.62399291992188,
    "value_loss": 0.5051194876432419,
    "entropy": 0.4440699368715286,
    "total_loss": -200.29650140702725
  },
  {
    "episode": 180,
    "avg_reward_per_step": -11.361355328264239,
    "episode_length": 3000,
    "policy_loss": 177.40775299072266,
    "value_loss": 2.9481281638145447,
    "entropy": 0.4737756922841072,
    "total_loss": 180.16637087762356
  },
  {
    "episode": 181,
    "avg_reward_per_step": -1.3392316303540965,
    "episode_length": 1993,
    "policy_loss": 8.071154594421387,
    "value_loss": 0.4999304264783859,
    "entropy": 0.47205650806427,
    "total_loss": 8.382262417674065
  },
  {
    "episode": 182,
    "avg_reward_per_step": 13.017118745320332,
    "episode_length": 892,
    "policy_loss": -234.80309677124023,
    "value_loss": 0.5066585689783096,
    "entropy": 0.4678883031010628,
    "total_loss": -234.48359352350235
  },
  {
    "episode": 183,
    "avg_reward_per_step": -11.564116247706469,
    "episode_length": 3000,
    "policy_loss": 180.13926315307617,
    "value_loss": 3.234787166118622,
    "entropy": 0.4869648367166519,
    "total_loss": 183.17926438450814
  },
  {
    "episode": 184,
    "avg_reward_per_step": -2.283914687044078,
    "episode_length": 2428,
    "policy_loss": 23.026577949523926,
    "value_loss": 0.4999511241912842,
    "entropy": 0.48821500688791275,
    "total_loss": 23.331243070960046
  },
  {
    "episode": 185,
    "avg_reward_per_step": -0.4527772079562274,
    "episode_length": 2114,
    "policy_loss": -7.934468865394592,
    "value_loss": 0.49995025992393494,
    "entropy": 0.5031813159584999,
    "total_loss": -7.635791131854058
  },
  {
    "episode": 186,
    "avg_reward_per_step": -10.473872716575082,
    "episode_length": 3000,
    "policy_loss": 161.28851318359375,
    "value_loss": 2.5963281989097595,
    "entropy": 0.5031837001442909,
    "total_loss": 163.6835679024458
  },
  {
    "episode": 187,
    "avg_reward_per_step": -9.612661005077442,
    "episode_length": 3000,
    "policy_loss": 146.75396347045898,
    "value_loss": 2.022481083869934,
    "entropy": 0.5453051179647446,
    "total_loss": 148.55832250714303
  },
  {
    "episode": 188,
    "avg_reward_per_step": 46.42370975045746,
    "episode_length": 362,
    "policy_loss": -801.2830352783203,
    "value_loss": 0.5340882390737534,
    "entropy": 0.5331317484378815,
    "total_loss": -800.9621997386217
  },
  {
    "episode": 189,
    "avg_reward_per_step": 15.799329336469267,
    "episode_length": 789,
    "policy_loss": -284.762939453125,
    "value_loss": 0.508551299571991,
    "entropy": 0.556794062256813,
    "total_loss": -284.4771057784557
  },
  {
    "episode": 190,
    "avg_reward_per_step": 5.145703582262298,
    "episode_length": 1491,
    "policy_loss": -104.25654220581055,
    "value_loss": 0.5018773078918457,
    "entropy": 0.5432222187519073,
    "total_loss": -103.97195378541946
  },
  {
    "episode": 191,
    "avg_reward_per_step": 46.74332447307523,
    "episode_length": 348,
    "policy_loss": -812.5941009521484,
    "value_loss": 0.5332674980163574,
    "entropy": 0.5216144621372223,
    "total_loss": -812.269479238987
  },
  {
    "episode": 192,
    "avg_reward_per_step": 5.818771272703664,
    "episode_length": 1337,
    "policy_loss": -116.30019760131836,
    "value_loss": 0.502332404255867,
    "entropy": 0.5680913776159286,
    "total_loss": -116.02510174810887
  },
  {
    "episode": 193,
    "avg_reward_per_step": 152.08141054976016,
    "episode_length": 131,
    "policy_loss": -2591.7489013671875,
    "value_loss": 0.660864531993866,
    "entropy": 0.6184042543172836,
    "total_loss": -2591.3353985369204
  },
  {
    "episode": 194,
    "avg_reward_per_step": 42.81952837853305,
    "episode_length": 423,
    "policy_loss": -748.8984832763672,
    "value_loss": 0.5342345237731934,
    "entropy": 0.6644826382398605,
    "total_loss": -748.6300418078899
  },
  {
    "episode": 195,
    "avg_reward_per_step": 44.17314983305507,
    "episode_length": 421,
    "policy_loss": -756.9625396728516,
    "value_loss": 0.5363458544015884,
    "entropy": 0.6877872347831726,
    "total_loss": -756.7013087123632
  },
  {
    "episode": 196,
    "avg_reward_per_step": 210.54676719424228,
    "episode_length": 94,
    "policy_loss": -3617.5103149414062,
    "value_loss": 0.7501028031110764,
    "entropy": 0.7055224478244781,
    "total_loss": -3617.042421117425
  },
  {
    "episode": 197,
    "avg_reward_per_step": 133.7135643969654,
    "episode_length": 146,
    "policy_loss": -2288.5762939453125,
    "value_loss": 0.6334961503744125,
    "entropy": 0.7192395925521851,
    "total_loss": -2288.230493631959
  },
  {
    "episode": 198,
    "avg_reward_per_step": 66.72232354420302,
    "episode_length": 289,
    "policy_loss": -1154.3303833007812,
    "value_loss": 0.5587180852890015,
    "entropy": 0.7105767726898193,
    "total_loss": -1154.0558959245682
  },
  {
    "episode": 199,
    "avg_reward_per_step": 96.31925695392042,
    "episode_length": 204,
    "policy_loss": -1646.6550903320312,
    "value_loss": 0.590702623128891,
    "entropy": 0.6931304931640625,
    "total_loss": -1646.341639906168
  },
  {
    "episode": 200,
    "avg_reward_per_step": 133.08770633429972,
    "episode_length": 148,
    "policy_loss": -2274.4675903320312,
    "value_loss": 0.634069487452507,
    "entropy": 0.7182505428791046,
    "total_loss": -2274.1208210617306
  },
  {
    "episode": 201,
    "avg_reward_per_step": 41.7527498187668,
    "episode_length": 465,
    "policy_loss": -722.7646942138672,
    "value_loss": 0.5357699394226074,
    "entropy": 0.7096149325370789,
    "total_loss": -722.5127702474595
  },
  {
    "episode": 202,
    "avg_reward_per_step": 88.13360730061768,
    "episode_length": 218,
    "policy_loss": -1545.64697265625,
    "value_loss": 0.5793652236461639,
    "entropy": 0.7704185545444489,
    "total_loss": -1545.3757748544217
  },
  {
    "episode": 203,
    "avg_reward_per_step": 217.10172613813916,
    "episode_length": 92,
    "policy_loss": -3674.5154418945312,
    "value_loss": 0.7648668736219406,
    "entropy": 0.7221931666135788,
    "total_loss": -3674.039452287555
  },
  {
    "episode": 204,
    "avg_reward_per_step": 25.77760962990642,
    "episode_length": 653,
    "policy_loss": -450.03649139404297,
    "value_loss": 0.5187036991119385,
    "entropy": 0.7159094363451004,
    "total_loss": -449.80415146946905
  },
  {
    "episode": 205,
    "avg_reward_per_step": 28.16435943047515,
    "episode_length": 591,
    "policy_loss": -491.74949645996094,
    "value_loss": 0.5201799422502518,
    "entropy": 0.694215252995491,
    "total_loss": -491.50700261890887
  },
  {
    "episode": 206,
    "avg_reward_per_step": 56.032344072758676,
    "episode_length": 331,
    "policy_loss": -964.6945037841797,
    "value_loss": 0.5462611466646194,
    "entropy": 0.6729084402322769,
    "total_loss": -964.417406013608
  },
  {
    "episode": 207,
    "avg_reward_per_step": 22.28358279193952,
    "episode_length": 695,
    "policy_loss": -394.2205276489258,
    "value_loss": 0.5149326324462891,
    "entropy": 0.6930813044309616,
    "total_loss": -393.98282753825185
  },
  {
    "episode": 208,
    "avg_reward_per_step": 74.37179503729213,
    "episode_length": 251,
    "policy_loss": -1274.4202575683594,
    "value_loss": 0.5635959059000015,
    "entropy": 0.7117146402597427,
    "total_loss": -1274.1413475185632
  },
  {
    "episode": 209,
    "avg_reward_per_step": 150.02288532895878,
    "episode_length": 131,
    "policy_loss": -2555.0205078125,
    "value_loss": 0.6556551605463028,
    "entropy": 0.6817213594913483,
    "total_loss": -2554.63754119575
  },
  {
    "episode": 210,
    "avg_reward_per_step": 27.20356891469522,
    "episode_length": 590,
    "policy_loss": -476.3960723876953,
    "value_loss": 0.5190075933933258,
    "entropy": 0.6829548329114914,
    "total_loss": -476.1502467274666
  },
  {
    "episode": 211,
    "avg_reward_per_step": 66.27976624321825,
    "episode_length": 284,
    "policy_loss": -1136.6630554199219,
    "value_loss": 0.5562744736671448,
    "entropy": 0.6728868782520294,
    "total_loss": -1136.3759356975556
  },
  {
    "episode": 212,
    "avg_reward_per_step": 27.023583546584216,
    "episode_length": 650,
    "policy_loss": -472.5807800292969,
    "value_loss": 0.5207254439592361,
    "entropy": 0.6904556304216385,
    "total_loss": -472.3362368375063
  },
  {
    "episode": 213,
    "avg_reward_per_step": 67.00853670964325,
    "episode_length": 280,
    "policy_loss": -1153.97412109375,
    "value_loss": 0.5569101125001907,
    "entropy": 0.6904747188091278,
    "total_loss": -1153.6934008687736
  },
  {
    "episode": 214,
    "avg_reward_per_step": 108.89783972071598,
    "episode_length": 178,
    "policy_loss": -1867.4191284179688,
    "value_loss": 0.6031236350536346,
    "entropy": 0.7147537022829056,
    "total_loss": -1867.1019062638284
  },
  {
    "episode": 215,
    "avg_reward_per_step": 44.330257351133525,
    "episode_length": 424,
    "policy_loss": -766.2500915527344,
    "value_loss": 0.5367835909128189,
    "entropy": 0.7221411466598511,
    "total_loss": -766.0021644204855
  },
  {
    "episode": 216,
    "avg_reward_per_step": 39.28017534917741,
    "episode_length": 469,
    "policy_loss": -679.2568511962891,
    "value_loss": 0.5316211134195328,
    "entropy": 0.7336670905351639,
    "total_loss": -679.0186969190836
  },
  {
    "episode": 217,
    "avg_reward_per_step": 44.785574244721836,
    "episode_length": 427,
    "policy_loss": -771.9132995605469,
    "value_loss": 0.5379597544670105,
    "entropy": 0.7287610322237015,
    "total_loss": -771.6668442189693
  },
  {
    "episode": 218,
    "avg_reward_per_step": 71.04228397072026,
    "episode_length": 275,
    "policy_loss": -1221.3660278320312,
    "value_loss": 0.5635656714439392,
    "entropy": 0.716312512755394,
    "total_loss": -1221.0889871656896
  },
  {
    "episode": 219,
    "avg_reward_per_step": 192.34411477447705,
    "episode_length": 103,
    "policy_loss": -3329.5877685546875,
    "value_loss": 0.7198873311281204,
    "entropy": 0.7227704674005508,
    "total_loss": -3329.1569894105196
  },
  {
    "episode": 220,
    "avg_reward_per_step": 35.28524516110403,
    "episode_length": 501,
    "policy_loss": -610.2791900634766,
    "value_loss": 0.5271428376436234,
    "entropy": 0.6573073416948318,
    "total_loss": -610.0149701625108
  },
  {
    "episode": 221,
    "avg_reward_per_step": 6.638519269887266,
    "episode_length": 1272,
    "policy_loss": -126.54862022399902,
    "value_loss": 0.5026356875896454,
    "entropy": 0.5724691897630692,
    "total_loss": -126.27497221231461
  },
  {
    "episode": 222,
    "avg_reward_per_step": -10.69767581836595,
    "episode_length": 3000,
    "policy_loss": 165.2000617980957,
    "value_loss": 2.9222832918167114,
    "entropy": 0.5132262855768204,
    "total_loss": 167.91705457568168
  },
  {
    "episode": 223,
    "avg_reward_per_step": -11.71534761303532,
    "episode_length": 3000,
    "policy_loss": 181.88773727416992,
    "value_loss": 3.080986201763153,
    "entropy": 0.48275504261255264,
    "total_loss": 184.77562145888805
  },
  {
    "episode": 224,
    "avg_reward_per_step": -11.42520890506796,
    "episode_length": 3000,
    "policy_loss": 176.94800186157227,
    "value_loss": 2.805088996887207,
    "entropy": 0.4592767208814621,
    "total_loss": 179.56938017010688
  },
  {
    "episode": 225,
    "avg_reward_per_step": -12.605293918845122,
    "episode_length": 3000,
    "policy_loss": 196.3857078552246,
    "value_loss": 3.0761295557022095,
    "entropy": 0.4305776283144951,
    "total_loss": 199.289606359601
  },
  {
    "episode": 226,
    "avg_reward_per_step": -12.001315339175443,
    "episode_length": 3000,
    "policy_loss": 185.5938377380371,
    "value_loss": 2.760160505771637,
    "entropy": 0.44319983571767807,
    "total_loss": 188.17671830952168
  },
  {
    "episode": 227,
    "avg_reward_per_step": 58.559137741088186,
    "episode_length": 303,
    "policy_loss": -1008.0543060302734,
    "value_loss": 0.5463738888502121,
    "entropy": 0.43682214617729187,
    "total_loss": -1007.6826609998941
  },
  {
    "episode": 228,
    "avg_reward_per_step": -9.084509474686293,
    "episode_length": 3000,
    "policy_loss": 135.76473236083984,
    "value_loss": 1.3583497107028961,
    "entropy": 0.43581099808216095,
    "total_loss": 136.94875767230988
  },
  {
    "episode": 229,
    "avg_reward_per_step": -11.829152463558518,
    "episode_length": 3000,
    "policy_loss": 181.46916580200195,
    "value_loss": 2.4259039163589478,
    "entropy": 0.3948103040456772,
    "total_loss": 183.73714559674264
  },
  {
    "episode": 230,
    "avg_reward_per_step": -12.143701059852086,
    "episode_length": 3000,
    "policy_loss": 186.47982788085938,
    "value_loss": 2.8636425733566284,
    "entropy": 0.38545092195272446,
    "total_loss": 189.18929008543492
  },
  {
    "episode": 231,
    "avg_reward_per_step": -12.686052526564756,
    "episode_length": 3000,
    "policy_loss": 195.05152893066406,
    "value_loss": 2.813015341758728,
    "entropy": 0.38077232241630554,
    "total_loss": 197.71223534345626
  },
  {
    "episode": 232,
    "avg_reward_per_step": 148.02543728888807,
    "episode_length": 135,
    "policy_loss": -2529.5086059570312,
    "value_loss": 0.6558000445365906,
    "entropy": 0.30300381034612656,
    "total_loss": -2528.974007436633
  },
  {
    "episode": 233,
    "avg_reward_per_step": -12.825925824397016,
    "episode_length": 3000,
    "policy_loss": 196.84442138671875,
    "value_loss": 2.9396342635154724,
    "entropy": 0.2967382222414017,
    "total_loss": 199.66536036133766
  },
  {
    "episode": 234,
    "avg_reward_per_step": -13.440647567100415,
    "episode_length": 3000,
    "policy_loss": 206.7028465270996,
    "value_loss": 2.718347907066345,
    "entropy": 0.2670334726572037,
    "total_loss": 209.31438104510306
  },
  {
    "episode": 235,
    "avg_reward_per_step": 38.80557647867817,
    "episode_length": 442,
    "policy_loss": -677.0823669433594,
    "value_loss": 0.5294184982776642,
    "entropy": 0.2439909316599369,
    "total_loss": -676.6505448177456
  },
  {
    "episode": 236,
    "avg_reward_per_step": -13.03890411649125,
    "episode_length": 3000,
    "policy_loss": 199.04325103759766,
    "value_loss": 2.462005853652954,
    "entropy": 0.2436145320534706,
    "total_loss": 201.40781107842923
  },
  {
    "episode": 237,
    "avg_reward_per_step": 50.46777178301256,
    "episode_length": 341,
    "policy_loss": -875.3163909912109,
    "value_loss": 0.5385012626647949,
    "entropy": 0.2299136184155941,
    "total_loss": -874.8698551759123
  },
  {
    "episode": 238,
    "avg_reward_per_step": -14.618154283300287,
    "episode_length": 3000,
    "policy_loss": 224.47284698486328,
    "value_loss": 3.073153257369995,
    "entropy": 0.24218960106372833,
    "total_loss": 227.44912440180778
  },
  {
    "episode": 239,
    "avg_reward_per_step": -14.012395173318232,
    "episode_length": 3000,
    "policy_loss": 214.23474884033203,
    "value_loss": 2.7587954998016357,
    "entropy": 0.2413465790450573,
    "total_loss": 216.89700570851565
  },
  {
    "episode": 240,
    "avg_reward_per_step": -13.577144070964778,
    "episode_length": 3000,
    "policy_loss": 206.29590225219727,
    "value_loss": 2.6412145495414734,
    "entropy": 0.2643887773156166,
    "total_loss": 208.83136129081248
  },
  {
    "episode": 241,
    "avg_reward_per_step": -12.633191858808663,
    "episode_length": 3000,
    "policy_loss": 190.25496673583984,
    "value_loss": 2.377881705760956,
    "entropy": 0.2723327651619911,
    "total_loss": 192.523915335536
  },
  {
    "episode": 242,
    "avg_reward_per_step": 39.80053095404077,
    "episode_length": 454,
    "policy_loss": -697.7239074707031,
    "value_loss": 0.5322988331317902,
    "entropy": 0.2728412002325058,
    "total_loss": -697.3007451176643
  },
  {
    "episode": 243,
    "avg_reward_per_step": 43.959999874359546,
    "episode_length": 368,
    "policy_loss": -770.4927978515625,
    "value_loss": 0.531363770365715,
    "entropy": 0.30739178508520126,
    "total_loss": -770.0843907952309
  },
  {
    "episode": 244,
    "avg_reward_per_step": -12.744585478075923,
    "episode_length": 3000,
    "policy_loss": 191.0357551574707,
    "value_loss": 2.777041733264923,
    "entropy": 0.31651129573583603,
    "total_loss": 193.6861923724413
  },
  {
    "episode": 245,
    "avg_reward_per_step": -12.65088800028321,
    "episode_length": 3000,
    "policy_loss": 189.32036209106445,
    "value_loss": 2.70494681596756,
    "entropy": 0.3415251597762108,
    "total_loss": 191.88869884312152
  },
  {
    "episode": 246,
    "avg_reward_per_step": -13.327961856335188,
    "episode_length": 3000,
    "policy_loss": 200.0340805053711,
    "value_loss": 2.6670849323272705,
    "entropy": 0.3429751694202423,
    "total_loss": 202.56397536993026
  },
  {
    "episode": 247,
    "avg_reward_per_step": 69.48773322381625,
    "episode_length": 261,
    "policy_loss": -1203.887451171875,
    "value_loss": 0.5579406172037125,
    "entropy": 0.3627691715955734,
    "total_loss": -1203.4746182233096
  },
  {
    "episode": 248,
    "avg_reward_per_step": -12.526261320230311,
    "episode_length": 3000,
    "policy_loss": 185.57680892944336,
    "value_loss": 2.495548367500305,
    "entropy": 0.37763073295354843,
    "total_loss": 187.92130500376226
  },
  {
    "episode": 249,
    "avg_reward_per_step": 69.73829530368157,
    "episode_length": 265,
    "policy_loss": -1207.750244140625,
    "value_loss": 0.5594059079885483,
    "entropy": 0.41201627999544144,
    "total_loss": -1207.3556447446347
  },
  {
    "episode": 250,
    "avg_reward_per_step": -12.318422986417358,
    "episode_length": 3000,
    "policy_loss": 181.59046173095703,
    "value_loss": 2.2159603238105774,
    "entropy": 0.3524632006883621,
    "total_loss": 183.66543677449226
  },
  {
    "episode": 251,
    "avg_reward_per_step": -11.27362833945919,
    "episode_length": 3000,
    "policy_loss": 163.47600173950195,
    "value_loss": 2.2837060689926147,
    "entropy": 0.3584463745355606,
    "total_loss": 165.61632925868034
  },
  {
    "episode": 252,
    "avg_reward_per_step": -11.869703839502188,
    "episode_length": 3000,
    "policy_loss": 173.0050163269043,
    "value_loss": 2.3109720945358276,
    "entropy": 0.36115114390850067,
    "total_loss": 175.1715279638767
  },
  {
    "episode": 253,
    "avg_reward_per_step": 76.52887624514555,
    "episode_length": 242,
    "policy_loss": -1327.6593322753906,
    "value_loss": 0.5660168379545212,
    "entropy": 0.37244172394275665,
    "total_loss": -1327.2422921270131
  },
  {
    "episode": 254,
    "avg_reward_per_step": -13.063520198042855,
    "episode_length": 3000,
    "policy_loss": 192.18653869628906,
    "value_loss": 3.004308342933655,
    "entropy": 0.35160548985004425,
    "total_loss": 195.0502048432827
  },
  {
    "episode": 255,
    "avg_reward_per_step": 86.84830729300964,
    "episode_length": 211,
    "policy_loss": -1501.3091125488281,
    "value_loss": 0.5753016322851181,
    "entropy": 0.37999100238084793,
    "total_loss": -1500.8858073174954
  },
  {
    "episode": 256,
    "avg_reward_per_step": -12.763191140817206,
    "episode_length": 3000,
    "policy_loss": 186.55434799194336,
    "value_loss": 2.6590309739112854,
    "entropy": 0.35154636204242706,
    "total_loss": 189.07276042103769
  },
  {
    "episode": 257,
    "avg_reward_per_step": -12.577443100805292,
    "episode_length": 3000,
    "policy_loss": 183.0958137512207,
    "value_loss": 2.3104010820388794,
    "entropy": 0.34962278604507446,
    "total_loss": 185.26636571884154
  },
  {
    "episode": 258,
    "avg_reward_per_step": -12.594913812033466,
    "episode_length": 3000,
    "policy_loss": 182.68168258666992,
    "value_loss": 2.239245653152466,
    "entropy": 0.3357793763279915,
    "total_loss": 184.7866164892912
  },
  {
    "episode": 259,
    "avg_reward_per_step": -12.759419939949165,
    "episode_length": 3000,
    "policy_loss": 185.00055694580078,
    "value_loss": 2.1735164523124695,
    "entropy": 0.3426639959216118,
    "total_loss": 187.0370077997446
  },
  {
    "episode": 260,
    "avg_reward_per_step": -12.841002097350557,
    "episode_length": 3000,
    "policy_loss": 185.67160415649414,
    "value_loss": 2.3391194343566895,
    "entropy": 0.35086433589458466,
    "total_loss": 187.870377856493
  },
  {
    "episode": 261,
    "avg_reward_per_step": -12.174146628345481,
    "episode_length": 3000,
    "policy_loss": 174.062255859375,
    "value_loss": 2.1036431789398193,
    "entropy": 0.3511240929365158,
    "total_loss": 176.0254494011402
  },
  {
    "episode": 262,
    "avg_reward_per_step": -12.133102430590109,
    "episode_length": 3000,
    "policy_loss": 172.71214294433594,
    "value_loss": 2.3830167651176453,
    "entropy": 0.34972934424877167,
    "total_loss": 174.95526797175407
  },
  {
    "episode": 263,
    "avg_reward_per_step": -12.153921388727031,
    "episode_length": 3000,
    "policy_loss": 172.4931755065918,
    "value_loss": 2.1992633938789368,
    "entropy": 0.35300546884536743,
    "total_loss": 174.5512367129326
  },
  {
    "episode": 264,
    "avg_reward_per_step": -12.101300407269807,
    "episode_length": 3000,
    "policy_loss": 170.7772102355957,
    "value_loss": 2.085464656352997,
    "entropy": 0.35427407175302505,
    "total_loss": 172.72096526324748
  },
  {
    "episode": 265,
    "avg_reward_per_step": 79.20032495730715,
    "episode_length": 230,
    "policy_loss": -1380.6010437011719,
    "value_loss": 0.567957416176796,
    "entropy": 0.36627092957496643,
    "total_loss": -1380.179594656825
  },
  {
    "episode": 266,
    "avg_reward_per_step": -12.77083545555082,
    "episode_length": 3000,
    "policy_loss": 181.22784042358398,
    "value_loss": 2.2708022594451904,
    "entropy": 0.33798976242542267,
    "total_loss": 183.363446778059
  },
  {
    "episode": 267,
    "avg_reward_per_step": 51.86266108012793,
    "episode_length": 335,
    "policy_loss": -917.2902374267578,
    "value_loss": 0.5410121530294418,
    "entropy": 0.3190983012318611,
    "total_loss": -916.8768645942212
  },
  {
    "episode": 268,
    "avg_reward_per_step": -13.05664431428266,
    "episode_length": 3000,
    "policy_loss": 184.6885223388672,
    "value_loss": 2.2372084856033325,
    "entropy": 0.31121743470430374,
    "total_loss": 186.8012438505888
  },
  {
    "episode": 269,
    "avg_reward_per_step": -12.817431374955293,
    "episode_length": 3000,
    "policy_loss": 180.1358871459961,
    "value_loss": 2.1580730080604553,
    "entropy": 0.2928769737482071,
    "total_loss": 182.17680936455727
  },
  {
    "episode": 270,
    "avg_reward_per_step": 50.28019619892974,
    "episode_length": 350,
    "policy_loss": -892.262451171875,
    "value_loss": 0.540355995297432,
    "entropy": 0.26286739110946655,
    "total_loss": -891.8272421330214
  },
  {
    "episode": 271,
    "avg_reward_per_step": -13.52924903894909,
    "episode_length": 3000,
    "policy_loss": 191.0060157775879,
    "value_loss": 2.288278341293335,
    "entropy": 0.23686760663986206,
    "total_loss": 193.1995470762253
  },
  {
    "episode": 272,
    "avg_reward_per_step": 49.25466604032117,
    "episode_length": 348,
    "policy_loss": -874.8741760253906,
    "value_loss": 0.5388074517250061,
    "entropy": 0.2723901644349098,
    "total_loss": -874.4443246394396
  },
  {
    "episode": 273,
    "avg_reward_per_step": 74.98973790693647,
    "episode_length": 243,
    "policy_loss": -1319.8959655761719,
    "value_loss": 0.5643956065177917,
    "entropy": 0.2730502188205719,
    "total_loss": -1319.4407900571823
  },
  {
    "episode": 274,
    "avg_reward_per_step": -12.405274884910005,
    "episode_length": 3000,
    "policy_loss": 171.12321090698242,
    "value_loss": 2.1162925362586975,
    "entropy": 0.3262368515133858,
    "total_loss": 173.10900870263578
  },
  {
    "episode": 275,
    "avg_reward_per_step": -3.731925159604834,
    "episode_length": 2435,
    "policy_loss": 23.29724359512329,
    "value_loss": 0.500226691365242,
    "entropy": 0.3044690415263176,
    "total_loss": 23.675682669878007
  },
  {
    "episode": 276,
    "avg_reward_per_step": -12.870090167448842,
    "episode_length": 3000,
    "policy_loss": 178.21104431152344,
    "value_loss": 2.2730273604393005,
    "entropy": 0.32992077618837357,
    "total_loss": 180.3521033614874
  },
  {
    "episode": 277,
    "avg_reward_per_step": -12.064735441158012,
    "episode_length": 3000,
    "policy_loss": 164.64033126831055,
    "value_loss": 2.2348495721817017,
    "entropy": 0.36772502213716507,
    "total_loss": 166.7280908316374
  },
  {
    "episode": 278,
    "avg_reward_per_step": -12.405200425444816,
    "episode_length": 3000,
    "policy_loss": 169.9241828918457,
    "value_loss": 2.2667899131774902,
    "entropy": 0.3917584717273712,
    "total_loss": 172.03426941633225
  },
  {
    "episode": 279,
    "avg_reward_per_step": -11.706238959470026,
    "episode_length": 3000,
    "policy_loss": 157.60739135742188,
    "value_loss": 2.239656984806061,
    "entropy": 0.4041752740740776,
    "total_loss": 159.6853782325983
  },
  {
    "episode": 280,
    "avg_reward_per_step": -11.6820220171071,
    "episode_length": 3000,
    "policy_loss": 156.41057968139648,
    "value_loss": 1.9655991792678833,
    "entropy": 0.4050426483154297,
    "total_loss": 158.2141618013382
  },
  {
    "episode": 281,
    "avg_reward_per_step": -11.871990110932883,
    "episode_length": 3000,
    "policy_loss": 158.4603500366211,
    "value_loss": 2.2768940329551697,
    "entropy": 0.37099621444940567,
    "total_loss": 160.5888455837965
  },
  {
    "episode": 282,
    "avg_reward_per_step": -11.01617967572296,
    "episode_length": 3000,
    "policy_loss": 143.9082260131836,
    "value_loss": 1.9561696350574493,
    "entropy": 0.42342129349708557,
    "total_loss": 145.69502713084222
  },
  {
    "episode": 283,
    "avg_reward_per_step": -11.667876499299297,
    "episode_length": 3000,
    "policy_loss": 153.76714706420898,
    "value_loss": 2.0230826437473297,
    "entropy": 0.41451161354780197,
    "total_loss": 155.6244250625372
  },
  {
    "episode": 284,
    "avg_reward_per_step": -11.815892600167926,
    "episode_length": 3000,
    "policy_loss": 155.43197631835938,
    "value_loss": 2.0369871854782104,
    "entropy": 0.43478672206401825,
    "total_loss": 157.29504881501197
  },
  {
    "episode": 285,
    "avg_reward_per_step": -11.379044922513188,
    "episode_length": 3000,
    "policy_loss": 147.5311737060547,
    "value_loss": 1.830665409564972,
    "entropy": 0.45915641635656357,
    "total_loss": 149.17817654907702
  },
  {
    "episode": 286,
    "avg_reward_per_step": 2.952935250773917,
    "episode_length": 1564,
    "policy_loss": -97.70504951477051,
    "value_loss": 0.5021752566099167,
    "entropy": 0.4221073240041733,
    "total_loss": -97.37171718776226
  },
  {
    "episode": 287,
    "avg_reward_per_step": 13.4216961189501,
    "episode_length": 894,
    "policy_loss": -277.0393600463867,
    "value_loss": 0.5096078515052795,
    "entropy": 0.4876007214188576,
    "total_loss": -276.724792483449
  },
  {
    "episode": 288,
    "avg_reward_per_step": -11.374315450722749,
    "episode_length": 3000,
    "policy_loss": 145.00496673583984,
    "value_loss": 1.9085149765014648,
    "entropy": 0.4586638882756233,
    "total_loss": 146.73001615703106
  },
  {
    "episode": 289,
    "avg_reward_per_step": 34.45825028055791,
    "episode_length": 470,
    "policy_loss": -637.0453338623047,
    "value_loss": 0.5270323157310486,
    "entropy": 0.5448129326105118,
    "total_loss": -636.7362267196179
  },
  {
    "episode": 290,
    "avg_reward_per_step": -1.865720786038727,
    "episode_length": 2920,
    "policy_loss": -17.393775463104248,
    "value_loss": 0.5003370940685272,
    "entropy": 0.5502681583166122,
    "total_loss": -17.113545632362367
  },
  {
    "episode": 291,
    "avg_reward_per_step": 87.87248788981053,
    "episode_length": 222,
    "policy_loss": -1548.8824462890625,
    "value_loss": 0.584855854511261,
    "entropy": 0.6408559232950211,
    "total_loss": -1548.5539328038692
  },
  {
    "episode": 292,
    "avg_reward_per_step": 10.809427608459579,
    "episode_length": 1037,
    "policy_loss": -232.9099998474121,
    "value_loss": 0.5071384310722351,
    "entropy": 0.597164049744606,
    "total_loss": -232.6417270362377
  },
  {
    "episode": 293,
    "avg_reward_per_step": 240.57955571348214,
    "episode_length": 83,
    "policy_loss": -4206.7662353515625,
    "value_loss": 0.8152135461568832,
    "entropy": 0.604944720864296,
    "total_loss": -4206.1929996937515
  },
  {
    "episode": 294,
    "avg_reward_per_step": -9.175484815019955,
    "episode_length": 3000,
    "policy_loss": 108.25824165344238,
    "value_loss": 1.577555239200592,
    "entropy": 0.49881429225206375,
    "total_loss": 109.63627117574215
  },
  {
    "episode": 295,
    "avg_reward_per_step": 78.06870251126816,
    "episode_length": 233,
    "policy_loss": -1379.7592468261719,
    "value_loss": 0.5679157674312592,
    "entropy": 0.3291795030236244,
    "total_loss": -1379.32300285995
  },
  {
    "episode": 296,
    "avg_reward_per_step": -11.016665160314284,
    "episode_length": 3000,
    "policy_loss": 137.8718147277832,
    "value_loss": 1.7681556344032288,
    "entropy": 0.3636874780058861,
    "total_loss": 139.49449537098408
  },
  {
    "episode": 297,
    "avg_reward_per_step": -2.8268675605064084,
    "episode_length": 2957,
    "policy_loss": -1.1981936395168304,
    "value_loss": 0.5002457350492477,
    "entropy": 0.3383944183588028,
    "total_loss": -0.8333056718111038
  },
  {
    "episode": 298,
    "avg_reward_per_step": 51.766089034673875,
    "episode_length": 335,
    "policy_loss": -937.1251525878906,
    "value_loss": 0.5418574064970016,
    "entropy": 0.23126878589391708,
    "total_loss": -936.6758026957511
  },
  {
    "episode": 299,
    "avg_reward_per_step": -10.389932979664449,
    "episode_length": 3000,
    "policy_loss": 126.56022644042969,
    "value_loss": 1.6000671982765198,
    "entropy": 0.36899711191654205,
    "total_loss": 128.0126947939396
  },
  {
    "episode": 300,
    "avg_reward_per_step": -10.526330438396332,
    "episode_length": 3000,
    "policy_loss": 128.4127082824707,
    "value_loss": 1.695886492729187,
    "entropy": 0.42184822261333466,
    "total_loss": 129.93985548615456
  }
]