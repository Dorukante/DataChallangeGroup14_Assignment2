[
  {
    "episode": 1,
    "avg_reward_per_step": 11.970024110662404,
    "episode_length": 1388,
    "policy_loss": -203.2144660949707,
    "value_loss": 0.5079076141119003,
    "entropy": 1.3783627450466156,
    "total_loss": -203.25790357887746
  },
  {
    "episode": 2,
    "avg_reward_per_step": -3.0220857120982685,
    "episode_length": 3000,
    "policy_loss": 50.64112091064453,
    "value_loss": 1.7067202031612396,
    "entropy": 1.3813938796520233,
    "total_loss": 51.79528356194496
  },
  {
    "episode": 3,
    "avg_reward_per_step": -2.5857632144291007,
    "episode_length": 3000,
    "policy_loss": 43.39576053619385,
    "value_loss": 1.5433430969715118,
    "entropy": 1.3803084790706635,
    "total_loss": 44.386980241537096
  },
  {
    "episode": 4,
    "avg_reward_per_step": 9.55505225367565,
    "episode_length": 1666,
    "policy_loss": -161.61906814575195,
    "value_loss": 0.5060351639986038,
    "entropy": 1.3742246329784393,
    "total_loss": -161.66272283494473
  },
  {
    "episode": 5,
    "avg_reward_per_step": 9.903282234835427,
    "episode_length": 1522,
    "policy_loss": -167.86106491088867,
    "value_loss": 0.5058679729700089,
    "entropy": 1.3729931116104126,
    "total_loss": -167.90439418256284
  },
  {
    "episode": 6,
    "avg_reward_per_step": -2.402625908985065,
    "episode_length": 3000,
    "policy_loss": 40.15188217163086,
    "value_loss": 1.558482676744461,
    "entropy": 1.3722843527793884,
    "total_loss": 41.16145110726357
  },
  {
    "episode": 7,
    "avg_reward_per_step": -2.411150486932577,
    "episode_length": 3000,
    "policy_loss": 40.34451484680176,
    "value_loss": 1.4158826768398285,
    "entropy": 1.3655503988265991,
    "total_loss": 41.214177364110945
  },
  {
    "episode": 8,
    "avg_reward_per_step": -2.2062239338116276,
    "episode_length": 3000,
    "policy_loss": 36.83702850341797,
    "value_loss": 1.6124572157859802,
    "entropy": 1.3622359931468964,
    "total_loss": 37.90459132194519
  },
  {
    "episode": 9,
    "avg_reward_per_step": -2.757501626309937,
    "episode_length": 3000,
    "policy_loss": 46.15183162689209,
    "value_loss": 1.5457560122013092,
    "entropy": 1.3628365099430084,
    "total_loss": 47.152453035116196
  },
  {
    "episode": 10,
    "avg_reward_per_step": -2.425471194762479,
    "episode_length": 3000,
    "policy_loss": 40.38991928100586,
    "value_loss": 1.634298175573349,
    "entropy": 1.3501412868499756,
    "total_loss": 41.48416094183922
  },
  {
    "episode": 11,
    "avg_reward_per_step": 5.623314507999946,
    "episode_length": 2554,
    "policy_loss": -95.25472450256348,
    "value_loss": 0.5031387805938721,
    "entropy": 1.342224270105362,
    "total_loss": -95.28847543001174
  },
  {
    "episode": 12,
    "avg_reward_per_step": 13.790118712838709,
    "episode_length": 1298,
    "policy_loss": -233.67773056030273,
    "value_loss": 0.5099444389343262,
    "entropy": 1.3491112291812897,
    "total_loss": -233.7074306130409
  },
  {
    "episode": 13,
    "avg_reward_per_step": 13.173147318558364,
    "episode_length": 1321,
    "policy_loss": -224.2708740234375,
    "value_loss": 0.5091886669397354,
    "entropy": 1.358872652053833,
    "total_loss": -224.3052344173193
  },
  {
    "episode": 14,
    "avg_reward_per_step": 54.82250753917218,
    "episode_length": 347,
    "policy_loss": -926.1269683837891,
    "value_loss": 0.5451519787311554,
    "entropy": 1.3457907736301422,
    "total_loss": -926.12013271451
  },
  {
    "episode": 15,
    "avg_reward_per_step": 21.184650826338693,
    "episode_length": 827,
    "policy_loss": -361.6008529663086,
    "value_loss": 0.5151331722736359,
    "entropy": 1.349548190832138,
    "total_loss": -361.62553907036784
  },
  {
    "episode": 16,
    "avg_reward_per_step": -3.0813163326786253,
    "episode_length": 3000,
    "policy_loss": 51.59922218322754,
    "value_loss": 1.4033034145832062,
    "entropy": 1.3595601320266724,
    "total_loss": 52.458701545000075
  },
  {
    "episode": 17,
    "avg_reward_per_step": 4.865295816334452,
    "episode_length": 2492,
    "policy_loss": -82.78757667541504,
    "value_loss": 0.5022386163473129,
    "entropy": 1.3542138040065765,
    "total_loss": -82.82702358067036
  },
  {
    "episode": 18,
    "avg_reward_per_step": 7.417366516120562,
    "episode_length": 1848,
    "policy_loss": -124.89346122741699,
    "value_loss": 0.5039283931255341,
    "entropy": 1.3446617126464844,
    "total_loss": -124.92739751935005
  },
  {
    "episode": 19,
    "avg_reward_per_step": 34.10699515456256,
    "episode_length": 531,
    "policy_loss": -576.0905151367188,
    "value_loss": 0.5256926864385605,
    "entropy": 1.3451703190803528,
    "total_loss": -576.1028905779124
  },
  {
    "episode": 20,
    "avg_reward_per_step": 33.98501093827963,
    "episode_length": 529,
    "policy_loss": -575.9301605224609,
    "value_loss": 0.5254261195659637,
    "entropy": 1.3373543918132782,
    "total_loss": -575.9396761596203
  },
  {
    "episode": 21,
    "avg_reward_per_step": 4.804584009665789,
    "episode_length": 2152,
    "policy_loss": -80.78826522827148,
    "value_loss": 0.5018180757761002,
    "entropy": 1.3421658873558044,
    "total_loss": -80.8233135074377
  },
  {
    "episode": 22,
    "avg_reward_per_step": 8.25382877910913,
    "episode_length": 1571,
    "policy_loss": -139.4347152709961,
    "value_loss": 0.5041453242301941,
    "entropy": 1.340853065252304,
    "total_loss": -139.46691117286682
  },
  {
    "episode": 23,
    "avg_reward_per_step": 35.75764761862314,
    "episode_length": 522,
    "policy_loss": -603.7731323242188,
    "value_loss": 0.5279589891433716,
    "entropy": 1.3440738916397095,
    "total_loss": -603.7828028917313
  },
  {
    "episode": 24,
    "avg_reward_per_step": -4.697222022460285,
    "episode_length": 3000,
    "policy_loss": 78.4284553527832,
    "value_loss": 2.096046566963196,
    "entropy": 1.3513231575489044,
    "total_loss": 79.98397265672683
  },
  {
    "episode": 25,
    "avg_reward_per_step": 13.446123585475608,
    "episode_length": 1071,
    "policy_loss": -229.21617889404297,
    "value_loss": 0.5076274573802948,
    "entropy": 1.3399008512496948,
    "total_loss": -229.24451177716256
  },
  {
    "episode": 26,
    "avg_reward_per_step": -4.194465085726682,
    "episode_length": 3000,
    "policy_loss": 70.07314109802246,
    "value_loss": 1.8417040705680847,
    "entropy": 1.3297903537750244,
    "total_loss": 71.38292902708054
  },
  {
    "episode": 27,
    "avg_reward_per_step": 12.927599403792918,
    "episode_length": 1146,
    "policy_loss": -219.09267807006836,
    "value_loss": 0.5075514167547226,
    "entropy": 1.307144671678543,
    "total_loss": -219.10798452198506
  },
  {
    "episode": 28,
    "avg_reward_per_step": 54.3791900449489,
    "episode_length": 343,
    "policy_loss": -923.7154541015625,
    "value_loss": 0.5437440574169159,
    "entropy": 1.3018504679203033,
    "total_loss": -923.6924502313137
  },
  {
    "episode": 29,
    "avg_reward_per_step": 71.3938095145304,
    "episode_length": 270,
    "policy_loss": -1211.9150390625,
    "value_loss": 0.5612581968307495,
    "entropy": 1.2730457782745361,
    "total_loss": -1211.862999176979
  },
  {
    "episode": 30,
    "avg_reward_per_step": 35.741813269200755,
    "episode_length": 492,
    "policy_loss": -608.1086730957031,
    "value_loss": 0.5261082202196121,
    "entropy": 1.2354503870010376,
    "total_loss": -608.076745030284
  },
  {
    "episode": 31,
    "avg_reward_per_step": 42.324414562131295,
    "episode_length": 425,
    "policy_loss": -716.0155487060547,
    "value_loss": 0.5319082885980606,
    "entropy": 1.193708747625351,
    "total_loss": -715.9611239165067
  },
  {
    "episode": 32,
    "avg_reward_per_step": 27.20956481071995,
    "episode_length": 645,
    "policy_loss": -461.2013244628906,
    "value_loss": 0.5196581184864044,
    "entropy": 1.185078740119934,
    "total_loss": -461.1556978404522
  },
  {
    "episode": 33,
    "avg_reward_per_step": 5.974946880400692,
    "episode_length": 1583,
    "policy_loss": -100.30573654174805,
    "value_loss": 0.5020112842321396,
    "entropy": 1.1344307661056519,
    "total_loss": -100.25749756395817
  },
  {
    "episode": 34,
    "avg_reward_per_step": 28.007317451616153,
    "episode_length": 626,
    "policy_loss": -473.7196502685547,
    "value_loss": 0.5202790051698685,
    "entropy": 1.1561936140060425,
    "total_loss": -473.66184870898724
  },
  {
    "episode": 35,
    "avg_reward_per_step": 9.82332554458113,
    "episode_length": 1292,
    "policy_loss": -165.4940948486328,
    "value_loss": 0.5047748535871506,
    "entropy": 1.1224342286586761,
    "total_loss": -165.43829368650913
  },
  {
    "episode": 36,
    "avg_reward_per_step": 71.42658517852921,
    "episode_length": 267,
    "policy_loss": -1223.2515563964844,
    "value_loss": 0.5606147199869156,
    "entropy": 1.160532832145691,
    "total_loss": -1223.1551548093557
  },
  {
    "episode": 37,
    "avg_reward_per_step": 8.39189710129724,
    "episode_length": 1692,
    "policy_loss": -141.31056213378906,
    "value_loss": 0.5046348124742508,
    "entropy": 1.1661643981933594,
    "total_loss": -141.27239308059217
  },
  {
    "episode": 38,
    "avg_reward_per_step": 27.332487343554,
    "episode_length": 643,
    "policy_loss": -461.92198944091797,
    "value_loss": 0.519620269536972,
    "entropy": 1.1419602930545807,
    "total_loss": -461.85915328860284
  },
  {
    "episode": 39,
    "avg_reward_per_step": 14.962133583769944,
    "episode_length": 1155,
    "policy_loss": -251.82104110717773,
    "value_loss": 0.5103984326124191,
    "entropy": 1.1350235044956207,
    "total_loss": -251.76465207636357
  },
  {
    "episode": 40,
    "avg_reward_per_step": 26.70592595440669,
    "episode_length": 702,
    "policy_loss": -449.67095947265625,
    "value_loss": 0.5206623822450638,
    "entropy": 1.088445097208023,
    "total_loss": -449.5856751292944
  },
  {
    "episode": 41,
    "avg_reward_per_step": 25.93648883759171,
    "episode_length": 711,
    "policy_loss": -439.2814407348633,
    "value_loss": 0.5196642577648163,
    "entropy": 1.087121844291687,
    "total_loss": -439.1966252148151
  },
  {
    "episode": 42,
    "avg_reward_per_step": 17.98273738404875,
    "episode_length": 1013,
    "policy_loss": -304.1839294433594,
    "value_loss": 0.5132861137390137,
    "entropy": 1.0941927433013916,
    "total_loss": -304.1083204269409
  },
  {
    "episode": 43,
    "avg_reward_per_step": 21.11644538371364,
    "episode_length": 844,
    "policy_loss": -355.81712341308594,
    "value_loss": 0.5153311491012573,
    "entropy": 1.1242595911026,
    "total_loss": -355.7514961004257
  },
  {
    "episode": 44,
    "avg_reward_per_step": 31.70640444593296,
    "episode_length": 598,
    "policy_loss": -536.5809631347656,
    "value_loss": 0.5250393599271774,
    "entropy": 1.1292303502559662,
    "total_loss": -536.5076159149409
  },
  {
    "episode": 45,
    "avg_reward_per_step": 13.613011272570384,
    "episode_length": 1306,
    "policy_loss": -229.42337036132812,
    "value_loss": 0.5097167491912842,
    "entropy": 1.1615857481956482,
    "total_loss": -229.3782879114151
  },
  {
    "episode": 46,
    "avg_reward_per_step": 21.185537484458823,
    "episode_length": 850,
    "policy_loss": -360.2494659423828,
    "value_loss": 0.5155503749847412,
    "entropy": 1.1734384596347809,
    "total_loss": -360.203290951252
  },
  {
    "episode": 47,
    "avg_reward_per_step": 39.162482524724865,
    "episode_length": 487,
    "policy_loss": -662.1196594238281,
    "value_loss": 0.5315058827400208,
    "entropy": 1.2095386683940887,
    "total_loss": -662.0719690084458
  },
  {
    "episode": 48,
    "avg_reward_per_step": 40.43784354318714,
    "episode_length": 456,
    "policy_loss": -682.7425079345703,
    "value_loss": 0.5313922315835953,
    "entropy": 1.1866815388202667,
    "total_loss": -682.6857883185148
  },
  {
    "episode": 49,
    "avg_reward_per_step": 93.4973910930897,
    "episode_length": 208,
    "policy_loss": -1594.4845275878906,
    "value_loss": 0.58498115837574,
    "entropy": 1.1950550079345703,
    "total_loss": -1594.3775684326888
  },
  {
    "episode": 50,
    "avg_reward_per_step": 34.61387042345246,
    "episode_length": 498,
    "policy_loss": -588.8003387451172,
    "value_loss": 0.5246342867612839,
    "entropy": 1.205225646495819,
    "total_loss": -588.7577947169542
  },
  {
    "episode": 51,
    "avg_reward_per_step": 60.56183560939535,
    "episode_length": 309,
    "policy_loss": -1018.2201843261719,
    "value_loss": 0.5495372265577316,
    "entropy": 1.2228830456733704,
    "total_loss": -1018.1598003178835
  },
  {
    "episode": 52,
    "avg_reward_per_step": 12.41438849238741,
    "episode_length": 1082,
    "policy_loss": -209.97573471069336,
    "value_loss": 0.5064553469419479,
    "entropy": 1.2237460017204285,
    "total_loss": -209.9587777644396
  },
  {
    "episode": 53,
    "avg_reward_per_step": 51.75233376570432,
    "episode_length": 355,
    "policy_loss": -875.3618621826172,
    "value_loss": 0.5407130271196365,
    "entropy": 1.2127277851104736,
    "total_loss": -875.3062402695417
  },
  {
    "episode": 54,
    "avg_reward_per_step": 18.17852043038558,
    "episode_length": 852,
    "policy_loss": -307.85408782958984,
    "value_loss": 0.5112374126911163,
    "entropy": 1.1859481036663055,
    "total_loss": -307.81722965836525
  },
  {
    "episode": 55,
    "avg_reward_per_step": 148.85316156877383,
    "episode_length": 131,
    "policy_loss": -2534.349609375,
    "value_loss": 0.6506795436143875,
    "entropy": 1.1796767115592957,
    "total_loss": -2534.1708005160094
  },
  {
    "episode": 56,
    "avg_reward_per_step": 64.4244853118844,
    "episode_length": 290,
    "policy_loss": -1081.7986145019531,
    "value_loss": 0.5529527813196182,
    "entropy": 1.1422162353992462,
    "total_loss": -1081.7025482147933
  },
  {
    "episode": 57,
    "avg_reward_per_step": 111.04191900074262,
    "episode_length": 178,
    "policy_loss": -1901.0602111816406,
    "value_loss": 0.6060966849327087,
    "entropy": 1.1259645819664001,
    "total_loss": -1900.9045003294946
  },
  {
    "episode": 58,
    "avg_reward_per_step": 75.2917870113934,
    "episode_length": 259,
    "policy_loss": -1270.5628967285156,
    "value_loss": 0.5662724077701569,
    "entropy": 1.0768858194351196,
    "total_loss": -1270.4273786485196
  },
  {
    "episode": 59,
    "avg_reward_per_step": 44.958882695339426,
    "episode_length": 418,
    "policy_loss": -760.2969970703125,
    "value_loss": 0.5359956920146942,
    "entropy": 1.0406555533409119,
    "total_loss": -760.1772635996342
  },
  {
    "episode": 60,
    "avg_reward_per_step": 17.266688363563762,
    "episode_length": 1032,
    "policy_loss": -292.37210845947266,
    "value_loss": 0.5124485194683075,
    "entropy": 1.0130389630794525,
    "total_loss": -292.2648755252361
  },
  {
    "episode": 61,
    "avg_reward_per_step": 21.953989476169795,
    "episode_length": 851,
    "policy_loss": -369.8065719604492,
    "value_loss": 0.5167610943317413,
    "entropy": 0.9820973128080368,
    "total_loss": -369.6826497912407
  },
  {
    "episode": 62,
    "avg_reward_per_step": 45.26068918323178,
    "episode_length": 427,
    "policy_loss": -762.9243469238281,
    "value_loss": 0.5373413860797882,
    "entropy": 0.9416376948356628,
    "total_loss": -762.7636606156826
  },
  {
    "episode": 63,
    "avg_reward_per_step": 17.646478901928337,
    "episode_length": 977,
    "policy_loss": -297.5631332397461,
    "value_loss": 0.5122572481632233,
    "entropy": 0.9555789828300476,
    "total_loss": -297.4331075847149
  },
  {
    "episode": 64,
    "avg_reward_per_step": 52.916889347460156,
    "episode_length": 361,
    "policy_loss": -892.8064117431641,
    "value_loss": 0.5436563193798065,
    "entropy": 0.9545090943574905,
    "total_loss": -892.6445590615273
  },
  {
    "episode": 65,
    "avg_reward_per_step": 58.14771371885897,
    "episode_length": 332,
    "policy_loss": -987.2572937011719,
    "value_loss": 0.549050897359848,
    "entropy": 0.9524229764938354,
    "total_loss": -987.0892119944095
  },
  {
    "episode": 66,
    "avg_reward_per_step": -2.574920465334557,
    "episode_length": 3000,
    "policy_loss": 42.85685348510742,
    "value_loss": 1.3465555012226105,
    "entropy": 1.005613386631012,
    "total_loss": 43.801163631677625
  },
  {
    "episode": 67,
    "avg_reward_per_step": 34.065781132230335,
    "episode_length": 546,
    "policy_loss": -574.1777496337891,
    "value_loss": 0.5264089852571487,
    "entropy": 0.9957185685634613,
    "total_loss": -574.0496280759573
  },
  {
    "episode": 68,
    "avg_reward_per_step": 62.91233554065029,
    "episode_length": 305,
    "policy_loss": -1060.5044555664062,
    "value_loss": 0.5529918372631073,
    "entropy": 0.9939502775669098,
    "total_loss": -1060.34904384017
  },
  {
    "episode": 69,
    "avg_reward_per_step": 17.976915267984193,
    "episode_length": 976,
    "policy_loss": -304.1249694824219,
    "value_loss": 0.5127391964197159,
    "entropy": 0.9908832460641861,
    "total_loss": -304.0085835844278
  },
  {
    "episode": 70,
    "avg_reward_per_step": 109.10731803815042,
    "episode_length": 182,
    "policy_loss": -1846.267578125,
    "value_loss": 0.6038886904716492,
    "entropy": 1.0020264238119125,
    "total_loss": -1846.0645000040531
  },
  {
    "episode": 71,
    "avg_reward_per_step": 12.530618846074942,
    "episode_length": 1246,
    "policy_loss": -214.0992088317871,
    "value_loss": 0.5077524185180664,
    "entropy": 0.9780501127243042,
    "total_loss": -213.98267645835875
  },
  {
    "episode": 72,
    "avg_reward_per_step": 28.303908739714405,
    "episode_length": 646,
    "policy_loss": -476.6713180541992,
    "value_loss": 0.5213438868522644,
    "entropy": 0.959478035569191,
    "total_loss": -476.53376538157465
  },
  {
    "episode": 73,
    "avg_reward_per_step": 26.79541550130323,
    "episode_length": 663,
    "policy_loss": -452.8017883300781,
    "value_loss": 0.5194989889860153,
    "entropy": 0.9711272269487381,
    "total_loss": -452.6707402318716
  },
  {
    "episode": 74,
    "avg_reward_per_step": 23.383204918439244,
    "episode_length": 789,
    "policy_loss": -394.6068878173828,
    "value_loss": 0.517673596739769,
    "entropy": 0.9461830258369446,
    "total_loss": -394.46768743097783
  },
  {
    "episode": 75,
    "avg_reward_per_step": -1.7001243258936325,
    "episode_length": 3000,
    "policy_loss": 28.118250370025635,
    "value_loss": 1.3902861773967743,
    "entropy": 0.9340517073869705,
    "total_loss": 29.134915864467622
  },
  {
    "episode": 76,
    "avg_reward_per_step": 42.40764469905622,
    "episode_length": 460,
    "policy_loss": -716.1939239501953,
    "value_loss": 0.5351641029119492,
    "entropy": 0.9183771163225174,
    "total_loss": -716.0261106938124
  },
  {
    "episode": 77,
    "avg_reward_per_step": 16.27516370026807,
    "episode_length": 1106,
    "policy_loss": -276.0102005004883,
    "value_loss": 0.5118326842784882,
    "entropy": 0.9369711875915527,
    "total_loss": -275.8731562912464
  },
  {
    "episode": 78,
    "avg_reward_per_step": 15.293653858822857,
    "episode_length": 1173,
    "policy_loss": -258.1807327270508,
    "value_loss": 0.5111000388860703,
    "entropy": 0.9417886734008789,
    "total_loss": -258.0463481575251
  },
  {
    "episode": 79,
    "avg_reward_per_step": 23.634549266593734,
    "episode_length": 803,
    "policy_loss": -398.83260345458984,
    "value_loss": 0.5184254795312881,
    "entropy": 0.9143158495426178,
    "total_loss": -398.6799043148756
  },
  {
    "episode": 80,
    "avg_reward_per_step": 9.430819618689055,
    "episode_length": 1790,
    "policy_loss": -159.55598068237305,
    "value_loss": 0.5063551664352417,
    "entropy": 0.9823360592126846,
    "total_loss": -159.44255993962287
  },
  {
    "episode": 81,
    "avg_reward_per_step": 63.318410224801674,
    "episode_length": 306,
    "policy_loss": -1071.7153625488281,
    "value_loss": 0.554083988070488,
    "entropy": 0.9609974771738052,
    "total_loss": -1071.5456775516273
  },
  {
    "episode": 82,
    "avg_reward_per_step": 35.719941354117815,
    "episode_length": 522,
    "policy_loss": -604.7754669189453,
    "value_loss": 0.527839869260788,
    "entropy": 1.006050169467926,
    "total_loss": -604.6500471174717
  },
  {
    "episode": 83,
    "avg_reward_per_step": 68.56539793514384,
    "episode_length": 284,
    "policy_loss": -1154.609130859375,
    "value_loss": 0.5595189183950424,
    "entropy": 0.9834185838699341,
    "total_loss": -1154.442979374528
  },
  {
    "episode": 84,
    "avg_reward_per_step": 36.649003247650214,
    "episode_length": 512,
    "policy_loss": -619.4413909912109,
    "value_loss": 0.5287545174360275,
    "entropy": 1.00135737657547,
    "total_loss": -619.3131794244051
  },
  {
    "episode": 85,
    "avg_reward_per_step": 25.316102417656158,
    "episode_length": 681,
    "policy_loss": -428.40799713134766,
    "value_loss": 0.5178355425596237,
    "entropy": 0.9979801625013351,
    "total_loss": -428.28935365378857
  },
  {
    "episode": 86,
    "avg_reward_per_step": 125.97001840403479,
    "episode_length": 157,
    "policy_loss": -2136.207763671875,
    "value_loss": 0.6241873353719711,
    "entropy": 0.9745330065488815,
    "total_loss": -2135.9733895391228
  },
  {
    "episode": 87,
    "avg_reward_per_step": 127.13490697267116,
    "episode_length": 154,
    "policy_loss": -2176.2637939453125,
    "value_loss": 0.6243966966867447,
    "entropy": 0.9804960191249847,
    "total_loss": -2176.031595656276
  },
  {
    "episode": 88,
    "avg_reward_per_step": 26.047773217941735,
    "episode_length": 646,
    "policy_loss": -443.0151138305664,
    "value_loss": 0.5177909433841705,
    "entropy": 0.9310666471719742,
    "total_loss": -442.869749546051
  },
  {
    "episode": 89,
    "avg_reward_per_step": 10.508942553423488,
    "episode_length": 1120,
    "policy_loss": -177.16697692871094,
    "value_loss": 0.5046430677175522,
    "entropy": 0.8767214417457581,
    "total_loss": -177.0130224376917
  },
  {
    "episode": 90,
    "avg_reward_per_step": -3.0570882755256266,
    "episode_length": 2964,
    "policy_loss": 51.08451843261719,
    "value_loss": 0.5009015202522278,
    "entropy": 0.8043071329593658,
    "total_loss": 51.26369709968567
  },
  {
    "episode": 91,
    "avg_reward_per_step": 38.792751038092746,
    "episode_length": 447,
    "policy_loss": -653.5152435302734,
    "value_loss": 0.5279244780540466,
    "entropy": 0.824889525771141,
    "total_loss": -653.3172748625278
  },
  {
    "episode": 92,
    "avg_reward_per_step": -1.7920254755605838,
    "episode_length": 2577,
    "policy_loss": 29.02969980239868,
    "value_loss": 0.5001224130392075,
    "entropy": 0.8002565503120422,
    "total_loss": 29.20971959531307
  },
  {
    "episode": 93,
    "avg_reward_per_step": 170.01695517393992,
    "episode_length": 116,
    "policy_loss": -2902.9769897460938,
    "value_loss": 0.6821747422218323,
    "entropy": 0.8781552463769913,
    "total_loss": -2902.6460771024226
  },
  {
    "episode": 94,
    "avg_reward_per_step": 6.702737191332027,
    "episode_length": 1538,
    "policy_loss": -111.76502990722656,
    "value_loss": 0.5025522112846375,
    "entropy": 0.8806295245885849,
    "total_loss": -111.61472950577736
  },
  {
    "episode": 95,
    "avg_reward_per_step": 57.84307325825329,
    "episode_length": 323,
    "policy_loss": -976.6380310058594,
    "value_loss": 0.5469771325588226,
    "entropy": 0.8723817616701126,
    "total_loss": -976.4400065779686
  },
  {
    "episode": 96,
    "avg_reward_per_step": 10.166543367928357,
    "episode_length": 1204,
    "policy_loss": -171.52231979370117,
    "value_loss": 0.5047101080417633,
    "entropy": 0.8802101165056229,
    "total_loss": -171.36969373226165
  },
  {
    "episode": 97,
    "avg_reward_per_step": 122.73781256893709,
    "episode_length": 161,
    "policy_loss": -2070.7044067382812,
    "value_loss": 0.6197886168956757,
    "entropy": 0.8945604562759399,
    "total_loss": -2070.442442303896
  },
  {
    "episode": 98,
    "avg_reward_per_step": 70.34890379819724,
    "episode_length": 276,
    "policy_loss": -1187.0933532714844,
    "value_loss": 0.5607786774635315,
    "entropy": 0.878534272313118,
    "total_loss": -1186.8839883029461
  },
  {
    "episode": 99,
    "avg_reward_per_step": 11.176671260862948,
    "episode_length": 1182,
    "policy_loss": -189.11170196533203,
    "value_loss": 0.5056976526975632,
    "entropy": 0.8738494515419006,
    "total_loss": -188.95554409325123
  },
  {
    "episode": 100,
    "avg_reward_per_step": 51.17110604546305,
    "episode_length": 365,
    "policy_loss": -863.7870330810547,
    "value_loss": 0.5411338955163956,
    "entropy": 0.8637948483228683,
    "total_loss": -863.5914171248675
  },
  {
    "episode": 101,
    "avg_reward_per_step": 36.56125146443062,
    "episode_length": 505,
    "policy_loss": -620.3177185058594,
    "value_loss": 0.5283845812082291,
    "entropy": 0.8674529492855072,
    "total_loss": -620.1363151043654
  },
  {
    "episode": 102,
    "avg_reward_per_step": 105.85141037000773,
    "episode_length": 186,
    "policy_loss": -1787.8507080078125,
    "value_loss": 0.599785789847374,
    "entropy": 0.8514277040958405,
    "total_loss": -1787.5914932996034
  },
  {
    "episode": 103,
    "avg_reward_per_step": 135.29781021322142,
    "episode_length": 147,
    "policy_loss": -2288.9285888671875,
    "value_loss": 0.6365080922842026,
    "entropy": 0.8205054104328156,
    "total_loss": -2288.6202829390763
  },
  {
    "episode": 104,
    "avg_reward_per_step": 101.9005380030987,
    "episode_length": 194,
    "policy_loss": -1721.2012634277344,
    "value_loss": 0.5958445966243744,
    "entropy": 0.7911226004362106,
    "total_loss": -1720.9218678712846
  },
  {
    "episode": 105,
    "avg_reward_per_step": 63.04731030389342,
    "episode_length": 307,
    "policy_loss": -1066.5537719726562,
    "value_loss": 0.554011344909668,
    "entropy": 0.795244961977005,
    "total_loss": -1066.3178586125373
  },
  {
    "episode": 106,
    "avg_reward_per_step": 16.688916392560937,
    "episode_length": 896,
    "policy_loss": -281.08558654785156,
    "value_loss": 0.5098413228988647,
    "entropy": 0.7880008667707443,
    "total_loss": -280.890945571661
  },
  {
    "episode": 107,
    "avg_reward_per_step": 122.74782058044299,
    "episode_length": 158,
    "policy_loss": -2079.16552734375,
    "value_loss": 0.6178104281425476,
    "entropy": 0.7843250334262848,
    "total_loss": -2078.861446928978
  },
  {
    "episode": 108,
    "avg_reward_per_step": 34.57249120786935,
    "episode_length": 540,
    "policy_loss": -586.1414642333984,
    "value_loss": 0.5268328040838242,
    "entropy": 0.7712128609418869,
    "total_loss": -585.9231165736913
  },
  {
    "episode": 109,
    "avg_reward_per_step": 82.20707780543331,
    "episode_length": 239,
    "policy_loss": -1404.5696716308594,
    "value_loss": 0.5737006664276123,
    "entropy": 0.7054110020399094,
    "total_loss": -1404.2781353652476
  },
  {
    "episode": 110,
    "avg_reward_per_step": 47.23257373333671,
    "episode_length": 411,
    "policy_loss": -789.7065124511719,
    "value_loss": 0.5393824577331543,
    "entropy": 0.6543098390102386,
    "total_loss": -789.4288539290428
  },
  {
    "episode": 111,
    "avg_reward_per_step": 36.03782533489154,
    "episode_length": 544,
    "policy_loss": -606.5485076904297,
    "value_loss": 0.5296976268291473,
    "entropy": 0.627343088388443,
    "total_loss": -606.269747298956
  },
  {
    "episode": 112,
    "avg_reward_per_step": 14.028024494444377,
    "episode_length": 1236,
    "policy_loss": -236.8170394897461,
    "value_loss": 0.5097433030605316,
    "entropy": 0.7428328394889832,
    "total_loss": -236.60442932248117
  },
  {
    "episode": 113,
    "avg_reward_per_step": 25.711368750746214,
    "episode_length": 729,
    "policy_loss": -433.0049819946289,
    "value_loss": 0.5198280662298203,
    "entropy": 0.6841214150190353,
    "total_loss": -432.7588024944067
  },
  {
    "episode": 114,
    "avg_reward_per_step": 14.94501296464965,
    "episode_length": 1193,
    "policy_loss": -252.08905410766602,
    "value_loss": 0.5107349455356598,
    "entropy": 0.6734208911657333,
    "total_loss": -251.84768751859664
  },
  {
    "episode": 115,
    "avg_reward_per_step": 21.770868775356195,
    "episode_length": 860,
    "policy_loss": -368.31742095947266,
    "value_loss": 0.5167033672332764,
    "entropy": 0.6557076573371887,
    "total_loss": -368.0630006551743
  },
  {
    "episode": 116,
    "avg_reward_per_step": 16.647224283206484,
    "episode_length": 1091,
    "policy_loss": -280.4982147216797,
    "value_loss": 0.5122458040714264,
    "entropy": 0.6560563743114471,
    "total_loss": -280.24839146733285
  },
  {
    "episode": 117,
    "avg_reward_per_step": 33.830858575276956,
    "episode_length": 573,
    "policy_loss": -571.4960479736328,
    "value_loss": 0.5274783819913864,
    "entropy": 0.6168359220027924,
    "total_loss": -571.2153039604425
  },
  {
    "episode": 118,
    "avg_reward_per_step": 106.32315748246259,
    "episode_length": 186,
    "policy_loss": -1795.9669494628906,
    "value_loss": 0.6005427688360214,
    "entropy": 0.7170394659042358,
    "total_loss": -1795.6532224804164
  },
  {
    "episode": 119,
    "avg_reward_per_step": 26.694617443485242,
    "episode_length": 712,
    "policy_loss": -449.9936218261719,
    "value_loss": 0.5209723263978958,
    "entropy": 0.6477129757404327,
    "total_loss": -449.73173469007014
  },
  {
    "episode": 120,
    "avg_reward_per_step": 156.1383891717541,
    "episode_length": 128,
    "policy_loss": -2643.121337890625,
    "value_loss": 0.6652379930019379,
    "entropy": 0.7337416559457779,
    "total_loss": -2642.7495965600015
  },
  {
    "episode": 121,
    "avg_reward_per_step": 163.51467897635985,
    "episode_length": 122,
    "policy_loss": -2761.4905395507812,
    "value_loss": 0.6759347021579742,
    "entropy": 0.6958962976932526,
    "total_loss": -2761.0929633677006
  },
  {
    "episode": 122,
    "avg_reward_per_step": 16.79583148279909,
    "episode_length": 1028,
    "policy_loss": -284.5352020263672,
    "value_loss": 0.5116712301969528,
    "entropy": 0.7056183218955994,
    "total_loss": -284.30577812492845
  },
  {
    "episode": 123,
    "avg_reward_per_step": 35.722036171998944,
    "episode_length": 497,
    "policy_loss": -602.9953460693359,
    "value_loss": 0.5262962132692337,
    "entropy": 0.7324551492929459,
    "total_loss": -602.7620319157838
  },
  {
    "episode": 124,
    "avg_reward_per_step": 46.26734283529293,
    "episode_length": 395,
    "policy_loss": -784.9647979736328,
    "value_loss": 0.5357642471790314,
    "entropy": 0.7374702990055084,
    "total_loss": -784.724021846056
  },
  {
    "episode": 125,
    "avg_reward_per_step": 25.500581395522566,
    "episode_length": 697,
    "policy_loss": -431.7495651245117,
    "value_loss": 0.5184829831123352,
    "entropy": 0.6983295828104019,
    "total_loss": -431.51041397452354
  },
  {
    "episode": 126,
    "avg_reward_per_step": 17.876762195710203,
    "episode_length": 865,
    "policy_loss": -300.45789337158203,
    "value_loss": 0.511039525270462,
    "entropy": 0.6994109004735947,
    "total_loss": -300.22661820650103
  },
  {
    "episode": 127,
    "avg_reward_per_step": 80.46030381581404,
    "episode_length": 238,
    "policy_loss": -1361.7658996582031,
    "value_loss": 0.5698403567075729,
    "entropy": 0.7270907759666443,
    "total_loss": -1361.4868956118821
  },
  {
    "episode": 128,
    "avg_reward_per_step": 85.253827701785,
    "episode_length": 228,
    "policy_loss": -1435.4442138671875,
    "value_loss": 0.5758519321680069,
    "entropy": 0.7152375876903534,
    "total_loss": -1435.1544569700957
  },
  {
    "episode": 129,
    "avg_reward_per_step": 36.04367914610959,
    "episode_length": 516,
    "policy_loss": -607.9578247070312,
    "value_loss": 0.5280042588710785,
    "entropy": 0.7215359956026077,
    "total_loss": -607.7184348464012
  },
  {
    "episode": 130,
    "avg_reward_per_step": 105.01904194381503,
    "episode_length": 188,
    "policy_loss": -1780.6053466796875,
    "value_loss": 0.598890095949173,
    "entropy": 0.6896668374538422,
    "total_loss": -1780.2823233187198
  },
  {
    "episode": 131,
    "avg_reward_per_step": 24.63481585310251,
    "episode_length": 752,
    "policy_loss": -414.3604507446289,
    "value_loss": 0.5187831819057465,
    "entropy": 0.6969967037439346,
    "total_loss": -414.1204662442207
  },
  {
    "episode": 132,
    "avg_reward_per_step": 98.68598362824982,
    "episode_length": 199,
    "policy_loss": -1680.9575500488281,
    "value_loss": 0.5916496366262436,
    "entropy": 0.7101169377565384,
    "total_loss": -1680.6499471873044
  },
  {
    "episode": 133,
    "avg_reward_per_step": 90.7717352582514,
    "episode_length": 215,
    "policy_loss": -1525.01904296875,
    "value_loss": 0.5821854770183563,
    "entropy": 0.7094609439373016,
    "total_loss": -1524.7206418693065
  },
  {
    "episode": 134,
    "avg_reward_per_step": 15.20329495942218,
    "episode_length": 934,
    "policy_loss": -256.62060546875,
    "value_loss": 0.5084190517663956,
    "entropy": 0.6663754433393478,
    "total_loss": -256.3787365943193
  },
  {
    "episode": 135,
    "avg_reward_per_step": 28.33981398155174,
    "episode_length": 587,
    "policy_loss": -478.2497787475586,
    "value_loss": 0.5191426873207092,
    "entropy": 0.6897706240415573,
    "total_loss": -478.0065443098545
  },
  {
    "episode": 136,
    "avg_reward_per_step": 174.72600888085384,
    "episode_length": 113,
    "policy_loss": -2980.6172485351562,
    "value_loss": 0.6899296790361404,
    "entropy": 0.706502377986908,
    "total_loss": -2980.2099198073147
  },
  {
    "episode": 137,
    "avg_reward_per_step": 23.703324132572508,
    "episode_length": 756,
    "policy_loss": -401.3666687011719,
    "value_loss": 0.5174369513988495,
    "entropy": 0.7120380848646164,
    "total_loss": -401.13404698371886
  },
  {
    "episode": 138,
    "avg_reward_per_step": 27.644905137693264,
    "episode_length": 641,
    "policy_loss": -463.73158264160156,
    "value_loss": 0.520028293132782,
    "entropy": 0.671032577753067,
    "total_loss": -463.47996737957
  },
  {
    "episode": 139,
    "avg_reward_per_step": 60.834480328186594,
    "episode_length": 325,
    "policy_loss": -1023.8213958740234,
    "value_loss": 0.5527100116014481,
    "entropy": 0.6644541323184967,
    "total_loss": -1023.5344675153494
  },
  {
    "episode": 140,
    "avg_reward_per_step": 106.58385004916687,
    "episode_length": 186,
    "policy_loss": -1799.4705810546875,
    "value_loss": 0.6012274473905563,
    "entropy": 0.6951013207435608,
    "total_loss": -1799.1473941355944
  },
  {
    "episode": 141,
    "avg_reward_per_step": 19.800152066333695,
    "episode_length": 911,
    "policy_loss": -334.1669692993164,
    "value_loss": 0.5145116597414017,
    "entropy": 0.6772901564836502,
    "total_loss": -333.9233737021685
  },
  {
    "episode": 142,
    "avg_reward_per_step": 47.072765610682296,
    "episode_length": 417,
    "policy_loss": -794.8498077392578,
    "value_loss": 0.5395345985889435,
    "entropy": 0.6248307228088379,
    "total_loss": -794.5602054297924
  },
  {
    "episode": 143,
    "avg_reward_per_step": 110.05913364203265,
    "episode_length": 178,
    "policy_loss": -1860.0344543457031,
    "value_loss": 0.604186087846756,
    "entropy": 0.6974125504493713,
    "total_loss": -1859.7092332780362
  },
  {
    "episode": 144,
    "avg_reward_per_step": 55.14224175762363,
    "episode_length": 357,
    "policy_loss": -930.5653686523438,
    "value_loss": 0.5471937507390976,
    "entropy": 0.6615414619445801,
    "total_loss": -930.2827914863825
  },
  {
    "episode": 145,
    "avg_reward_per_step": 12.898491251137173,
    "episode_length": 1246,
    "policy_loss": -217.66609954833984,
    "value_loss": 0.508275642991066,
    "entropy": 0.7563659250736237,
    "total_loss": -217.46037027537824
  },
  {
    "episode": 146,
    "avg_reward_per_step": 14.439697207496224,
    "episode_length": 1074,
    "policy_loss": -243.8600311279297,
    "value_loss": 0.5088705569505692,
    "entropy": 0.7491464614868164,
    "total_loss": -243.65081915557386
  },
  {
    "episode": 147,
    "avg_reward_per_step": 95.63860875104261,
    "episode_length": 203,
    "policy_loss": -1632.3087768554688,
    "value_loss": 0.5872075259685516,
    "entropy": 0.7120927572250366,
    "total_loss": -1632.0064064323901
  },
  {
    "episode": 148,
    "avg_reward_per_step": 55.62303330396592,
    "episode_length": 340,
    "policy_loss": -932.3352508544922,
    "value_loss": 0.5455563068389893,
    "entropy": 0.6940993666648865,
    "total_loss": -932.0673342943192
  },
  {
    "episode": 149,
    "avg_reward_per_step": 98.66269689957471,
    "episode_length": 197,
    "policy_loss": -1669.6254577636719,
    "value_loss": 0.5906868278980255,
    "entropy": 0.6613459885120392,
    "total_loss": -1669.2993093311786
  },
  {
    "episode": 150,
    "avg_reward_per_step": 16.133202388349613,
    "episode_length": 918,
    "policy_loss": -273.7844696044922,
    "value_loss": 0.5094654560089111,
    "entropy": 0.7108724117279053,
    "total_loss": -273.55935311317444
  },
  {
    "episode": 151,
    "avg_reward_per_step": 19.463807802169093,
    "episode_length": 870,
    "policy_loss": -327.5203170776367,
    "value_loss": 0.513221800327301,
    "entropy": 0.726279154419899,
    "total_loss": -327.29760693907735
  },
  {
    "episode": 152,
    "avg_reward_per_step": 47.04134901899895,
    "episode_length": 405,
    "policy_loss": -798.1918334960938,
    "value_loss": 0.5383064299821854,
    "entropy": 0.6619959473609924,
    "total_loss": -797.918325445056
  },
  {
    "episode": 153,
    "avg_reward_per_step": 66.54661605721266,
    "episode_length": 298,
    "policy_loss": -1122.2163391113281,
    "value_loss": 0.5585042983293533,
    "entropy": 0.5679889023303986,
    "total_loss": -1121.885030373931
  },
  {
    "episode": 154,
    "avg_reward_per_step": 22.08350182331348,
    "episode_length": 791,
    "policy_loss": -372.4987335205078,
    "value_loss": 0.515627920627594,
    "entropy": 0.6659659892320633,
    "total_loss": -372.24949199557307
  },
  {
    "episode": 155,
    "avg_reward_per_step": 10.340455132346003,
    "episode_length": 1444,
    "policy_loss": -174.67235946655273,
    "value_loss": 0.5060499906539917,
    "entropy": 0.6658011376857758,
    "total_loss": -174.43262993097306
  },
  {
    "episode": 156,
    "avg_reward_per_step": 118.70468495576286,
    "episode_length": 166,
    "policy_loss": -2007.4556579589844,
    "value_loss": 0.6150298416614532,
    "entropy": 0.6154834628105164,
    "total_loss": -2007.086821502447
  },
  {
    "episode": 157,
    "avg_reward_per_step": 23.43562571423877,
    "episode_length": 829,
    "policy_loss": -394.77337646484375,
    "value_loss": 0.5186927616596222,
    "entropy": 0.4827025830745697,
    "total_loss": -394.44776473641394
  },
  {
    "episode": 158,
    "avg_reward_per_step": 54.22051421952864,
    "episode_length": 353,
    "policy_loss": -916.2095184326172,
    "value_loss": 0.544745072722435,
    "entropy": 0.6338909566402435,
    "total_loss": -915.9183297425509
  },
  {
    "episode": 159,
    "avg_reward_per_step": 65.51294760108718,
    "episode_length": 303,
    "policy_loss": -1104.5129089355469,
    "value_loss": 0.5576056092977524,
    "entropy": 0.5555288940668106,
    "total_loss": -1104.1775148838758
  },
  {
    "episode": 160,
    "avg_reward_per_step": 22.809188833452584,
    "episode_length": 808,
    "policy_loss": -384.08079528808594,
    "value_loss": 0.5171144902706146,
    "entropy": 0.6068950295448303,
    "total_loss": -383.8064388096333
  },
  {
    "episode": 161,
    "avg_reward_per_step": -0.9556114554802889,
    "episode_length": 3000,
    "policy_loss": 15.500380516052246,
    "value_loss": 0.9879651218652725,
    "entropy": 0.4679679572582245,
    "total_loss": 16.301158455014228
  },
  {
    "episode": 162,
    "avg_reward_per_step": 12.04783473040556,
    "episode_length": 1365,
    "policy_loss": -203.3157958984375,
    "value_loss": 0.5078833997249603,
    "entropy": 0.6217391639947891,
    "total_loss": -203.05660816431046
  },
  {
    "episode": 163,
    "avg_reward_per_step": 5.584750848595059,
    "episode_length": 2837,
    "policy_loss": -94.47858047485352,
    "value_loss": 0.5034880340099335,
    "entropy": 0.5285046845674515,
    "total_loss": -94.18649431467057
  },
  {
    "episode": 164,
    "avg_reward_per_step": 19.672308965581063,
    "episode_length": 966,
    "policy_loss": -332.37085723876953,
    "value_loss": 0.5152357965707779,
    "entropy": 0.5565651208162308,
    "total_loss": -332.07824749052526
  },
  {
    "episode": 165,
    "avg_reward_per_step": 49.76828558197943,
    "episode_length": 388,
    "policy_loss": -840.5664520263672,
    "value_loss": 0.5413362830877304,
    "entropy": 0.6317225098609924,
    "total_loss": -840.2778047472239
  },
  {
    "episode": 166,
    "avg_reward_per_step": 31.088866486413277,
    "episode_length": 625,
    "policy_loss": -524.1133575439453,
    "value_loss": 0.5251302272081375,
    "entropy": 0.521571934223175,
    "total_loss": -523.7968560904264
  },
  {
    "episode": 167,
    "avg_reward_per_step": 66.32526708149878,
    "episode_length": 298,
    "policy_loss": -1125.5027770996094,
    "value_loss": 0.5580835044384003,
    "entropy": 0.5621701627969742,
    "total_loss": -1125.1695616602897
  },
  {
    "episode": 168,
    "avg_reward_per_step": 21.541411589156027,
    "episode_length": 876,
    "policy_loss": -363.57706451416016,
    "value_loss": 0.5166105329990387,
    "entropy": 0.576372817158699,
    "total_loss": -363.2910031080246
  },
  {
    "episode": 169,
    "avg_reward_per_step": 289.9020547148656,
    "episode_length": 69,
    "policy_loss": -4883.4444580078125,
    "value_loss": 0.9114997982978821,
    "entropy": 0.6504999548196793,
    "total_loss": -4882.793158191443
  },
  {
    "episode": 170,
    "avg_reward_per_step": 131.51437495807872,
    "episode_length": 150,
    "policy_loss": -2214.4288330078125,
    "value_loss": 0.6305311620235443,
    "entropy": 0.6654026061296463,
    "total_loss": -2214.064462888241
  },
  {
    "episode": 171,
    "avg_reward_per_step": 37.50759197383363,
    "episode_length": 463,
    "policy_loss": -632.6605377197266,
    "value_loss": 0.5270673185586929,
    "entropy": 0.6526465564966202,
    "total_loss": -632.3945290237665
  },
  {
    "episode": 172,
    "avg_reward_per_step": 98.00679278280217,
    "episode_length": 198,
    "policy_loss": -1654.3418579101562,
    "value_loss": 0.5887432992458344,
    "entropy": 0.6611232161521912,
    "total_loss": -1654.0175638973712
  },
  {
    "episode": 173,
    "avg_reward_per_step": 42.370596577326125,
    "episode_length": 439,
    "policy_loss": -713.9909210205078,
    "value_loss": 0.5332260280847549,
    "entropy": 0.648944079875946,
    "total_loss": -713.7172726243734
  },
  {
    "episode": 174,
    "avg_reward_per_step": 50.69422805590675,
    "episode_length": 359,
    "policy_loss": -854.4969940185547,
    "value_loss": 0.5391726344823837,
    "entropy": 0.6573444902896881,
    "total_loss": -854.2207591801882
  },
  {
    "episode": 175,
    "avg_reward_per_step": 23.21906271632066,
    "episode_length": 714,
    "policy_loss": -393.13001251220703,
    "value_loss": 0.5155488848686218,
    "entropy": 0.6420191377401352,
    "total_loss": -392.87127128243446
  },
  {
    "episode": 176,
    "avg_reward_per_step": 62.46731348483378,
    "episode_length": 311,
    "policy_loss": -1054.8448791503906,
    "value_loss": 0.5537013858556747,
    "entropy": 0.5962074995040894,
    "total_loss": -1054.5296607643365
  },
  {
    "episode": 177,
    "avg_reward_per_step": 50.54612191274925,
    "episode_length": 380,
    "policy_loss": -855.8137969970703,
    "value_loss": 0.541998103260994,
    "entropy": 0.5947117060422897,
    "total_loss": -855.5096835762263
  },
  {
    "episode": 178,
    "avg_reward_per_step": 39.13734225874559,
    "episode_length": 469,
    "policy_loss": -657.6574859619141,
    "value_loss": 0.5300917774438858,
    "entropy": 0.6275551170110703,
    "total_loss": -657.3784162312746
  },
  {
    "episode": 179,
    "avg_reward_per_step": 19.218589804882097,
    "episode_length": 763,
    "policy_loss": -324.86356353759766,
    "value_loss": 0.5110772103071213,
    "entropy": 0.6815032064914703,
    "total_loss": -324.62508760988715
  },
  {
    "episode": 180,
    "avg_reward_per_step": 114.98019188095448,
    "episode_length": 170,
    "policy_loss": -1939.9935607910156,
    "value_loss": 0.6094950288534164,
    "entropy": 0.6510447561740875,
    "total_loss": -1939.644483664632
  },
  {
    "episode": 181,
    "avg_reward_per_step": 31.10456661338388,
    "episode_length": 567,
    "policy_loss": -524.8390045166016,
    "value_loss": 0.5224605351686478,
    "entropy": 0.6368304789066315,
    "total_loss": -524.5712761729956
  },
  {
    "episode": 182,
    "avg_reward_per_step": 27.88430393221458,
    "episode_length": 632,
    "policy_loss": -471.26058197021484,
    "value_loss": 0.5200091302394867,
    "entropy": 0.6083770841360092,
    "total_loss": -470.98392367362976
  },
  {
    "episode": 183,
    "avg_reward_per_step": 144.1147044567095,
    "episode_length": 137,
    "policy_loss": -2442.6599731445312,
    "value_loss": 0.6474645137786865,
    "entropy": 0.6412835866212845,
    "total_loss": -2442.2690220654013
  },
  {
    "episode": 184,
    "avg_reward_per_step": 102.24481025072058,
    "episode_length": 193,
    "policy_loss": -1736.2490539550781,
    "value_loss": 0.5958570837974548,
    "entropy": 0.5862343162298203,
    "total_loss": -1735.8876905977727
  },
  {
    "episode": 185,
    "avg_reward_per_step": 26.57278072015443,
    "episode_length": 708,
    "policy_loss": -449.6204376220703,
    "value_loss": 0.5205892473459244,
    "entropy": 0.5440378040075302,
    "total_loss": -449.3174634963274
  },
  {
    "episode": 186,
    "avg_reward_per_step": 93.241513633327,
    "episode_length": 213,
    "policy_loss": -1582.5604248046875,
    "value_loss": 0.5863568484783173,
    "entropy": 0.6017392873764038,
    "total_loss": -1582.2147636711597
  },
  {
    "episode": 187,
    "avg_reward_per_step": 54.46423154856751,
    "episode_length": 350,
    "policy_loss": -916.6559906005859,
    "value_loss": 0.5448199510574341,
    "entropy": 0.6055584400892258,
    "total_loss": -916.3533940255642
  },
  {
    "episode": 188,
    "avg_reward_per_step": 41.5086551862809,
    "episode_length": 457,
    "policy_loss": -704.8753051757812,
    "value_loss": 0.5332419276237488,
    "entropy": 0.5645040273666382,
    "total_loss": -704.5678648591041
  },
  {
    "episode": 189,
    "avg_reward_per_step": 39.85242962180556,
    "episode_length": 492,
    "policy_loss": -668.5226745605469,
    "value_loss": 0.532987967133522,
    "entropy": 0.5242177546024323,
    "total_loss": -668.1993736952543
  },
  {
    "episode": 190,
    "avg_reward_per_step": 175.5312477035792,
    "episode_length": 114,
    "policy_loss": -2971.13525390625,
    "value_loss": 0.6939144432544708,
    "entropy": 0.587976723909378,
    "total_loss": -2970.6765301525593
  },
  {
    "episode": 191,
    "avg_reward_per_step": 7.7424156958515535,
    "episode_length": 2272,
    "policy_loss": -129.80231475830078,
    "value_loss": 0.505419135093689,
    "entropy": 0.4178249463438988,
    "total_loss": -129.46402560174465
  },
  {
    "episode": 192,
    "avg_reward_per_step": 14.545580530948218,
    "episode_length": 1248,
    "policy_loss": -245.06268310546875,
    "value_loss": 0.5106180608272552,
    "entropy": 0.427744559943676,
    "total_loss": -244.72316286861897
  },
  {
    "episode": 193,
    "avg_reward_per_step": 68.66661835116196,
    "episode_length": 288,
    "policy_loss": -1158.0141906738281,
    "value_loss": 0.5604100674390793,
    "entropy": 0.5402262806892395,
    "total_loss": -1157.6698711186648
  },
  {
    "episode": 194,
    "avg_reward_per_step": 74.63817570446076,
    "episode_length": 263,
    "policy_loss": -1270.0838012695312,
    "value_loss": 0.5656882077455521,
    "entropy": 0.6385762095451355,
    "total_loss": -1269.7735435456038
  },
  {
    "episode": 195,
    "avg_reward_per_step": 17.24230440882878,
    "episode_length": 1081,
    "policy_loss": -291.3060989379883,
    "value_loss": 0.5130185931921005,
    "entropy": 0.4994538426399231,
    "total_loss": -290.99286188185215
  },
  {
    "episode": 196,
    "avg_reward_per_step": 28.41663165300295,
    "episode_length": 668,
    "policy_loss": -479.3997116088867,
    "value_loss": 0.5222964733839035,
    "entropy": 0.5185017585754395,
    "total_loss": -479.08481583893297
  },
  {
    "episode": 197,
    "avg_reward_per_step": 53.88176987559676,
    "episode_length": 367,
    "policy_loss": -909.5041198730469,
    "value_loss": 0.5461873859167099,
    "entropy": 0.48471809923648834,
    "total_loss": -909.1518197268248
  },
  {
    "episode": 198,
    "avg_reward_per_step": 29.60966587411936,
    "episode_length": 628,
    "policy_loss": -499.6947937011719,
    "value_loss": 0.5227668583393097,
    "entropy": 0.5629341006278992,
    "total_loss": -499.39720048308374
  },
  {
    "episode": 199,
    "avg_reward_per_step": 51.55704979527561,
    "episode_length": 375,
    "policy_loss": -876.0795440673828,
    "value_loss": 0.5429615080356598,
    "entropy": 0.5957799553871155,
    "total_loss": -875.774894541502
  },
  {
    "episode": 200,
    "avg_reward_per_step": 18.64121021303057,
    "episode_length": 1024,
    "policy_loss": -313.78458404541016,
    "value_loss": 0.514493465423584,
    "entropy": 0.5019964650273323,
    "total_loss": -313.4708891659975
  },
  {
    "episode": 201,
    "avg_reward_per_step": 51.38107852206312,
    "episode_length": 379,
    "policy_loss": -870.6719207763672,
    "value_loss": 0.5430623143911362,
    "entropy": 0.5884614586830139,
    "total_loss": -870.3642430454493
  },
  {
    "episode": 202,
    "avg_reward_per_step": 90.51881903542503,
    "episode_length": 220,
    "policy_loss": -1530.5816040039062,
    "value_loss": 0.5835994482040405,
    "entropy": 0.5346770882606506,
    "total_loss": -1530.2118753910065
  },
  {
    "episode": 203,
    "avg_reward_per_step": 100.68453289410266,
    "episode_length": 197,
    "policy_loss": -1696.1269226074219,
    "value_loss": 0.5945561677217484,
    "entropy": 0.5048635303974152,
    "total_loss": -1695.734311851859
  },
  {
    "episode": 204,
    "avg_reward_per_step": 166.06827577852476,
    "episode_length": 120,
    "policy_loss": -2845.717529296875,
    "value_loss": 0.678874209523201,
    "entropy": 0.5883499830961227,
    "total_loss": -2845.2739950805903
  },
  {
    "episode": 205,
    "avg_reward_per_step": 34.782726070395,
    "episode_length": 548,
    "policy_loss": -588.5321044921875,
    "value_loss": 0.5276627987623215,
    "entropy": 0.5615579038858414,
    "total_loss": -588.2290648549795
  },
  {
    "episode": 206,
    "avg_reward_per_step": 94.40263353379622,
    "episode_length": 204,
    "policy_loss": -1619.5639953613281,
    "value_loss": 0.58494932949543,
    "entropy": 0.6429001539945602,
    "total_loss": -1619.2362060934306
  },
  {
    "episode": 207,
    "avg_reward_per_step": 20.320145763217962,
    "episode_length": 899,
    "policy_loss": -342.8495788574219,
    "value_loss": 0.515067994594574,
    "entropy": 0.5493668764829636,
    "total_loss": -342.5542576134205
  },
  {
    "episode": 208,
    "avg_reward_per_step": 58.96465054983243,
    "episode_length": 320,
    "policy_loss": -1000.2071380615234,
    "value_loss": 0.5481567084789276,
    "entropy": 0.6225362867116928,
    "total_loss": -999.9079958677291
  },
  {
    "episode": 209,
    "avg_reward_per_step": 9.997499002921478,
    "episode_length": 1244,
    "policy_loss": -170.68596649169922,
    "value_loss": 0.5047003775835037,
    "entropy": 0.6518957018852234,
    "total_loss": -170.4420243948698
  },
  {
    "episode": 210,
    "avg_reward_per_step": 154.40175955133168,
    "episode_length": 129,
    "policy_loss": -2619.548095703125,
    "value_loss": 0.6622420847415924,
    "entropy": 0.5395810306072235,
    "total_loss": -2619.1016860306263
  },
  {
    "episode": 211,
    "avg_reward_per_step": 183.24508828846342,
    "episode_length": 109,
    "policy_loss": -3083.74755859375,
    "value_loss": 0.705129936337471,
    "entropy": 0.5360564291477203,
    "total_loss": -3083.256851229072
  },
  {
    "episode": 212,
    "avg_reward_per_step": -2.7010093779997004,
    "episode_length": 2936,
    "policy_loss": 44.861473083496094,
    "value_loss": 0.5006372481584549,
    "entropy": 0.54183429479599,
    "total_loss": 45.145376613736154
  },
  {
    "episode": 213,
    "avg_reward_per_step": -9.100356737959986,
    "episode_length": 3000,
    "policy_loss": 152.24370574951172,
    "value_loss": 2.1792958974838257,
    "entropy": 0.5541324615478516,
    "total_loss": 154.2013486623764
  },
  {
    "episode": 214,
    "avg_reward_per_step": 68.86643452038976,
    "episode_length": 273,
    "policy_loss": -1164.1332397460938,
    "value_loss": 0.5576943010091782,
    "entropy": 0.5067202895879745,
    "total_loss": -1163.7782335609197
  },
  {
    "episode": 215,
    "avg_reward_per_step": 81.57508253306202,
    "episode_length": 229,
    "policy_loss": -1377.4657287597656,
    "value_loss": 0.5693432539701462,
    "entropy": 0.529137596487999,
    "total_loss": -1377.1080405443906
  },
  {
    "episode": 216,
    "avg_reward_per_step": 116.78453683030017,
    "episode_length": 166,
    "policy_loss": -1966.6680297851562,
    "value_loss": 0.610771507024765,
    "entropy": 0.550321102142334,
    "total_loss": -1966.2773867189885
  },
  {
    "episode": 217,
    "avg_reward_per_step": 91.43887931183156,
    "episode_length": 212,
    "policy_loss": -1541.3526306152344,
    "value_loss": 0.582681804895401,
    "entropy": 0.541138082742691,
    "total_loss": -1540.986404043436
  },
  {
    "episode": 218,
    "avg_reward_per_step": 12.215629973703122,
    "episode_length": 1009,
    "policy_loss": -206.7734031677246,
    "value_loss": 0.5057668387889862,
    "entropy": 0.5402309894561768,
    "total_loss": -206.4837287247181
  },
  {
    "episode": 219,
    "avg_reward_per_step": 27.989334116921057,
    "episode_length": 617,
    "policy_loss": -474.2047576904297,
    "value_loss": 0.5197032690048218,
    "entropy": 0.582375556230545,
    "total_loss": -473.9180046439171
  },
  {
    "episode": 220,
    "avg_reward_per_step": 9.301028691693357,
    "episode_length": 1205,
    "policy_loss": -157.81936264038086,
    "value_loss": 0.5038997828960419,
    "entropy": 0.5694140642881393,
    "total_loss": -157.54322848320007
  },
  {
    "episode": 221,
    "avg_reward_per_step": 1.0534834591992526,
    "episode_length": 2378,
    "policy_loss": -19.212080478668213,
    "value_loss": 0.49989431351423264,
    "entropy": 0.5944847911596298,
    "total_loss": -18.94998008161783
  },
  {
    "episode": 222,
    "avg_reward_per_step": 8.927200796333613,
    "episode_length": 1410,
    "policy_loss": -150.99010467529297,
    "value_loss": 0.5043084919452667,
    "entropy": 0.5578869134187698,
    "total_loss": -150.7089509487152
  },
  {
    "episode": 223,
    "avg_reward_per_step": 16.377048670111467,
    "episode_length": 868,
    "policy_loss": -277.04683685302734,
    "value_loss": 0.5091051310300827,
    "entropy": 0.5960696041584015,
    "total_loss": -276.7761595636606
  },
  {
    "episode": 224,
    "avg_reward_per_step": 45.14148513968483,
    "episode_length": 419,
    "policy_loss": -763.5618743896484,
    "value_loss": 0.5365637242794037,
    "entropy": 0.5307783782482147,
    "total_loss": -763.2376220166683
  },
  {
    "episode": 225,
    "avg_reward_per_step": 22.875993837675882,
    "episode_length": 731,
    "policy_loss": -385.83145904541016,
    "value_loss": 0.5154333412647247,
    "entropy": 0.5846197009086609,
    "total_loss": -385.5498735845089
  },
  {
    "episode": 226,
    "avg_reward_per_step": 17.063453808609363,
    "episode_length": 891,
    "policy_loss": -288.6773452758789,
    "value_loss": 0.5102519989013672,
    "entropy": 0.5832995921373367,
    "total_loss": -288.4004131138325
  },
  {
    "episode": 227,
    "avg_reward_per_step": 143.3689458228559,
    "episode_length": 139,
    "policy_loss": -2450.0538940429688,
    "value_loss": 0.6475033760070801,
    "entropy": 0.5684249699115753,
    "total_loss": -2449.6337606549264
  },
  {
    "episode": 228,
    "avg_reward_per_step": 17.17032046275764,
    "episode_length": 902,
    "policy_loss": -292.17415618896484,
    "value_loss": 0.5105506032705307,
    "entropy": 0.6027906537055969,
    "total_loss": -291.9047218471766
  },
  {
    "episode": 229,
    "avg_reward_per_step": 4.528171443374638,
    "episode_length": 1899,
    "policy_loss": -77.55630302429199,
    "value_loss": 0.5013371556997299,
    "entropy": 0.6548263281583786,
    "total_loss": -77.31689639985561
  },
  {
    "episode": 230,
    "avg_reward_per_step": 83.5320745837211,
    "episode_length": 230,
    "policy_loss": -1419.2776489257812,
    "value_loss": 0.5735867768526077,
    "entropy": 0.5390079617500305,
    "total_loss": -1418.9196653336287
  },
  {
    "episode": 231,
    "avg_reward_per_step": 7.545596216709516,
    "episode_length": 1552,
    "policy_loss": -127.26372337341309,
    "value_loss": 0.5033198744058609,
    "entropy": 0.6710493266582489,
    "total_loss": -127.02882322967052
  },
  {
    "episode": 232,
    "avg_reward_per_step": 10.689827140584017,
    "episode_length": 1264,
    "policy_loss": -180.4000244140625,
    "value_loss": 0.5055710673332214,
    "entropy": 0.6890684068202972,
    "total_loss": -180.1700807094574
  },
  {
    "episode": 233,
    "avg_reward_per_step": 125.34313464595373,
    "episode_length": 156,
    "policy_loss": -2121.640625,
    "value_loss": 0.622000977396965,
    "entropy": 0.6204140484333038,
    "total_loss": -2121.266789641976
  },
  {
    "episode": 234,
    "avg_reward_per_step": 132.81154881647757,
    "episode_length": 148,
    "policy_loss": -2251.5573120117188,
    "value_loss": 0.6318581700325012,
    "entropy": 0.6057274639606476,
    "total_loss": -2251.1677448272703
  },
  {
    "episode": 235,
    "avg_reward_per_step": 71.03214089292214,
    "episode_length": 274,
    "policy_loss": -1208.1423950195312,
    "value_loss": 0.5616978257894516,
    "entropy": 0.5492372661828995,
    "total_loss": -1207.800392100215
  },
  {
    "episode": 236,
    "avg_reward_per_step": 18.67036974383021,
    "episode_length": 913,
    "policy_loss": -316.8970947265625,
    "value_loss": 0.5127982497215271,
    "entropy": 0.6348165422677994,
    "total_loss": -316.6382230937481
  },
  {
    "episode": 237,
    "avg_reward_per_step": 48.39399317247313,
    "episode_length": 390,
    "policy_loss": -814.5851593017578,
    "value_loss": 0.5390529185533524,
    "entropy": 0.6377207040786743,
    "total_loss": -814.301194664836
  },
  {
    "episode": 238,
    "avg_reward_per_step": 38.627208313163734,
    "episode_length": 496,
    "policy_loss": -653.6001739501953,
    "value_loss": 0.5310992449522018,
    "entropy": 0.6305962949991226,
    "total_loss": -653.3213132232428
  },
  {
    "episode": 239,
    "avg_reward_per_step": 79.93005515571551,
    "episode_length": 247,
    "policy_loss": -1345.3827819824219,
    "value_loss": 0.5717526078224182,
    "entropy": 0.48746341466903687,
    "total_loss": -1345.006014740467
  },
  {
    "episode": 240,
    "avg_reward_per_step": 7.7402335630408485,
    "episode_length": 2264,
    "policy_loss": -130.98012161254883,
    "value_loss": 0.5054189264774323,
    "entropy": 0.4707433879375458,
    "total_loss": -130.66300004124642
  },
  {
    "episode": 241,
    "avg_reward_per_step": 46.57645211035294,
    "episode_length": 425,
    "policy_loss": -790.0589294433594,
    "value_loss": 0.5393718928098679,
    "entropy": 0.40680139511823654,
    "total_loss": -789.6822781085968
  },
  {
    "episode": 242,
    "avg_reward_per_step": 64.74075904001357,
    "episode_length": 306,
    "policy_loss": -1099.2711486816406,
    "value_loss": 0.5566540360450745,
    "entropy": 0.5017551109194756,
    "total_loss": -1098.9151966899633
  },
  {
    "episode": 243,
    "avg_reward_per_step": 177.02343765812813,
    "episode_length": 113,
    "policy_loss": -2980.616455078125,
    "value_loss": 0.6965421289205551,
    "entropy": 0.5596673339605331,
    "total_loss": -2980.1437798827887
  },
  {
    "episode": 244,
    "avg_reward_per_step": 29.10556880162958,
    "episode_length": 655,
    "policy_loss": -491.67749786376953,
    "value_loss": 0.522998109459877,
    "entropy": 0.5088558793067932,
    "total_loss": -491.35804210603237
  },
  {
    "episode": 245,
    "avg_reward_per_step": 123.60074831390111,
    "episode_length": 160,
    "policy_loss": -2086.2662353515625,
    "value_loss": 0.6212760955095291,
    "entropy": 0.5358534753322601,
    "total_loss": -2085.859300646186
  },
  {
    "episode": 246,
    "avg_reward_per_step": 53.48832472284914,
    "episode_length": 369,
    "policy_loss": -925.8029174804688,
    "value_loss": 0.5458078980445862,
    "entropy": 0.47746045887470245,
    "total_loss": -925.448093765974
  },
  {
    "episode": 247,
    "avg_reward_per_step": 74.17376272773645,
    "episode_length": 268,
    "policy_loss": -1248.8471069335938,
    "value_loss": 0.5662698894739151,
    "entropy": 0.4393812566995621,
    "total_loss": -1248.4565895467997
  },
  {
    "episode": 248,
    "avg_reward_per_step": 96.29142709326227,
    "episode_length": 207,
    "policy_loss": -1631.8052978515625,
    "value_loss": 0.590070828795433,
    "entropy": 0.46727778762578964,
    "total_loss": -1631.4021381378175
  },
  {
    "episode": 249,
    "avg_reward_per_step": 42.82538280851825,
    "episode_length": 452,
    "policy_loss": -725.1772918701172,
    "value_loss": 0.535163626074791,
    "entropy": 0.5176489800214767,
    "total_loss": -724.849187836051
  },
  {
    "episode": 250,
    "avg_reward_per_step": 12.801246552052811,
    "episode_length": 1433,
    "policy_loss": -214.93988800048828,
    "value_loss": 0.5094636976718903,
    "entropy": 0.45807377994060516,
    "total_loss": -214.61365381479263
  },
  {
    "episode": 251,
    "avg_reward_per_step": 16.310066431394212,
    "episode_length": 1171,
    "policy_loss": -275.1887512207031,
    "value_loss": 0.5126618891954422,
    "entropy": 0.410594180226326,
    "total_loss": -274.8403270035982
  },
  {
    "episode": 252,
    "avg_reward_per_step": 75.52484943451496,
    "episode_length": 263,
    "policy_loss": -1279.2369079589844,
    "value_loss": 0.5677429437637329,
    "entropy": 0.4475899115204811,
    "total_loss": -1278.8482009798288
  },
  {
    "episode": 253,
    "avg_reward_per_step": 27.994081456408136,
    "episode_length": 694,
    "policy_loss": -474.35076904296875,
    "value_loss": 0.5225349068641663,
    "entropy": 0.4574858024716377,
    "total_loss": -474.01122845709324
  },
  {
    "episode": 254,
    "avg_reward_per_step": 176.778577071599,
    "episode_length": 113,
    "policy_loss": -3018.9930419921875,
    "value_loss": 0.6956862807273865,
    "entropy": 0.5805415362119675,
    "total_loss": -3018.529572325945
  },
  {
    "episode": 255,
    "avg_reward_per_step": 18.454345230584536,
    "episode_length": 1032,
    "policy_loss": -304.58301544189453,
    "value_loss": 0.5143394619226456,
    "entropy": 0.44701216369867325,
    "total_loss": -304.2474808454514
  },
  {
    "episode": 256,
    "avg_reward_per_step": 22.677248853674282,
    "episode_length": 843,
    "policy_loss": -381.6448516845703,
    "value_loss": 0.5177536904811859,
    "entropy": 0.4471753090620041,
    "total_loss": -381.3059681177139
  },
  {
    "episode": 257,
    "avg_reward_per_step": 16.89936544027058,
    "episode_length": 1121,
    "policy_loss": -285.5648880004883,
    "value_loss": 0.513053685426712,
    "entropy": 0.4190768226981163,
    "total_loss": -285.2194650441408
  },
  {
    "episode": 258,
    "avg_reward_per_step": 9.09286810094563,
    "episode_length": 2027,
    "policy_loss": -153.3746566772461,
    "value_loss": 0.5067205131053925,
    "entropy": 0.3799423798918724,
    "total_loss": -153.01991311609746
  },
  {
    "episode": 259,
    "avg_reward_per_step": 14.253830085571439,
    "episode_length": 1318,
    "policy_loss": -240.7488670349121,
    "value_loss": 0.5108310729265213,
    "entropy": 0.4271295592188835,
    "total_loss": -240.40888778567313
  },
  {
    "episode": 260,
    "avg_reward_per_step": 10.948425460302754,
    "episode_length": 1710,
    "policy_loss": -185.11431884765625,
    "value_loss": 0.5082880854606628,
    "entropy": 0.38322261720895767,
    "total_loss": -184.75931980907916
  },
  {
    "episode": 261,
    "avg_reward_per_step": 27.294898814378296,
    "episode_length": 714,
    "policy_loss": -459.99178314208984,
    "value_loss": 0.5220347940921783,
    "entropy": 0.4119259640574455,
    "total_loss": -459.63451873362067
  },
  {
    "episode": 262,
    "avg_reward_per_step": 25.093708495228174,
    "episode_length": 776,
    "policy_loss": -424.63111114501953,
    "value_loss": 0.5201480239629745,
    "entropy": 0.418695330619812,
    "total_loss": -424.2784412533045
  },
  {
    "episode": 263,
    "avg_reward_per_step": 31.343810817646066,
    "episode_length": 622,
    "policy_loss": -528.0323028564453,
    "value_loss": 0.5254875868558884,
    "entropy": 0.4258110821247101,
    "total_loss": -527.6771397024393
  },
  {
    "episode": 264,
    "avg_reward_per_step": 56.043438152987626,
    "episode_length": 352,
    "policy_loss": -949.6648559570312,
    "value_loss": 0.5481292009353638,
    "entropy": 0.5299855172634125,
    "total_loss": -949.3287209630013
  },
  {
    "episode": 265,
    "avg_reward_per_step": 9.960483724296225,
    "episode_length": 1866,
    "policy_loss": -168.43850326538086,
    "value_loss": 0.5074411183595657,
    "entropy": 0.4204549938440323,
    "total_loss": -168.0992441445589
  },
  {
    "episode": 266,
    "avg_reward_per_step": 12.445486869792397,
    "episode_length": 1497,
    "policy_loss": -211.3648567199707,
    "value_loss": 0.5093738436698914,
    "entropy": 0.44940412789583206,
    "total_loss": -211.03524452745916
  },
  {
    "episode": 267,
    "avg_reward_per_step": 85.27038888279392,
    "episode_length": 232,
    "policy_loss": -1460.5889587402344,
    "value_loss": 0.5775286704301834,
    "entropy": 0.6071368753910065,
    "total_loss": -1460.2542848199605
  },
  {
    "episode": 268,
    "avg_reward_per_step": 55.44899129823568,
    "episode_length": 352,
    "policy_loss": -934.4780120849609,
    "value_loss": 0.5471139699220657,
    "entropy": 0.556757852435112,
    "total_loss": -934.153601256013
  },
  {
    "episode": 269,
    "avg_reward_per_step": 58.31563542672154,
    "episode_length": 338,
    "policy_loss": -983.798828125,
    "value_loss": 0.5501776486635208,
    "entropy": 0.5513599961996078,
    "total_loss": -983.4691944748163
  },
  {
    "episode": 270,
    "avg_reward_per_step": 53.674145204190275,
    "episode_length": 362,
    "policy_loss": -904.8261108398438,
    "value_loss": 0.5452786386013031,
    "entropy": 0.570346862077713,
    "total_loss": -904.5089709460735
  },
  {
    "episode": 271,
    "avg_reward_per_step": 145.32502429406156,
    "episode_length": 137,
    "policy_loss": -2451.17041015625,
    "value_loss": 0.6496051698923111,
    "entropy": 0.5992073267698288,
    "total_loss": -2450.760487917066
  },
  {
    "episode": 272,
    "avg_reward_per_step": 91.2164727374742,
    "episode_length": 216,
    "policy_loss": -1538.9065856933594,
    "value_loss": 0.5833255797624588,
    "entropy": 0.6173582375049591,
    "total_loss": -1538.570203408599
  },
  {
    "episode": 273,
    "avg_reward_per_step": 155.75599468800115,
    "episode_length": 128,
    "policy_loss": -2661.5574951171875,
    "value_loss": 0.6643790304660797,
    "entropy": 0.5958137661218643,
    "total_loss": -2661.13144159317
  },
  {
    "episode": 274,
    "avg_reward_per_step": 59.14401959629939,
    "episode_length": 332,
    "policy_loss": -1001.0440979003906,
    "value_loss": 0.5509308725595474,
    "entropy": 0.547197699546814,
    "total_loss": -1000.7120461076498
  },
  {
    "episode": 275,
    "avg_reward_per_step": 34.197101928122414,
    "episode_length": 566,
    "policy_loss": -578.0137939453125,
    "value_loss": 0.5278048813343048,
    "entropy": 0.5298340767621994,
    "total_loss": -577.697922694683
  },
  {
    "episode": 276,
    "avg_reward_per_step": 54.06154226415672,
    "episode_length": 361,
    "policy_loss": -913.8705291748047,
    "value_loss": 0.5457505732774734,
    "entropy": 0.6007234901189804,
    "total_loss": -913.5650679975748
  },
  {
    "episode": 277,
    "avg_reward_per_step": 44.813189145149416,
    "episode_length": 429,
    "policy_loss": -756.7153930664062,
    "value_loss": 0.5368124097585678,
    "entropy": 0.5996516644954681,
    "total_loss": -756.4184413224459
  },
  {
    "episode": 278,
    "avg_reward_per_step": 24.425993968159425,
    "episode_length": 764,
    "policy_loss": -412.7087097167969,
    "value_loss": 0.5186870992183685,
    "entropy": 0.6254957765340805,
    "total_loss": -412.44022092819216
  },
  {
    "episode": 279,
    "avg_reward_per_step": 47.62179434700364,
    "episode_length": 402,
    "policy_loss": -804.7489013671875,
    "value_loss": 0.5391658693552017,
    "entropy": 0.6395481526851654,
    "total_loss": -804.4655547589064
  },
  {
    "episode": 280,
    "avg_reward_per_step": 80.8425369848103,
    "episode_length": 242,
    "policy_loss": -1368.7449035644531,
    "value_loss": 0.5722935497760773,
    "entropy": 0.6097446233034134,
    "total_loss": -1368.4165078639985
  },
  {
    "episode": 281,
    "avg_reward_per_step": 100.61042547622804,
    "episode_length": 193,
    "policy_loss": -1701.158935546875,
    "value_loss": 0.5925647765398026,
    "entropy": 0.5940287709236145,
    "total_loss": -1700.8039822787046
  },
  {
    "episode": 282,
    "avg_reward_per_step": 128.47740411144332,
    "episode_length": 154,
    "policy_loss": -2171.6683349609375,
    "value_loss": 0.626974493265152,
    "entropy": 0.6223356276750565,
    "total_loss": -2171.290294718742
  },
  {
    "episode": 283,
    "avg_reward_per_step": 18.31422431428561,
    "episode_length": 974,
    "policy_loss": -308.8637008666992,
    "value_loss": 0.513176292181015,
    "entropy": 0.6025619059801102,
    "total_loss": -308.59154933691025
  },
  {
    "episode": 284,
    "avg_reward_per_step": 87.92978881486023,
    "episode_length": 224,
    "policy_loss": -1485.5670166015625,
    "value_loss": 0.5797422528266907,
    "entropy": 0.629912257194519,
    "total_loss": -1485.2392392516135
  },
  {
    "episode": 285,
    "avg_reward_per_step": 21.51842561253303,
    "episode_length": 862,
    "policy_loss": -361.76444244384766,
    "value_loss": 0.5162911266088486,
    "entropy": 0.6061831116676331,
    "total_loss": -361.49062456190586
  },
  {
    "episode": 286,
    "avg_reward_per_step": 31.0887654531241,
    "episode_length": 622,
    "policy_loss": -525.0591583251953,
    "value_loss": 0.525001123547554,
    "entropy": 0.5669965445995331,
    "total_loss": -524.7609558194875
  },
  {
    "episode": 287,
    "avg_reward_per_step": 40.83730024398767,
    "episode_length": 473,
    "policy_loss": -689.0372161865234,
    "value_loss": 0.5333552062511444,
    "entropy": 0.6149371266365051,
    "total_loss": -688.7498358309269
  },
  {
    "episode": 288,
    "avg_reward_per_step": 46.77413251050045,
    "episode_length": 415,
    "policy_loss": -791.1385345458984,
    "value_loss": 0.5389480292797089,
    "entropy": 0.5414108484983444,
    "total_loss": -790.8161508560181
  },
  {
    "episode": 289,
    "avg_reward_per_step": 24.576967521390667,
    "episode_length": 765,
    "policy_loss": -415.5642623901367,
    "value_loss": 0.5189633816480637,
    "entropy": 0.5929596424102783,
    "total_loss": -415.2824828654528
  },
  {
    "episode": 290,
    "avg_reward_per_step": 141.2242407497994,
    "episode_length": 141,
    "policy_loss": -2382.580322265625,
    "value_loss": 0.6444044709205627,
    "entropy": 0.5667306482791901,
    "total_loss": -2382.162610054016
  },
  {
    "episode": 291,
    "avg_reward_per_step": 11.193997542204812,
    "episode_length": 1552,
    "policy_loss": -189.79962921142578,
    "value_loss": 0.5077626407146454,
    "entropy": 0.5815611928701401,
    "total_loss": -189.5244910478592
  },
  {
    "episode": 292,
    "avg_reward_per_step": 63.966075480165074,
    "episode_length": 306,
    "policy_loss": -1082.9099426269531,
    "value_loss": 0.555154949426651,
    "entropy": 0.5646794438362122,
    "total_loss": -1082.5806594550609
  },
  {
    "episode": 293,
    "avg_reward_per_step": 79.34875580542347,
    "episode_length": 247,
    "policy_loss": -1337.3242797851562,
    "value_loss": 0.5706818848848343,
    "entropy": 0.5844102501869202,
    "total_loss": -1336.9873620003461
  },
  {
    "episode": 294,
    "avg_reward_per_step": 32.85842014165365,
    "episode_length": 575,
    "policy_loss": -559.9311981201172,
    "value_loss": 0.5258023589849472,
    "entropy": 0.5784246325492859,
    "total_loss": -559.636765614152
  },
  {
    "episode": 295,
    "avg_reward_per_step": 55.244773299798084,
    "episode_length": 354,
    "policy_loss": -936.3679046630859,
    "value_loss": 0.5469274073839188,
    "entropy": 0.5051222592592239,
    "total_loss": -936.0230261594057
  },
  {
    "episode": 296,
    "avg_reward_per_step": 15.033646657093968,
    "episode_length": 1252,
    "policy_loss": -252.74587631225586,
    "value_loss": 0.5114283114671707,
    "entropy": 0.44607073813676834,
    "total_loss": -252.4128762960434
  },
  {
    "episode": 297,
    "avg_reward_per_step": 48.45781025055064,
    "episode_length": 408,
    "policy_loss": -815.8875122070312,
    "value_loss": 0.5410584658384323,
    "entropy": 0.3904409781098366,
    "total_loss": -815.5026301324367
  },
  {
    "episode": 298,
    "avg_reward_per_step": 44.676761723818096,
    "episode_length": 440,
    "policy_loss": -752.2939758300781,
    "value_loss": 0.5373684763908386,
    "entropy": 0.42336512356996536,
    "total_loss": -751.9259534031153
  },
  {
    "episode": 299,
    "avg_reward_per_step": 53.364756987263554,
    "episode_length": 370,
    "policy_loss": -902.1489105224609,
    "value_loss": 0.5456256419420242,
    "entropy": 0.4855896830558777,
    "total_loss": -901.7975207537413
  },
  {
    "episode": 300,
    "avg_reward_per_step": 54.30176875761403,
    "episode_length": 360,
    "policy_loss": -924.1963806152344,
    "value_loss": 0.5460109710693359,
    "entropy": 0.5512514114379883,
    "total_loss": -923.8708702087403
  }
]