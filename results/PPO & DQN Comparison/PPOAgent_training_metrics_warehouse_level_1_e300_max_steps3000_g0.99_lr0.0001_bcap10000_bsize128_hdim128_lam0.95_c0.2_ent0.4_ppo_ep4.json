[
  {
    "episode": 1,
    "avg_reward_per_step": 23.197518938610784,
    "episode_length": 789,
    "policy_loss": -397.4329528808594,
    "value_loss": 0.5173210501670837,
    "entropy": 1.3712445199489594,
    "total_loss": -397.46412963867186
  },
  {
    "episode": 2,
    "avg_reward_per_step": -2.9172976347721447,
    "episode_length": 3000,
    "policy_loss": 48.878539085388184,
    "value_loss": 1.783541202545166,
    "entropy": 1.3711694180965424,
    "total_loss": 50.11361252069473
  },
  {
    "episode": 3,
    "avg_reward_per_step": 10.624446590128036,
    "episode_length": 1344,
    "policy_loss": -178.76212310791016,
    "value_loss": 0.5058846771717072,
    "entropy": 1.365773767232895,
    "total_loss": -178.8025479376316
  },
  {
    "episode": 4,
    "avg_reward_per_step": 3.935231749976366,
    "episode_length": 2592,
    "policy_loss": -66.48592376708984,
    "value_loss": 0.5014560371637344,
    "entropy": 1.3667751252651215,
    "total_loss": -66.53117778003215
  },
  {
    "episode": 5,
    "avg_reward_per_step": 14.45793136548856,
    "episode_length": 1094,
    "policy_loss": -244.4394302368164,
    "value_loss": 0.5090659260749817,
    "entropy": 1.3668379485607147,
    "total_loss": -244.4770994901657
  },
  {
    "episode": 6,
    "avg_reward_per_step": -3.0860942293809046,
    "episode_length": 3000,
    "policy_loss": 51.69301509857178,
    "value_loss": 1.5891079008579254,
    "entropy": 1.3615404665470123,
    "total_loss": 52.7375068128109
  },
  {
    "episode": 7,
    "avg_reward_per_step": -3.602037772509446,
    "episode_length": 3000,
    "policy_loss": 60.322203636169434,
    "value_loss": 1.7054360210895538,
    "entropy": 1.3562640845775604,
    "total_loss": 61.48513402342796
  },
  {
    "episode": 8,
    "avg_reward_per_step": 28.17793145252901,
    "episode_length": 644,
    "policy_loss": -475.91580963134766,
    "value_loss": 0.5209862142801285,
    "entropy": 1.3463435769081116,
    "total_loss": -475.9333608478308
  },
  {
    "episode": 9,
    "avg_reward_per_step": 7.640259548566778,
    "episode_length": 1940,
    "policy_loss": -128.84656524658203,
    "value_loss": 0.5044249147176743,
    "entropy": 1.3490414917469025,
    "total_loss": -128.8817569285631
  },
  {
    "episode": 10,
    "avg_reward_per_step": -2.9242650223723783,
    "episode_length": 3000,
    "policy_loss": 48.92948341369629,
    "value_loss": 1.6452921628952026,
    "entropy": 1.3440974056720734,
    "total_loss": 50.03713661432266
  },
  {
    "episode": 11,
    "avg_reward_per_step": 59.52802465019507,
    "episode_length": 329,
    "policy_loss": -1004.3663787841797,
    "value_loss": 0.5510401725769043,
    "entropy": 1.3359413146972656,
    "total_loss": -1004.3497151374817
  },
  {
    "episode": 12,
    "avg_reward_per_step": 17.269279090276648,
    "episode_length": 1001,
    "policy_loss": -291.8383331298828,
    "value_loss": 0.5120104104280472,
    "entropy": 1.3356992602348328,
    "total_loss": -291.8606024235487
  },
  {
    "episode": 13,
    "avg_reward_per_step": 68.58047341793208,
    "episode_length": 278,
    "policy_loss": -1157.831787109375,
    "value_loss": 0.5578455179929733,
    "entropy": 1.3187501430511475,
    "total_loss": -1157.8014416486026
  },
  {
    "episode": 14,
    "avg_reward_per_step": 30.15114471997702,
    "episode_length": 612,
    "policy_loss": -509.7552032470703,
    "value_loss": 0.5230399519205093,
    "entropy": 1.3097615838050842,
    "total_loss": -509.7560679286718
  },
  {
    "episode": 15,
    "avg_reward_per_step": -2.8630154647332753,
    "episode_length": 3000,
    "policy_loss": 47.90224361419678,
    "value_loss": 1.4203182756900787,
    "entropy": 1.312364399433136,
    "total_loss": 48.7976161301136
  },
  {
    "episode": 16,
    "avg_reward_per_step": 7.809489780118142,
    "episode_length": 1928,
    "policy_loss": -131.72024154663086,
    "value_loss": 0.5046010613441467,
    "entropy": 1.3002522587776184,
    "total_loss": -131.73574138879775
  },
  {
    "episode": 17,
    "avg_reward_per_step": 5.24917217461524,
    "episode_length": 2597,
    "policy_loss": -88.77930641174316,
    "value_loss": 0.5027633011341095,
    "entropy": 1.300257295370102,
    "total_loss": -88.7966460287571
  },
  {
    "episode": 18,
    "avg_reward_per_step": 35.26592390089553,
    "episode_length": 536,
    "policy_loss": -594.7821655273438,
    "value_loss": 0.5278527289628983,
    "entropy": 1.2722814083099365,
    "total_loss": -594.7632253617048
  },
  {
    "episode": 19,
    "avg_reward_per_step": 60.013267752002875,
    "episode_length": 323,
    "policy_loss": -1015.40673828125,
    "value_loss": 0.5507917255163193,
    "entropy": 1.2804323732852936,
    "total_loss": -1015.3681195050478
  },
  {
    "episode": 20,
    "avg_reward_per_step": 38.32929090148827,
    "episode_length": 479,
    "policy_loss": -646.1888427734375,
    "value_loss": 0.5294631868600845,
    "entropy": 1.249571830034256,
    "total_loss": -646.1592083185911
  },
  {
    "episode": 21,
    "avg_reward_per_step": 8.391309945047361,
    "episode_length": 1763,
    "policy_loss": -142.2545509338379,
    "value_loss": 0.5048439353704453,
    "entropy": 1.2555177509784698,
    "total_loss": -142.25191409885883
  },
  {
    "episode": 22,
    "avg_reward_per_step": 70.15376208036533,
    "episode_length": 278,
    "policy_loss": -1185.9881286621094,
    "value_loss": 0.5610794723033905,
    "entropy": 1.227871149778366,
    "total_loss": -1185.9181976497173
  },
  {
    "episode": 23,
    "avg_reward_per_step": 14.320845484534615,
    "episode_length": 1180,
    "policy_loss": -241.21441650390625,
    "value_loss": 0.5096612721681595,
    "entropy": 1.2122603356838226,
    "total_loss": -241.18965936601163
  },
  {
    "episode": 24,
    "avg_reward_per_step": 17.867244834255228,
    "episode_length": 1000,
    "policy_loss": -300.81580352783203,
    "value_loss": 0.5129135698080063,
    "entropy": 1.1818619966506958,
    "total_loss": -300.7756347566843
  },
  {
    "episode": 25,
    "avg_reward_per_step": 9.605093353856386,
    "episode_length": 1665,
    "policy_loss": -161.86974716186523,
    "value_loss": 0.5060714781284332,
    "entropy": 1.1724886298179626,
    "total_loss": -161.832671135664
  },
  {
    "episode": 26,
    "avg_reward_per_step": 39.88292645339091,
    "episode_length": 467,
    "policy_loss": -676.3391265869141,
    "value_loss": 0.5313462764024734,
    "entropy": 1.1519307494163513,
    "total_loss": -676.2685526102781
  },
  {
    "episode": 27,
    "avg_reward_per_step": 10.257141129594059,
    "episode_length": 1579,
    "policy_loss": -175.49541473388672,
    "value_loss": 0.5065808892250061,
    "entropy": 1.1950331628322601,
    "total_loss": -175.46684710979463
  },
  {
    "episode": 28,
    "avg_reward_per_step": 20.201160358217205,
    "episode_length": 894,
    "policy_loss": -339.80225372314453,
    "value_loss": 0.5147913843393326,
    "entropy": 1.1990008652210236,
    "total_loss": -339.76706268489363
  },
  {
    "episode": 29,
    "avg_reward_per_step": 68.7344570847954,
    "episode_length": 285,
    "policy_loss": -1164.7310180664062,
    "value_loss": 0.5600821822881699,
    "entropy": 1.1966224014759064,
    "total_loss": -1164.6495848447084
  },
  {
    "episode": 30,
    "avg_reward_per_step": 33.5478100392041,
    "episode_length": 553,
    "policy_loss": -563.55078125,
    "value_loss": 0.5258762985467911,
    "entropy": 1.1968604028224945,
    "total_loss": -563.5036491125823
  },
  {
    "episode": 31,
    "avg_reward_per_step": 65.963412393816,
    "episode_length": 291,
    "policy_loss": -1118.1196594238281,
    "value_loss": 0.5560631603002548,
    "entropy": 1.1835318207740784,
    "total_loss": -1118.0370089918374
  },
  {
    "episode": 32,
    "avg_reward_per_step": 64.8944676011908,
    "episode_length": 297,
    "policy_loss": -1100.3727111816406,
    "value_loss": 0.5552121251821518,
    "entropy": 1.209837168455124,
    "total_loss": -1100.3014339238405
  },
  {
    "episode": 33,
    "avg_reward_per_step": 24.82079013323709,
    "episode_length": 693,
    "policy_loss": -421.5873107910156,
    "value_loss": 0.5173702836036682,
    "entropy": 1.222023367881775,
    "total_loss": -421.55874985456467
  },
  {
    "episode": 34,
    "avg_reward_per_step": 39.95347973671403,
    "episode_length": 469,
    "policy_loss": -672.0254669189453,
    "value_loss": 0.5315543115139008,
    "entropy": 1.2285865545272827,
    "total_loss": -671.9853472292423
  },
  {
    "episode": 35,
    "avg_reward_per_step": 41.44485156540055,
    "episode_length": 455,
    "policy_loss": -701.3595733642578,
    "value_loss": 0.5330832451581955,
    "entropy": 1.2428623139858246,
    "total_loss": -701.3236350446939
  },
  {
    "episode": 36,
    "avg_reward_per_step": 35.87097839077872,
    "episode_length": 526,
    "policy_loss": -605.3214416503906,
    "value_loss": 0.5283023416996002,
    "entropy": 1.2443236410617828,
    "total_loss": -605.2908687651158
  },
  {
    "episode": 37,
    "avg_reward_per_step": 31.688273189084782,
    "episode_length": 592,
    "policy_loss": -533.7037658691406,
    "value_loss": 0.5247596651315689,
    "entropy": 1.254699170589447,
    "total_loss": -533.6808858722449
  },
  {
    "episode": 38,
    "avg_reward_per_step": 5.9498017045701195,
    "episode_length": 2329,
    "policy_loss": -100.56573867797852,
    "value_loss": 0.5031918883323669,
    "entropy": 1.2623158395290375,
    "total_loss": -100.56747312545777
  },
  {
    "episode": 39,
    "avg_reward_per_step": 11.810555953972306,
    "episode_length": 1381,
    "policy_loss": -199.2423439025879,
    "value_loss": 0.5076472908258438,
    "entropy": 1.2725309431552887,
    "total_loss": -199.24370898902416
  },
  {
    "episode": 40,
    "avg_reward_per_step": 56.82843701876063,
    "episode_length": 345,
    "policy_loss": -959.4647979736328,
    "value_loss": 0.5486340373754501,
    "entropy": 1.2629788219928741,
    "total_loss": -959.4213554650545
  },
  {
    "episode": 41,
    "avg_reward_per_step": 9.10473088887559,
    "episode_length": 1756,
    "policy_loss": -153.48789596557617,
    "value_loss": 0.5057437121868134,
    "entropy": 1.2671048939228058,
    "total_loss": -153.48899421095848
  },
  {
    "episode": 42,
    "avg_reward_per_step": 92.43948565517755,
    "episode_length": 211,
    "policy_loss": -1560.9238891601562,
    "value_loss": 0.5839311927556992,
    "entropy": 1.2547272145748138,
    "total_loss": -1560.8418488532304
  },
  {
    "episode": 43,
    "avg_reward_per_step": 18.85853030129129,
    "episode_length": 960,
    "policy_loss": -317.30865478515625,
    "value_loss": 0.5138501524925232,
    "entropy": 1.2605916857719421,
    "total_loss": -317.2990413069725
  },
  {
    "episode": 44,
    "avg_reward_per_step": 82.49071048030214,
    "episode_length": 238,
    "policy_loss": -1395.7292785644531,
    "value_loss": 0.5739254504442215,
    "entropy": 1.2626137435436249,
    "total_loss": -1395.6603986114264
  },
  {
    "episode": 45,
    "avg_reward_per_step": 36.229394428730195,
    "episode_length": 510,
    "policy_loss": -609.3407592773438,
    "value_loss": 0.527940645813942,
    "entropy": 1.2573294639587402,
    "total_loss": -609.3157504171133
  },
  {
    "episode": 46,
    "avg_reward_per_step": 16.204288434188193,
    "episode_length": 1081,
    "policy_loss": -273.55574798583984,
    "value_loss": 0.5114246755838394,
    "entropy": 1.267857551574707,
    "total_loss": -273.5514663308859
  },
  {
    "episode": 47,
    "avg_reward_per_step": 49.51183178555336,
    "episode_length": 389,
    "policy_loss": -836.274658203125,
    "value_loss": 0.5411173403263092,
    "entropy": 1.2527200281620026,
    "total_loss": -836.2346288740634
  },
  {
    "episode": 48,
    "avg_reward_per_step": 38.44248162139542,
    "episode_length": 485,
    "policy_loss": -650.4853210449219,
    "value_loss": 0.5300897508859634,
    "entropy": 1.252244085073471,
    "total_loss": -650.4561289280653
  },
  {
    "episode": 49,
    "avg_reward_per_step": 73.37680832543417,
    "episode_length": 265,
    "policy_loss": -1237.0457153320312,
    "value_loss": 0.564155787229538,
    "entropy": 1.2414052784442902,
    "total_loss": -1236.9781216561794
  },
  {
    "episode": 50,
    "avg_reward_per_step": 45.421465591173025,
    "episode_length": 410,
    "policy_loss": -766.3270111083984,
    "value_loss": 0.5359414964914322,
    "entropy": 1.2312992215156555,
    "total_loss": -766.2835893005133
  },
  {
    "episode": 51,
    "avg_reward_per_step": 45.33745806182711,
    "episode_length": 415,
    "policy_loss": -764.4424285888672,
    "value_loss": 0.5363003462553024,
    "entropy": 1.2507351636886597,
    "total_loss": -764.4064223080874
  },
  {
    "episode": 52,
    "avg_reward_per_step": 24.642876936317236,
    "episode_length": 739,
    "policy_loss": -415.07630920410156,
    "value_loss": 0.5184561908245087,
    "entropy": 1.2575719356536865,
    "total_loss": -415.0608817875385
  },
  {
    "episode": 53,
    "avg_reward_per_step": 13.186639709996083,
    "episode_length": 1227,
    "policy_loss": -222.5233039855957,
    "value_loss": 0.5084678828716278,
    "entropy": 1.2763065695762634,
    "total_loss": -222.5253587305546
  },
  {
    "episode": 54,
    "avg_reward_per_step": 98.22492626942692,
    "episode_length": 198,
    "policy_loss": -1661.9839172363281,
    "value_loss": 0.5900107771158218,
    "entropy": 1.2493408024311066,
    "total_loss": -1661.8936427801848
  },
  {
    "episode": 55,
    "avg_reward_per_step": 26.669422062422292,
    "episode_length": 664,
    "policy_loss": -450.74097442626953,
    "value_loss": 0.5194623172283173,
    "entropy": 1.2623853087425232,
    "total_loss": -450.7264662325382
  },
  {
    "episode": 56,
    "avg_reward_per_step": 60.3581928000919,
    "episode_length": 313,
    "policy_loss": -1022.6181182861328,
    "value_loss": 0.5496170669794083,
    "entropy": 1.2470545768737793,
    "total_loss": -1022.5673230499029
  },
  {
    "episode": 57,
    "avg_reward_per_step": 30.62089376747178,
    "episode_length": 598,
    "policy_loss": -514.1785736083984,
    "value_loss": 0.5232519060373306,
    "entropy": 1.2341665923595428,
    "total_loss": -514.1489883393049
  },
  {
    "episode": 58,
    "avg_reward_per_step": 87.24769193727731,
    "episode_length": 221,
    "policy_loss": -1473.2947082519531,
    "value_loss": 0.5774066299200058,
    "entropy": 1.2042627036571503,
    "total_loss": -1473.199006703496
  },
  {
    "episode": 59,
    "avg_reward_per_step": 55.69493665502269,
    "episode_length": 350,
    "policy_loss": -942.9731597900391,
    "value_loss": 0.5472967773675919,
    "entropy": 1.2208212912082672,
    "total_loss": -942.9141915291548
  },
  {
    "episode": 60,
    "avg_reward_per_step": 105.29347125736992,
    "episode_length": 184,
    "policy_loss": -1774.5719909667969,
    "value_loss": 0.5970046669244766,
    "entropy": 1.2003074884414673,
    "total_loss": -1774.455109295249
  },
  {
    "episode": 61,
    "avg_reward_per_step": 37.78009747385699,
    "episode_length": 494,
    "policy_loss": -637.5943756103516,
    "value_loss": 0.5295765846967697,
    "entropy": 1.192116141319275,
    "total_loss": -637.5416454821825
  },
  {
    "episode": 62,
    "avg_reward_per_step": 34.61273147331777,
    "episode_length": 542,
    "policy_loss": -584.068603515625,
    "value_loss": 0.5270399153232574,
    "entropy": 1.1989217698574066,
    "total_loss": -584.0211323082447
  },
  {
    "episode": 63,
    "avg_reward_per_step": 75.55367877227455,
    "episode_length": 252,
    "policy_loss": -1277.2339782714844,
    "value_loss": 0.5649116486310959,
    "entropy": 1.1546966433525085,
    "total_loss": -1277.1309452801943
  },
  {
    "episode": 64,
    "avg_reward_per_step": 53.59770655513557,
    "episode_length": 356,
    "policy_loss": -903.4856872558594,
    "value_loss": 0.5442638248205185,
    "entropy": 1.1653518974781036,
    "total_loss": -903.4075641900301
  },
  {
    "episode": 65,
    "avg_reward_per_step": 21.592808631352682,
    "episode_length": 807,
    "policy_loss": -364.5013198852539,
    "value_loss": 0.5152253657579422,
    "entropy": 1.1851463615894318,
    "total_loss": -364.46015306413176
  },
  {
    "episode": 66,
    "avg_reward_per_step": 4.451140756097865,
    "episode_length": 2419,
    "policy_loss": -75.08784484863281,
    "value_loss": 0.5017635673284531,
    "entropy": 1.1622994244098663,
    "total_loss": -75.05100105106831
  },
  {
    "episode": 67,
    "avg_reward_per_step": 19.125229265607324,
    "episode_length": 892,
    "policy_loss": -322.53040313720703,
    "value_loss": 0.5131415575742722,
    "entropy": 1.1459668278694153,
    "total_loss": -322.4756483107805
  },
  {
    "episode": 68,
    "avg_reward_per_step": 106.75689829966598,
    "episode_length": 181,
    "policy_loss": -1815.9332580566406,
    "value_loss": 0.5985503047704697,
    "entropy": 1.1190663278102875,
    "total_loss": -1815.7823342829943
  },
  {
    "episode": 69,
    "avg_reward_per_step": 168.84090016576184,
    "episode_length": 117,
    "policy_loss": -2844.3160400390625,
    "value_loss": 0.6814682930707932,
    "entropy": 1.1123724579811096,
    "total_loss": -2844.079520729184
  },
  {
    "episode": 70,
    "avg_reward_per_step": 20.45388950197326,
    "episode_length": 817,
    "policy_loss": -345.0584030151367,
    "value_loss": 0.5138086229562759,
    "entropy": 1.1201162040233612,
    "total_loss": -344.9926408737898
  },
  {
    "episode": 71,
    "avg_reward_per_step": 14.845645741909616,
    "episode_length": 1092,
    "policy_loss": -251.73834991455078,
    "value_loss": 0.5095739513635635,
    "entropy": 1.137509524822235,
    "total_loss": -251.6837797731161
  },
  {
    "episode": 72,
    "avg_reward_per_step": 88.5699387888372,
    "episode_length": 222,
    "policy_loss": -1492.966796875,
    "value_loss": 0.5806605815887451,
    "entropy": 1.1403535902500153,
    "total_loss": -1492.8422777295114
  },
  {
    "episode": 73,
    "avg_reward_per_step": 84.88705508133394,
    "episode_length": 227,
    "policy_loss": -1435.2393798828125,
    "value_loss": 0.5749213546514511,
    "entropy": 1.1361958980560303,
    "total_loss": -1435.1189368873834
  },
  {
    "episode": 74,
    "avg_reward_per_step": 16.578782607487277,
    "episode_length": 1020,
    "policy_loss": -279.7454528808594,
    "value_loss": 0.5112475752830505,
    "entropy": 1.1752241849899292,
    "total_loss": -279.7042949795723
  },
  {
    "episode": 75,
    "avg_reward_per_step": 115.53155718951417,
    "episode_length": 171,
    "policy_loss": -1957.7628173828125,
    "value_loss": 0.6114416718482971,
    "entropy": 1.1891475915908813,
    "total_loss": -1957.6270347476006
  },
  {
    "episode": 76,
    "avg_reward_per_step": 173.7843968745468,
    "episode_length": 114,
    "policy_loss": -2939.2675170898438,
    "value_loss": 0.689135953783989,
    "entropy": 1.1672369837760925,
    "total_loss": -2939.0452759295704
  },
  {
    "episode": 77,
    "avg_reward_per_step": 31.191504580948234,
    "episode_length": 591,
    "policy_loss": -525.6726989746094,
    "value_loss": 0.523875042796135,
    "entropy": 1.1759900450706482,
    "total_loss": -525.6192199498415
  },
  {
    "episode": 78,
    "avg_reward_per_step": 5.422554627182927,
    "episode_length": 2346,
    "policy_loss": -92.00844192504883,
    "value_loss": 0.502624899148941,
    "entropy": 1.1722476482391357,
    "total_loss": -91.97471608519554
  },
  {
    "episode": 79,
    "avg_reward_per_step": 80.95257057966728,
    "episode_length": 240,
    "policy_loss": -1364.8182678222656,
    "value_loss": 0.5714077055454254,
    "entropy": 1.1417254209518433,
    "total_loss": -1364.7035502851008
  },
  {
    "episode": 80,
    "avg_reward_per_step": 9.660080362557473,
    "episode_length": 1603,
    "policy_loss": -163.22282791137695,
    "value_loss": 0.5058825761079788,
    "entropy": 1.1674221456050873,
    "total_loss": -163.18391419351101
  },
  {
    "episode": 81,
    "avg_reward_per_step": 23.949055117458343,
    "episode_length": 755,
    "policy_loss": -403.41941833496094,
    "value_loss": 0.5177076905965805,
    "entropy": 1.1615846157073975,
    "total_loss": -403.3663444906473
  },
  {
    "episode": 82,
    "avg_reward_per_step": 46.847536442458924,
    "episode_length": 411,
    "policy_loss": -790.4899291992188,
    "value_loss": 0.5385859906673431,
    "entropy": 1.1652278900146484,
    "total_loss": -790.4174343645573
  },
  {
    "episode": 83,
    "avg_reward_per_step": 29.64985529277966,
    "episode_length": 610,
    "policy_loss": -502.86255645751953,
    "value_loss": 0.5221282988786697,
    "entropy": 1.1592295467853546,
    "total_loss": -502.804119977355
  },
  {
    "episode": 84,
    "avg_reward_per_step": 44.99999708699339,
    "episode_length": 419,
    "policy_loss": -761.2153167724609,
    "value_loss": 0.5360996276140213,
    "entropy": 1.1717998683452606,
    "total_loss": -761.147937092185
  },
  {
    "episode": 85,
    "avg_reward_per_step": 35.200512272400005,
    "episode_length": 513,
    "policy_loss": -591.9391021728516,
    "value_loss": 0.5264184921979904,
    "entropy": 1.181406706571579,
    "total_loss": -591.8852463632822
  },
  {
    "episode": 86,
    "avg_reward_per_step": 3.6575999659317064,
    "episode_length": 2791,
    "policy_loss": -61.50748252868652,
    "value_loss": 0.5013490468263626,
    "entropy": 1.204300731420517,
    "total_loss": -61.487853774428366
  },
  {
    "episode": 87,
    "avg_reward_per_step": 37.99778253674939,
    "episode_length": 475,
    "policy_loss": -640.9715270996094,
    "value_loss": 0.5286009609699249,
    "entropy": 1.1684711575508118,
    "total_loss": -640.9103146016598
  },
  {
    "episode": 88,
    "avg_reward_per_step": 27.733464599605252,
    "episode_length": 634,
    "policy_loss": -469.56348419189453,
    "value_loss": 0.5199689716100693,
    "entropy": 1.1822238564491272,
    "total_loss": -469.5164047628641
  },
  {
    "episode": 89,
    "avg_reward_per_step": 17.337200729622783,
    "episode_length": 992,
    "policy_loss": -291.8232192993164,
    "value_loss": 0.5119926333427429,
    "entropy": 1.2041257917881012,
    "total_loss": -291.7928769826889
  },
  {
    "episode": 90,
    "avg_reward_per_step": 34.378653926465745,
    "episode_length": 530,
    "policy_loss": -584.8621520996094,
    "value_loss": 0.5260802358388901,
    "entropy": 1.2012700736522675,
    "total_loss": -584.8165798932314
  },
  {
    "episode": 91,
    "avg_reward_per_step": 101.17785855311884,
    "episode_length": 195,
    "policy_loss": -1709.5423889160156,
    "value_loss": 0.5945060104131699,
    "entropy": 1.2082217633724213,
    "total_loss": -1709.4311716109514
  },
  {
    "episode": 92,
    "avg_reward_per_step": 28.525053516929518,
    "episode_length": 628,
    "policy_loss": -482.4500503540039,
    "value_loss": 0.520958885550499,
    "entropy": 1.2206731736660004,
    "total_loss": -482.4173607379198
  },
  {
    "episode": 93,
    "avg_reward_per_step": 36.587872413777625,
    "episode_length": 507,
    "policy_loss": -617.3231658935547,
    "value_loss": 0.5283550173044205,
    "entropy": 1.2124891877174377,
    "total_loss": -617.2798065513373
  },
  {
    "episode": 94,
    "avg_reward_per_step": 86.95073825146495,
    "episode_length": 223,
    "policy_loss": -1465.717041015625,
    "value_loss": 0.5774663090705872,
    "entropy": 1.1950609683990479,
    "total_loss": -1465.6175990939141
  },
  {
    "episode": 95,
    "avg_reward_per_step": 17.052098104242223,
    "episode_length": 965,
    "policy_loss": -287.8770217895508,
    "value_loss": 0.5112344175577164,
    "entropy": 1.2213979363441467,
    "total_loss": -287.85434654653073
  },
  {
    "episode": 96,
    "avg_reward_per_step": 15.05907907102897,
    "episode_length": 1028,
    "policy_loss": -254.45920944213867,
    "value_loss": 0.5092063695192337,
    "entropy": 1.2155928015708923,
    "total_loss": -254.43624019324778
  },
  {
    "episode": 97,
    "avg_reward_per_step": 11.404954746468679,
    "episode_length": 1225,
    "policy_loss": -191.92559814453125,
    "value_loss": 0.5061736702919006,
    "entropy": 1.2175396978855133,
    "total_loss": -191.90644035339355
  },
  {
    "episode": 98,
    "avg_reward_per_step": 65.25645528638228,
    "episode_length": 295,
    "policy_loss": -1102.552978515625,
    "value_loss": 0.5553847849369049,
    "entropy": 1.211481511592865,
    "total_loss": -1102.4821863353252
  },
  {
    "episode": 99,
    "avg_reward_per_step": 25.393787139361404,
    "episode_length": 689,
    "policy_loss": -427.6648712158203,
    "value_loss": 0.5181604325771332,
    "entropy": 1.2178282737731934,
    "total_loss": -427.63384209275245
  },
  {
    "episode": 100,
    "avg_reward_per_step": 19.775563849563685,
    "episode_length": 809,
    "policy_loss": -334.52909088134766,
    "value_loss": 0.5126269310712814,
    "entropy": 1.2077877223491669,
    "total_loss": -334.49957903921603
  },
  {
    "episode": 101,
    "avg_reward_per_step": 160.25181645124826,
    "episode_length": 124,
    "policy_loss": -2710.3901977539062,
    "value_loss": 0.6700246036052704,
    "entropy": 1.178930640220642,
    "total_loss": -2710.191745406389
  },
  {
    "episode": 102,
    "avg_reward_per_step": -3.2884932741534083,
    "episode_length": 3000,
    "policy_loss": 54.910502433776855,
    "value_loss": 1.4737176597118378,
    "entropy": 1.2213257849216461,
    "total_loss": 55.89568977952003
  },
  {
    "episode": 103,
    "avg_reward_per_step": 49.486127282007736,
    "episode_length": 387,
    "policy_loss": -831.7414855957031,
    "value_loss": 0.5406076312065125,
    "entropy": 1.2081076204776764,
    "total_loss": -831.6841210126877
  },
  {
    "episode": 104,
    "avg_reward_per_step": 76.70798805599716,
    "episode_length": 254,
    "policy_loss": -1295.3345031738281,
    "value_loss": 0.5672535747289658,
    "entropy": 1.2060833275318146,
    "total_loss": -1295.249682930112
  },
  {
    "episode": 105,
    "avg_reward_per_step": 52.625509387364424,
    "episode_length": 368,
    "policy_loss": -890.4106597900391,
    "value_loss": 0.5440543293952942,
    "entropy": 1.194007933139801,
    "total_loss": -890.3442086338997
  },
  {
    "episode": 106,
    "avg_reward_per_step": 58.088213438407784,
    "episode_length": 328,
    "policy_loss": -984.22607421875,
    "value_loss": 0.5480795204639435,
    "entropy": 1.1628073155879974,
    "total_loss": -984.1431176245212
  },
  {
    "episode": 107,
    "avg_reward_per_step": 13.394028359345409,
    "episode_length": 1256,
    "policy_loss": -226.99179458618164,
    "value_loss": 0.5089884698390961,
    "entropy": 1.155422955751419,
    "total_loss": -226.9449752986431
  },
  {
    "episode": 108,
    "avg_reward_per_step": 45.792627387573766,
    "episode_length": 426,
    "policy_loss": -770.5851745605469,
    "value_loss": 0.5381077229976654,
    "entropy": 1.145708978176117,
    "total_loss": -770.5053504288196
  },
  {
    "episode": 109,
    "avg_reward_per_step": 30.016413721722913,
    "episode_length": 635,
    "policy_loss": -506.2303161621094,
    "value_loss": 0.5237594842910767,
    "entropy": 1.0945205390453339,
    "total_loss": -506.14436489343643
  },
  {
    "episode": 110,
    "avg_reward_per_step": 23.20910863103218,
    "episode_length": 782,
    "policy_loss": -392.05809783935547,
    "value_loss": 0.5171754658222198,
    "entropy": 1.10317862033844,
    "total_loss": -391.9821938216686
  },
  {
    "episode": 111,
    "avg_reward_per_step": 41.32756749918017,
    "episode_length": 466,
    "policy_loss": -699.2403869628906,
    "value_loss": 0.5336840897798538,
    "entropy": 1.0816940665245056,
    "total_loss": -699.1393804997206
  },
  {
    "episode": 112,
    "avg_reward_per_step": 59.752435076416134,
    "episode_length": 322,
    "policy_loss": -1007.5340728759766,
    "value_loss": 0.5501184165477753,
    "entropy": 1.0642980337142944,
    "total_loss": -1007.4096736729146
  },
  {
    "episode": 113,
    "avg_reward_per_step": 55.08458576426027,
    "episode_length": 349,
    "policy_loss": -933.6400146484375,
    "value_loss": 0.5457904636859894,
    "entropy": 1.0566655099391937,
    "total_loss": -933.5168903887272
  },
  {
    "episode": 114,
    "avg_reward_per_step": 10.907195031490888,
    "episode_length": 1457,
    "policy_loss": -184.5270767211914,
    "value_loss": 0.5068448632955551,
    "entropy": 1.1154274642467499,
    "total_loss": -184.46640284359455
  },
  {
    "episode": 115,
    "avg_reward_per_step": 18.11772531908186,
    "episode_length": 932,
    "policy_loss": -305.9792785644531,
    "value_loss": 0.5122871845960617,
    "entropy": 1.083374798297882,
    "total_loss": -305.9003412991762
  },
  {
    "episode": 116,
    "avg_reward_per_step": 42.35799856620215,
    "episode_length": 443,
    "policy_loss": -713.8556976318359,
    "value_loss": 0.5336330085992813,
    "entropy": 1.0760401487350464,
    "total_loss": -713.7524806827307
  },
  {
    "episode": 117,
    "avg_reward_per_step": 144.0004957497707,
    "episode_length": 136,
    "policy_loss": -2431.3226928710938,
    "value_loss": 0.6454301476478577,
    "entropy": 1.0714706480503082,
    "total_loss": -2431.105850982666
  },
  {
    "episode": 118,
    "avg_reward_per_step": 33.98887582013882,
    "episode_length": 524,
    "policy_loss": -574.5824890136719,
    "value_loss": 0.525112509727478,
    "entropy": 1.0850290954113007,
    "total_loss": -574.4913881421089
  },
  {
    "episode": 119,
    "avg_reward_per_step": 51.22801265075284,
    "episode_length": 368,
    "policy_loss": -865.3678894042969,
    "value_loss": 0.5414263755083084,
    "entropy": 1.0872240364551544,
    "total_loss": -865.2613526433706
  },
  {
    "episode": 120,
    "avg_reward_per_step": 22.96433003679577,
    "episode_length": 720,
    "policy_loss": -388.17405700683594,
    "value_loss": 0.5153147280216217,
    "entropy": 1.063581258058548,
    "total_loss": -388.08417478203773
  },
  {
    "episode": 121,
    "avg_reward_per_step": 103.81038882381677,
    "episode_length": 189,
    "policy_loss": -1755.6359252929688,
    "value_loss": 0.5969094038009644,
    "entropy": 1.0423457622528076,
    "total_loss": -1755.455954194069
  },
  {
    "episode": 122,
    "avg_reward_per_step": 17.564895786104554,
    "episode_length": 929,
    "policy_loss": -296.63287353515625,
    "value_loss": 0.5114606767892838,
    "entropy": 1.0284226834774017,
    "total_loss": -296.53278193175794
  },
  {
    "episode": 123,
    "avg_reward_per_step": 72.1463735815705,
    "episode_length": 270,
    "policy_loss": -1214.9941101074219,
    "value_loss": 0.5629267692565918,
    "entropy": 1.0126258730888367,
    "total_loss": -1214.8362336874009
  },
  {
    "episode": 124,
    "avg_reward_per_step": 17.707999295679542,
    "episode_length": 903,
    "policy_loss": -300.7421188354492,
    "value_loss": 0.5112657994031906,
    "entropy": 1.0441082417964935,
    "total_loss": -300.64849633276464
  },
  {
    "episode": 125,
    "avg_reward_per_step": 61.289920801442406,
    "episode_length": 311,
    "policy_loss": -1036.224365234375,
    "value_loss": 0.5509942770004272,
    "entropy": 1.0627315938472748,
    "total_loss": -1036.0984635949135
  },
  {
    "episode": 126,
    "avg_reward_per_step": 61.884836602297646,
    "episode_length": 296,
    "policy_loss": -1043.1856689453125,
    "value_loss": 0.5493240356445312,
    "entropy": 1.0211040377616882,
    "total_loss": -1043.0447865247727
  },
  {
    "episode": 127,
    "avg_reward_per_step": 6.914131052238092,
    "episode_length": 1549,
    "policy_loss": -116.59781455993652,
    "value_loss": 0.5027174055576324,
    "entropy": 1.0000014752149582,
    "total_loss": -116.49509774446487
  },
  {
    "episode": 128,
    "avg_reward_per_step": 80.35265006541402,
    "episode_length": 240,
    "policy_loss": -1357.937744140625,
    "value_loss": 0.570230707526207,
    "entropy": 1.0590298771858215,
    "total_loss": -1357.7911253839732
  },
  {
    "episode": 129,
    "avg_reward_per_step": 57.03208802503264,
    "episode_length": 317,
    "policy_loss": -961.1812133789062,
    "value_loss": 0.5443795174360275,
    "entropy": 0.993942454457283,
    "total_loss": -961.0344108432531
  },
  {
    "episode": 130,
    "avg_reward_per_step": 28.87398745557261,
    "episode_length": 610,
    "policy_loss": -487.9419250488281,
    "value_loss": 0.5208385735750198,
    "entropy": 1.003539726138115,
    "total_loss": -487.8225023657084
  },
  {
    "episode": 131,
    "avg_reward_per_step": 57.15485082607692,
    "episode_length": 318,
    "policy_loss": -966.1018981933594,
    "value_loss": 0.5448116213083267,
    "entropy": 0.9781115353107452,
    "total_loss": -965.9483311861753
  },
  {
    "episode": 132,
    "avg_reward_per_step": 36.88110200694337,
    "episode_length": 492,
    "policy_loss": -621.0973968505859,
    "value_loss": 0.5279412120580673,
    "entropy": 1.0017947554588318,
    "total_loss": -620.9701735407114
  },
  {
    "episode": 133,
    "avg_reward_per_step": 30.056450824774092,
    "episode_length": 564,
    "policy_loss": -506.73130798339844,
    "value_loss": 0.520751342177391,
    "entropy": 0.987613171339035,
    "total_loss": -506.6056019097567
  },
  {
    "episode": 134,
    "avg_reward_per_step": 137.80374993446574,
    "episode_length": 142,
    "policy_loss": -2325.1853637695312,
    "value_loss": 0.6369316726922989,
    "entropy": 0.9855343997478485,
    "total_loss": -2324.942645856738
  },
  {
    "episode": 135,
    "avg_reward_per_step": 109.97341684543906,
    "episode_length": 179,
    "policy_loss": -1867.1196594238281,
    "value_loss": 0.6043796092271805,
    "entropy": 0.9916101098060608,
    "total_loss": -1866.9119238585233
  },
  {
    "episode": 136,
    "avg_reward_per_step": 17.078168795227093,
    "episode_length": 966,
    "policy_loss": -285.98243713378906,
    "value_loss": 0.5113292783498764,
    "entropy": 0.9893205910921097,
    "total_loss": -285.86683609187605
  },
  {
    "episode": 137,
    "avg_reward_per_step": 10.161546125030096,
    "episode_length": 1453,
    "policy_loss": -171.3227310180664,
    "value_loss": 0.5058571398258209,
    "entropy": 0.9968097358942032,
    "total_loss": -171.21559777259827
  },
  {
    "episode": 138,
    "avg_reward_per_step": 117.22709218280345,
    "episode_length": 169,
    "policy_loss": -1992.8877563476562,
    "value_loss": 0.6136454790830612,
    "entropy": 0.9619228392839432,
    "total_loss": -1992.6588800042869
  },
  {
    "episode": 139,
    "avg_reward_per_step": 145.85069858723182,
    "episode_length": 136,
    "policy_loss": -2459.8406982421875,
    "value_loss": 0.6508074104785919,
    "entropy": 0.8923655897378922,
    "total_loss": -2459.546837067604
  },
  {
    "episode": 140,
    "avg_reward_per_step": 91.07749826878515,
    "episode_length": 215,
    "policy_loss": -1548.7429504394531,
    "value_loss": 0.5828568637371063,
    "entropy": 0.9415486007928848,
    "total_loss": -1548.5367130160332
  },
  {
    "episode": 141,
    "avg_reward_per_step": 29.533278841705496,
    "episode_length": 628,
    "policy_loss": -495.57752990722656,
    "value_loss": 0.5226010382175446,
    "entropy": 0.9893774539232254,
    "total_loss": -495.4506798505783
  },
  {
    "episode": 142,
    "avg_reward_per_step": 52.808917685276654,
    "episode_length": 362,
    "policy_loss": -889.2937927246094,
    "value_loss": 0.5436079204082489,
    "entropy": 0.9829962253570557,
    "total_loss": -889.143383294344
  },
  {
    "episode": 143,
    "avg_reward_per_step": 10.352250306903073,
    "episode_length": 1578,
    "policy_loss": -174.62171173095703,
    "value_loss": 0.5066801607608795,
    "entropy": 1.0005682706832886,
    "total_loss": -174.51525887846947
  },
  {
    "episode": 144,
    "avg_reward_per_step": 51.82153411760365,
    "episode_length": 379,
    "policy_loss": -878.0579071044922,
    "value_loss": 0.5439695566892624,
    "entropy": 0.9704181402921677,
    "total_loss": -877.9021048039198
  },
  {
    "episode": 145,
    "avg_reward_per_step": 13.018875886702585,
    "episode_length": 1243,
    "policy_loss": -220.1214714050293,
    "value_loss": 0.508347675204277,
    "entropy": 0.9979903101921082,
    "total_loss": -220.01231985390186
  },
  {
    "episode": 146,
    "avg_reward_per_step": 37.692453560679795,
    "episode_length": 501,
    "policy_loss": -636.2124481201172,
    "value_loss": 0.5298091322183609,
    "entropy": 0.9984893798828125,
    "total_loss": -636.0820347398519
  },
  {
    "episode": 147,
    "avg_reward_per_step": 57.87755446788136,
    "episode_length": 327,
    "policy_loss": -975.6898345947266,
    "value_loss": 0.5475381463766098,
    "entropy": 0.9681871086359024,
    "total_loss": -975.5295712918044
  },
  {
    "episode": 148,
    "avg_reward_per_step": 90.6563346349655,
    "episode_length": 217,
    "policy_loss": -1534.1824035644531,
    "value_loss": 0.582821249961853,
    "entropy": 0.9572865515947342,
    "total_loss": -1533.9824969351291
  },
  {
    "episode": 149,
    "avg_reward_per_step": 50.390463471222105,
    "episode_length": 372,
    "policy_loss": -848.029296875,
    "value_loss": 0.5407090336084366,
    "entropy": 0.9655728042125702,
    "total_loss": -847.8748169630766
  },
  {
    "episode": 150,
    "avg_reward_per_step": 213.89011688305797,
    "episode_length": 93,
    "policy_loss": -3603.4610595703125,
    "value_loss": 0.754848450422287,
    "entropy": 0.9521132856607437,
    "total_loss": -3603.0870564341544
  },
  {
    "episode": 151,
    "avg_reward_per_step": 62.361113790237596,
    "episode_length": 313,
    "policy_loss": -1057.4407043457031,
    "value_loss": 0.553716167807579,
    "entropy": 0.9235176593065262,
    "total_loss": -1057.256395241618
  },
  {
    "episode": 152,
    "avg_reward_per_step": 15.27976124882829,
    "episode_length": 1039,
    "policy_loss": -256.71595001220703,
    "value_loss": 0.5096253603696823,
    "entropy": 0.9356905966997147,
    "total_loss": -256.58060089051725
  },
  {
    "episode": 153,
    "avg_reward_per_step": 29.166457582217987,
    "episode_length": 612,
    "policy_loss": -491.90059661865234,
    "value_loss": 0.5213814377784729,
    "entropy": 0.9173480570316315,
    "total_loss": -491.74615440368655
  },
  {
    "episode": 154,
    "avg_reward_per_step": 58.336301734516304,
    "episode_length": 318,
    "policy_loss": -988.1103515625,
    "value_loss": 0.5469380617141724,
    "entropy": 0.908751904964447,
    "total_loss": -987.9269142627716
  },
  {
    "episode": 155,
    "avg_reward_per_step": 29.57974897644281,
    "episode_length": 614,
    "policy_loss": -498.4722213745117,
    "value_loss": 0.5222363024950027,
    "entropy": 0.9218282550573349,
    "total_loss": -498.31871637403964
  },
  {
    "episode": 156,
    "avg_reward_per_step": 122.74576909570924,
    "episode_length": 162,
    "policy_loss": -2074.5777587890625,
    "value_loss": 0.6210992485284805,
    "entropy": 0.9221476465463638,
    "total_loss": -2074.3255185991525
  },
  {
    "episode": 157,
    "avg_reward_per_step": 30.039716240854435,
    "episode_length": 614,
    "policy_loss": -508.0874328613281,
    "value_loss": 0.5229769647121429,
    "entropy": 0.9233555942773819,
    "total_loss": -507.93379813432693
  },
  {
    "episode": 158,
    "avg_reward_per_step": 97.32644350662443,
    "episode_length": 201,
    "policy_loss": -1652.2275390625,
    "value_loss": 0.5893586426973343,
    "entropy": 0.9207915365695953,
    "total_loss": -1652.0064970344306
  },
  {
    "episode": 159,
    "avg_reward_per_step": 39.17017502036407,
    "episode_length": 482,
    "policy_loss": -658.2855987548828,
    "value_loss": 0.5311718583106995,
    "entropy": 0.9273949265480042,
    "total_loss": -658.1253848671913
  },
  {
    "episode": 160,
    "avg_reward_per_step": 12.615989827986562,
    "episode_length": 1320,
    "policy_loss": -212.8034324645996,
    "value_loss": 0.5083529502153397,
    "entropy": 0.9462751597166061,
    "total_loss": -212.6735895782709
  },
  {
    "episode": 161,
    "avg_reward_per_step": 88.8961456038014,
    "episode_length": 223,
    "policy_loss": -1501.995849609375,
    "value_loss": 0.5818028151988983,
    "entropy": 0.8796786218881607,
    "total_loss": -1501.7659182429313
  },
  {
    "episode": 162,
    "avg_reward_per_step": 77.29241078430034,
    "episode_length": 253,
    "policy_loss": -1301.9295654296875,
    "value_loss": 0.5683794617652893,
    "entropy": 0.9159762561321259,
    "total_loss": -1301.727576470375
  },
  {
    "episode": 163,
    "avg_reward_per_step": 74.99768867130635,
    "episode_length": 263,
    "policy_loss": -1264.0087280273438,
    "value_loss": 0.5668750703334808,
    "entropy": 0.8929391801357269,
    "total_loss": -1263.7990286290647
  },
  {
    "episode": 164,
    "avg_reward_per_step": 10.572517767844502,
    "episode_length": 1570,
    "policy_loss": -178.59667205810547,
    "value_loss": 0.5069408714771271,
    "entropy": 0.9445106983184814,
    "total_loss": -178.46753546595573
  },
  {
    "episode": 165,
    "avg_reward_per_step": 6.00268894347367,
    "episode_length": 2437,
    "policy_loss": -101.6460189819336,
    "value_loss": 0.5033994913101196,
    "entropy": 0.9529050290584564,
    "total_loss": -101.52378150224686
  },
  {
    "episode": 166,
    "avg_reward_per_step": 25.63975806328653,
    "episode_length": 738,
    "policy_loss": -431.8102722167969,
    "value_loss": 0.519985020160675,
    "entropy": 0.9335312396287918,
    "total_loss": -431.66369969248774
  },
  {
    "episode": 167,
    "avg_reward_per_step": 51.98445140240044,
    "episode_length": 369,
    "policy_loss": -878.5017700195312,
    "value_loss": 0.5429160594940186,
    "entropy": 0.8814532160758972,
    "total_loss": -878.3114352464676
  },
  {
    "episode": 168,
    "avg_reward_per_step": 30.586192895845798,
    "episode_length": 613,
    "policy_loss": -515.9413146972656,
    "value_loss": 0.5237361341714859,
    "entropy": 0.9330441057682037,
    "total_loss": -515.7907962054014
  },
  {
    "episode": 169,
    "avg_reward_per_step": 73.81386474204884,
    "episode_length": 267,
    "policy_loss": -1245.1155395507812,
    "value_loss": 0.5654683262109756,
    "entropy": 0.948339581489563,
    "total_loss": -1244.9294070571661
  },
  {
    "episode": 170,
    "avg_reward_per_step": 22.443632956233,
    "episode_length": 822,
    "policy_loss": -376.4606628417969,
    "value_loss": 0.516874685883522,
    "entropy": 0.9749567359685898,
    "total_loss": -376.33377085030077
  },
  {
    "episode": 171,
    "avg_reward_per_step": 31.94918240106919,
    "episode_length": 586,
    "policy_loss": -539.2401733398438,
    "value_loss": 0.5248716622591019,
    "entropy": 0.9577923119068146,
    "total_loss": -539.0984186023474
  },
  {
    "episode": 172,
    "avg_reward_per_step": 87.56595043861951,
    "episode_length": 225,
    "policy_loss": -1479.4025268554688,
    "value_loss": 0.5797197967767715,
    "entropy": 0.8830887973308563,
    "total_loss": -1479.1760425776242
  },
  {
    "episode": 173,
    "avg_reward_per_step": 24.81812700006593,
    "episode_length": 749,
    "policy_loss": -418.2954788208008,
    "value_loss": 0.5189292877912521,
    "entropy": 0.9176883548498154,
    "total_loss": -418.14362487494947
  },
  {
    "episode": 174,
    "avg_reward_per_step": 50.54190198787779,
    "episode_length": 386,
    "policy_loss": -857.7725067138672,
    "value_loss": 0.5424840152263641,
    "entropy": 0.9286427199840546,
    "total_loss": -857.6014797866344
  },
  {
    "episode": 175,
    "avg_reward_per_step": 125.73708064816107,
    "episode_length": 158,
    "policy_loss": -2147.8469848632812,
    "value_loss": 0.6244004666805267,
    "entropy": 0.9461652338504791,
    "total_loss": -2147.601050490141
  },
  {
    "episode": 176,
    "avg_reward_per_step": 24.825703446847914,
    "episode_length": 718,
    "policy_loss": -422.41873931884766,
    "value_loss": 0.5180489867925644,
    "entropy": 0.9392555356025696,
    "total_loss": -422.2763925462961
  },
  {
    "episode": 177,
    "avg_reward_per_step": 37.315952667754566,
    "episode_length": 499,
    "policy_loss": -633.2252197265625,
    "value_loss": 0.5291408598423004,
    "entropy": 0.9354571849107742,
    "total_loss": -633.0702617406845
  },
  {
    "episode": 178,
    "avg_reward_per_step": 63.09386750514683,
    "episode_length": 300,
    "policy_loss": -1062.128662109375,
    "value_loss": 0.5522295534610748,
    "entropy": 0.9316553473472595,
    "total_loss": -1061.9490946948529
  },
  {
    "episode": 179,
    "avg_reward_per_step": 126.17653380113259,
    "episode_length": 155,
    "policy_loss": -2134.1338500976562,
    "value_loss": 0.6227832436561584,
    "entropy": 0.9207176268100739,
    "total_loss": -2133.879353904724
  },
  {
    "episode": 180,
    "avg_reward_per_step": 53.71475984505376,
    "episode_length": 340,
    "policy_loss": -907.5738983154297,
    "value_loss": 0.5420432686805725,
    "entropy": 0.894501581788063,
    "total_loss": -907.3896556794643
  },
  {
    "episode": 181,
    "avg_reward_per_step": 5.711339952693604,
    "episode_length": 1549,
    "policy_loss": -96.82430458068848,
    "value_loss": 0.5017474144697189,
    "entropy": 0.9001685082912445,
    "total_loss": -96.68262456953525
  },
  {
    "episode": 182,
    "avg_reward_per_step": 65.29446119867522,
    "episode_length": 292,
    "policy_loss": -1101.4212036132812,
    "value_loss": 0.5547755211591721,
    "entropy": 0.9322298616170883,
    "total_loss": -1101.239320036769
  },
  {
    "episode": 183,
    "avg_reward_per_step": 165.4827558367992,
    "episode_length": 118,
    "policy_loss": -2797.3353271484375,
    "value_loss": 0.6742419302463531,
    "entropy": 0.9380557835102081,
    "total_loss": -2797.0363075315954
  },
  {
    "episode": 184,
    "avg_reward_per_step": 81.14800267581903,
    "episode_length": 235,
    "policy_loss": -1376.8632507324219,
    "value_loss": 0.569910541176796,
    "entropy": 0.9344110935926437,
    "total_loss": -1376.6671046286822
  },
  {
    "episode": 185,
    "avg_reward_per_step": 74.40782467664432,
    "episode_length": 262,
    "policy_loss": -1259.3249206542969,
    "value_loss": 0.565307080745697,
    "entropy": 0.9584033042192459,
    "total_loss": -1259.142974895239
  },
  {
    "episode": 186,
    "avg_reward_per_step": 78.33369304126127,
    "episode_length": 249,
    "policy_loss": -1322.3940124511719,
    "value_loss": 0.5690851360559464,
    "entropy": 0.9760692715644836,
    "total_loss": -1322.2153550237417
  },
  {
    "episode": 187,
    "avg_reward_per_step": 122.68417965990413,
    "episode_length": 161,
    "policy_loss": -2072.6062622070312,
    "value_loss": 0.6195507198572159,
    "entropy": 0.9908804148435593,
    "total_loss": -2072.3830636531115
  },
  {
    "episode": 188,
    "avg_reward_per_step": 20.523203867455283,
    "episode_length": 869,
    "policy_loss": -346.0434265136719,
    "value_loss": 0.5148321241140366,
    "entropy": 0.992168590426445,
    "total_loss": -345.9254618257284
  },
  {
    "episode": 189,
    "avg_reward_per_step": 26.200864957809188,
    "episode_length": 652,
    "policy_loss": -442.37342834472656,
    "value_loss": 0.5181798040866852,
    "entropy": 1.0095466673374176,
    "total_loss": -442.25906720757484
  },
  {
    "episode": 190,
    "avg_reward_per_step": 28.98090782249145,
    "episode_length": 601,
    "policy_loss": -487.6090850830078,
    "value_loss": 0.5206437408924103,
    "entropy": 1.0073441863059998,
    "total_loss": -487.4913790166378
  },
  {
    "episode": 191,
    "avg_reward_per_step": 56.52480105751486,
    "episode_length": 340,
    "policy_loss": -953.3961486816406,
    "value_loss": 0.5470936596393585,
    "entropy": 0.9816607087850571,
    "total_loss": -953.2417193055153
  },
  {
    "episode": 192,
    "avg_reward_per_step": 12.813591460499543,
    "episode_length": 1229,
    "policy_loss": -215.96049118041992,
    "value_loss": 0.5079674571752548,
    "entropy": 0.9896355271339417,
    "total_loss": -215.84837793409824
  },
  {
    "episode": 193,
    "avg_reward_per_step": 83.57488263471856,
    "episode_length": 237,
    "policy_loss": -1411.0110778808594,
    "value_loss": 0.5758113414049149,
    "entropy": 0.9377703070640564,
    "total_loss": -1410.81037466228
  },
  {
    "episode": 194,
    "avg_reward_per_step": 210.4792618305112,
    "episode_length": 95,
    "policy_loss": -3542.2119140625,
    "value_loss": 0.7512021213769913,
    "entropy": 0.9878522753715515,
    "total_loss": -3541.8558528512717
  },
  {
    "episode": 195,
    "avg_reward_per_step": 131.82016352573146,
    "episode_length": 151,
    "policy_loss": -2229.97998046875,
    "value_loss": 0.6324172168970108,
    "entropy": 0.9399192035198212,
    "total_loss": -2229.723530933261
  },
  {
    "episode": 196,
    "avg_reward_per_step": 19.25041180376098,
    "episode_length": 936,
    "policy_loss": -323.73021697998047,
    "value_loss": 0.514015719294548,
    "entropy": 0.9417513459920883,
    "total_loss": -323.59290179908277
  },
  {
    "episode": 197,
    "avg_reward_per_step": 41.88197741166136,
    "episode_length": 460,
    "policy_loss": -704.9824981689453,
    "value_loss": 0.5341812521219254,
    "entropy": 0.8764860928058624,
    "total_loss": -704.7989113539458
  },
  {
    "episode": 198,
    "avg_reward_per_step": 13.258694000671376,
    "episode_length": 1324,
    "policy_loss": -222.52460861206055,
    "value_loss": 0.5093066245317459,
    "entropy": 0.9285136461257935,
    "total_loss": -222.3867074459791
  },
  {
    "episode": 199,
    "avg_reward_per_step": 68.57327249054575,
    "episode_length": 287,
    "policy_loss": -1166.4101867675781,
    "value_loss": 0.5599566251039505,
    "entropy": 0.8558795303106308,
    "total_loss": -1166.1925819545984
  },
  {
    "episode": 200,
    "avg_reward_per_step": 37.53271608546765,
    "episode_length": 507,
    "policy_loss": -637.285888671875,
    "value_loss": 0.5299286842346191,
    "entropy": 0.9228108525276184,
    "total_loss": -637.1250843286514
  },
  {
    "episode": 201,
    "avg_reward_per_step": 36.33486716126454,
    "episode_length": 517,
    "policy_loss": -612.5909881591797,
    "value_loss": 0.5285051614046097,
    "entropy": 0.9428286254405975,
    "total_loss": -612.4396144479513
  },
  {
    "episode": 202,
    "avg_reward_per_step": 139.27182320936365,
    "episode_length": 143,
    "policy_loss": -2357.3606567382812,
    "value_loss": 0.6420850157737732,
    "entropy": 0.9079692214727402,
    "total_loss": -2357.0817594110968
  },
  {
    "episode": 203,
    "avg_reward_per_step": 14.29317802935586,
    "episode_length": 1153,
    "policy_loss": -240.65151596069336,
    "value_loss": 0.5093676149845123,
    "entropy": 0.9384367018938065,
    "total_loss": -240.51752302646636
  },
  {
    "episode": 204,
    "avg_reward_per_step": 70.76038904145531,
    "episode_length": 271,
    "policy_loss": -1200.5126037597656,
    "value_loss": 0.5602272152900696,
    "entropy": 0.9439219534397125,
    "total_loss": -1200.3299453258514
  },
  {
    "episode": 205,
    "avg_reward_per_step": 68.79186154395643,
    "episode_length": 280,
    "policy_loss": -1165.4315185546875,
    "value_loss": 0.5587415546178818,
    "entropy": 0.9238838404417038,
    "total_loss": -1165.2423305362463
  },
  {
    "episode": 206,
    "avg_reward_per_step": 52.242768247362726,
    "episode_length": 353,
    "policy_loss": -881.82763671875,
    "value_loss": 0.5412261635065079,
    "entropy": 0.9063689112663269,
    "total_loss": -881.64895811975
  },
  {
    "episode": 207,
    "avg_reward_per_step": 7.759447540982676,
    "episode_length": 1348,
    "policy_loss": -130.42470169067383,
    "value_loss": 0.5029465854167938,
    "entropy": 0.8926399052143097,
    "total_loss": -130.27881106734276
  },
  {
    "episode": 208,
    "avg_reward_per_step": 56.97483252980286,
    "episode_length": 320,
    "policy_loss": -960.2553405761719,
    "value_loss": 0.5448714941740036,
    "entropy": 0.9023026078939438,
    "total_loss": -960.0713901251554
  },
  {
    "episode": 209,
    "avg_reward_per_step": 18.93416869957497,
    "episode_length": 747,
    "policy_loss": -320.3457565307617,
    "value_loss": 0.5104728490114212,
    "entropy": 0.8790725618600845,
    "total_loss": -320.18691270649435
  },
  {
    "episode": 210,
    "avg_reward_per_step": 4.258804954660758,
    "episode_length": 1610,
    "policy_loss": -72.24422264099121,
    "value_loss": 0.5008672773838043,
    "entropy": 0.902937114238739,
    "total_loss": -72.10453020930291
  },
  {
    "episode": 211,
    "avg_reward_per_step": -7.872508512846348,
    "episode_length": 3000,
    "policy_loss": 132.08376693725586,
    "value_loss": 2.043635845184326,
    "entropy": 0.9050118327140808,
    "total_loss": 133.76539804935456
  },
  {
    "episode": 212,
    "avg_reward_per_step": 53.78926853914141,
    "episode_length": 345,
    "policy_loss": -908.1593627929688,
    "value_loss": 0.5428249090909958,
    "entropy": 0.9186007678508759,
    "total_loss": -907.9839781910181
  },
  {
    "episode": 213,
    "avg_reward_per_step": 12.037099135107562,
    "episode_length": 939,
    "policy_loss": -202.8432846069336,
    "value_loss": 0.5050947368144989,
    "entropy": 0.8920634090900421,
    "total_loss": -202.6950152337551
  },
  {
    "episode": 214,
    "avg_reward_per_step": 2.407728349048473,
    "episode_length": 1888,
    "policy_loss": -40.829641342163086,
    "value_loss": 0.500183179974556,
    "entropy": 0.9028057157993317,
    "total_loss": -40.690580448508264
  },
  {
    "episode": 215,
    "avg_reward_per_step": 0.7759260510333028,
    "episode_length": 1991,
    "policy_loss": -14.019880771636963,
    "value_loss": 0.49978360533714294,
    "entropy": 0.9047335684299469,
    "total_loss": -13.881990593671798
  },
  {
    "episode": 216,
    "avg_reward_per_step": 3.4432713254941882,
    "episode_length": 1589,
    "policy_loss": -58.71804428100586,
    "value_loss": 0.5004474520683289,
    "entropy": 0.9147704690694809,
    "total_loss": -58.583505016565326
  },
  {
    "episode": 217,
    "avg_reward_per_step": 11.260047466783572,
    "episode_length": 1042,
    "policy_loss": -190.71261596679688,
    "value_loss": 0.5049416869878769,
    "entropy": 0.9287645667791367,
    "total_loss": -190.57918010652065
  },
  {
    "episode": 218,
    "avg_reward_per_step": 29.65640677217748,
    "episode_length": 549,
    "policy_loss": -501.04064178466797,
    "value_loss": 0.5196851640939713,
    "entropy": 0.9473724961280823,
    "total_loss": -500.8999056190252
  },
  {
    "episode": 219,
    "avg_reward_per_step": 168.4763460804,
    "episode_length": 118,
    "policy_loss": -2857.1075439453125,
    "value_loss": 0.6830132305622101,
    "entropy": 0.9298602789640427,
    "total_loss": -2856.7964748263357
  },
  {
    "episode": 220,
    "avg_reward_per_step": 146.66629145989234,
    "episode_length": 135,
    "policy_loss": -2469.2898559570312,
    "value_loss": 0.6505262702703476,
    "entropy": 0.9746237844228745,
    "total_loss": -2469.02917920053
  },
  {
    "episode": 221,
    "avg_reward_per_step": 45.04362088668345,
    "episode_length": 401,
    "policy_loss": -759.3414764404297,
    "value_loss": 0.534299686551094,
    "entropy": 0.9821176379919052,
    "total_loss": -759.2000238090753
  },
  {
    "episode": 222,
    "avg_reward_per_step": 7.578910766327174,
    "episode_length": 1536,
    "policy_loss": -127.10851860046387,
    "value_loss": 0.5032774358987808,
    "entropy": 0.9916478842496872,
    "total_loss": -127.00190031826496
  },
  {
    "episode": 223,
    "avg_reward_per_step": 131.65728722834126,
    "episode_length": 150,
    "policy_loss": -2226.235595703125,
    "value_loss": 0.6310473680496216,
    "entropy": 0.9560700505971909,
    "total_loss": -2225.9869763553143
  },
  {
    "episode": 224,
    "avg_reward_per_step": 155.0667481722908,
    "episode_length": 128,
    "policy_loss": -2655.7042846679688,
    "value_loss": 0.6628891378641129,
    "entropy": 0.986334040760994,
    "total_loss": -2655.435929146409
  },
  {
    "episode": 225,
    "avg_reward_per_step": 72.28721722551039,
    "episode_length": 265,
    "policy_loss": -1207.2196960449219,
    "value_loss": 0.561634436249733,
    "entropy": 0.9900605082511902,
    "total_loss": -1207.0540858119725
  },
  {
    "episode": 226,
    "avg_reward_per_step": 42.03350421839089,
    "episode_length": 459,
    "policy_loss": -706.8178405761719,
    "value_loss": 0.5344535261392593,
    "entropy": 0.9057157337665558,
    "total_loss": -706.6456733435392
  },
  {
    "episode": 227,
    "avg_reward_per_step": 48.0545137137784,
    "episode_length": 404,
    "policy_loss": -810.1316528320312,
    "value_loss": 0.5399581789970398,
    "entropy": 0.8466894030570984,
    "total_loss": -809.930370414257
  },
  {
    "episode": 228,
    "avg_reward_per_step": 57.61760803323728,
    "episode_length": 339,
    "policy_loss": -980.1138305664062,
    "value_loss": 0.5491074174642563,
    "entropy": 0.8955096006393433,
    "total_loss": -979.9229269891978
  },
  {
    "episode": 229,
    "avg_reward_per_step": 86.12178243153113,
    "episode_length": 229,
    "policy_loss": -1451.7474060058594,
    "value_loss": 0.5780618637800217,
    "entropy": 0.9991598427295685,
    "total_loss": -1451.5690080791712
  },
  {
    "episode": 230,
    "avg_reward_per_step": -2.1607540795323814,
    "episode_length": 3000,
    "policy_loss": 36.02043628692627,
    "value_loss": 1.2478191554546356,
    "entropy": 0.9325763881206512,
    "total_loss": 36.89522488713264
  },
  {
    "episode": 231,
    "avg_reward_per_step": 40.646936784166556,
    "episode_length": 470,
    "policy_loss": -685.7398681640625,
    "value_loss": 0.5328122526407242,
    "entropy": 0.9508414715528488,
    "total_loss": -685.5873925000429
  },
  {
    "episode": 232,
    "avg_reward_per_step": 35.04234698981946,
    "episode_length": 531,
    "policy_loss": -594.0491180419922,
    "value_loss": 0.5272235572338104,
    "entropy": 0.9872160404920578,
    "total_loss": -593.9167809009552
  },
  {
    "episode": 233,
    "avg_reward_per_step": 151.98675148708995,
    "episode_length": 131,
    "policy_loss": -2562.7240600585938,
    "value_loss": 0.65915846824646,
    "entropy": 0.935523048043251,
    "total_loss": -2562.4391108095647
  },
  {
    "episode": 234,
    "avg_reward_per_step": 207.73472363288795,
    "episode_length": 96,
    "policy_loss": -3526.6063842773438,
    "value_loss": 0.7465159893035889,
    "entropy": 0.8937580287456512,
    "total_loss": -3526.2173714995383
  },
  {
    "episode": 235,
    "avg_reward_per_step": 207.40163455028335,
    "episode_length": 96,
    "policy_loss": -3487.4981689453125,
    "value_loss": 0.7449294328689575,
    "entropy": 0.9333198666572571,
    "total_loss": -3487.1265674591064
  },
  {
    "episode": 236,
    "avg_reward_per_step": 181.86769082036983,
    "episode_length": 109,
    "policy_loss": -3063.8273315429688,
    "value_loss": 0.702038049697876,
    "entropy": 0.929383784532547,
    "total_loss": -3063.497047007084
  },
  {
    "episode": 237,
    "avg_reward_per_step": 48.11564487047299,
    "episode_length": 381,
    "policy_loss": -809.5734100341797,
    "value_loss": 0.5373141467571259,
    "entropy": 0.9135734289884567,
    "total_loss": -809.401525259018
  },
  {
    "episode": 238,
    "avg_reward_per_step": 60.572521153445294,
    "episode_length": 303,
    "policy_loss": -1020.6636505126953,
    "value_loss": 0.5482640266418457,
    "entropy": 0.9117977321147919,
    "total_loss": -1020.4801055788994
  },
  {
    "episode": 239,
    "avg_reward_per_step": 9.997466471308764,
    "episode_length": 1132,
    "policy_loss": -169.0773696899414,
    "value_loss": 0.5042012184858322,
    "entropy": 0.904582604765892,
    "total_loss": -168.93500151336193
  },
  {
    "episode": 240,
    "avg_reward_per_step": 137.0654842978055,
    "episode_length": 144,
    "policy_loss": -2321.1436767578125,
    "value_loss": 0.6370818465948105,
    "entropy": 0.8932889252901077,
    "total_loss": -2320.8639104813337
  },
  {
    "episode": 241,
    "avg_reward_per_step": 8.568226208468447,
    "episode_length": 1418,
    "policy_loss": -144.9954948425293,
    "value_loss": 0.5039224326610565,
    "entropy": 0.8963591605424881,
    "total_loss": -144.85011607408524
  },
  {
    "episode": 242,
    "avg_reward_per_step": 112.71316431578906,
    "episode_length": 176,
    "policy_loss": -1904.879150390625,
    "value_loss": 0.608565554022789,
    "entropy": 0.8835717886686325,
    "total_loss": -1904.6240135520698
  },
  {
    "episode": 243,
    "avg_reward_per_step": 211.66796868778607,
    "episode_length": 94,
    "policy_loss": -3654.4386596679688,
    "value_loss": 0.7512171864509583,
    "entropy": 0.8875774294137955,
    "total_loss": -3654.0424734532835
  },
  {
    "episode": 244,
    "avg_reward_per_step": 40.93576561864711,
    "episode_length": 432,
    "policy_loss": -688.79345703125,
    "value_loss": 0.5301140546798706,
    "entropy": 0.8492958694696426,
    "total_loss": -688.603061324358
  },
  {
    "episode": 245,
    "avg_reward_per_step": 52.569146338583614,
    "episode_length": 343,
    "policy_loss": -883.2144470214844,
    "value_loss": 0.5405651926994324,
    "entropy": 0.8468243479728699,
    "total_loss": -883.0126115679741
  },
  {
    "episode": 246,
    "avg_reward_per_step": 18.332788504235044,
    "episode_length": 739,
    "policy_loss": -309.2430725097656,
    "value_loss": 0.5096823126077652,
    "entropy": 0.8065173625946045,
    "total_loss": -309.0559971421957
  },
  {
    "episode": 247,
    "avg_reward_per_step": -8.97576347697689,
    "episode_length": 3000,
    "policy_loss": 150.47768020629883,
    "value_loss": 2.7883349657058716,
    "entropy": 0.7933717668056488,
    "total_loss": 152.94866646528243
  },
  {
    "episode": 248,
    "avg_reward_per_step": -9.246298229708842,
    "episode_length": 3000,
    "policy_loss": 154.9034423828125,
    "value_loss": 2.668410003185272,
    "entropy": 0.7915326356887817,
    "total_loss": 157.25523933172227
  },
  {
    "episode": 249,
    "avg_reward_per_step": 29.147844795598868,
    "episode_length": 536,
    "policy_loss": -492.6497573852539,
    "value_loss": 0.5185072720050812,
    "entropy": 0.8008213490247726,
    "total_loss": -492.45157865285876
  },
  {
    "episode": 250,
    "avg_reward_per_step": 16.846451928808825,
    "episode_length": 785,
    "policy_loss": -284.8409881591797,
    "value_loss": 0.5086794346570969,
    "entropy": 0.7783880978822708,
    "total_loss": -284.6436639636755
  },
  {
    "episode": 251,
    "avg_reward_per_step": 1.4869009694928261,
    "episode_length": 1876,
    "policy_loss": -26.160764694213867,
    "value_loss": 0.49989472329616547,
    "entropy": 0.7757845968008041,
    "total_loss": -25.971183809638024
  },
  {
    "episode": 252,
    "avg_reward_per_step": 94.07495418228851,
    "episode_length": 205,
    "policy_loss": -1586.7533264160156,
    "value_loss": 0.5850319713354111,
    "entropy": 0.7991945296525955,
    "total_loss": -1586.4879722565413
  },
  {
    "episode": 253,
    "avg_reward_per_step": -1.6275782816198192,
    "episode_length": 2576,
    "policy_loss": 26.633726596832275,
    "value_loss": 0.500050351023674,
    "entropy": 0.7654218524694443,
    "total_loss": 26.82760820686817
  },
  {
    "episode": 254,
    "avg_reward_per_step": 36.71698226453801,
    "episode_length": 465,
    "policy_loss": -619.2019653320312,
    "value_loss": 0.5258183926343918,
    "entropy": 0.7815895974636078,
    "total_loss": -618.9887827783823
  },
  {
    "episode": 255,
    "avg_reward_per_step": -2.5527604907049493,
    "episode_length": 2922,
    "policy_loss": 42.16946983337402,
    "value_loss": 0.500525563955307,
    "entropy": 0.7784159034490585,
    "total_loss": 42.358629035949704
  },
  {
    "episode": 256,
    "avg_reward_per_step": 24.063777037823094,
    "episode_length": 609,
    "policy_loss": -406.4559555053711,
    "value_loss": 0.5140296667814255,
    "entropy": 0.7886719703674316,
    "total_loss": -406.25739462673664
  },
  {
    "episode": 257,
    "avg_reward_per_step": 2.922158159487749,
    "episode_length": 1472,
    "policy_loss": -50.25662803649902,
    "value_loss": 0.5001938492059708,
    "entropy": 0.768119141459465,
    "total_loss": -50.063681843876836
  },
  {
    "episode": 258,
    "avg_reward_per_step": -9.481818608523175,
    "episode_length": 3000,
    "policy_loss": 158.5831527709961,
    "value_loss": 2.6004392504692078,
    "entropy": 0.7855745702981949,
    "total_loss": 160.86936219334603
  },
  {
    "episode": 259,
    "avg_reward_per_step": 7.2058297825145425,
    "episode_length": 1206,
    "policy_loss": -122.5838851928711,
    "value_loss": 0.502169132232666,
    "entropy": 0.7836214005947113,
    "total_loss": -122.39516462087632
  },
  {
    "episode": 260,
    "avg_reward_per_step": 10.32216874720913,
    "episode_length": 989,
    "policy_loss": -174.71833038330078,
    "value_loss": 0.5038625001907349,
    "entropy": 0.7868925631046295,
    "total_loss": -174.5292249083519
  },
  {
    "episode": 261,
    "avg_reward_per_step": 2.7082814348278954,
    "episode_length": 1942,
    "policy_loss": -46.73861598968506,
    "value_loss": 0.500344917178154,
    "entropy": 0.815532997250557,
    "total_loss": -46.564484271407125
  },
  {
    "episode": 262,
    "avg_reward_per_step": 6.40529447472377,
    "episode_length": 1347,
    "policy_loss": -108.70877456665039,
    "value_loss": 0.5018999725580215,
    "entropy": 0.8054357022047043,
    "total_loss": -108.52904887497425
  },
  {
    "episode": 263,
    "avg_reward_per_step": 1.6465019880574967,
    "episode_length": 1823,
    "policy_loss": -28.535839080810547,
    "value_loss": 0.4999157190322876,
    "entropy": 0.7940783649682999,
    "total_loss": -28.35355470776558
  },
  {
    "episode": 264,
    "avg_reward_per_step": 27.598227265504704,
    "episode_length": 580,
    "policy_loss": -465.64537811279297,
    "value_loss": 0.5177969485521317,
    "entropy": 0.8099412024021149,
    "total_loss": -465.45155764520166
  },
  {
    "episode": 265,
    "avg_reward_per_step": 5.93079335623031,
    "episode_length": 1386,
    "policy_loss": -100.88504409790039,
    "value_loss": 0.5016256719827652,
    "entropy": 0.8227699548006058,
    "total_loss": -100.71252640783787
  },
  {
    "episode": 266,
    "avg_reward_per_step": 35.14662298396287,
    "episode_length": 498,
    "policy_loss": -593.8787078857422,
    "value_loss": 0.5255174487829208,
    "entropy": 0.8405563086271286,
    "total_loss": -593.6894129604101
  },
  {
    "episode": 267,
    "avg_reward_per_step": 39.423945132697,
    "episode_length": 437,
    "policy_loss": -665.749755859375,
    "value_loss": 0.5282372683286667,
    "entropy": 0.820153996348381,
    "total_loss": -665.5495801895856
  },
  {
    "episode": 268,
    "avg_reward_per_step": 18.092222636888057,
    "episode_length": 756,
    "policy_loss": -305.7521057128906,
    "value_loss": 0.5096511691808701,
    "entropy": 0.8225175440311432,
    "total_loss": -305.5714615613222
  },
  {
    "episode": 269,
    "avg_reward_per_step": 14.515688311640341,
    "episode_length": 862,
    "policy_loss": -245.73690032958984,
    "value_loss": 0.5069381147623062,
    "entropy": 0.8172320872545242,
    "total_loss": -245.55685504972934
  },
  {
    "episode": 270,
    "avg_reward_per_step": 23.3255545532535,
    "episode_length": 627,
    "policy_loss": -394.1082077026367,
    "value_loss": 0.5134995877742767,
    "entropy": 0.8284197598695755,
    "total_loss": -393.92607601881025
  },
  {
    "episode": 271,
    "avg_reward_per_step": 158.19027276673484,
    "episode_length": 125,
    "policy_loss": -2672.52734375,
    "value_loss": 0.6663249433040619,
    "entropy": 0.7854472696781158,
    "total_loss": -2672.1751977145673
  },
  {
    "episode": 272,
    "avg_reward_per_step": 10.433896902544856,
    "episode_length": 1159,
    "policy_loss": -177.8290023803711,
    "value_loss": 0.50480517745018,
    "entropy": 0.8250193893909454,
    "total_loss": -177.6542049586773
  },
  {
    "episode": 273,
    "avg_reward_per_step": 35.713247047661476,
    "episode_length": 485,
    "policy_loss": -601.4835815429688,
    "value_loss": 0.525619238615036,
    "entropy": 0.81673264503479,
    "total_loss": -601.2846553623676
  },
  {
    "episode": 274,
    "avg_reward_per_step": 67.1766290834758,
    "episode_length": 280,
    "policy_loss": -1135.333740234375,
    "value_loss": 0.555731788277626,
    "entropy": 0.7968100160360336,
    "total_loss": -1135.0967324525118
  },
  {
    "episode": 275,
    "avg_reward_per_step": 191.58600784588637,
    "episode_length": 104,
    "policy_loss": -3262.8543090820312,
    "value_loss": 0.7176575511693954,
    "entropy": 0.8368652015924454,
    "total_loss": -3262.471397611499
  },
  {
    "episode": 276,
    "avg_reward_per_step": 87.6353219704558,
    "episode_length": 219,
    "policy_loss": -1468.8380126953125,
    "value_loss": 0.5769712775945663,
    "entropy": 0.8511907756328583,
    "total_loss": -1468.601517727971
  },
  {
    "episode": 277,
    "avg_reward_per_step": 211.47296554150378,
    "episode_length": 94,
    "policy_loss": -3570.691162109375,
    "value_loss": 0.7507258653640747,
    "entropy": 0.8394452333450317,
    "total_loss": -3570.276214337349
  },
  {
    "episode": 278,
    "avg_reward_per_step": 232.1193167946683,
    "episode_length": 86,
    "policy_loss": -3891.9825439453125,
    "value_loss": 0.7894038707017899,
    "entropy": 0.8212475925683975,
    "total_loss": -3891.5216391116383
  },
  {
    "episode": 279,
    "avg_reward_per_step": 159.15896449789741,
    "episode_length": 125,
    "policy_loss": -2688.2591552734375,
    "value_loss": 0.6693069934844971,
    "entropy": 0.7848869860172272,
    "total_loss": -2687.90380307436
  },
  {
    "episode": 280,
    "avg_reward_per_step": 104.04084900421412,
    "episode_length": 190,
    "policy_loss": -1776.7662048339844,
    "value_loss": 0.5981694310903549,
    "entropy": 0.6831731200218201,
    "total_loss": -1776.4413046509028
  },
  {
    "episode": 281,
    "avg_reward_per_step": 43.37253363246061,
    "episode_length": 447,
    "policy_loss": -731.5265960693359,
    "value_loss": 0.5356905460357666,
    "entropy": 0.7858830839395523,
    "total_loss": -731.305258756876
  },
  {
    "episode": 282,
    "avg_reward_per_step": 15.149718331987454,
    "episode_length": 1244,
    "policy_loss": -256.1160316467285,
    "value_loss": 0.511618047952652,
    "entropy": 0.577923133969307,
    "total_loss": -255.8355828523636
  },
  {
    "episode": 283,
    "avg_reward_per_step": 124.75378690442372,
    "episode_length": 160,
    "policy_loss": -2102.3646240234375,
    "value_loss": 0.6235761493444443,
    "entropy": 0.7279388159513474,
    "total_loss": -2102.0322234004734
  },
  {
    "episode": 284,
    "avg_reward_per_step": 10.011278943619757,
    "episode_length": 1843,
    "policy_loss": -168.3951416015625,
    "value_loss": 0.507460817694664,
    "entropy": 0.5424253940582275,
    "total_loss": -168.10465094149112
  },
  {
    "episode": 285,
    "avg_reward_per_step": 28.34062272153946,
    "episode_length": 687,
    "policy_loss": -478.6101303100586,
    "value_loss": 0.5229093879461288,
    "entropy": 0.5717666149139404,
    "total_loss": -478.31592756807805
  },
  {
    "episode": 286,
    "avg_reward_per_step": 37.16020364737991,
    "episode_length": 521,
    "policy_loss": -629.9574584960938,
    "value_loss": 0.5303357541561127,
    "entropy": 0.6147509664297104,
    "total_loss": -629.6730231285095
  },
  {
    "episode": 287,
    "avg_reward_per_step": 10.090351347567482,
    "episode_length": 1798,
    "policy_loss": -170.82100296020508,
    "value_loss": 0.5073328763246536,
    "entropy": 0.6317547559738159,
    "total_loss": -170.56637198626996
  },
  {
    "episode": 288,
    "avg_reward_per_step": 24.900617256444672,
    "episode_length": 773,
    "policy_loss": -421.6464309692383,
    "value_loss": 0.5197508633136749,
    "entropy": 0.6642826348543167,
    "total_loss": -421.39239315986634
  },
  {
    "episode": 289,
    "avg_reward_per_step": 22.097070517847072,
    "episode_length": 861,
    "policy_loss": -373.45667266845703,
    "value_loss": 0.5172320455312729,
    "entropy": 0.6651052087545395,
    "total_loss": -373.2054827064276
  },
  {
    "episode": 290,
    "avg_reward_per_step": 32.5809698315255,
    "episode_length": 584,
    "policy_loss": -549.9222106933594,
    "value_loss": 0.5259126424789429,
    "entropy": 0.7516819536685944,
    "total_loss": -549.6969708323479
  },
  {
    "episode": 291,
    "avg_reward_per_step": 110.30231312311057,
    "episode_length": 179,
    "policy_loss": -1864.6540222167969,
    "value_loss": 0.6050583571195602,
    "entropy": 0.7980336099863052,
    "total_loss": -1864.368177303672
  },
  {
    "episode": 292,
    "avg_reward_per_step": 49.42971187747908,
    "episode_length": 394,
    "policy_loss": -832.8067321777344,
    "value_loss": 0.5412894189357758,
    "entropy": 0.7560606747865677,
    "total_loss": -832.5678670287132
  },
  {
    "episode": 293,
    "avg_reward_per_step": 118.61032414904287,
    "episode_length": 167,
    "policy_loss": -2015.5723266601562,
    "value_loss": 0.615467444062233,
    "entropy": 0.7411167621612549,
    "total_loss": -2015.2533059209586
  },
  {
    "episode": 294,
    "avg_reward_per_step": 23.696205273662198,
    "episode_length": 797,
    "policy_loss": -398.7489242553711,
    "value_loss": 0.5184000581502914,
    "entropy": 0.6685912311077118,
    "total_loss": -398.4979606896639
  },
  {
    "episode": 295,
    "avg_reward_per_step": 129.26530718327788,
    "episode_length": 154,
    "policy_loss": -2195.22119140625,
    "value_loss": 0.6290566325187683,
    "entropy": 0.6662101894617081,
    "total_loss": -2194.858618849516
  },
  {
    "episode": 296,
    "avg_reward_per_step": 26.457049063198387,
    "episode_length": 729,
    "policy_loss": -450.9647903442383,
    "value_loss": 0.5211084634065628,
    "entropy": 0.6993635147809982,
    "total_loss": -450.72342728674414
  },
  {
    "episode": 297,
    "avg_reward_per_step": 14.247219578615862,
    "episode_length": 1301,
    "policy_loss": -238.71455764770508,
    "value_loss": 0.510681539773941,
    "entropy": 0.6682911068201065,
    "total_loss": -238.47119255065917
  },
  {
    "episode": 298,
    "avg_reward_per_step": 75.9293316853846,
    "episode_length": 261,
    "policy_loss": -1279.3011779785156,
    "value_loss": 0.5679477900266647,
    "entropy": 0.6041721999645233,
    "total_loss": -1278.9748990684748
  },
  {
    "episode": 299,
    "avg_reward_per_step": 50.10955096939284,
    "episode_length": 392,
    "policy_loss": -845.0398254394531,
    "value_loss": 0.5423214286565781,
    "entropy": 0.6643927991390228,
    "total_loss": -844.7632611304522
  },
  {
    "episode": 300,
    "avg_reward_per_step": 34.312441370271074,
    "episode_length": 568,
    "policy_loss": -578.9269256591797,
    "value_loss": 0.5280965864658356,
    "entropy": 0.5797947198152542,
    "total_loss": -578.63074696064
  }
]