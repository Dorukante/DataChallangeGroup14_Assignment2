[
  {
    "episode": 1,
    "avg_reward_per_step": 43.09313915356981,
    "episode_length": 432,
    "policy_loss": -745.5166625976562,
    "value_loss": 0.5339870303869247,
    "entropy": 1.374794363975525,
    "total_loss": -745.5325933128595
  },
  {
    "episode": 2,
    "avg_reward_per_step": 108.3768640947104,
    "episode_length": 182,
    "policy_loss": -1853.0163879394531,
    "value_loss": 0.6028708219528198,
    "entropy": 1.3635097444057465,
    "total_loss": -1852.9589210152626
  },
  {
    "episode": 3,
    "avg_reward_per_step": 26.79391116072406,
    "episode_length": 648,
    "policy_loss": -457.84574127197266,
    "value_loss": 0.5190148204565048,
    "entropy": 1.3527157008647919,
    "total_loss": -457.86781273186205
  },
  {
    "episode": 4,
    "avg_reward_per_step": 22.09673373096946,
    "episode_length": 791,
    "policy_loss": -376.7735137939453,
    "value_loss": 0.5156234949827194,
    "entropy": 1.3295170068740845,
    "total_loss": -376.78969710171225
  },
  {
    "episode": 5,
    "avg_reward_per_step": 9.282367636496422,
    "episode_length": 1669,
    "policy_loss": -156.80087280273438,
    "value_loss": 0.5056342333555222,
    "entropy": 1.3100238740444183,
    "total_loss": -156.81924811899663
  },
  {
    "episode": 6,
    "avg_reward_per_step": 12.441527705988523,
    "episode_length": 1341,
    "policy_loss": -210.1427116394043,
    "value_loss": 0.508232593536377,
    "entropy": 1.2867726981639862,
    "total_loss": -210.14918812513352
  },
  {
    "episode": 7,
    "avg_reward_per_step": 8.303313347244893,
    "episode_length": 1854,
    "policy_loss": -139.9490852355957,
    "value_loss": 0.5049949735403061,
    "entropy": 1.2647187113761902,
    "total_loss": -139.94997774660587
  },
  {
    "episode": 8,
    "avg_reward_per_step": 86.60586085586782,
    "episode_length": 227,
    "policy_loss": -1467.2388610839844,
    "value_loss": 0.5781966596841812,
    "entropy": 1.2417580485343933,
    "total_loss": -1467.157367643714
  },
  {
    "episode": 9,
    "avg_reward_per_step": 30.943848116318716,
    "episode_length": 620,
    "policy_loss": -521.8616943359375,
    "value_loss": 0.524637371301651,
    "entropy": 1.2327709794044495,
    "total_loss": -521.8301653563976
  },
  {
    "episode": 10,
    "avg_reward_per_step": 17.285314505442685,
    "episode_length": 1008,
    "policy_loss": -293.7283020019531,
    "value_loss": 0.5121042281389236,
    "entropy": 1.220747172832489,
    "total_loss": -293.7044966429472
  },
  {
    "episode": 11,
    "avg_reward_per_step": 34.427654430982194,
    "episode_length": 544,
    "policy_loss": -589.1266174316406,
    "value_loss": 0.5267782360315323,
    "entropy": 1.215974599123001,
    "total_loss": -589.0862290352583
  },
  {
    "episode": 12,
    "avg_reward_per_step": 60.25521574856012,
    "episode_length": 322,
    "policy_loss": -1037.77587890625,
    "value_loss": 0.5510844141244888,
    "entropy": 1.1997501850128174,
    "total_loss": -1037.7046945661307
  },
  {
    "episode": 13,
    "avg_reward_per_step": 52.88430569461798,
    "episode_length": 341,
    "policy_loss": -890.0759124755859,
    "value_loss": 0.5408579856157303,
    "entropy": 1.1224673092365265,
    "total_loss": -889.9840414136648
  },
  {
    "episode": 14,
    "avg_reward_per_step": 97.53629952801263,
    "episode_length": 195,
    "policy_loss": -1644.5094604492188,
    "value_loss": 0.5867437720298767,
    "entropy": 1.0484525859355927,
    "total_loss": -1644.3420977115632
  },
  {
    "episode": 15,
    "avg_reward_per_step": 8.845337905072936,
    "episode_length": 1115,
    "policy_loss": -148.6664695739746,
    "value_loss": 0.5030946731567383,
    "entropy": 1.0552922487258911,
    "total_loss": -148.58549180030823
  },
  {
    "episode": 16,
    "avg_reward_per_step": 4.443587945565354,
    "episode_length": 1624,
    "policy_loss": -75.55418395996094,
    "value_loss": 0.500958651304245,
    "entropy": 1.0455291867256165,
    "total_loss": -75.47143698334693
  },
  {
    "episode": 17,
    "avg_reward_per_step": 112.74967008692508,
    "episode_length": 175,
    "policy_loss": -1910.5399169921875,
    "value_loss": 0.6074694842100143,
    "entropy": 1.1147697865962982,
    "total_loss": -1910.378355422616
  },
  {
    "episode": 18,
    "avg_reward_per_step": 2.693341120491105,
    "episode_length": 1852,
    "policy_loss": -44.94645595550537,
    "value_loss": 0.5002488195896149,
    "entropy": 0.9842859208583832,
    "total_loss": -44.83992150425911
  },
  {
    "episode": 19,
    "avg_reward_per_step": 22.758614977980713,
    "episode_length": 657,
    "policy_loss": -385.69322204589844,
    "value_loss": 0.5135291963815689,
    "entropy": 0.971354752779007,
    "total_loss": -385.56823475062845
  },
  {
    "episode": 20,
    "avg_reward_per_step": 3.92157300341432,
    "episode_length": 1564,
    "policy_loss": -65.94633865356445,
    "value_loss": 0.5006222277879715,
    "entropy": 0.9075804501771927,
    "total_loss": -65.80874860584736
  },
  {
    "episode": 21,
    "avg_reward_per_step": 51.06274326932513,
    "episode_length": 361,
    "policy_loss": -862.4482421875,
    "value_loss": 0.5399413257837296,
    "entropy": 0.9646976590156555,
    "total_loss": -862.2941799253225
  },
  {
    "episode": 22,
    "avg_reward_per_step": 27.66282327639226,
    "episode_length": 608,
    "policy_loss": -466.87857818603516,
    "value_loss": 0.5189126431941986,
    "entropy": 0.9006440937519073,
    "total_loss": -466.7199231803417
  },
  {
    "episode": 23,
    "avg_reward_per_step": 113.66275746282292,
    "episode_length": 167,
    "policy_loss": -1963.6371459960938,
    "value_loss": 0.6035717576742172,
    "entropy": 0.8516853004693985,
    "total_loss": -1963.3742483586072
  },
  {
    "episode": 24,
    "avg_reward_per_step": -9.212261781464361,
    "episode_length": 3000,
    "policy_loss": 156.36845016479492,
    "value_loss": 2.0736597180366516,
    "entropy": 0.7357145696878433,
    "total_loss": 158.14782405495643
  },
  {
    "episode": 25,
    "avg_reward_per_step": -12.824977758455121,
    "episode_length": 3000,
    "policy_loss": 215.85343170166016,
    "value_loss": 4.08510947227478,
    "entropy": 0.597027063369751,
    "total_loss": 219.69973034858702
  },
  {
    "episode": 26,
    "avg_reward_per_step": -12.81360497991992,
    "episode_length": 3000,
    "policy_loss": 215.91820526123047,
    "value_loss": 2.88788503408432,
    "entropy": 0.5268333554267883,
    "total_loss": 218.59535695314406
  },
  {
    "episode": 27,
    "avg_reward_per_step": 5.010810273342422,
    "episode_length": 1091,
    "policy_loss": -83.73047065734863,
    "value_loss": 0.5006484538316727,
    "entropy": 0.4253668636083603,
    "total_loss": -83.3999689489603
  },
  {
    "episode": 28,
    "avg_reward_per_step": 8.703247917928298,
    "episode_length": 1002,
    "policy_loss": -145.91375350952148,
    "value_loss": 0.5025716722011566,
    "entropy": 0.4247773513197899,
    "total_loss": -145.58109277784826
  },
  {
    "episode": 29,
    "avg_reward_per_step": -12.386738985063007,
    "episode_length": 3000,
    "policy_loss": 208.44783782958984,
    "value_loss": 2.733959674835205,
    "entropy": 0.4738052040338516,
    "total_loss": 210.9922754228115
  },
  {
    "episode": 30,
    "avg_reward_per_step": -14.859277067561118,
    "episode_length": 3000,
    "policy_loss": 249.8529052734375,
    "value_loss": 4.337373733520508,
    "entropy": 0.41850343346595764,
    "total_loss": 254.02287763357162
  },
  {
    "episode": 31,
    "avg_reward_per_step": -13.882537440064647,
    "episode_length": 3000,
    "policy_loss": 233.27387619018555,
    "value_loss": 3.8131192326545715,
    "entropy": 0.5070545971393585,
    "total_loss": 236.88417358398436
  },
  {
    "episode": 32,
    "avg_reward_per_step": -12.897845840183654,
    "episode_length": 3000,
    "policy_loss": 216.6352996826172,
    "value_loss": 3.2862995862960815,
    "entropy": 0.507366269826889,
    "total_loss": 219.7186527609825
  },
  {
    "episode": 33,
    "avg_reward_per_step": -13.344788028803709,
    "episode_length": 3000,
    "policy_loss": 223.84555435180664,
    "value_loss": 3.2622100114822388,
    "entropy": 0.5162966996431351,
    "total_loss": 226.90124568343163
  },
  {
    "episode": 34,
    "avg_reward_per_step": -14.272713720808966,
    "episode_length": 3000,
    "policy_loss": 239.4226531982422,
    "value_loss": 3.869441032409668,
    "entropy": 0.5004242062568665,
    "total_loss": 243.0919245481491
  },
  {
    "episode": 35,
    "avg_reward_per_step": 250.01444561077406,
    "episode_length": 80,
    "policy_loss": -4190.2738037109375,
    "value_loss": 0.8257091343402863,
    "entropy": 0.42971372604370117,
    "total_loss": -4189.619980067015
  },
  {
    "episode": 36,
    "avg_reward_per_step": -13.93541918852407,
    "episode_length": 3000,
    "policy_loss": 233.40884017944336,
    "value_loss": 3.130964994430542,
    "entropy": 0.4413462057709694,
    "total_loss": 236.3632666915655
  },
  {
    "episode": 37,
    "avg_reward_per_step": -14.985746036373836,
    "episode_length": 3000,
    "policy_loss": 251.37421035766602,
    "value_loss": 3.946798086166382,
    "entropy": 0.34414125978946686,
    "total_loss": 255.1833519399166
  },
  {
    "episode": 38,
    "avg_reward_per_step": 6.444941385235141,
    "episode_length": 1113,
    "policy_loss": -109.21285629272461,
    "value_loss": 0.5014643967151642,
    "entropy": 0.28250887244939804,
    "total_loss": -108.82439544498921
  },
  {
    "episode": 39,
    "avg_reward_per_step": -14.794190189063634,
    "episode_length": 3000,
    "policy_loss": 247.4296760559082,
    "value_loss": 3.928391993045807,
    "entropy": 0.29137609899044037,
    "total_loss": 251.24151760935783
  },
  {
    "episode": 40,
    "avg_reward_per_step": -12.334834973146009,
    "episode_length": 3000,
    "policy_loss": 206.03622817993164,
    "value_loss": 2.2914071083068848,
    "entropy": 0.3678540736436844,
    "total_loss": 208.18049365878105
  },
  {
    "episode": 41,
    "avg_reward_per_step": -14.168673481300427,
    "episode_length": 3000,
    "policy_loss": 236.87181091308594,
    "value_loss": 3.429491400718689,
    "entropy": 0.34329573065042496,
    "total_loss": 240.16398402154445
  },
  {
    "episode": 42,
    "avg_reward_per_step": -13.38771926091026,
    "episode_length": 3000,
    "policy_loss": 223.6641616821289,
    "value_loss": 3.1148149371147156,
    "entropy": 0.3465627506375313,
    "total_loss": 226.6403515189886
  },
  {
    "episode": 43,
    "avg_reward_per_step": -14.851931798406754,
    "episode_length": 3000,
    "policy_loss": 248.13827514648438,
    "value_loss": 3.787230372428894,
    "entropy": 0.2862084284424782,
    "total_loss": 251.81102214753628
  },
  {
    "episode": 44,
    "avg_reward_per_step": 230.10338422725474,
    "episode_length": 87,
    "policy_loss": -3862.5955200195312,
    "value_loss": 0.7859228551387787,
    "entropy": 0.22733421251177788,
    "total_loss": -3861.900530849397
  },
  {
    "episode": 45,
    "avg_reward_per_step": 351.64485064341727,
    "episode_length": 57,
    "policy_loss": -5768.9068603515625,
    "value_loss": 1.0693025588989258,
    "entropy": 0.2827562019228935,
    "total_loss": -5767.950660273433
  },
  {
    "episode": 46,
    "avg_reward_per_step": -14.318034474878255,
    "episode_length": 3000,
    "policy_loss": 238.8903923034668,
    "value_loss": 4.272093653678894,
    "entropy": 0.3545403555035591,
    "total_loss": 243.02066981494426
  },
  {
    "episode": 47,
    "avg_reward_per_step": 143.7633806922821,
    "episode_length": 139,
    "policy_loss": -2423.995361328125,
    "value_loss": 0.6477630883455276,
    "entropy": 0.21112936735153198,
    "total_loss": -2423.43204998672
  },
  {
    "episode": 48,
    "avg_reward_per_step": -13.444568891491581,
    "episode_length": 3000,
    "policy_loss": 223.91511154174805,
    "value_loss": 3.2579897046089172,
    "entropy": 0.3368925601243973,
    "total_loss": 227.03834422230722
  },
  {
    "episode": 49,
    "avg_reward_per_step": -15.274948789814296,
    "episode_length": 3000,
    "policy_loss": 254.63416290283203,
    "value_loss": 3.898565709590912,
    "entropy": 0.2830177992582321,
    "total_loss": 258.41952149271964
  },
  {
    "episode": 50,
    "avg_reward_per_step": -16.319093256358077,
    "episode_length": 3000,
    "policy_loss": 271.9522476196289,
    "value_loss": 5.624455809593201,
    "entropy": 0.2658878266811371,
    "total_loss": 277.47034829854965
  },
  {
    "episode": 51,
    "avg_reward_per_step": -15.330025608218886,
    "episode_length": 3000,
    "policy_loss": 255.36206436157227,
    "value_loss": 3.423328220844269,
    "entropy": 0.29045191407203674,
    "total_loss": 258.6692118167877
  },
  {
    "episode": 52,
    "avg_reward_per_step": 1.0639740892617602,
    "episode_length": 1372,
    "policy_loss": -20.834099769592285,
    "value_loss": 0.499714232981205,
    "entropy": 0.18116926029324532,
    "total_loss": -20.406853240728378
  },
  {
    "episode": 53,
    "avg_reward_per_step": 0.8965912495721444,
    "episode_length": 1503,
    "policy_loss": -18.815989017486572,
    "value_loss": 0.4997358173131943,
    "entropy": 0.18349453806877136,
    "total_loss": -18.389651015400887
  },
  {
    "episode": 54,
    "avg_reward_per_step": 1.5123066534872975,
    "episode_length": 1430,
    "policy_loss": -29.441790103912354,
    "value_loss": 0.4998088479042053,
    "entropy": 0.1973087675869465,
    "total_loss": -29.020904763042928
  },
  {
    "episode": 55,
    "avg_reward_per_step": -15.542419328348121,
    "episode_length": 3000,
    "policy_loss": 258.10340881347656,
    "value_loss": 4.7454612255096436,
    "entropy": 0.31056372821331024,
    "total_loss": 262.7246445477009
  },
  {
    "episode": 56,
    "avg_reward_per_step": -13.124409277594697,
    "episode_length": 3000,
    "policy_loss": 217.5314178466797,
    "value_loss": 2.3237701654434204,
    "entropy": 0.45549045503139496,
    "total_loss": 219.67299183011056
  },
  {
    "episode": 57,
    "avg_reward_per_step": 37.2025408825407,
    "episode_length": 437,
    "policy_loss": -630.3989562988281,
    "value_loss": 0.5250795036554337,
    "entropy": 0.30225662887096405,
    "total_loss": -629.994779446721
  },
  {
    "episode": 58,
    "avg_reward_per_step": 26.87320465388259,
    "episode_length": 544,
    "policy_loss": -458.7239456176758,
    "value_loss": 0.5159412175416946,
    "entropy": 0.3432932421565056,
    "total_loss": -458.3453216969967
  },
  {
    "episode": 59,
    "avg_reward_per_step": -14.387514671383398,
    "episode_length": 3000,
    "policy_loss": 238.4244842529297,
    "value_loss": 3.5590031147003174,
    "entropy": 0.3770247846841812,
    "total_loss": 241.83267745375633
  },
  {
    "episode": 60,
    "avg_reward_per_step": -14.557992225954115,
    "episode_length": 3000,
    "policy_loss": 241.1474723815918,
    "value_loss": 3.6963343620300293,
    "entropy": 0.382339671254158,
    "total_loss": 244.69087087512017
  },
  {
    "episode": 61,
    "avg_reward_per_step": 24.424266434123595,
    "episode_length": 574,
    "policy_loss": -416.6287384033203,
    "value_loss": 0.5136789083480835,
    "entropy": 0.49557404965162277,
    "total_loss": -416.31328911483286
  },
  {
    "episode": 62,
    "avg_reward_per_step": -13.39575584658059,
    "episode_length": 3000,
    "policy_loss": 221.38111114501953,
    "value_loss": 3.2570608854293823,
    "entropy": 0.42125628143548965,
    "total_loss": 224.4696695178747
  },
  {
    "episode": 63,
    "avg_reward_per_step": -13.796177358341888,
    "episode_length": 3000,
    "policy_loss": 228.06021881103516,
    "value_loss": 3.642381429672241,
    "entropy": 0.38938137888908386,
    "total_loss": 231.54684768915178
  },
  {
    "episode": 64,
    "avg_reward_per_step": 0.9938975686105007,
    "episode_length": 1553,
    "policy_loss": -23.354942321777344,
    "value_loss": 0.4997497946023941,
    "entropy": 0.45446840673685074,
    "total_loss": -23.03697988986969
  },
  {
    "episode": 65,
    "avg_reward_per_step": 210.64626334770617,
    "episode_length": 95,
    "policy_loss": -3578.4259033203125,
    "value_loss": 0.7515316903591156,
    "entropy": 0.8265988677740097,
    "total_loss": -3578.005011177063
  },
  {
    "episode": 66,
    "avg_reward_per_step": -13.545358723764975,
    "episode_length": 3000,
    "policy_loss": 224.7127227783203,
    "value_loss": 3.3511457443237305,
    "entropy": 0.4152612015604973,
    "total_loss": 227.89776404201984
  },
  {
    "episode": 67,
    "avg_reward_per_step": -14.174433782647617,
    "episode_length": 3000,
    "policy_loss": 234.07129287719727,
    "value_loss": 3.3551345467567444,
    "entropy": 0.3678111657500267,
    "total_loss": 237.279302957654
  },
  {
    "episode": 68,
    "avg_reward_per_step": -12.241730569233951,
    "episode_length": 3000,
    "policy_loss": 201.48025512695312,
    "value_loss": 2.931836187839508,
    "entropy": 0.41385743021965027,
    "total_loss": 204.24654834270478
  },
  {
    "episode": 69,
    "avg_reward_per_step": -14.085691748762617,
    "episode_length": 3000,
    "policy_loss": 232.1731414794922,
    "value_loss": 3.444013297557831,
    "entropy": 0.39030297845602036,
    "total_loss": 235.46103358566762
  },
  {
    "episode": 70,
    "avg_reward_per_step": -13.298813533441551,
    "episode_length": 3000,
    "policy_loss": 218.74774932861328,
    "value_loss": 3.34177827835083,
    "entropy": 0.39913180470466614,
    "total_loss": 221.92987488508226
  },
  {
    "episode": 71,
    "avg_reward_per_step": -13.12468615844277,
    "episode_length": 3000,
    "policy_loss": 215.4156036376953,
    "value_loss": 3.7309223413467407,
    "entropy": 0.4152083322405815,
    "total_loss": 218.98044264614583
  },
  {
    "episode": 72,
    "avg_reward_per_step": -13.905220445722597,
    "episode_length": 3000,
    "policy_loss": 228.22475814819336,
    "value_loss": 3.183087944984436,
    "entropy": 0.37718844413757324,
    "total_loss": 231.25697071552275
  },
  {
    "episode": 73,
    "avg_reward_per_step": -13.856559374831145,
    "episode_length": 3000,
    "policy_loss": 227.30542755126953,
    "value_loss": 3.2073825001716614,
    "entropy": 0.3775031641125679,
    "total_loss": 230.36180878579617
  },
  {
    "episode": 74,
    "avg_reward_per_step": -14.18115017619182,
    "episode_length": 3000,
    "policy_loss": 232.63409042358398,
    "value_loss": 3.4793575406074524,
    "entropy": 0.39517180621623993,
    "total_loss": 235.95537924170495
  },
  {
    "episode": 75,
    "avg_reward_per_step": -13.965840366175614,
    "episode_length": 3000,
    "policy_loss": 228.76956176757812,
    "value_loss": 3.181871771812439,
    "entropy": 0.37774889171123505,
    "total_loss": 231.80033398270606
  },
  {
    "episode": 76,
    "avg_reward_per_step": -13.38692405838663,
    "episode_length": 3000,
    "policy_loss": 218.80435180664062,
    "value_loss": 2.7890408635139465,
    "entropy": 0.42880096286535263,
    "total_loss": 221.42187228500842
  },
  {
    "episode": 77,
    "avg_reward_per_step": -14.191022183166085,
    "episode_length": 3000,
    "policy_loss": 231.76038360595703,
    "value_loss": 3.1053611636161804,
    "entropy": 0.42985381931066513,
    "total_loss": 234.69380324184894
  },
  {
    "episode": 78,
    "avg_reward_per_step": -12.657132353502675,
    "episode_length": 3000,
    "policy_loss": 205.89423751831055,
    "value_loss": 2.7735756039619446,
    "entropy": 0.48524171113967896,
    "total_loss": 208.47371643781662
  },
  {
    "episode": 79,
    "avg_reward_per_step": 232.54617289943099,
    "episode_length": 86,
    "policy_loss": -3912.5733032226562,
    "value_loss": 0.7922815680503845,
    "entropy": 0.29549309611320496,
    "total_loss": -3911.899218893051
  },
  {
    "episode": 80,
    "avg_reward_per_step": 33.27783142638808,
    "episode_length": 488,
    "policy_loss": -573.1540985107422,
    "value_loss": 0.5227938592433929,
    "entropy": 0.383943609893322,
    "total_loss": -572.7848820954562
  },
  {
    "episode": 81,
    "avg_reward_per_step": -10.999497572745057,
    "episode_length": 3000,
    "policy_loss": 177.3672981262207,
    "value_loss": 2.6699151396751404,
    "entropy": 0.5994604676961899,
    "total_loss": 179.79742907881737
  },
  {
    "episode": 82,
    "avg_reward_per_step": -11.269122053269637,
    "episode_length": 3000,
    "policy_loss": 181.57684707641602,
    "value_loss": 2.492826759815216,
    "entropy": 0.5581398606300354,
    "total_loss": 183.84641789197923
  },
  {
    "episode": 83,
    "avg_reward_per_step": 36.69806855423617,
    "episode_length": 483,
    "policy_loss": -632.7958831787109,
    "value_loss": 0.5279517620801926,
    "entropy": 0.5207945331931114,
    "total_loss": -632.476249229908
  },
  {
    "episode": 84,
    "avg_reward_per_step": 4.942463914184519,
    "episode_length": 1509,
    "policy_loss": -91.90059089660645,
    "value_loss": 0.5011809766292572,
    "entropy": 0.6190668344497681,
    "total_loss": -91.6470366537571
  },
  {
    "episode": 85,
    "avg_reward_per_step": 8.82504160560991,
    "episode_length": 1196,
    "policy_loss": -158.22825622558594,
    "value_loss": 0.5039081126451492,
    "entropy": 0.6373316198587418,
    "total_loss": -157.97928076088428
  },
  {
    "episode": 86,
    "avg_reward_per_step": 33.81878844741467,
    "episode_length": 503,
    "policy_loss": -586.3054809570312,
    "value_loss": 0.5243908166885376,
    "entropy": 0.7815943211317062,
    "total_loss": -586.0937278687954
  },
  {
    "episode": 87,
    "avg_reward_per_step": 22.7024337254055,
    "episode_length": 670,
    "policy_loss": -397.27088165283203,
    "value_loss": 0.5143143236637115,
    "entropy": 0.7307913154363632,
    "total_loss": -397.04888385534286
  },
  {
    "episode": 88,
    "avg_reward_per_step": 40.36503080719196,
    "episode_length": 475,
    "policy_loss": -692.5254974365234,
    "value_loss": 0.5332382172346115,
    "entropy": 0.8644418865442276,
    "total_loss": -692.3380359739065
  },
  {
    "episode": 89,
    "avg_reward_per_step": 138.5113605368902,
    "episode_length": 144,
    "policy_loss": -2389.704833984375,
    "value_loss": 0.6417910754680634,
    "entropy": 0.799043819308281,
    "total_loss": -2389.3826604366304
  },
  {
    "episode": 90,
    "avg_reward_per_step": 54.75125430004233,
    "episode_length": 335,
    "policy_loss": -948.5753479003906,
    "value_loss": 0.5442723035812378,
    "entropy": 0.7174821048974991,
    "total_loss": -948.3180684387684
  },
  {
    "episode": 91,
    "avg_reward_per_step": 26.752580888389723,
    "episode_length": 671,
    "policy_loss": -465.25960540771484,
    "value_loss": 0.5206299275159836,
    "entropy": 0.8732868283987045,
    "total_loss": -465.08829021155833
  },
  {
    "episode": 92,
    "avg_reward_per_step": 27.966097231690906,
    "episode_length": 618,
    "policy_loss": -478.9527130126953,
    "value_loss": 0.5206135660409927,
    "entropy": 0.49610283225774765,
    "total_loss": -478.6305405795574
  },
  {
    "episode": 93,
    "avg_reward_per_step": -10.604437075673324,
    "episode_length": 3000,
    "policy_loss": 169.86495208740234,
    "value_loss": 2.2231287360191345,
    "entropy": 0.6978538334369659,
    "total_loss": 171.80893929004668
  },
  {
    "episode": 94,
    "avg_reward_per_step": 29.846556579868913,
    "episode_length": 571,
    "policy_loss": -514.0155487060547,
    "value_loss": 0.5217815190553665,
    "entropy": 0.7103815674781799,
    "total_loss": -513.7779198139906
  },
  {
    "episode": 95,
    "avg_reward_per_step": 221.84782563796085,
    "episode_length": 90,
    "policy_loss": -3747.2685546875,
    "value_loss": 0.7704213261604309,
    "entropy": 0.5868425816297531,
    "total_loss": -3746.7328703939916
  },
  {
    "episode": 96,
    "avg_reward_per_step": 46.74093539155145,
    "episode_length": 375,
    "policy_loss": -801.9214782714844,
    "value_loss": 0.5355249345302582,
    "entropy": 0.441089004278183,
    "total_loss": -801.5623889386654
  },
  {
    "episode": 97,
    "avg_reward_per_step": -10.34766944333262,
    "episode_length": 3000,
    "policy_loss": 165.58861541748047,
    "value_loss": 2.385880947113037,
    "entropy": 0.7261203974485397,
    "total_loss": 167.6840482056141
  },
  {
    "episode": 98,
    "avg_reward_per_step": -11.354734737064165,
    "episode_length": 3000,
    "policy_loss": 182.2508544921875,
    "value_loss": 2.2645888328552246,
    "entropy": 0.555878296494484,
    "total_loss": 184.29309200644494
  },
  {
    "episode": 99,
    "avg_reward_per_step": 88.76366303606117,
    "episode_length": 219,
    "policy_loss": -1515.5433349609375,
    "value_loss": 0.5802954435348511,
    "entropy": 0.8823651373386383,
    "total_loss": -1515.3159855723381
  },
  {
    "episode": 100,
    "avg_reward_per_step": -13.659040717792111,
    "episode_length": 3000,
    "policy_loss": 221.0148696899414,
    "value_loss": 2.49092835187912,
    "entropy": 0.4729798510670662,
    "total_loss": 223.3166061013937
  },
  {
    "episode": 101,
    "avg_reward_per_step": -13.168670524169402,
    "episode_length": 3000,
    "policy_loss": 212.56787872314453,
    "value_loss": 2.3407914638519287,
    "entropy": 0.3749811053276062,
    "total_loss": 214.75867774486542
  },
  {
    "episode": 102,
    "avg_reward_per_step": 149.2011040022481,
    "episode_length": 133,
    "policy_loss": -2547.6996459960938,
    "value_loss": 0.6557617038488388,
    "entropy": 0.6971247494220734,
    "total_loss": -2547.3227341920137
  },
  {
    "episode": 103,
    "avg_reward_per_step": 24.968970442974463,
    "episode_length": 670,
    "policy_loss": -430.1742172241211,
    "value_loss": 0.5174912214279175,
    "entropy": 0.5425508767366409,
    "total_loss": -429.87374635338784
  },
  {
    "episode": 104,
    "avg_reward_per_step": 10.054652875248905,
    "episode_length": 1198,
    "policy_loss": -179.15591430664062,
    "value_loss": 0.5053295195102692,
    "entropy": 0.20381679385900497,
    "total_loss": -178.73211150467395
  },
  {
    "episode": 105,
    "avg_reward_per_step": -12.313486818379873,
    "episode_length": 3000,
    "policy_loss": 197.5790901184082,
    "value_loss": 1.8155495524406433,
    "entropy": 0.2680080235004425,
    "total_loss": 199.28743646144866
  },
  {
    "episode": 106,
    "avg_reward_per_step": -13.010119453763465,
    "episode_length": 3000,
    "policy_loss": 209.06819915771484,
    "value_loss": 2.0284454226493835,
    "entropy": 0.33387361466884613,
    "total_loss": 210.96309513449668
  },
  {
    "episode": 107,
    "avg_reward_per_step": 229.7354756583715,
    "episode_length": 87,
    "policy_loss": -3892.0435791015625,
    "value_loss": 0.7868717014789581,
    "entropy": 0.5956527292728424,
    "total_loss": -3891.494968491793
  },
  {
    "episode": 108,
    "avg_reward_per_step": 244.194723427531,
    "episode_length": 82,
    "policy_loss": -4141.7001953125,
    "value_loss": 0.8161003738641739,
    "entropy": 0.23523631319403648,
    "total_loss": -4140.978189463914
  },
  {
    "episode": 109,
    "avg_reward_per_step": 5.049308536603661,
    "episode_length": 1857,
    "policy_loss": -95.2051944732666,
    "value_loss": 0.5022473335266113,
    "entropy": 0.21705570444464684,
    "total_loss": -94.78976942151785
  },
  {
    "episode": 110,
    "avg_reward_per_step": -4.3252501603259415,
    "episode_length": 3000,
    "policy_loss": 63.02639579772949,
    "value_loss": 0.7873226404190063,
    "entropy": 0.11156509630382061,
    "total_loss": 63.76909239962697
  },
  {
    "episode": 111,
    "avg_reward_per_step": 48.32929866378575,
    "episode_length": 387,
    "policy_loss": -827.9796142578125,
    "value_loss": 0.53932985663414,
    "entropy": 0.44846682995557785,
    "total_loss": -827.6196711331606
  },
  {
    "episode": 112,
    "avg_reward_per_step": 28.415443954475307,
    "episode_length": 615,
    "policy_loss": -490.49349212646484,
    "value_loss": 0.5209457874298096,
    "entropy": 0.5135575830936432,
    "total_loss": -490.1779693722725
  },
  {
    "episode": 113,
    "avg_reward_per_step": 307.97172220223405,
    "episode_length": 65,
    "policy_loss": -5128.224853515625,
    "value_loss": 0.9540996104478836,
    "entropy": 0.20221123471856117,
    "total_loss": -5127.3516383990645
  },
  {
    "episode": 114,
    "avg_reward_per_step": 127.88794629690554,
    "episode_length": 156,
    "policy_loss": -2178.2938842773438,
    "value_loss": 0.627826064825058,
    "entropy": 0.27009159326553345,
    "total_loss": -2177.774094849825
  },
  {
    "episode": 115,
    "avg_reward_per_step": 40.93604757342906,
    "episode_length": 459,
    "policy_loss": -703.9377593994141,
    "value_loss": 0.5332705080509186,
    "entropy": 0.3960874155163765,
    "total_loss": -703.5629238575697
  },
  {
    "episode": 116,
    "avg_reward_per_step": -12.356373497839655,
    "episode_length": 3000,
    "policy_loss": 197.5810432434082,
    "value_loss": 2.189442217350006,
    "entropy": 0.14900154992938042,
    "total_loss": 199.71088484078646
  },
  {
    "episode": 117,
    "avg_reward_per_step": 40.48489596457191,
    "episode_length": 454,
    "policy_loss": -694.7103118896484,
    "value_loss": 0.5322843492031097,
    "entropy": 0.282417893409729,
    "total_loss": -694.2909946978092
  },
  {
    "episode": 118,
    "avg_reward_per_step": 17.67960944731611,
    "episode_length": 850,
    "policy_loss": -309.62381744384766,
    "value_loss": 0.5111360996961594,
    "entropy": 0.3447515591979027,
    "total_loss": -309.25058196783067
  },
  {
    "episode": 119,
    "avg_reward_per_step": 206.00570992844877,
    "episode_length": 97,
    "policy_loss": -3494.5803833007812,
    "value_loss": 0.744392991065979,
    "entropy": 0.34554819762706757,
    "total_loss": -3493.974209588766
  },
  {
    "episode": 120,
    "avg_reward_per_step": 246.62200962445678,
    "episode_length": 81,
    "policy_loss": -4164.3216552734375,
    "value_loss": 0.8195279985666275,
    "entropy": 0.34984609484672546,
    "total_loss": -4163.642065712809
  },
  {
    "episode": 121,
    "avg_reward_per_step": 98.86643021977955,
    "episode_length": 196,
    "policy_loss": -1684.6773376464844,
    "value_loss": 0.5905831456184387,
    "entropy": 0.4054252654314041,
    "total_loss": -1684.2489246070386
  },
  {
    "episode": 122,
    "avg_reward_per_step": 108.92985022082412,
    "episode_length": 183,
    "policy_loss": -1860.883056640625,
    "value_loss": 0.6054590493440628,
    "entropy": 0.3105213791131973,
    "total_loss": -1860.4018061429263
  },
  {
    "episode": 123,
    "avg_reward_per_step": 22.997697934368823,
    "episode_length": 749,
    "policy_loss": -398.9033203125,
    "value_loss": 0.5168385207653046,
    "entropy": 0.3894915506243706,
    "total_loss": -398.54227841198446
  },
  {
    "episode": 124,
    "avg_reward_per_step": 212.76662899094973,
    "episode_length": 94,
    "policy_loss": -3624.4063110351562,
    "value_loss": 0.7559560835361481,
    "entropy": 0.41104285418987274,
    "total_loss": -3623.814772093296
  },
  {
    "episode": 125,
    "avg_reward_per_step": 455.6676317471001,
    "episode_length": 44,
    "policy_loss": -7257.26123046875,
    "value_loss": 1.3971985578536987,
    "entropy": 0.27941684052348137,
    "total_loss": -7255.975798647106
  },
  {
    "episode": 126,
    "avg_reward_per_step": -11.091037574735205,
    "episode_length": 3000,
    "policy_loss": 176.1439666748047,
    "value_loss": 5.892806887626648,
    "entropy": 0.08258333429694176,
    "total_loss": 182.00374022871256
  },
  {
    "episode": 127,
    "avg_reward_per_step": 214.8582911462919,
    "episode_length": 93,
    "policy_loss": -3642.48095703125,
    "value_loss": 0.7597611844539642,
    "entropy": 0.5029457211494446,
    "total_loss": -3641.9223741352557
  },
  {
    "episode": 128,
    "avg_reward_per_step": 130.44404440116773,
    "episode_length": 153,
    "policy_loss": -2214.7838745117188,
    "value_loss": 0.6321776360273361,
    "entropy": 0.15297814831137657,
    "total_loss": -2214.212888135016
  },
  {
    "episode": 129,
    "avg_reward_per_step": 345.8290157612409,
    "episode_length": 58,
    "policy_loss": -5738.3143310546875,
    "value_loss": 1.0545768737792969,
    "entropy": 0.22841503843665123,
    "total_loss": -5737.351120196283
  },
  {
    "episode": 130,
    "avg_reward_per_step": 270.8805213802615,
    "episode_length": 74,
    "policy_loss": -4574.0103759765625,
    "value_loss": 0.8714095950126648,
    "entropy": 0.19733092188835144,
    "total_loss": -4573.217898750305
  },
  {
    "episode": 131,
    "avg_reward_per_step": -12.468932659159558,
    "episode_length": 3000,
    "policy_loss": 198.53497314453125,
    "value_loss": 2.3175045251846313,
    "entropy": 0.23219820857048035,
    "total_loss": 200.75959838628768
  },
  {
    "episode": 132,
    "avg_reward_per_step": -19.433507361379665,
    "episode_length": 3000,
    "policy_loss": 316.2450180053711,
    "value_loss": 14.612582921981812,
    "entropy": 0.061320606619119644,
    "total_loss": 330.83307268470526
  },
  {
    "episode": 133,
    "avg_reward_per_step": 401.21101927753466,
    "episode_length": 50,
    "policy_loss": -6597.819580078125,
    "value_loss": 1.2177673876285553,
    "entropy": 0.19696076214313507,
    "total_loss": -6596.680596995354
  },
  {
    "episode": 134,
    "avg_reward_per_step": 34.679872922647526,
    "episode_length": 570,
    "policy_loss": -595.1379852294922,
    "value_loss": 0.5300235152244568,
    "entropy": 0.03643206972628832,
    "total_loss": -594.6225345421583
  },
  {
    "episode": 135,
    "avg_reward_per_step": 378.47265969494157,
    "episode_length": 53,
    "policy_loss": -6182.8258056640625,
    "value_loss": 1.1485963761806488,
    "entropy": 0.0786932148039341,
    "total_loss": -6181.708686573804
  },
  {
    "episode": 136,
    "avg_reward_per_step": 194.40904757132242,
    "episode_length": 103,
    "policy_loss": -3291.9202270507812,
    "value_loss": 0.7257669270038605,
    "entropy": 0.11416047997772694,
    "total_loss": -3291.2401243157683
  },
  {
    "episode": 137,
    "avg_reward_per_step": 489.03616823671916,
    "episode_length": 41,
    "policy_loss": -7640.367431640625,
    "value_loss": 1.520016461610794,
    "entropy": 0.1458042487502098,
    "total_loss": -7638.905736878514
  },
  {
    "episode": 138,
    "avg_reward_per_step": 203.89891694233862,
    "episode_length": 98,
    "policy_loss": -3451.263916015625,
    "value_loss": 0.7397362142801285,
    "entropy": 0.16919946670532227,
    "total_loss": -3450.591859588027
  },
  {
    "episode": 139,
    "avg_reward_per_step": 435.25334257598644,
    "episode_length": 46,
    "policy_loss": -6951.2073974609375,
    "value_loss": 1.3266048729419708,
    "entropy": 0.22004199773073196,
    "total_loss": -6949.968809387088
  },
  {
    "episode": 140,
    "avg_reward_per_step": 385.7605954581404,
    "episode_length": 52,
    "policy_loss": -6257.52587890625,
    "value_loss": 1.1702923774719238,
    "entropy": 0.26977451890707016,
    "total_loss": -6256.4634963363405
  },
  {
    "episode": 141,
    "avg_reward_per_step": 542.354576674173,
    "episode_length": 37,
    "policy_loss": -8233.7509765625,
    "value_loss": 1.733386069536209,
    "entropy": 0.17505893111228943,
    "total_loss": -8232.087614065409
  },
  {
    "episode": 142,
    "avg_reward_per_step": 339.57216924132126,
    "episode_length": 59,
    "policy_loss": -5612.9466552734375,
    "value_loss": 1.0377752184867859,
    "entropy": 0.25563935190439224,
    "total_loss": -5612.011135795712
  },
  {
    "episode": 143,
    "avg_reward_per_step": 542.2610427605321,
    "episode_length": 37,
    "policy_loss": -8235.587158203125,
    "value_loss": 1.732664167881012,
    "entropy": 0.18445618450641632,
    "total_loss": -8233.928276509047
  },
  {
    "episode": 144,
    "avg_reward_per_step": 527.9778574247201,
    "episode_length": 38,
    "policy_loss": -8107.4056396484375,
    "value_loss": 1.6736421585083008,
    "entropy": 0.1660362035036087,
    "total_loss": -8105.798411971331
  },
  {
    "episode": 145,
    "avg_reward_per_step": 572.8359692312752,
    "episode_length": 35,
    "policy_loss": -8576.284423828125,
    "value_loss": 1.8629166185855865,
    "entropy": 0.08006885647773743,
    "total_loss": -8574.45353475213
  },
  {
    "episode": 146,
    "avg_reward_per_step": 590.0069202651986,
    "episode_length": 34,
    "policy_loss": -8766.870849609375,
    "value_loss": 1.940008670091629,
    "entropy": 0.14855965971946716,
    "total_loss": -8764.990264803171
  },
  {
    "episode": 147,
    "avg_reward_per_step": 608.0527588151232,
    "episode_length": 33,
    "policy_loss": -8966.10791015625,
    "value_loss": 2.0235868096351624,
    "entropy": 0.12160822562873363,
    "total_loss": -8964.132966636866
  },
  {
    "episode": 148,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8748.8447265625,
    "value_loss": 1.9420553147792816,
    "entropy": 0.11701788194477558,
    "total_loss": -8746.949478400498
  },
  {
    "episode": 149,
    "avg_reward_per_step": 501.6404834234113,
    "episode_length": 40,
    "policy_loss": -7805.263916015625,
    "value_loss": 1.5688906013965607,
    "entropy": 0.17050093784928322,
    "total_loss": -7803.763225789368
  },
  {
    "episode": 150,
    "avg_reward_per_step": 466.5269437706825,
    "episode_length": 43,
    "policy_loss": -7345.644775390625,
    "value_loss": 1.4368616342544556,
    "entropy": 0.14925894513726234,
    "total_loss": -7344.267617334425
  },
  {
    "episode": 151,
    "avg_reward_per_step": 557.4342586009036,
    "episode_length": 36,
    "policy_loss": -8407.402099609375,
    "value_loss": 1.7970036268234253,
    "entropy": 0.10523203201591969,
    "total_loss": -8405.647188795358
  },
  {
    "episode": 152,
    "avg_reward_per_step": -0.5353521117927558,
    "episode_length": 3000,
    "policy_loss": -2.2644391655921936,
    "value_loss": 0.5329865515232086,
    "entropy": 0.006973272538743913,
    "total_loss": -1.7342419230844826
  },
  {
    "episode": 153,
    "avg_reward_per_step": -0.5377336569790704,
    "episode_length": 3000,
    "policy_loss": -1.972205400466919,
    "value_loss": 0.507937029004097,
    "entropy": 0.008772382512688637,
    "total_loss": -1.4677773244678973
  },
  {
    "episode": 154,
    "avg_reward_per_step": 409.4105987129888,
    "episode_length": 49,
    "policy_loss": -6594.3995361328125,
    "value_loss": 1.242307186126709,
    "entropy": 0.11700199544429779,
    "total_loss": -6593.204029744864
  },
  {
    "episode": 155,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8762.115234375,
    "value_loss": 1.9413737952709198,
    "entropy": 0.07278076745569706,
    "total_loss": -8760.202972886711
  },
  {
    "episode": 156,
    "avg_reward_per_step": 501.6404834234113,
    "episode_length": 40,
    "policy_loss": -7760.7369384765625,
    "value_loss": 1.5682916045188904,
    "entropy": 0.13950853422284126,
    "total_loss": -7759.224450285733
  },
  {
    "episode": 157,
    "avg_reward_per_step": 436.14569111927506,
    "episode_length": 46,
    "policy_loss": -6955.2366943359375,
    "value_loss": 1.3301216959953308,
    "entropy": 0.1956353336572647,
    "total_loss": -6953.984826773405
  },
  {
    "episode": 158,
    "avg_reward_per_step": 417.9504028528427,
    "episode_length": 48,
    "policy_loss": -6711.77783203125,
    "value_loss": 1.2696758806705475,
    "entropy": 0.19497868418693542,
    "total_loss": -6710.586147624254
  },
  {
    "episode": 159,
    "avg_reward_per_step": 542.354576674173,
    "episode_length": 37,
    "policy_loss": -8208.29931640625,
    "value_loss": 1.7322923243045807,
    "entropy": 0.05983789078891277,
    "total_loss": -8206.590959238261
  },
  {
    "episode": 160,
    "avg_reward_per_step": 37.4684261984766,
    "episode_length": 528,
    "policy_loss": -644.6244812011719,
    "value_loss": 0.5319560766220093,
    "entropy": 0.013937480049207807,
    "total_loss": -644.0981001165695
  },
  {
    "episode": 161,
    "avg_reward_per_step": 445.8470963763656,
    "episode_length": 45,
    "policy_loss": -7056.5504150390625,
    "value_loss": 1.3632721900939941,
    "entropy": 0.09686654433608055,
    "total_loss": -7055.225889466703
  },
  {
    "episode": 162,
    "avg_reward_per_step": 489.3931545594257,
    "episode_length": 41,
    "policy_loss": -7597.16748046875,
    "value_loss": 1.5211336016654968,
    "entropy": 0.09275759570300579,
    "total_loss": -7595.683449905366
  },
  {
    "episode": 163,
    "avg_reward_per_step": 308.5095282605608,
    "episode_length": 65,
    "policy_loss": -5123.6761474609375,
    "value_loss": 0.9580222368240356,
    "entropy": 0.1978653185069561,
    "total_loss": -5122.797271351516
  },
  {
    "episode": 164,
    "avg_reward_per_step": 426.8536029135415,
    "episode_length": 47,
    "policy_loss": -6804.84033203125,
    "value_loss": 1.2988446652889252,
    "entropy": 0.09039662033319473,
    "total_loss": -6803.577646014094
  },
  {
    "episode": 165,
    "avg_reward_per_step": 401.21238673872904,
    "episode_length": 50,
    "policy_loss": -6461.6038818359375,
    "value_loss": 1.2161412835121155,
    "entropy": 0.08443840406835079,
    "total_loss": -6460.421515914053
  },
  {
    "episode": 166,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8733.624267578125,
    "value_loss": 1.9410541951656342,
    "entropy": 0.025031070224940777,
    "total_loss": -8731.69322581105
  },
  {
    "episode": 167,
    "avg_reward_per_step": 542.354576674173,
    "episode_length": 37,
    "policy_loss": -8211.237060546875,
    "value_loss": 1.7321859300136566,
    "entropy": 0.057223137468099594,
    "total_loss": -8209.527763871849
  },
  {
    "episode": 168,
    "avg_reward_per_step": 542.354576674173,
    "episode_length": 37,
    "policy_loss": -8211.59130859375,
    "value_loss": 1.7321723997592926,
    "entropy": 0.07112879492342472,
    "total_loss": -8209.88758771196
  },
  {
    "episode": 169,
    "avg_reward_per_step": 489.3931545594257,
    "episode_length": 41,
    "policy_loss": -7599.0572509765625,
    "value_loss": 1.5210855305194855,
    "entropy": 0.11605207435786724,
    "total_loss": -7597.5825862757865
  },
  {
    "episode": 170,
    "avg_reward_per_step": 557.4338704757291,
    "episode_length": 36,
    "policy_loss": -8371.76220703125,
    "value_loss": 1.7960716485977173,
    "entropy": 0.046709771268069744,
    "total_loss": -8369.98481929116
  },
  {
    "episode": 171,
    "avg_reward_per_step": 573.4515037034167,
    "episode_length": 35,
    "policy_loss": -8572.2158203125,
    "value_loss": 1.8660073578357697,
    "entropy": 0.03963080793619156,
    "total_loss": -8570.365665277839
  },
  {
    "episode": 172,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8548.677734375,
    "value_loss": 1.865457683801651,
    "entropy": 0.05244776327162981,
    "total_loss": -8546.833255796508
  },
  {
    "episode": 173,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8724.124267578125,
    "value_loss": 1.940972238779068,
    "entropy": 0.05761889833956957,
    "total_loss": -8722.206342898682
  },
  {
    "episode": 174,
    "avg_reward_per_step": 501.6404834234113,
    "episode_length": 40,
    "policy_loss": -7758.216552734375,
    "value_loss": 1.5680054128170013,
    "entropy": 0.14234468713402748,
    "total_loss": -7756.705485196411
  },
  {
    "episode": 175,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9089.558837890625,
    "value_loss": 2.1140857934951782,
    "entropy": 0.04503324721008539,
    "total_loss": -9087.462765396014
  },
  {
    "episode": 176,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8724.236083984375,
    "value_loss": 1.9409676492214203,
    "entropy": 0.053800445050001144,
    "total_loss": -8722.316636513173
  },
  {
    "episode": 177,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9117.2412109375,
    "value_loss": 2.1140135526657104,
    "entropy": 0.05653747357428074,
    "total_loss": -9115.149812374264
  },
  {
    "episode": 178,
    "avg_reward_per_step": 557.4338704757291,
    "episode_length": 36,
    "policy_loss": -8366.465576171875,
    "value_loss": 1.7959558069705963,
    "entropy": 0.08257813937962055,
    "total_loss": -8364.702651620657
  },
  {
    "episode": 179,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9099.258544921875,
    "value_loss": 2.11396324634552,
    "entropy": 0.054458378814160824,
    "total_loss": -9097.166365027055
  },
  {
    "episode": 180,
    "avg_reward_per_step": 608.0160858062335,
    "episode_length": 33,
    "policy_loss": -8942.35595703125,
    "value_loss": 2.0219772458076477,
    "entropy": 0.06255659833550453,
    "total_loss": -8940.359002424777
  },
  {
    "episode": 181,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9087.790771484375,
    "value_loss": 2.114052712917328,
    "entropy": 0.06288887187838554,
    "total_loss": -9085.70187432021
  },
  {
    "episode": 182,
    "avg_reward_per_step": 557.4338704757291,
    "episode_length": 36,
    "policy_loss": -8389.702880859375,
    "value_loss": 1.7959979474544525,
    "entropy": 0.07603177987039089,
    "total_loss": -8387.93729562387
  },
  {
    "episode": 183,
    "avg_reward_per_step": 589.841833522328,
    "episode_length": 34,
    "policy_loss": -8764.02978515625,
    "value_loss": 1.9377653896808624,
    "entropy": 0.05411374103277922,
    "total_loss": -8762.113665262983
  },
  {
    "episode": 184,
    "avg_reward_per_step": 542.354576674173,
    "episode_length": 37,
    "policy_loss": -8221.55419921875,
    "value_loss": 1.7321559488773346,
    "entropy": 0.10928409174084663,
    "total_loss": -8219.865756906569
  },
  {
    "episode": 185,
    "avg_reward_per_step": 514.5158804342684,
    "episode_length": 39,
    "policy_loss": -7929.01611328125,
    "value_loss": 1.6185620725154877,
    "entropy": 0.12165103666484356,
    "total_loss": -7927.446211623401
  },
  {
    "episode": 186,
    "avg_reward_per_step": 528.0689299193892,
    "episode_length": 38,
    "policy_loss": -8048.4207763671875,
    "value_loss": 1.6730681657791138,
    "entropy": 0.07757937721908092,
    "total_loss": -8046.778739952296
  },
  {
    "episode": 187,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8718.71435546875,
    "value_loss": 1.940891832113266,
    "entropy": 0.03393422346562147,
    "total_loss": -8716.787037326023
  },
  {
    "episode": 188,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8554.14599609375,
    "value_loss": 1.8652912080287933,
    "entropy": 0.03913282975554466,
    "total_loss": -8552.296358017624
  },
  {
    "episode": 189,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8553.158203125,
    "value_loss": 1.865238606929779,
    "entropy": 0.04377067741006613,
    "total_loss": -8551.310472789035
  },
  {
    "episode": 190,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8547.5615234375,
    "value_loss": 1.865194708108902,
    "entropy": 0.046123992651700974,
    "total_loss": -8545.714778326452
  },
  {
    "episode": 191,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8721.1728515625,
    "value_loss": 1.940680980682373,
    "entropy": 0.048200697638094425,
    "total_loss": -8719.251450860873
  },
  {
    "episode": 192,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8543.9248046875,
    "value_loss": 1.8651104271411896,
    "entropy": 0.04902667645365,
    "total_loss": -8542.07930493094
  },
  {
    "episode": 193,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8720.724609375,
    "value_loss": 1.9406009316444397,
    "entropy": 0.04984469432383776,
    "total_loss": -8718.803946321084
  },
  {
    "episode": 194,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8722.530029296875,
    "value_loss": 1.9405620098114014,
    "entropy": 0.048904492519795895,
    "total_loss": -8720.609029084071
  },
  {
    "episode": 195,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8724.31884765625,
    "value_loss": 1.9405146837234497,
    "entropy": 0.045937640592455864,
    "total_loss": -8722.396708028764
  },
  {
    "episode": 196,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8721.5634765625,
    "value_loss": 1.9404587745666504,
    "entropy": 0.04105480760335922,
    "total_loss": -8719.639439710974
  },
  {
    "episode": 197,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8720.1845703125,
    "value_loss": 1.9404045045375824,
    "entropy": 0.03722730837762356,
    "total_loss": -8718.259056731313
  },
  {
    "episode": 198,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8721.580322265625,
    "value_loss": 1.9403671622276306,
    "entropy": 0.03609625343233347,
    "total_loss": -8719.654393604771
  },
  {
    "episode": 199,
    "avg_reward_per_step": 542.354576674173,
    "episode_length": 37,
    "policy_loss": -8209.642578125,
    "value_loss": 1.7315151393413544,
    "entropy": 0.08054764568805695,
    "total_loss": -8207.943282043934
  },
  {
    "episode": 200,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8534.543701171875,
    "value_loss": 1.864766389131546,
    "entropy": 0.0410846509039402,
    "total_loss": -8532.695368643104
  },
  {
    "episode": 201,
    "avg_reward_per_step": 528.0689299193892,
    "episode_length": 38,
    "policy_loss": -8042.875,
    "value_loss": 1.6724620759487152,
    "entropy": 0.07834069803357124,
    "total_loss": -8041.233874203264
  },
  {
    "episode": 202,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8721.6025390625,
    "value_loss": 1.9402223527431488,
    "entropy": 0.024600121658295393,
    "total_loss": -8719.67215675842
  },
  {
    "episode": 203,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9122.971923828125,
    "value_loss": 2.1132978796958923,
    "entropy": 0.03734869696199894,
    "total_loss": -9120.873565427213
  },
  {
    "episode": 204,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8715.164794921875,
    "value_loss": 1.9401768743991852,
    "entropy": 0.0378081351518631,
    "total_loss": -8713.239741301537
  },
  {
    "episode": 205,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8712.7490234375,
    "value_loss": 1.9401344656944275,
    "entropy": 0.04043619800359011,
    "total_loss": -8710.825063451008
  },
  {
    "episode": 206,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8718.990966796875,
    "value_loss": 1.94008669257164,
    "entropy": 0.03930164221674204,
    "total_loss": -8717.06660076119
  },
  {
    "episode": 207,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8718.533447265625,
    "value_loss": 1.9400400817394257,
    "entropy": 0.0355345793068409,
    "total_loss": -8716.607621015608
  },
  {
    "episode": 208,
    "avg_reward_per_step": 573.3748383631245,
    "episode_length": 35,
    "policy_loss": -8540.336669921875,
    "value_loss": 1.864499568939209,
    "entropy": 0.0411682790145278,
    "total_loss": -8538.48863766454
  },
  {
    "episode": 209,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8714.44287109375,
    "value_loss": 1.9399693608283997,
    "entropy": 0.03072656085714698,
    "total_loss": -8712.515192357265
  },
  {
    "episode": 210,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8716.772216796875,
    "value_loss": 1.9399397373199463,
    "entropy": 0.030167200602591038,
    "total_loss": -8714.844343939796
  },
  {
    "episode": 211,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9107.987548828125,
    "value_loss": 2.112964391708374,
    "entropy": 0.03366577532142401,
    "total_loss": -9105.888050746546
  },
  {
    "episode": 212,
    "avg_reward_per_step": 590.2559351675344,
    "episode_length": 34,
    "policy_loss": -8706.31494140625,
    "value_loss": 1.9398635923862457,
    "entropy": 0.03492337837815285,
    "total_loss": -8704.389047165216
  },
  {
    "episode": 213,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9098.84326171875,
    "value_loss": 2.1128516793251038,
    "entropy": 0.036233434453606606,
    "total_loss": -9096.744903413206
  },
  {
    "episode": 214,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9099.258544921875,
    "value_loss": 2.1128000020980835,
    "entropy": 0.03157775569707155,
    "total_loss": -9097.158376022056
  },
  {
    "episode": 215,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9089.51318359375,
    "value_loss": 2.1127272844314575,
    "entropy": 0.023249562364071608,
    "total_loss": -9087.409756134264
  },
  {
    "episode": 216,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9085.619140625,
    "value_loss": 2.112652599811554,
    "entropy": 0.018911263905465603,
    "total_loss": -9083.51405253075
  },
  {
    "episode": 217,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9084.426025390625,
    "value_loss": 2.1125831604003906,
    "entropy": 0.016727862879633904,
    "total_loss": -9082.320133375377
  },
  {
    "episode": 218,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9083.742919921875,
    "value_loss": 2.1125208139419556,
    "entropy": 0.015268428949639201,
    "total_loss": -9081.636506479514
  },
  {
    "episode": 219,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9083.24951171875,
    "value_loss": 2.1124666929244995,
    "entropy": 0.013927134685218334,
    "total_loss": -9081.1426158797
  },
  {
    "episode": 220,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9082.765380859375,
    "value_loss": 2.1124146580696106,
    "entropy": 0.01256485446356237,
    "total_loss": -9080.657992143091
  },
  {
    "episode": 221,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9082.2490234375,
    "value_loss": 2.1123658418655396,
    "entropy": 0.011245042318478227,
    "total_loss": -9080.141155612562
  },
  {
    "episode": 222,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9081.70458984375,
    "value_loss": 2.112318277359009,
    "entropy": 0.010060027940198779,
    "total_loss": -9079.596295577567
  },
  {
    "episode": 223,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9081.1552734375,
    "value_loss": 2.112269639968872,
    "entropy": 0.009034529095515609,
    "total_loss": -9079.046617609169
  },
  {
    "episode": 224,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9080.609130859375,
    "value_loss": 2.1122209429740906,
    "entropy": 0.008161055855453014,
    "total_loss": -9078.500174338744
  },
  {
    "episode": 225,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9080.0693359375,
    "value_loss": 2.1121723651885986,
    "entropy": 0.007426296127960086,
    "total_loss": -9077.960134090763
  },
  {
    "episode": 226,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9079.537841796875,
    "value_loss": 2.11212295293808,
    "entropy": 0.0068030214169994,
    "total_loss": -9077.428440052503
  },
  {
    "episode": 227,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9079.01025390625,
    "value_loss": 2.112070918083191,
    "entropy": 0.0062647220911458135,
    "total_loss": -9076.900688877004
  },
  {
    "episode": 228,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9078.484375,
    "value_loss": 2.1120190620422363,
    "entropy": 0.00579308660235256,
    "total_loss": -9076.374673172599
  },
  {
    "episode": 229,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9077.95849609375,
    "value_loss": 2.1119654774665833,
    "entropy": 0.005375300999730825,
    "total_loss": -9075.848680736683
  },
  {
    "episode": 230,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9077.434814453125,
    "value_loss": 2.11191189289093,
    "entropy": 0.005002968246117234,
    "total_loss": -9075.324903747533
  },
  {
    "episode": 231,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9076.907958984375,
    "value_loss": 2.1118571758270264,
    "entropy": 0.0046701820101588964,
    "total_loss": -9074.797969881352
  },
  {
    "episode": 232,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9076.38134765625,
    "value_loss": 2.1118026971817017,
    "entropy": 0.004371238290332258,
    "total_loss": -9074.271293454385
  },
  {
    "episode": 233,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9075.854248046875,
    "value_loss": 2.1117475628852844,
    "entropy": 0.004102024715393782,
    "total_loss": -9073.744141293875
  },
  {
    "episode": 234,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9075.322509765625,
    "value_loss": 2.111690640449524,
    "entropy": 0.003859240678139031,
    "total_loss": -9073.212362821447
  },
  {
    "episode": 235,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9074.794189453125,
    "value_loss": 2.1116350293159485,
    "entropy": 0.003639717062469572,
    "total_loss": -9072.684010310633
  },
  {
    "episode": 236,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9074.258056640625,
    "value_loss": 2.1115769743919373,
    "entropy": 0.003440577653236687,
    "total_loss": -9072.147855897294
  },
  {
    "episode": 237,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9073.722900390625,
    "value_loss": 2.1115201115608215,
    "entropy": 0.003259829303715378,
    "total_loss": -9071.612684210786
  },
  {
    "episode": 238,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9073.184814453125,
    "value_loss": 2.1114625930786133,
    "entropy": 0.003095364896580577,
    "total_loss": -9071.074590006005
  },
  {
    "episode": 239,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9072.644775390625,
    "value_loss": 2.111403703689575,
    "entropy": 0.0029455445474013686,
    "total_loss": -9070.534549904754
  },
  {
    "episode": 240,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9072.100830078125,
    "value_loss": 2.1113451719284058,
    "entropy": 0.002808720339089632,
    "total_loss": -9069.990608394332
  },
  {
    "episode": 241,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9071.553466796875,
    "value_loss": 2.1112853288650513,
    "entropy": 0.0026834222371689975,
    "total_loss": -9069.443254836904
  },
  {
    "episode": 242,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9071.00341796875,
    "value_loss": 2.1112248301506042,
    "entropy": 0.0025683584972284734,
    "total_loss": -9068.893220481998
  },
  {
    "episode": 243,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9070.453125,
    "value_loss": 2.111164927482605,
    "entropy": 0.0024624192737974226,
    "total_loss": -9068.342945040227
  },
  {
    "episode": 244,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9069.900390625,
    "value_loss": 2.111104965209961,
    "entropy": 0.0023645423934794962,
    "total_loss": -9067.790231476747
  },
  {
    "episode": 245,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9069.34375,
    "value_loss": 2.1110439896583557,
    "entropy": 0.0022738708648830652,
    "total_loss": -9067.233615558687
  },
  {
    "episode": 246,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9068.785888671875,
    "value_loss": 2.1109827756881714,
    "entropy": 0.002189818420447409,
    "total_loss": -9066.675781823555
  },
  {
    "episode": 247,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9068.222412109375,
    "value_loss": 2.1109203696250916,
    "entropy": 0.0021117713185958564,
    "total_loss": -9066.112336448277
  },
  {
    "episode": 248,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9067.658203125,
    "value_loss": 2.1108583211898804,
    "entropy": 0.0020390936406329274,
    "total_loss": -9065.548160441267
  },
  {
    "episode": 249,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9067.09130859375,
    "value_loss": 2.1107958555221558,
    "entropy": 0.0019711548229679465,
    "total_loss": -9064.981301200158
  },
  {
    "episode": 250,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9066.52197265625,
    "value_loss": 2.110732913017273,
    "entropy": 0.0019075099262408912,
    "total_loss": -9064.412002747204
  },
  {
    "episode": 251,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9065.952392578125,
    "value_loss": 2.110670506954193,
    "entropy": 0.001847781502874568,
    "total_loss": -9063.842461183773
  },
  {
    "episode": 252,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9065.377197265625,
    "value_loss": 2.1106066703796387,
    "entropy": 0.001791583636077121,
    "total_loss": -9063.2673072287
  },
  {
    "episode": 253,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9064.800048828125,
    "value_loss": 2.110542595386505,
    "entropy": 0.001738636288791895,
    "total_loss": -9062.690201687254
  },
  {
    "episode": 254,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9064.222412109375,
    "value_loss": 2.110478937625885,
    "entropy": 0.001688678952632472,
    "total_loss": -9062.11260864333
  },
  {
    "episode": 255,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9063.64111328125,
    "value_loss": 2.1104151606559753,
    "entropy": 0.0016414495767094195,
    "total_loss": -9061.531354700424
  },
  {
    "episode": 256,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9063.05859375,
    "value_loss": 2.1103508472442627,
    "entropy": 0.0015967308136168867,
    "total_loss": -9060.94888159508
  },
  {
    "episode": 257,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9062.4697265625,
    "value_loss": 2.1102850437164307,
    "entropy": 0.0015543263871222734,
    "total_loss": -9060.360063249338
  },
  {
    "episode": 258,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9061.880859375,
    "value_loss": 2.1102206110954285,
    "entropy": 0.001514066563686356,
    "total_loss": -9059.77124439053
  },
  {
    "episode": 259,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9061.28955078125,
    "value_loss": 2.1101547479629517,
    "entropy": 0.0014757918543182313,
    "total_loss": -9059.17998635003
  },
  {
    "episode": 260,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9060.6962890625,
    "value_loss": 2.110089421272278,
    "entropy": 0.0014393542078323662,
    "total_loss": -9058.586775382912
  },
  {
    "episode": 261,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9060.101318359375,
    "value_loss": 2.1100236773490906,
    "entropy": 0.0014046194264665246,
    "total_loss": -9057.991856529796
  },
  {
    "episode": 262,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9059.50244140625,
    "value_loss": 2.1099579334259033,
    "entropy": 0.0013714807864744216,
    "total_loss": -9057.393032065138
  },
  {
    "episode": 263,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9058.9013671875,
    "value_loss": 2.1098907589912415,
    "entropy": 0.0013398299342952669,
    "total_loss": -9056.792012360482
  },
  {
    "episode": 264,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9058.2958984375,
    "value_loss": 2.1098239421844482,
    "entropy": 0.0013096282200422138,
    "total_loss": -9056.186598346603
  },
  {
    "episode": 265,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9057.690673828125,
    "value_loss": 2.109756588935852,
    "entropy": 0.001280762633541599,
    "total_loss": -9055.581429544243
  },
  {
    "episode": 266,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9057.083251953125,
    "value_loss": 2.109689950942993,
    "entropy": 0.0012531804095488042,
    "total_loss": -9054.974063274345
  },
  {
    "episode": 267,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9056.4716796875,
    "value_loss": 2.1096221804618835,
    "entropy": 0.0012267444399185479,
    "total_loss": -9054.362548204814
  },
  {
    "episode": 268,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9055.8583984375,
    "value_loss": 2.1095535159111023,
    "entropy": 0.001201374689117074,
    "total_loss": -9053.749325471465
  },
  {
    "episode": 269,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9055.239990234375,
    "value_loss": 2.1094847321510315,
    "entropy": 0.001176992227556184,
    "total_loss": -9053.130976299115
  },
  {
    "episode": 270,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9054.621826171875,
    "value_loss": 2.1094162464141846,
    "entropy": 0.0011535620142240077,
    "total_loss": -9052.512871350267
  },
  {
    "episode": 271,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9054.00244140625,
    "value_loss": 2.1093481183052063,
    "entropy": 0.0011310383852105588,
    "total_loss": -9051.893545703299
  },
  {
    "episode": 272,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9053.376953125,
    "value_loss": 2.109277904033661,
    "entropy": 0.0011093450884800404,
    "total_loss": -9051.268118959002
  },
  {
    "episode": 273,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9052.751708984375,
    "value_loss": 2.109208345413208,
    "entropy": 0.0010884344228543341,
    "total_loss": -9050.642936012731
  },
  {
    "episode": 274,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9052.12451171875,
    "value_loss": 2.109139621257782,
    "entropy": 0.0010682670108508319,
    "total_loss": -9050.015799404297
  },
  {
    "episode": 275,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9051.49365234375,
    "value_loss": 2.1090689301490784,
    "entropy": 0.001048802922014147,
    "total_loss": -9049.38500293477
  },
  {
    "episode": 276,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9050.862548828125,
    "value_loss": 2.10899955034256,
    "entropy": 0.0010300052526872605,
    "total_loss": -9048.753961279883
  },
  {
    "episode": 277,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9050.22314453125,
    "value_loss": 2.108927369117737,
    "entropy": 0.0010118374193552881,
    "total_loss": -9048.1146218971
  },
  {
    "episode": 278,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9049.587158203125,
    "value_loss": 2.1088573932647705,
    "entropy": 0.0009942979668267071,
    "total_loss": -9047.478698529047
  },
  {
    "episode": 279,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9048.9453125,
    "value_loss": 2.108785569667816,
    "entropy": 0.0009773336932994425,
    "total_loss": -9046.83691786381
  },
  {
    "episode": 280,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9048.3046875,
    "value_loss": 2.1087145805358887,
    "entropy": 0.0009609085827833042,
    "total_loss": -9046.196357282897
  },
  {
    "episode": 281,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9047.65869140625,
    "value_loss": 2.1086421608924866,
    "entropy": 0.0009449863864574581,
    "total_loss": -9045.550427239912
  },
  {
    "episode": 282,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9047.010498046875,
    "value_loss": 2.108570396900177,
    "entropy": 0.000929559872020036,
    "total_loss": -9044.902299473924
  },
  {
    "episode": 283,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9046.360107421875,
    "value_loss": 2.108497738838196,
    "entropy": 0.0009146236261585727,
    "total_loss": -9044.251975532487
  },
  {
    "episode": 284,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9045.708251953125,
    "value_loss": 2.108425259590149,
    "entropy": 0.0009001238649943843,
    "total_loss": -9043.60018674308
  },
  {
    "episode": 285,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9045.05224609375,
    "value_loss": 2.1083524227142334,
    "entropy": 0.0008860521775204688,
    "total_loss": -9042.944248091906
  },
  {
    "episode": 286,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9044.396240234375,
    "value_loss": 2.108279824256897,
    "entropy": 0.0008723990176804364,
    "total_loss": -9042.288309369726
  },
  {
    "episode": 287,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9043.7353515625,
    "value_loss": 2.1082062125205994,
    "entropy": 0.0008591902151238173,
    "total_loss": -9041.627489026065
  },
  {
    "episode": 288,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9043.07470703125,
    "value_loss": 2.1081329584121704,
    "entropy": 0.00084634633094538,
    "total_loss": -9040.96691261137
  },
  {
    "episode": 289,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9042.40869140625,
    "value_loss": 2.108058750629425,
    "entropy": 0.000833851401694119,
    "total_loss": -9040.30096619618
  },
  {
    "episode": 290,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9041.7412109375,
    "value_loss": 2.1079837679862976,
    "entropy": 0.0008216944261221215,
    "total_loss": -9039.633555847284
  },
  {
    "episode": 291,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9041.071044921875,
    "value_loss": 2.1079099774360657,
    "entropy": 0.000809860837762244,
    "total_loss": -9038.963458888775
  },
  {
    "episode": 292,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9040.39892578125,
    "value_loss": 2.1078346967697144,
    "entropy": 0.000798332184785977,
    "total_loss": -9038.291410417354
  },
  {
    "episode": 293,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9039.725830078125,
    "value_loss": 2.107760429382324,
    "entropy": 0.0007871077250456437,
    "total_loss": -9037.618384491832
  },
  {
    "episode": 294,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9039.047119140625,
    "value_loss": 2.1076850295066833,
    "entropy": 0.0007761691958876327,
    "total_loss": -9036.939744578796
  },
  {
    "episode": 295,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9038.37060546875,
    "value_loss": 2.107609748840332,
    "entropy": 0.00076550935045816,
    "total_loss": -9036.26330192365
  },
  {
    "episode": 296,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9037.687744140625,
    "value_loss": 2.107534348964691,
    "entropy": 0.0007551191374659538,
    "total_loss": -9035.580511839315
  },
  {
    "episode": 297,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9037.004638671875,
    "value_loss": 2.107458233833313,
    "entropy": 0.0007449943950632587,
    "total_loss": -9034.8974784358
  },
  {
    "episode": 298,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9036.31591796875,
    "value_loss": 2.1073814034461975,
    "entropy": 0.0007351026579272002,
    "total_loss": -9034.208830606367
  },
  {
    "episode": 299,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9035.62841796875,
    "value_loss": 2.1073049902915955,
    "entropy": 0.0007254584634210914,
    "total_loss": -9033.521403161843
  },
  {
    "episode": 300,
    "avg_reward_per_step": 627.2167642603091,
    "episode_length": 32,
    "policy_loss": -9034.935791015625,
    "value_loss": 2.1072278022766113,
    "entropy": 0.0007160315435612574,
    "total_loss": -9032.828849625967
  }
]