[
  {
    "episode": 1,
    "avg_reward_per_step": 14.364132210820422,
    "episode_length": 1158,
    "policy_loss": -289.8032989501953,
    "value_loss": 0.5112991034984589,
    "entropy": 1.382113516330719,
    "total_loss": -289.84484525322915
  },
  {
    "episode": 2,
    "avg_reward_per_step": -2.5075862923063235,
    "episode_length": 3000,
    "policy_loss": 48.95078945159912,
    "value_loss": 2.123116970062256,
    "entropy": 1.3790789246559143,
    "total_loss": 50.52227485179901
  },
  {
    "episode": 3,
    "avg_reward_per_step": 59.31840508967253,
    "episode_length": 327,
    "policy_loss": -1188.0439453125,
    "value_loss": 0.5606818199157715,
    "entropy": 1.3643997013568878,
    "total_loss": -1188.029023373127
  },
  {
    "episode": 4,
    "avg_reward_per_step": -3.562667612442366,
    "episode_length": 3000,
    "policy_loss": 69.89111709594727,
    "value_loss": 1.9734979569911957,
    "entropy": 1.3632719814777374,
    "total_loss": 71.31930626034736
  },
  {
    "episode": 5,
    "avg_reward_per_step": 40.0296109822977,
    "episode_length": 464,
    "policy_loss": -789.7910308837891,
    "value_loss": 0.5374327600002289,
    "entropy": 1.3412721455097198,
    "total_loss": -789.7901069819927
  },
  {
    "episode": 6,
    "avg_reward_per_step": -3.3187394676182165,
    "episode_length": 3000,
    "policy_loss": 64.76930618286133,
    "value_loss": 1.8387432098388672,
    "entropy": 1.3611856400966644,
    "total_loss": 66.06357513666153
  },
  {
    "episode": 7,
    "avg_reward_per_step": 34.86405031929419,
    "episode_length": 520,
    "policy_loss": -696.5999908447266,
    "value_loss": 0.5314570367336273,
    "entropy": 1.34341761469841,
    "total_loss": -696.6059008538723
  },
  {
    "episode": 8,
    "avg_reward_per_step": -4.129103201650615,
    "episode_length": 3000,
    "policy_loss": 80.67047119140625,
    "value_loss": 2.033811867237091,
    "entropy": 1.364054262638092,
    "total_loss": 82.1586613535881
  },
  {
    "episode": 9,
    "avg_reward_per_step": 6.939729410103518,
    "episode_length": 1793,
    "policy_loss": -137.77894592285156,
    "value_loss": 0.5038999319076538,
    "entropy": 1.3515313565731049,
    "total_loss": -137.81565853357316
  },
  {
    "episode": 10,
    "avg_reward_per_step": 58.02149287838063,
    "episode_length": 333,
    "policy_loss": -1144.9086303710938,
    "value_loss": 0.5587672293186188,
    "entropy": 1.3458903431892395,
    "total_loss": -1144.8882192790509
  },
  {
    "episode": 11,
    "avg_reward_per_step": -3.398364203871422,
    "episode_length": 3000,
    "policy_loss": 66.39355087280273,
    "value_loss": 1.8956032991409302,
    "entropy": 1.350800335407257,
    "total_loss": 67.74883403778077
  },
  {
    "episode": 12,
    "avg_reward_per_step": 5.308647855964841,
    "episode_length": 2305,
    "policy_loss": -104.83723449707031,
    "value_loss": 0.5029398798942566,
    "entropy": 1.3520760536193848,
    "total_loss": -104.8751250386238
  },
  {
    "episode": 13,
    "avg_reward_per_step": 20.698743342532794,
    "episode_length": 856,
    "policy_loss": -409.9385452270508,
    "value_loss": 0.5176579356193542,
    "entropy": 1.3530467450618744,
    "total_loss": -409.9621059894562
  },
  {
    "episode": 14,
    "avg_reward_per_step": 57.86455038907085,
    "episode_length": 327,
    "policy_loss": -1145.2041015625,
    "value_loss": 0.5573340207338333,
    "entropy": 1.3125860691070557,
    "total_loss": -1145.171801969409
  },
  {
    "episode": 15,
    "avg_reward_per_step": 5.933087057273612,
    "episode_length": 2070,
    "policy_loss": -118.22472763061523,
    "value_loss": 0.5032826364040375,
    "entropy": 1.3190592527389526,
    "total_loss": -118.24906869530678
  },
  {
    "episode": 16,
    "avg_reward_per_step": 26.603434830827442,
    "episode_length": 652,
    "policy_loss": -526.7331390380859,
    "value_loss": 0.5223949253559113,
    "entropy": 1.2747682631015778,
    "total_loss": -526.7206514179707
  },
  {
    "episode": 17,
    "avg_reward_per_step": 56.17011332454136,
    "episode_length": 331,
    "policy_loss": -1108.4907531738281,
    "value_loss": 0.5540029108524323,
    "entropy": 1.217426598072052,
    "total_loss": -1108.4237209022044
  },
  {
    "episode": 18,
    "avg_reward_per_step": 23.446675442441563,
    "episode_length": 764,
    "policy_loss": -463.49117279052734,
    "value_loss": 0.5204135626554489,
    "entropy": 1.2618703246116638,
    "total_loss": -463.47550735771654
  },
  {
    "episode": 19,
    "avg_reward_per_step": 16.29357337442293,
    "episode_length": 1030,
    "policy_loss": -322.61194610595703,
    "value_loss": 0.5129716545343399,
    "entropy": 1.240031749010086,
    "total_loss": -322.5949871510267
  },
  {
    "episode": 20,
    "avg_reward_per_step": 61.09204845335153,
    "episode_length": 311,
    "policy_loss": -1213.4635925292969,
    "value_loss": 0.5609594285488129,
    "entropy": 1.176064819097519,
    "total_loss": -1213.3730590283872
  },
  {
    "episode": 21,
    "avg_reward_per_step": 10.822617154938445,
    "episode_length": 1295,
    "policy_loss": -213.33430862426758,
    "value_loss": 0.50702303647995,
    "entropy": 1.224250704050064,
    "total_loss": -213.31698586940766
  },
  {
    "episode": 22,
    "avg_reward_per_step": 29.026916295459227,
    "episode_length": 600,
    "policy_loss": -578.5892028808594,
    "value_loss": 0.5246029794216156,
    "entropy": 1.2211484014987946,
    "total_loss": -578.5530592620373
  },
  {
    "episode": 23,
    "avg_reward_per_step": -0.8293300905189431,
    "episode_length": 2864,
    "policy_loss": 14.90172266960144,
    "value_loss": 0.4999110922217369,
    "entropy": 1.1268370747566223,
    "total_loss": 14.950898931920529
  },
  {
    "episode": 24,
    "avg_reward_per_step": 34.400406257004796,
    "episode_length": 482,
    "policy_loss": -677.2450103759766,
    "value_loss": 0.5279481261968613,
    "entropy": 1.062964677810669,
    "total_loss": -677.142248120904
  },
  {
    "episode": 25,
    "avg_reward_per_step": 16.457605166349104,
    "episode_length": 825,
    "policy_loss": -325.55287170410156,
    "value_loss": 0.5104111731052399,
    "entropy": 1.0817669034004211,
    "total_loss": -325.4751672923565
  },
  {
    "episode": 26,
    "avg_reward_per_step": 21.695608634092338,
    "episode_length": 749,
    "policy_loss": -430.02811431884766,
    "value_loss": 0.5170321017503738,
    "entropy": 1.1271249651908875,
    "total_loss": -429.96193220317366
  },
  {
    "episode": 27,
    "avg_reward_per_step": 20.86193370244529,
    "episode_length": 744,
    "policy_loss": -413.78124237060547,
    "value_loss": 0.5153491497039795,
    "entropy": 1.1144249439239502,
    "total_loss": -413.71166319847106
  },
  {
    "episode": 28,
    "avg_reward_per_step": 20.65558569507243,
    "episode_length": 727,
    "policy_loss": -408.8396987915039,
    "value_loss": 0.5147044211626053,
    "entropy": 1.1024406254291534,
    "total_loss": -408.765970620513
  },
  {
    "episode": 29,
    "avg_reward_per_step": 131.1534799480706,
    "episode_length": 151,
    "policy_loss": -2612.5985717773438,
    "value_loss": 0.6618170738220215,
    "entropy": 1.1770741045475006,
    "total_loss": -2612.4075843453406
  },
  {
    "episode": 30,
    "avg_reward_per_step": 117.0048808309294,
    "episode_length": 160,
    "policy_loss": -2341.7283325195312,
    "value_loss": 0.6304183751344681,
    "entropy": 0.9519548714160919,
    "total_loss": -2341.478696092963
  },
  {
    "episode": 31,
    "avg_reward_per_step": 26.171129976620172,
    "episode_length": 553,
    "policy_loss": -518.6185302734375,
    "value_loss": 0.517980232834816,
    "entropy": 0.8669250756502151,
    "total_loss": -518.4473200708628
  },
  {
    "episode": 32,
    "avg_reward_per_step": 3.1420907559309716,
    "episode_length": 1383,
    "policy_loss": -63.65702247619629,
    "value_loss": 0.5003164410591125,
    "entropy": 0.8237349987030029,
    "total_loss": -63.48620003461838
  },
  {
    "episode": 33,
    "avg_reward_per_step": -11.287755183532637,
    "episode_length": 3000,
    "policy_loss": 221.1558380126953,
    "value_loss": 4.151415586471558,
    "entropy": 0.8337687999010086,
    "total_loss": 224.97374607920648
  },
  {
    "episode": 34,
    "avg_reward_per_step": 31.422573169977618,
    "episode_length": 469,
    "policy_loss": -622.2975158691406,
    "value_loss": 0.5222894996404648,
    "entropy": 0.7320039570331573,
    "total_loss": -622.0680279523134
  },
  {
    "episode": 35,
    "avg_reward_per_step": -10.93070598443184,
    "episode_length": 3000,
    "policy_loss": 214.06224060058594,
    "value_loss": 3.094666063785553,
    "entropy": 0.8003084361553192,
    "total_loss": 216.83678328990936
  },
  {
    "episode": 36,
    "avg_reward_per_step": 514.0476252976479,
    "episode_length": 39,
    "policy_loss": -8937.24462890625,
    "value_loss": 2.0032809376716614,
    "entropy": 0.8418482840061188,
    "total_loss": -8935.578087282182
  },
  {
    "episode": 37,
    "avg_reward_per_step": -2.1371079454759645,
    "episode_length": 2060,
    "policy_loss": 43.629937171936035,
    "value_loss": 0.5001623779535294,
    "entropy": 0.6622582972049713,
    "total_loss": 43.86519623100757
  },
  {
    "episode": 38,
    "avg_reward_per_step": -1.3539791244831465,
    "episode_length": 1753,
    "policy_loss": 27.126944065093994,
    "value_loss": 0.4998561590909958,
    "entropy": 0.5785311907529831,
    "total_loss": 27.395387747883795
  },
  {
    "episode": 39,
    "avg_reward_per_step": -1.6508074785182056,
    "episode_length": 1853,
    "policy_loss": 31.100122928619385,
    "value_loss": 0.4999382719397545,
    "entropy": 0.5278719663619995,
    "total_loss": 31.38891241401434
  },
  {
    "episode": 40,
    "avg_reward_per_step": -1.648343855222001,
    "episode_length": 1832,
    "policy_loss": 31.248048782348633,
    "value_loss": 0.49993328750133514,
    "entropy": 0.5252656042575836,
    "total_loss": 31.537875828146934
  },
  {
    "episode": 41,
    "avg_reward_per_step": -12.775280495385108,
    "episode_length": 3000,
    "policy_loss": 250.28296661376953,
    "value_loss": 3.5527769923210144,
    "entropy": 0.5392455756664276,
    "total_loss": 253.62004537582396
  },
  {
    "episode": 42,
    "avg_reward_per_step": -4.28651485875624,
    "episode_length": 2262,
    "policy_loss": 83.42098617553711,
    "value_loss": 0.5016576200723648,
    "entropy": 0.5207093358039856,
    "total_loss": 83.71436006128788
  },
  {
    "episode": 43,
    "avg_reward_per_step": 11.160563812594459,
    "episode_length": 847,
    "policy_loss": -222.7060546875,
    "value_loss": 0.5045959204435349,
    "entropy": 0.5214668214321136,
    "total_loss": -222.4100454956293
  },
  {
    "episode": 44,
    "avg_reward_per_step": 27.78025206602077,
    "episode_length": 490,
    "policy_loss": -549.3213806152344,
    "value_loss": 0.5178548097610474,
    "entropy": 0.5290522277355194,
    "total_loss": -549.0151466965675
  },
  {
    "episode": 45,
    "avg_reward_per_step": 20.23889224155334,
    "episode_length": 638,
    "policy_loss": -401.6802520751953,
    "value_loss": 0.5122104287147522,
    "entropy": 0.5954060256481171,
    "total_loss": -401.4062040567398
  },
  {
    "episode": 46,
    "avg_reward_per_step": -2.520531616188112,
    "episode_length": 2165,
    "policy_loss": 47.98602771759033,
    "value_loss": 0.5003821551799774,
    "entropy": 0.6210077404975891,
    "total_loss": 48.238006776571275
  },
  {
    "episode": 47,
    "avg_reward_per_step": -2.6750008018380296,
    "episode_length": 2788,
    "policy_loss": 51.24141979217529,
    "value_loss": 0.5007213801145554,
    "entropy": 0.7025377601385117,
    "total_loss": 51.46112606823444
  },
  {
    "episode": 48,
    "avg_reward_per_step": -12.067233836462343,
    "episode_length": 3000,
    "policy_loss": 236.0339012145996,
    "value_loss": 3.6083128452301025,
    "entropy": 0.6746046543121338,
    "total_loss": 239.37237219810487
  },
  {
    "episode": 49,
    "avg_reward_per_step": 7.74068722673814,
    "episode_length": 1034,
    "policy_loss": -154.30608367919922,
    "value_loss": 0.5025425553321838,
    "entropy": 0.6858976185321808,
    "total_loss": -154.0779001712799
  },
  {
    "episode": 50,
    "avg_reward_per_step": -11.309405393856526,
    "episode_length": 3000,
    "policy_loss": 221.3419303894043,
    "value_loss": 3.2730560898780823,
    "entropy": 0.7025998681783676,
    "total_loss": 224.33394653201103
  },
  {
    "episode": 51,
    "avg_reward_per_step": 15.426763093615715,
    "episode_length": 744,
    "policy_loss": -305.28507232666016,
    "value_loss": 0.5080411583185196,
    "entropy": 0.6753801852464676,
    "total_loss": -305.0471832424402
  },
  {
    "episode": 52,
    "avg_reward_per_step": -11.220198383728349,
    "episode_length": 3000,
    "policy_loss": 219.5938262939453,
    "value_loss": 3.469427466392517,
    "entropy": 0.7152980118989944,
    "total_loss": 222.77713455557824
  },
  {
    "episode": 53,
    "avg_reward_per_step": -10.311466198769525,
    "episode_length": 3000,
    "policy_loss": 201.58729553222656,
    "value_loss": 2.548249900341034,
    "entropy": 0.7425095289945602,
    "total_loss": 203.83854162096978
  },
  {
    "episode": 54,
    "avg_reward_per_step": -10.62455330457965,
    "episode_length": 3000,
    "policy_loss": 207.8553581237793,
    "value_loss": 2.922440230846405,
    "entropy": 0.7280373871326447,
    "total_loss": 210.48658339977266
  },
  {
    "episode": 55,
    "avg_reward_per_step": -3.1452442892549364,
    "episode_length": 2314,
    "policy_loss": 60.66411113739014,
    "value_loss": 0.5007960051298141,
    "entropy": 0.6844507157802582,
    "total_loss": 60.89112685620785
  },
  {
    "episode": 56,
    "avg_reward_per_step": 4.712360017777963,
    "episode_length": 1211,
    "policy_loss": -93.96430206298828,
    "value_loss": 0.5009017437696457,
    "entropy": 0.6752627640962601,
    "total_loss": -93.73350542485714
  },
  {
    "episode": 57,
    "avg_reward_per_step": 8.659484562662099,
    "episode_length": 985,
    "policy_loss": -171.90901565551758,
    "value_loss": 0.503070056438446,
    "entropy": 0.7023397535085678,
    "total_loss": -171.68688150048257
  },
  {
    "episode": 58,
    "avg_reward_per_step": -3.621318576034142,
    "episode_length": 2415,
    "policy_loss": 70.04995536804199,
    "value_loss": 0.501221776008606,
    "entropy": 0.7017281800508499,
    "total_loss": 70.27048587203026
  },
  {
    "episode": 59,
    "avg_reward_per_step": -4.6666122612620375,
    "episode_length": 2953,
    "policy_loss": 90.64462471008301,
    "value_loss": 0.5027588456869125,
    "entropy": 0.7308481186628342,
    "total_loss": 90.85504430830478
  },
  {
    "episode": 60,
    "avg_reward_per_step": 16.360488296234855,
    "episode_length": 789,
    "policy_loss": -324.57022857666016,
    "value_loss": 0.509696438908577,
    "entropy": 0.8452311456203461,
    "total_loss": -324.3986245959997
  },
  {
    "episode": 61,
    "avg_reward_per_step": 2.535059058002692,
    "episode_length": 1489,
    "policy_loss": -52.233792304992676,
    "value_loss": 0.5001378357410431,
    "entropy": 0.7816014736890793,
    "total_loss": -52.04629505872727
  },
  {
    "episode": 62,
    "avg_reward_per_step": -0.7383100084433126,
    "episode_length": 2022,
    "policy_loss": 11.701728582382202,
    "value_loss": 0.4997948482632637,
    "entropy": 0.8379591405391693,
    "total_loss": 11.866339774429798
  },
  {
    "episode": 63,
    "avg_reward_per_step": 21.517242179335398,
    "episode_length": 716,
    "policy_loss": -429.02645111083984,
    "value_loss": 0.5159356743097305,
    "entropy": 0.9949666261672974,
    "total_loss": -428.90850208699703
  },
  {
    "episode": 64,
    "avg_reward_per_step": -8.724195832924215,
    "episode_length": 3000,
    "policy_loss": 170.2834587097168,
    "value_loss": 3.4995654821395874,
    "entropy": 0.9792035967111588,
    "total_loss": 173.39134275317193
  },
  {
    "episode": 65,
    "avg_reward_per_step": 4.725512821985095,
    "episode_length": 1653,
    "policy_loss": -94.02522659301758,
    "value_loss": 0.5015092343091965,
    "entropy": 1.0392251014709473,
    "total_loss": -93.93940739929675
  },
  {
    "episode": 66,
    "avg_reward_per_step": 13.316157509985677,
    "episode_length": 1056,
    "policy_loss": -264.73876953125,
    "value_loss": 0.5087142139673233,
    "entropy": 1.0756076276302338,
    "total_loss": -264.6602983683348
  },
  {
    "episode": 67,
    "avg_reward_per_step": 16.03678313967121,
    "episode_length": 942,
    "policy_loss": -319.4434814453125,
    "value_loss": 0.5114056318998337,
    "entropy": 1.120620459318161,
    "total_loss": -319.38032399713995
  },
  {
    "episode": 68,
    "avg_reward_per_step": 33.41514767326902,
    "episode_length": 544,
    "policy_loss": -661.9160614013672,
    "value_loss": 0.5299856215715408,
    "entropy": 1.1241386234760284,
    "total_loss": -661.8357312291861
  },
  {
    "episode": 69,
    "avg_reward_per_step": 53.25551188308641,
    "episode_length": 362,
    "policy_loss": -1053.4099426269531,
    "value_loss": 0.5532633066177368,
    "entropy": 1.1023658514022827,
    "total_loss": -1053.2976256608963
  },
  {
    "episode": 70,
    "avg_reward_per_step": 72.08783979183238,
    "episode_length": 269,
    "policy_loss": -1449.2073364257812,
    "value_loss": 0.575691282749176,
    "entropy": 1.1124124228954315,
    "total_loss": -1449.0766101121903
  },
  {
    "episode": 71,
    "avg_reward_per_step": 161.229153957916,
    "episode_length": 122,
    "policy_loss": -3198.6897583007812,
    "value_loss": 0.7114860117435455,
    "entropy": 1.0553343296051025,
    "total_loss": -3198.40040602088
  },
  {
    "episode": 72,
    "avg_reward_per_step": 94.71413732407254,
    "episode_length": 205,
    "policy_loss": -1896.8144226074219,
    "value_loss": 0.6053322404623032,
    "entropy": 0.9692479223012924,
    "total_loss": -1896.5967895358801
  },
  {
    "episode": 73,
    "avg_reward_per_step": 60.79248227546584,
    "episode_length": 306,
    "policy_loss": -1201.2998657226562,
    "value_loss": 0.5595302134752274,
    "entropy": 0.8499137163162231,
    "total_loss": -1201.0803009957076
  },
  {
    "episode": 74,
    "avg_reward_per_step": 86.20902506924416,
    "episode_length": 218,
    "policy_loss": -1750.0643615722656,
    "value_loss": 0.5892453640699387,
    "entropy": 0.6925825923681259,
    "total_loss": -1749.7521492451428
  },
  {
    "episode": 75,
    "avg_reward_per_step": -2.8933535377711603,
    "episode_length": 2452,
    "policy_loss": 59.769015312194824,
    "value_loss": 0.5007151514291763,
    "entropy": 0.5727369487285614,
    "total_loss": 60.040635684132575
  },
  {
    "episode": 76,
    "avg_reward_per_step": -12.859823059820162,
    "episode_length": 3000,
    "policy_loss": 251.5438690185547,
    "value_loss": 3.9059919714927673,
    "entropy": 0.45082419365644455,
    "total_loss": 255.2695313125849
  },
  {
    "episode": 77,
    "avg_reward_per_step": -11.651719962659932,
    "episode_length": 3000,
    "policy_loss": 228.19391632080078,
    "value_loss": 2.357505679130554,
    "entropy": 0.4975961893796921,
    "total_loss": 230.35238352417946
  },
  {
    "episode": 78,
    "avg_reward_per_step": -13.886316268074001,
    "episode_length": 3000,
    "policy_loss": 271.6445999145508,
    "value_loss": 4.144370198249817,
    "entropy": 0.39573827385902405,
    "total_loss": 275.63067480325697
  },
  {
    "episode": 79,
    "avg_reward_per_step": 0.16693004242057194,
    "episode_length": 1572,
    "policy_loss": -4.960050582885742,
    "value_loss": 0.4996887370944023,
    "entropy": 0.36233606934547424,
    "total_loss": -4.60529627352953
  },
  {
    "episode": 80,
    "avg_reward_per_step": 156.03485001870007,
    "episode_length": 128,
    "policy_loss": -3068.58935546875,
    "value_loss": 0.7047824859619141,
    "entropy": 0.31852125376462936,
    "total_loss": -3068.0119814842938
  },
  {
    "episode": 81,
    "avg_reward_per_step": -13.819522831637126,
    "episode_length": 3000,
    "policy_loss": 270.40867614746094,
    "value_loss": 3.2704273462295532,
    "entropy": 0.3128262460231781,
    "total_loss": 273.55397299528124
  },
  {
    "episode": 82,
    "avg_reward_per_step": -14.950779071624217,
    "episode_length": 3000,
    "policy_loss": 292.81299591064453,
    "value_loss": 3.921432614326477,
    "entropy": 0.32057203352451324,
    "total_loss": 296.6061997115612
  },
  {
    "episode": 83,
    "avg_reward_per_step": 1.9403145683698984,
    "episode_length": 1300,
    "policy_loss": -40.49684810638428,
    "value_loss": 0.49986307322978973,
    "entropy": 0.2917651832103729,
    "total_loss": -40.11369110643864
  },
  {
    "episode": 84,
    "avg_reward_per_step": -15.1772810050354,
    "episode_length": 3000,
    "policy_loss": 297.13536834716797,
    "value_loss": 4.653804540634155,
    "entropy": 0.27150850743055344,
    "total_loss": 301.6805694848299
  },
  {
    "episode": 85,
    "avg_reward_per_step": 23.938474192509123,
    "episode_length": 646,
    "policy_loss": -471.9785461425781,
    "value_loss": 0.5176903307437897,
    "entropy": 0.2582353949546814,
    "total_loss": -471.5641499698162
  },
  {
    "episode": 86,
    "avg_reward_per_step": -13.85496468216395,
    "episode_length": 3000,
    "policy_loss": 271.07625579833984,
    "value_loss": 3.8124701976776123,
    "entropy": 0.3016577735543251,
    "total_loss": 274.7680628865957
  },
  {
    "episode": 87,
    "avg_reward_per_step": -14.836989707854926,
    "episode_length": 3000,
    "policy_loss": 290.0534133911133,
    "value_loss": 4.163577198982239,
    "entropy": 0.29370249807834625,
    "total_loss": 294.09950959086416
  },
  {
    "episode": 88,
    "avg_reward_per_step": -13.835095660679139,
    "episode_length": 3000,
    "policy_loss": 270.290283203125,
    "value_loss": 3.6552822589874268,
    "entropy": 0.29686783254146576,
    "total_loss": 273.82681832909583
  },
  {
    "episode": 89,
    "avg_reward_per_step": -14.03370476378227,
    "episode_length": 3000,
    "policy_loss": 274.2174835205078,
    "value_loss": 3.9907110929489136,
    "entropy": 0.3038458228111267,
    "total_loss": 278.08665628433226
  },
  {
    "episode": 90,
    "avg_reward_per_step": 31.673200528829863,
    "episode_length": 501,
    "policy_loss": -627.2808837890625,
    "value_loss": 0.5244704335927963,
    "entropy": 0.28734157234430313,
    "total_loss": -626.8713499844074
  },
  {
    "episode": 91,
    "avg_reward_per_step": -14.288650724153781,
    "episode_length": 3000,
    "policy_loss": 279.3556823730469,
    "value_loss": 4.223908066749573,
    "entropy": 0.3286279961466789,
    "total_loss": 283.4481392413378
  },
  {
    "episode": 92,
    "avg_reward_per_step": 45.63831046702627,
    "episode_length": 375,
    "policy_loss": -899.8842315673828,
    "value_loss": 0.5394608974456787,
    "entropy": 0.33246537297964096,
    "total_loss": -899.477756819129
  },
  {
    "episode": 93,
    "avg_reward_per_step": -12.715444569486678,
    "episode_length": 3000,
    "policy_loss": 248.44784927368164,
    "value_loss": 3.7829463481903076,
    "entropy": 0.3676661476492882,
    "total_loss": 252.08372916281223
  },
  {
    "episode": 94,
    "avg_reward_per_step": 31.881443887367944,
    "episode_length": 462,
    "policy_loss": -631.7962646484375,
    "value_loss": 0.5225058495998383,
    "entropy": 0.36515214294195175,
    "total_loss": -631.4198196560144
  },
  {
    "episode": 95,
    "avg_reward_per_step": -13.837604569217547,
    "episode_length": 3000,
    "policy_loss": 270.24574279785156,
    "value_loss": 4.1575822830200195,
    "entropy": 0.35527853667736053,
    "total_loss": 274.26121366620066
  },
  {
    "episode": 96,
    "avg_reward_per_step": 47.19150066096747,
    "episode_length": 352,
    "policy_loss": -930.7049255371094,
    "value_loss": 0.5395122468471527,
    "entropy": 0.3387257903814316,
    "total_loss": -930.3009036064147
  },
  {
    "episode": 97,
    "avg_reward_per_step": 136.6397877042381,
    "episode_length": 146,
    "policy_loss": -2690.4971923828125,
    "value_loss": 0.6705698221921921,
    "entropy": 0.25982843339443207,
    "total_loss": -2689.930553933978
  },
  {
    "episode": 98,
    "avg_reward_per_step": -13.917487434316019,
    "episode_length": 3000,
    "policy_loss": 271.68152618408203,
    "value_loss": 3.745316803455353,
    "entropy": 0.35225943475961685,
    "total_loss": 275.2859392136335
  },
  {
    "episode": 99,
    "avg_reward_per_step": 51.35115310307236,
    "episode_length": 339,
    "policy_loss": -1017.699951171875,
    "value_loss": 0.5457715839147568,
    "entropy": 0.35429519414901733,
    "total_loss": -1017.2958976656198
  },
  {
    "episode": 100,
    "avg_reward_per_step": 89.7274532614561,
    "episode_length": 207,
    "policy_loss": -1780.6085815429688,
    "value_loss": 0.5934676975011826,
    "entropy": 0.4141164794564247,
    "total_loss": -1780.1807604372502
  },
  {
    "episode": 101,
    "avg_reward_per_step": -14.172717567388371,
    "episode_length": 3000,
    "policy_loss": 276.92708587646484,
    "value_loss": 3.8688021898269653,
    "entropy": 0.34953608363866806,
    "total_loss": 280.65607363283635
  },
  {
    "episode": 102,
    "avg_reward_per_step": -14.078560390337552,
    "episode_length": 3000,
    "policy_loss": 274.65599060058594,
    "value_loss": 4.133109211921692,
    "entropy": 0.35177113115787506,
    "total_loss": 278.64839136004446
  },
  {
    "episode": 103,
    "avg_reward_per_step": 61.692150762018876,
    "episode_length": 291,
    "policy_loss": -1224.3486328125,
    "value_loss": 0.5581709146499634,
    "entropy": 0.38398871570825577,
    "total_loss": -1223.9440573841334
  },
  {
    "episode": 104,
    "avg_reward_per_step": -15.029327820842232,
    "episode_length": 3000,
    "policy_loss": 293.81639862060547,
    "value_loss": 3.9165139198303223,
    "entropy": 0.27931055426597595,
    "total_loss": 297.6211883187294
  },
  {
    "episode": 105,
    "avg_reward_per_step": -14.68951054603568,
    "episode_length": 3000,
    "policy_loss": 286.5783386230469,
    "value_loss": 4.050600647926331,
    "entropy": 0.29780008643865585,
    "total_loss": 290.50981923639773
  },
  {
    "episode": 106,
    "avg_reward_per_step": -13.832310789801863,
    "episode_length": 3000,
    "policy_loss": 269.9728240966797,
    "value_loss": 3.92632794380188,
    "entropy": 0.2972835898399353,
    "total_loss": 273.7802386045456
  },
  {
    "episode": 107,
    "avg_reward_per_step": -12.277511935800188,
    "episode_length": 3000,
    "policy_loss": 239.40366744995117,
    "value_loss": 2.0794395208358765,
    "entropy": 0.3669423311948776,
    "total_loss": 241.3363300383091
  },
  {
    "episode": 108,
    "avg_reward_per_step": -14.64251947088774,
    "episode_length": 3000,
    "policy_loss": 286.2474365234375,
    "value_loss": 3.816485345363617,
    "entropy": 0.27860911190509796,
    "total_loss": 289.95247822403906
  },
  {
    "episode": 109,
    "avg_reward_per_step": -14.771983215668207,
    "episode_length": 3000,
    "policy_loss": 288.25315856933594,
    "value_loss": 4.134816646575928,
    "entropy": 0.2467922866344452,
    "total_loss": 292.2892583012581
  },
  {
    "episode": 110,
    "avg_reward_per_step": -14.617701072975608,
    "episode_length": 3000,
    "policy_loss": 285.00037384033203,
    "value_loss": 3.941981792449951,
    "entropy": 0.27453741431236267,
    "total_loss": 288.83254066705706
  },
  {
    "episode": 111,
    "avg_reward_per_step": -10.87514815382348,
    "episode_length": 3000,
    "policy_loss": 211.47604370117188,
    "value_loss": 1.7996331453323364,
    "entropy": 0.37696827203035355,
    "total_loss": 213.12488953769207
  },
  {
    "episode": 112,
    "avg_reward_per_step": 31.124874361648104,
    "episode_length": 509,
    "policy_loss": -614.9674377441406,
    "value_loss": 0.5239679366350174,
    "entropy": 0.2532237768173218,
    "total_loss": -614.5447593182325
  },
  {
    "episode": 113,
    "avg_reward_per_step": -14.011702957636832,
    "episode_length": 3000,
    "policy_loss": 272.9487533569336,
    "value_loss": 3.7350358963012695,
    "entropy": 0.2683911994099617,
    "total_loss": 276.57643277347086
  },
  {
    "episode": 114,
    "avg_reward_per_step": -12.881473365067691,
    "episode_length": 3000,
    "policy_loss": 250.93177032470703,
    "value_loss": 2.5201013684272766,
    "entropy": 0.3192441910505295,
    "total_loss": 253.3241740167141
  },
  {
    "episode": 115,
    "avg_reward_per_step": -14.778058269389836,
    "episode_length": 3000,
    "policy_loss": 288.4255676269531,
    "value_loss": 2.9545512199401855,
    "entropy": 0.29189103841781616,
    "total_loss": 291.26336243152616
  },
  {
    "episode": 116,
    "avg_reward_per_step": -14.317359767613736,
    "episode_length": 3000,
    "policy_loss": 279.1402053833008,
    "value_loss": 3.784272253513336,
    "entropy": 0.2803795635700226,
    "total_loss": 282.81232581138613
  },
  {
    "episode": 117,
    "avg_reward_per_step": 57.97384361369207,
    "episode_length": 311,
    "policy_loss": -1146.3446655273438,
    "value_loss": 0.5545835345983505,
    "entropy": 0.2597326189279556,
    "total_loss": -1145.8939750403165
  },
  {
    "episode": 118,
    "avg_reward_per_step": -2.1233218792654416,
    "episode_length": 1664,
    "policy_loss": 38.137938499450684,
    "value_loss": 0.4999893009662628,
    "entropy": 0.2936907857656479,
    "total_loss": 38.52045148611069
  },
  {
    "episode": 119,
    "avg_reward_per_step": -14.589607755197948,
    "episode_length": 3000,
    "policy_loss": 284.31848907470703,
    "value_loss": 3.710562527179718,
    "entropy": 0.31666573882102966,
    "total_loss": 287.9023853063583
  },
  {
    "episode": 120,
    "avg_reward_per_step": -8.9421768704155,
    "episode_length": 3000,
    "policy_loss": 173.55747985839844,
    "value_loss": 1.3750393092632294,
    "entropy": 0.48807190358638763,
    "total_loss": 174.73729040622712
  },
  {
    "episode": 121,
    "avg_reward_per_step": -13.382776216367914,
    "episode_length": 3000,
    "policy_loss": 260.8039321899414,
    "value_loss": 3.6297081112861633,
    "entropy": 0.33240505307912827,
    "total_loss": 264.3006782799959
  },
  {
    "episode": 122,
    "avg_reward_per_step": -14.127270874921441,
    "episode_length": 3000,
    "policy_loss": 275.13155364990234,
    "value_loss": 4.008511960506439,
    "entropy": 0.28677792847156525,
    "total_loss": 279.02535443902013
  },
  {
    "episode": 123,
    "avg_reward_per_step": -11.644416983251636,
    "episode_length": 3000,
    "policy_loss": 226.31988525390625,
    "value_loss": 1.9396454393863678,
    "entropy": 0.4331395849585533,
    "total_loss": 228.08627485930919
  },
  {
    "episode": 124,
    "avg_reward_per_step": 57.1766562986342,
    "episode_length": 296,
    "policy_loss": -1143.6071472167969,
    "value_loss": 0.5497698783874512,
    "entropy": 0.34842538833618164,
    "total_loss": -1143.196747493744
  },
  {
    "episode": 125,
    "avg_reward_per_step": -12.980108777203192,
    "episode_length": 3000,
    "policy_loss": 252.09740447998047,
    "value_loss": 3.6690632700920105,
    "entropy": 0.4113558754324913,
    "total_loss": 255.60192539989947
  },
  {
    "episode": 126,
    "avg_reward_per_step": -12.876545101839083,
    "episode_length": 3000,
    "policy_loss": 250.0555877685547,
    "value_loss": 3.7376673817634583,
    "entropy": 0.44479475915431976,
    "total_loss": 253.61533724665642
  },
  {
    "episode": 127,
    "avg_reward_per_step": -13.18540039121589,
    "episode_length": 3000,
    "policy_loss": 256.3011817932129,
    "value_loss": 3.9814361333847046,
    "entropy": 0.4800621122121811,
    "total_loss": 260.0905930817127
  },
  {
    "episode": 128,
    "avg_reward_per_step": -12.349153917432579,
    "episode_length": 3000,
    "policy_loss": 239.54870223999023,
    "value_loss": 4.254512548446655,
    "entropy": 0.507147878408432,
    "total_loss": 243.6003556370735
  },
  {
    "episode": 129,
    "avg_reward_per_step": -11.88198650277649,
    "episode_length": 3000,
    "policy_loss": 230.47530364990234,
    "value_loss": 3.8061999678611755,
    "entropy": 0.5029481053352356,
    "total_loss": 234.08032437562943
  },
  {
    "episode": 130,
    "avg_reward_per_step": -12.085453328613054,
    "episode_length": 3000,
    "policy_loss": 234.44583129882812,
    "value_loss": 3.969078004360199,
    "entropy": 0.48800764977931976,
    "total_loss": 238.2197062432766
  },
  {
    "episode": 131,
    "avg_reward_per_step": -11.510487588013243,
    "episode_length": 3000,
    "policy_loss": 223.12634658813477,
    "value_loss": 3.4842320680618286,
    "entropy": 0.5442078560590744,
    "total_loss": 226.39289551377297
  },
  {
    "episode": 132,
    "avg_reward_per_step": 3.578999684112376,
    "episode_length": 1527,
    "policy_loss": -74.84192657470703,
    "value_loss": 0.5005888044834137,
    "entropy": 0.5810109376907349,
    "total_loss": -74.57374214529992
  },
  {
    "episode": 133,
    "avg_reward_per_step": -11.282327839608897,
    "episode_length": 3000,
    "policy_loss": 218.85509872436523,
    "value_loss": 2.268888235092163,
    "entropy": 0.51056769490242,
    "total_loss": 220.91975988149642
  },
  {
    "episode": 134,
    "avg_reward_per_step": 2.7464223834636687,
    "episode_length": 1558,
    "policy_loss": -58.78552722930908,
    "value_loss": 0.5002446472644806,
    "entropy": 0.6108087450265884,
    "total_loss": -58.52960608005524
  },
  {
    "episode": 135,
    "avg_reward_per_step": 17.576436070327766,
    "episode_length": 754,
    "policy_loss": -352.8379592895508,
    "value_loss": 0.5114913731813431,
    "entropy": 0.6091375052928925,
    "total_loss": -352.5701229184866
  },
  {
    "episode": 136,
    "avg_reward_per_step": -9.680880178233961,
    "episode_length": 3000,
    "policy_loss": 186.87346267700195,
    "value_loss": 2.82965624332428,
    "entropy": 0.6443575024604797,
    "total_loss": 189.44537591934204
  },
  {
    "episode": 137,
    "avg_reward_per_step": -9.629193336209239,
    "episode_length": 3000,
    "policy_loss": 186.0487518310547,
    "value_loss": 3.005094349384308,
    "entropy": 0.6415813118219376,
    "total_loss": 188.7972136557102
  },
  {
    "episode": 138,
    "avg_reward_per_step": 1.4736943720254394,
    "episode_length": 1999,
    "policy_loss": -34.24140930175781,
    "value_loss": 0.5005382597446442,
    "entropy": 0.6888405084609985,
    "total_loss": -34.016407245397566
  },
  {
    "episode": 139,
    "avg_reward_per_step": -8.545576651457832,
    "episode_length": 3000,
    "policy_loss": 164.38500213623047,
    "value_loss": 2.607540011405945,
    "entropy": 0.700033113360405,
    "total_loss": 166.71252890229226
  },
  {
    "episode": 140,
    "avg_reward_per_step": 105.83193154687629,
    "episode_length": 183,
    "policy_loss": -2114.1305541992188,
    "value_loss": 0.6210368424654007,
    "entropy": 0.7708553522825241,
    "total_loss": -2113.817859497666
  },
  {
    "episode": 141,
    "avg_reward_per_step": 7.74605258760596,
    "episode_length": 1410,
    "policy_loss": -158.2225570678711,
    "value_loss": 0.5038783550262451,
    "entropy": 0.7728491574525833,
    "total_loss": -158.0278183758259
  },
  {
    "episode": 142,
    "avg_reward_per_step": 51.430739699758156,
    "episode_length": 362,
    "policy_loss": -1025.5094146728516,
    "value_loss": 0.5500156581401825,
    "entropy": 0.7686640471220016,
    "total_loss": -1025.26686463356
  },
  {
    "episode": 143,
    "avg_reward_per_step": -1.9951471415914577,
    "episode_length": 2857,
    "policy_loss": 35.72420692443848,
    "value_loss": 0.5004921406507492,
    "entropy": 0.6688295006752014,
    "total_loss": 35.95716726481915
  },
  {
    "episode": 144,
    "avg_reward_per_step": 84.94857376020806,
    "episode_length": 231,
    "policy_loss": -1695.7335815429688,
    "value_loss": 0.5936835408210754,
    "entropy": 0.8099384307861328,
    "total_loss": -1695.463873374462
  },
  {
    "episode": 145,
    "avg_reward_per_step": 4.503453223023123,
    "episode_length": 1519,
    "policy_loss": -93.15415000915527,
    "value_loss": 0.5014039278030396,
    "entropy": 0.674147292971611,
    "total_loss": -92.92240499854088
  },
  {
    "episode": 146,
    "avg_reward_per_step": -9.698012320558169,
    "episode_length": 3000,
    "policy_loss": 187.1731719970703,
    "value_loss": 4.233404636383057,
    "entropy": 0.6510602682828903,
    "total_loss": 191.1461525261402
  },
  {
    "episode": 147,
    "avg_reward_per_step": -3.4783357226025213,
    "episode_length": 2743,
    "policy_loss": 63.93248462677002,
    "value_loss": 0.5014940351247787,
    "entropy": 0.5268527865409851,
    "total_loss": 64.2232375472784
  },
  {
    "episode": 148,
    "avg_reward_per_step": 12.001962799496706,
    "episode_length": 943,
    "policy_loss": -242.85646438598633,
    "value_loss": 0.5066944807767868,
    "entropy": 0.6221156716346741,
    "total_loss": -242.5986161738634
  },
  {
    "episode": 149,
    "avg_reward_per_step": -1.948851293510379,
    "episode_length": 2454,
    "policy_loss": 33.42264270782471,
    "value_loss": 0.5001290291547775,
    "entropy": 0.6076752841472626,
    "total_loss": 33.67970162332058
  },
  {
    "episode": 150,
    "avg_reward_per_step": -10.215247018484181,
    "episode_length": 3000,
    "policy_loss": 197.28417587280273,
    "value_loss": 3.846647024154663,
    "entropy": 0.6375916302204132,
    "total_loss": 200.87578624486923
  },
  {
    "episode": 151,
    "avg_reward_per_step": 43.56852418075652,
    "episode_length": 428,
    "policy_loss": -870.8066253662109,
    "value_loss": 0.5423967987298965,
    "entropy": 0.7778799831867218,
    "total_loss": -870.5753805607558
  },
  {
    "episode": 152,
    "avg_reward_per_step": -10.074005363744682,
    "episode_length": 3000,
    "policy_loss": 194.04547882080078,
    "value_loss": 3.4482523798942566,
    "entropy": 0.6069312244653702,
    "total_loss": 197.2509587109089
  },
  {
    "episode": 153,
    "avg_reward_per_step": 7.6706521455283285,
    "episode_length": 1254,
    "policy_loss": -156.70157623291016,
    "value_loss": 0.5035986006259918,
    "entropy": 0.6991320699453354,
    "total_loss": -156.4776304602623
  },
  {
    "episode": 154,
    "avg_reward_per_step": 65.95862535829914,
    "episode_length": 278,
    "policy_loss": -1319.6402587890625,
    "value_loss": 0.5648085325956345,
    "entropy": 0.659271314740181,
    "total_loss": -1319.339158782363
  },
  {
    "episode": 155,
    "avg_reward_per_step": 14.965668977758362,
    "episode_length": 889,
    "policy_loss": -304.85719299316406,
    "value_loss": 0.5098538994789124,
    "entropy": 0.6706097424030304,
    "total_loss": -304.6155829906464
  },
  {
    "episode": 156,
    "avg_reward_per_step": 122.67054322492083,
    "episode_length": 159,
    "policy_loss": -2441.5499877929688,
    "value_loss": 0.6460157781839371,
    "entropy": 0.6452759951353073,
    "total_loss": -2441.162082412839
  },
  {
    "episode": 157,
    "avg_reward_per_step": 44.786130287973485,
    "episode_length": 409,
    "policy_loss": -904.6561889648438,
    "value_loss": 0.542497381567955,
    "entropy": 0.8010569214820862,
    "total_loss": -904.4341143518686
  },
  {
    "episode": 158,
    "avg_reward_per_step": 4.089728494271433,
    "episode_length": 1679,
    "policy_loss": -84.96193313598633,
    "value_loss": 0.5014244467020035,
    "entropy": 0.724785566329956,
    "total_loss": -84.7504229158163
  },
  {
    "episode": 159,
    "avg_reward_per_step": -10.690906614616573,
    "episode_length": 3000,
    "policy_loss": 206.36125946044922,
    "value_loss": 3.388877749443054,
    "entropy": 0.5853098779916763,
    "total_loss": 209.5160132586956
  },
  {
    "episode": 160,
    "avg_reward_per_step": -12.910395110314338,
    "episode_length": 3000,
    "policy_loss": 250.03053665161133,
    "value_loss": 3.321627616882324,
    "entropy": 0.48346421867609024,
    "total_loss": 253.15877858102323
  },
  {
    "episode": 161,
    "avg_reward_per_step": -12.136962721294319,
    "episode_length": 3000,
    "policy_loss": 234.74886322021484,
    "value_loss": 3.7748746275901794,
    "entropy": 0.541333869099617,
    "total_loss": 238.30720430016518
  },
  {
    "episode": 162,
    "avg_reward_per_step": -2.385983064077966,
    "episode_length": 2646,
    "policy_loss": 41.64358425140381,
    "value_loss": 0.5006101876497269,
    "entropy": 0.6564180105924606,
    "total_loss": 41.88162723481655
  },
  {
    "episode": 163,
    "avg_reward_per_step": 35.27506212507852,
    "episode_length": 472,
    "policy_loss": -706.4000549316406,
    "value_loss": 0.5291606783866882,
    "entropy": 0.6975401937961578,
    "total_loss": -706.1499103307724
  },
  {
    "episode": 164,
    "avg_reward_per_step": 160.93195248961922,
    "episode_length": 124,
    "policy_loss": -3215.9273071289062,
    "value_loss": 0.7172118276357651,
    "entropy": 0.6920452266931534,
    "total_loss": -3215.486913391948
  },
  {
    "episode": 165,
    "avg_reward_per_step": -10.173370224220383,
    "episode_length": 3000,
    "policy_loss": 196.0567970275879,
    "value_loss": 2.326302647590637,
    "entropy": 0.5990689843893051,
    "total_loss": 198.1434720814228
  },
  {
    "episode": 166,
    "avg_reward_per_step": 3.551556106728193,
    "episode_length": 1552,
    "policy_loss": -75.9998779296875,
    "value_loss": 0.5010009407997131,
    "entropy": 0.6366788148880005,
    "total_loss": -75.75354851484299
  },
  {
    "episode": 167,
    "avg_reward_per_step": 6.36437315377769,
    "episode_length": 1348,
    "policy_loss": -133.73046493530273,
    "value_loss": 0.5027592778205872,
    "entropy": 0.6879343390464783,
    "total_loss": -133.50287939310073
  },
  {
    "episode": 168,
    "avg_reward_per_step": -9.946342730574365,
    "episode_length": 3000,
    "policy_loss": 191.10194778442383,
    "value_loss": 3.5033544301986694,
    "entropy": 0.6638166755437851,
    "total_loss": 194.33977554440497
  },
  {
    "episode": 169,
    "avg_reward_per_step": 18.442450661481274,
    "episode_length": 673,
    "policy_loss": -372.6932678222656,
    "value_loss": 0.511160135269165,
    "entropy": 0.5730602592229843,
    "total_loss": -372.41133179068567
  },
  {
    "episode": 170,
    "avg_reward_per_step": 189.49157076122353,
    "episode_length": 105,
    "policy_loss": -3787.7020874023438,
    "value_loss": 0.7741924971342087,
    "entropy": 0.7069088667631149,
    "total_loss": -3787.2106584519147
  },
  {
    "episode": 171,
    "avg_reward_per_step": 23.789233749066163,
    "episode_length": 646,
    "policy_loss": -474.0148162841797,
    "value_loss": 0.5185174494981766,
    "entropy": 0.7169256210327148,
    "total_loss": -473.7830690830946
  },
  {
    "episode": 172,
    "avg_reward_per_step": 19.171550526569433,
    "episode_length": 754,
    "policy_loss": -387.26329803466797,
    "value_loss": 0.5137294381856918,
    "entropy": 0.7228658497333527,
    "total_loss": -387.03871493637564
  },
  {
    "episode": 173,
    "avg_reward_per_step": 210.0988855442434,
    "episode_length": 95,
    "policy_loss": -4170.8475341796875,
    "value_loss": 0.8203706294298172,
    "entropy": 0.7290288805961609,
    "total_loss": -4170.318775102496
  },
  {
    "episode": 174,
    "avg_reward_per_step": 18.65253728358207,
    "episode_length": 855,
    "policy_loss": -373.4844055175781,
    "value_loss": 0.5147925168275833,
    "entropy": 0.7334458529949188,
    "total_loss": -373.2629913419485
  },
  {
    "episode": 175,
    "avg_reward_per_step": 0.521107901888561,
    "episode_length": 2141,
    "policy_loss": -16.08889675140381,
    "value_loss": 0.5003239661455154,
    "entropy": 0.6268055140972137,
    "total_loss": -15.839294990897178
  },
  {
    "episode": 176,
    "avg_reward_per_step": 77.31769697012017,
    "episode_length": 243,
    "policy_loss": -1545.2421875,
    "value_loss": 0.5798968523740768,
    "entropy": 0.6862162798643112,
    "total_loss": -1544.9367771595716
  },
  {
    "episode": 177,
    "avg_reward_per_step": 252.57101284399414,
    "episode_length": 79,
    "policy_loss": -5012.109375,
    "value_loss": 0.9278634041547775,
    "entropy": 0.6295171827077866,
    "total_loss": -5011.4333184689285
  },
  {
    "episode": 178,
    "avg_reward_per_step": -10.48912713351877,
    "episode_length": 3000,
    "policy_loss": 202.71622467041016,
    "value_loss": 2.839430093765259,
    "entropy": 0.5018540024757385,
    "total_loss": 205.35491316318513
  },
  {
    "episode": 179,
    "avg_reward_per_step": 199.84026262238214,
    "episode_length": 100,
    "policy_loss": -3972.2944946289062,
    "value_loss": 0.7961509525775909,
    "entropy": 0.5644417703151703,
    "total_loss": -3971.7241203844546
  },
  {
    "episode": 180,
    "avg_reward_per_step": 1.3631420410301487,
    "episode_length": 2034,
    "policy_loss": -32.05240726470947,
    "value_loss": 0.5006405711174011,
    "entropy": 0.6074191927909851,
    "total_loss": -31.794734370708465
  },
  {
    "episode": 181,
    "avg_reward_per_step": 1.5216271781892026,
    "episode_length": 1963,
    "policy_loss": -35.59747314453125,
    "value_loss": 0.5001597553491592,
    "entropy": 0.5727938264608383,
    "total_loss": -35.32643091976642
  },
  {
    "episode": 182,
    "avg_reward_per_step": 165.84791561665315,
    "episode_length": 120,
    "policy_loss": -3301.8306274414062,
    "value_loss": 0.7250249236822128,
    "entropy": 0.5589101016521454,
    "total_loss": -3301.3291665583847
  },
  {
    "episode": 183,
    "avg_reward_per_step": 33.681183411562714,
    "episode_length": 490,
    "policy_loss": -674.9045715332031,
    "value_loss": 0.528113842010498,
    "entropy": 0.4602922424674034,
    "total_loss": -674.5605745881796
  },
  {
    "episode": 184,
    "avg_reward_per_step": -10.214474936788518,
    "episode_length": 3000,
    "policy_loss": 196.71134185791016,
    "value_loss": 2.654743015766144,
    "entropy": 0.5327503681182861,
    "total_loss": 199.152984726429
  },
  {
    "episode": 185,
    "avg_reward_per_step": -11.212480330823265,
    "episode_length": 3000,
    "policy_loss": 216.0816650390625,
    "value_loss": 2.7944284081459045,
    "entropy": 0.4319346845149994,
    "total_loss": 218.7033195734024
  },
  {
    "episode": 186,
    "avg_reward_per_step": -10.606051152951284,
    "episode_length": 3000,
    "policy_loss": 204.46305465698242,
    "value_loss": 2.3954397439956665,
    "entropy": 0.49877460300922394,
    "total_loss": 206.6589845597744
  },
  {
    "episode": 187,
    "avg_reward_per_step": 123.09252994569653,
    "episode_length": 161,
    "policy_loss": -2470.153564453125,
    "value_loss": 0.6498250961303711,
    "entropy": 0.6048586070537567,
    "total_loss": -2469.745682799816
  },
  {
    "episode": 188,
    "avg_reward_per_step": -11.503924935495895,
    "episode_length": 3000,
    "policy_loss": 221.9312744140625,
    "value_loss": 2.0925974249839783,
    "entropy": 0.31809576600790024,
    "total_loss": 223.8966335326433
  },
  {
    "episode": 189,
    "avg_reward_per_step": -12.60316269404455,
    "episode_length": 3000,
    "policy_loss": 243.23844146728516,
    "value_loss": 2.2537304759025574,
    "entropy": 0.28973497450351715,
    "total_loss": 245.3762779533863
  },
  {
    "episode": 190,
    "avg_reward_per_step": -12.411901417138063,
    "episode_length": 3000,
    "policy_loss": 239.40803146362305,
    "value_loss": 3.173154056072235,
    "entropy": 0.4167562499642372,
    "total_loss": 242.4144830197096
  },
  {
    "episode": 191,
    "avg_reward_per_step": 26.26185665062352,
    "episode_length": 567,
    "policy_loss": -532.4704895019531,
    "value_loss": 0.5194960683584213,
    "entropy": 0.2775347903370857,
    "total_loss": -532.0620073497296
  },
  {
    "episode": 192,
    "avg_reward_per_step": 44.0111395821821,
    "episode_length": 392,
    "policy_loss": -879.6575012207031,
    "value_loss": 0.5391065925359726,
    "entropy": 0.3287896513938904,
    "total_loss": -879.2499104887247
  },
  {
    "episode": 193,
    "avg_reward_per_step": -12.146175839342387,
    "episode_length": 3000,
    "policy_loss": 233.40456771850586,
    "value_loss": 2.801900267601013,
    "entropy": 0.4455586373806,
    "total_loss": 236.02824453115463
  },
  {
    "episode": 194,
    "avg_reward_per_step": 42.95368655464488,
    "episode_length": 453,
    "policy_loss": -857.9185943603516,
    "value_loss": 0.5426588505506516,
    "entropy": 0.5014263391494751,
    "total_loss": -857.5765060454607
  },
  {
    "episode": 195,
    "avg_reward_per_step": 45.03208363584334,
    "episode_length": 395,
    "policy_loss": -899.6006317138672,
    "value_loss": 0.5415551364421844,
    "entropy": 0.34135618805885315,
    "total_loss": -899.1956190526486
  },
  {
    "episode": 196,
    "avg_reward_per_step": 30.634759667881216,
    "episode_length": 625,
    "policy_loss": -614.6137084960938,
    "value_loss": 0.5304944068193436,
    "entropy": 0.4114595428109169,
    "total_loss": -614.2477979063988
  },
  {
    "episode": 197,
    "avg_reward_per_step": -1.0335991480379891,
    "episode_length": 2010,
    "policy_loss": 12.967440366744995,
    "value_loss": 0.5002413243055344,
    "entropy": 0.4208466336131096,
    "total_loss": 13.299343037605286
  },
  {
    "episode": 198,
    "avg_reward_per_step": -10.862597270467496,
    "episode_length": 3000,
    "policy_loss": 208.8474884033203,
    "value_loss": 2.542416214942932,
    "entropy": 0.4652674123644829,
    "total_loss": 211.20379765331745
  },
  {
    "episode": 199,
    "avg_reward_per_step": -10.439737659766427,
    "episode_length": 3000,
    "policy_loss": 200.75864028930664,
    "value_loss": 1.9706564843654633,
    "entropy": 0.4392026513814926,
    "total_loss": 202.5536157131195
  },
  {
    "episode": 200,
    "avg_reward_per_step": -11.398911132200796,
    "episode_length": 3000,
    "policy_loss": 219.27685546875,
    "value_loss": 2.47839218378067,
    "entropy": 0.4490474686026573,
    "total_loss": 221.5756286650896
  },
  {
    "episode": 201,
    "avg_reward_per_step": 31.318453180963193,
    "episode_length": 503,
    "policy_loss": -628.5682525634766,
    "value_loss": 0.5247960239648819,
    "entropy": 0.27752242237329483,
    "total_loss": -628.154465508461
  },
  {
    "episode": 202,
    "avg_reward_per_step": -10.64455244591138,
    "episode_length": 3000,
    "policy_loss": 204.28191757202148,
    "value_loss": 2.572623312473297,
    "entropy": 0.48768553137779236,
    "total_loss": 206.65946667194368
  },
  {
    "episode": 203,
    "avg_reward_per_step": -11.78966524833506,
    "episode_length": 3000,
    "policy_loss": 226.88484954833984,
    "value_loss": 2.195928156375885,
    "entropy": 0.3678106740117073,
    "total_loss": 228.93365343511104
  },
  {
    "episode": 204,
    "avg_reward_per_step": 250.0554976527967,
    "episode_length": 80,
    "policy_loss": -4907.9251708984375,
    "value_loss": 0.9230649173259735,
    "entropy": 0.21496204286813736,
    "total_loss": -4907.088090798259
  },
  {
    "episode": 205,
    "avg_reward_per_step": 127.05910988318966,
    "episode_length": 157,
    "policy_loss": -2532.8989868164062,
    "value_loss": 0.6572678536176682,
    "entropy": 0.3942626789212227,
    "total_loss": -2532.3994240343573
  },
  {
    "episode": 206,
    "avg_reward_per_step": 8.84895252101419,
    "episode_length": 963,
    "policy_loss": -185.26435470581055,
    "value_loss": 0.5038500130176544,
    "entropy": 0.46110180765390396,
    "total_loss": -184.94494541585445
  },
  {
    "episode": 207,
    "avg_reward_per_step": 67.16484027556389,
    "episode_length": 292,
    "policy_loss": -1345.8628540039062,
    "value_loss": 0.5717860758304596,
    "entropy": 0.48749352246522903,
    "total_loss": -1345.486065337062
  },
  {
    "episode": 208,
    "avg_reward_per_step": 69.12539208747883,
    "episode_length": 286,
    "policy_loss": -1386.1813354492188,
    "value_loss": 0.5744533985853195,
    "entropy": 0.443237766623497,
    "total_loss": -1385.7841771572828
  },
  {
    "episode": 209,
    "avg_reward_per_step": 101.77358583603935,
    "episode_length": 196,
    "policy_loss": -2064.7172241210938,
    "value_loss": 0.6187300384044647,
    "entropy": 0.35967719554901123,
    "total_loss": -2064.242364960909
  },
  {
    "episode": 210,
    "avg_reward_per_step": 167.75835336224745,
    "episode_length": 119,
    "policy_loss": -3332.8355102539062,
    "value_loss": 0.7273106426000595,
    "entropy": 0.22453303262591362,
    "total_loss": -3332.1980128243567
  },
  {
    "episode": 211,
    "avg_reward_per_step": -10.239036552686276,
    "episode_length": 3000,
    "policy_loss": 196.36174392700195,
    "value_loss": 2.955354332923889,
    "entropy": 0.5236283838748932,
    "total_loss": 199.1076469063759
  },
  {
    "episode": 212,
    "avg_reward_per_step": 190.6522736993953,
    "episode_length": 105,
    "policy_loss": -3826.1890869140625,
    "value_loss": 0.7770649939775467,
    "entropy": 0.4359617084264755,
    "total_loss": -3825.5864066034555
  },
  {
    "episode": 213,
    "avg_reward_per_step": 208.23036999299748,
    "episode_length": 96,
    "policy_loss": -4155.5799560546875,
    "value_loss": 0.8162394613027573,
    "entropy": 0.3791304677724838,
    "total_loss": -4154.915368780494
  },
  {
    "episode": 214,
    "avg_reward_per_step": 175.64200451272683,
    "episode_length": 114,
    "policy_loss": -3495.31103515625,
    "value_loss": 0.7468006163835526,
    "entropy": 0.1632867306470871,
    "total_loss": -3494.629549232125
  },
  {
    "episode": 215,
    "avg_reward_per_step": 67.03533022491173,
    "episode_length": 261,
    "policy_loss": -1344.53271484375,
    "value_loss": 0.5626131743192673,
    "entropy": 0.34841248393058777,
    "total_loss": -1344.1094666630029
  },
  {
    "episode": 216,
    "avg_reward_per_step": 40.37872934846988,
    "episode_length": 485,
    "policy_loss": -807.6119537353516,
    "value_loss": 0.541642501950264,
    "entropy": 0.33356428891420364,
    "total_loss": -807.2037369489669
  },
  {
    "episode": 217,
    "avg_reward_per_step": 175.54713467079878,
    "episode_length": 114,
    "policy_loss": -3521.746337890625,
    "value_loss": 0.7457689344882965,
    "entropy": 0.31965743750333786,
    "total_loss": -3521.128431931138
  },
  {
    "episode": 218,
    "avg_reward_per_step": 294.7834919905413,
    "episode_length": 68,
    "policy_loss": -5744.3350830078125,
    "value_loss": 1.0567167103290558,
    "entropy": 0.20271467044949532,
    "total_loss": -5743.359452165663
  },
  {
    "episode": 219,
    "avg_reward_per_step": 436.07880965832214,
    "episode_length": 46,
    "policy_loss": -7965.004638671875,
    "value_loss": 1.6120612025260925,
    "entropy": 0.20308584347367287,
    "total_loss": -7963.473811806738
  },
  {
    "episode": 220,
    "avg_reward_per_step": 477.6943284571926,
    "episode_length": 42,
    "policy_loss": -8474.37060546875,
    "value_loss": 1.8159033954143524,
    "entropy": 0.19637927412986755,
    "total_loss": -8472.633253782988
  },
  {
    "episode": 221,
    "avg_reward_per_step": 308.4387328254333,
    "episode_length": 65,
    "policy_loss": -5962.600341796875,
    "value_loss": 1.1027337312698364,
    "entropy": 0.15777043625712395,
    "total_loss": -5961.560716240108
  },
  {
    "episode": 222,
    "avg_reward_per_step": 238.31673894947258,
    "episode_length": 84,
    "policy_loss": -4708.14013671875,
    "value_loss": 0.8925163000822067,
    "entropy": 0.23643724247813225,
    "total_loss": -4707.342195315659
  },
  {
    "episode": 223,
    "avg_reward_per_step": 72.11645266374396,
    "episode_length": 276,
    "policy_loss": -1451.6519165039062,
    "value_loss": 0.5800863206386566,
    "entropy": 0.23943853005766869,
    "total_loss": -1451.1676055952908
  },
  {
    "episode": 224,
    "avg_reward_per_step": 68.28547245378564,
    "episode_length": 292,
    "policy_loss": -1359.8768615722656,
    "value_loss": 0.5768447369337082,
    "entropy": 0.1080265510827303,
    "total_loss": -1359.343227455765
  },
  {
    "episode": 225,
    "avg_reward_per_step": 129.9244023149702,
    "episode_length": 154,
    "policy_loss": -2582.6371459960938,
    "value_loss": 0.664986714720726,
    "entropy": 0.10593820177018642,
    "total_loss": -2582.0145345620813
  },
  {
    "episode": 226,
    "avg_reward_per_step": 244.4433897134806,
    "episode_length": 82,
    "policy_loss": -4787.47900390625,
    "value_loss": 0.9113538563251495,
    "entropy": 0.12301804311573505,
    "total_loss": -4786.616857267171
  },
  {
    "episode": 227,
    "avg_reward_per_step": 154.00275351158007,
    "episode_length": 130,
    "policy_loss": -3053.8856201171875,
    "value_loss": 0.7076269090175629,
    "entropy": 0.1506352461874485,
    "total_loss": -3053.238247306645
  },
  {
    "episode": 228,
    "avg_reward_per_step": 190.7891233952896,
    "episode_length": 105,
    "policy_loss": -3770.769287109375,
    "value_loss": 0.7815842479467392,
    "entropy": 0.14916470274329185,
    "total_loss": -3770.0473687425256
  },
  {
    "episode": 229,
    "avg_reward_per_step": 267.17189976648325,
    "episode_length": 75,
    "policy_loss": -5196.223876953125,
    "value_loss": 0.9760950058698654,
    "entropy": 0.15131480246782303,
    "total_loss": -5195.308307868242
  },
  {
    "episode": 230,
    "avg_reward_per_step": 501.6339489126352,
    "episode_length": 40,
    "policy_loss": -8723.4697265625,
    "value_loss": 1.943063199520111,
    "entropy": 0.07022783905267715,
    "total_loss": -8721.5547544986
  },
  {
    "episode": 231,
    "avg_reward_per_step": 178.81015645394623,
    "episode_length": 112,
    "policy_loss": -3555.8073120117188,
    "value_loss": 0.7542027682065964,
    "entropy": 0.2637394368648529,
    "total_loss": -3555.158605018258
  },
  {
    "episode": 232,
    "avg_reward_per_step": 573.367370350809,
    "episode_length": 35,
    "policy_loss": -9554.7451171875,
    "value_loss": 2.35225909948349,
    "entropy": 0.06046772561967373,
    "total_loss": -9552.417045178265
  },
  {
    "episode": 233,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9737.6533203125,
    "value_loss": 2.456429898738861,
    "entropy": 0.05472648609429598,
    "total_loss": -9735.2187810082
  },
  {
    "episode": 234,
    "avg_reward_per_step": 514.5091783719339,
    "episode_length": 39,
    "policy_loss": -8880.635009765625,
    "value_loss": 2.0130006670951843,
    "entropy": 0.11073793470859528,
    "total_loss": -8878.666304272414
  },
  {
    "episode": 235,
    "avg_reward_per_step": 528.0620514869933,
    "episode_length": 38,
    "policy_loss": -9034.794189453125,
    "value_loss": 2.0874236822128296,
    "entropy": 0.06644346937537193,
    "total_loss": -9032.733343158663
  },
  {
    "episode": 236,
    "avg_reward_per_step": 528.0620514869933,
    "episode_length": 38,
    "policy_loss": -9037.263916015625,
    "value_loss": 2.0870360136032104,
    "entropy": 0.08151492662727833,
    "total_loss": -9035.209485972673
  },
  {
    "episode": 237,
    "avg_reward_per_step": 501.6339489126352,
    "episode_length": 40,
    "policy_loss": -8718.7607421875,
    "value_loss": 1.942674607038498,
    "entropy": 0.0892307236790657,
    "total_loss": -8716.853759869933
  },
  {
    "episode": 238,
    "avg_reward_per_step": 573.367370350809,
    "episode_length": 35,
    "policy_loss": -9555.61865234375,
    "value_loss": 2.351443827152252,
    "entropy": 0.0386377377435565,
    "total_loss": -9553.282663611695
  },
  {
    "episode": 239,
    "avg_reward_per_step": 542.3475123381988,
    "episode_length": 37,
    "policy_loss": -9199.74072265625,
    "value_loss": 2.168141186237335,
    "entropy": 0.08290100656449795,
    "total_loss": -9197.605741872638
  },
  {
    "episode": 240,
    "avg_reward_per_step": 385.75688377895017,
    "episode_length": 52,
    "policy_loss": -7218.6519775390625,
    "value_loss": 1.3952737748622894,
    "entropy": 0.1624244786798954,
    "total_loss": -7217.3216735556725
  },
  {
    "episode": 241,
    "avg_reward_per_step": 339.92979587297305,
    "episode_length": 59,
    "policy_loss": -6417.766845703125,
    "value_loss": 1.2153096795082092,
    "entropy": 0.04644293896853924,
    "total_loss": -6416.570113199205
  },
  {
    "episode": 242,
    "avg_reward_per_step": 155.20044927523574,
    "episode_length": 129,
    "policy_loss": -3074.9315185546875,
    "value_loss": 0.7101404219865799,
    "entropy": 0.04775675479322672,
    "total_loss": -3074.240480834618
  },
  {
    "episode": 243,
    "avg_reward_per_step": 188.98450902363595,
    "episode_length": 106,
    "policy_loss": -3736.2946166992188,
    "value_loss": 0.7778413891792297,
    "entropy": 0.05963262729346752,
    "total_loss": -3735.540628360957
  },
  {
    "episode": 244,
    "avg_reward_per_step": 82.15579405969305,
    "episode_length": 243,
    "policy_loss": -1631.6383972167969,
    "value_loss": 0.5958785861730576,
    "entropy": 0.10587449185550213,
    "total_loss": -1631.084868427366
  },
  {
    "episode": 245,
    "avg_reward_per_step": 194.6699859671091,
    "episode_length": 103,
    "policy_loss": -3848.1633911132812,
    "value_loss": 0.7906069755554199,
    "entropy": 0.12110316008329391,
    "total_loss": -3847.4212254017593
  },
  {
    "episode": 246,
    "avg_reward_per_step": 514.5091783719339,
    "episode_length": 39,
    "policy_loss": -8876.228515625,
    "value_loss": 2.0115535855293274,
    "entropy": 0.05059048905968666,
    "total_loss": -8874.237198235094
  },
  {
    "episode": 247,
    "avg_reward_per_step": 501.6339489126352,
    "episode_length": 40,
    "policy_loss": -8714.7958984375,
    "value_loss": 1.9423585832118988,
    "entropy": 0.08048793114721775,
    "total_loss": -8712.885735026746
  },
  {
    "episode": 248,
    "avg_reward_per_step": 489.3867794269612,
    "episode_length": 41,
    "policy_loss": -8561.07958984375,
    "value_loss": 1.8782691955566406,
    "entropy": 0.08899231441318989,
    "total_loss": -8559.236917573959
  },
  {
    "episode": 249,
    "avg_reward_per_step": 467.0001989444707,
    "episode_length": 43,
    "policy_loss": -8293.653076171875,
    "value_loss": 1.765016883611679,
    "entropy": 0.10925723984837532,
    "total_loss": -8291.931762184202
  },
  {
    "episode": 250,
    "avg_reward_per_step": 455.9854081023957,
    "episode_length": 44,
    "policy_loss": -8130.669189453125,
    "value_loss": 1.710606426000595,
    "entropy": 0.10036339610815048,
    "total_loss": -8128.998728385568
  },
  {
    "episode": 251,
    "avg_reward_per_step": 401.5501710922448,
    "episode_length": 50,
    "policy_loss": -7383.57958984375,
    "value_loss": 1.4615643322467804,
    "entropy": 0.11771433986723423,
    "total_loss": -7382.16511124745
  },
  {
    "episode": 252,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9728.42724609375,
    "value_loss": 2.4556251168251038,
    "entropy": 0.03803252801299095,
    "total_loss": -9725.98683398813
  },
  {
    "episode": 253,
    "avg_reward_per_step": 528.5133830161204,
    "episode_length": 38,
    "policy_loss": -9047.454345703125,
    "value_loss": 2.091499447822571,
    "entropy": 0.09949287213385105,
    "total_loss": -9045.402643404155
  },
  {
    "episode": 254,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9724.65869140625,
    "value_loss": 2.4562345147132874,
    "entropy": 0.06092451233416796,
    "total_loss": -9722.226826696471
  },
  {
    "episode": 255,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9729.581787109375,
    "value_loss": 2.456228733062744,
    "entropy": 0.06576821021735668,
    "total_loss": -9727.151865660398
  },
  {
    "episode": 256,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9731.389892578125,
    "value_loss": 2.456291377544403,
    "entropy": 0.05962106492370367,
    "total_loss": -9728.95744962655
  },
  {
    "episode": 257,
    "avg_reward_per_step": 557.4266099082001,
    "episode_length": 36,
    "policy_loss": -9367.00537109375,
    "value_loss": 2.2566059827804565,
    "entropy": 0.07881065271794796,
    "total_loss": -9364.780289372056
  },
  {
    "episode": 258,
    "avg_reward_per_step": 573.367370350809,
    "episode_length": 35,
    "policy_loss": -9541.38037109375,
    "value_loss": 2.3516693711280823,
    "entropy": 0.04955551587045193,
    "total_loss": -9539.04852392897
  },
  {
    "episode": 259,
    "avg_reward_per_step": 557.4266099082001,
    "episode_length": 36,
    "policy_loss": -9367.430419921875,
    "value_loss": 2.255664587020874,
    "entropy": 0.06323156040161848,
    "total_loss": -9365.200047959015
  },
  {
    "episode": 260,
    "avg_reward_per_step": 542.3475123381988,
    "episode_length": 37,
    "policy_loss": -9200.907470703125,
    "value_loss": 2.1676379442214966,
    "entropy": 0.07333528250455856,
    "total_loss": -9198.769166871905
  },
  {
    "episode": 261,
    "avg_reward_per_step": 528.0620514869933,
    "episode_length": 38,
    "policy_loss": -9030.807861328125,
    "value_loss": 2.08626788854599,
    "entropy": 0.06689311191439629,
    "total_loss": -9028.748350684345
  },
  {
    "episode": 262,
    "avg_reward_per_step": 371.4510732686187,
    "episode_length": 54,
    "policy_loss": -6936.298583984375,
    "value_loss": 1.3362118601799011,
    "entropy": 0.12344648689031601,
    "total_loss": -6935.011750718952
  },
  {
    "episode": 263,
    "avg_reward_per_step": 477.722808488224,
    "episode_length": 42,
    "policy_loss": -8410.117919921875,
    "value_loss": 1.8166718780994415,
    "entropy": 0.03662534151226282,
    "total_loss": -8408.31589818038
  },
  {
    "episode": 264,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9741.3935546875,
    "value_loss": 2.454072415828705,
    "entropy": 0.013247767696157098,
    "total_loss": -9738.94478137875
  },
  {
    "episode": 265,
    "avg_reward_per_step": 557.4266099082001,
    "episode_length": 36,
    "policy_loss": -9365.68896484375,
    "value_loss": 2.2547088861465454,
    "entropy": 0.05098017770797014,
    "total_loss": -9363.454648028686
  },
  {
    "episode": 266,
    "avg_reward_per_step": 557.4266099082001,
    "episode_length": 36,
    "policy_loss": -9365.376708984375,
    "value_loss": 2.2551109194755554,
    "entropy": 0.057884763926267624,
    "total_loss": -9363.14475197047
  },
  {
    "episode": 267,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9730.50439453125,
    "value_loss": 2.454460024833679,
    "entropy": 0.03368165669962764,
    "total_loss": -9728.063407169097
  },
  {
    "episode": 268,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9724.935302734375,
    "value_loss": 2.4545511603355408,
    "entropy": 0.04060058109462261,
    "total_loss": -9722.496991806478
  },
  {
    "episode": 269,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9718.895263671875,
    "value_loss": 2.454822599887848,
    "entropy": 0.04153443593531847,
    "total_loss": -9716.457054846362
  },
  {
    "episode": 270,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9722.1787109375,
    "value_loss": 2.4549447298049927,
    "entropy": 0.03428371297195554,
    "total_loss": -9719.737479692883
  },
  {
    "episode": 271,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9719.456787109375,
    "value_loss": 2.4546146392822266,
    "entropy": 0.026164200622588396,
    "total_loss": -9717.012638150341
  },
  {
    "episode": 272,
    "avg_reward_per_step": 542.3475123381988,
    "episode_length": 37,
    "policy_loss": -9212.07275390625,
    "value_loss": 2.167287766933441,
    "entropy": 0.06973377242684364,
    "total_loss": -9209.933359648287
  },
  {
    "episode": 273,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9726.4462890625,
    "value_loss": 2.453912317752838,
    "entropy": 0.02392117865383625,
    "total_loss": -9724.001945216209
  },
  {
    "episode": 274,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9726.896240234375,
    "value_loss": 2.4536731243133545,
    "entropy": 0.020085330121219158,
    "total_loss": -9724.45060124211
  },
  {
    "episode": 275,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9712.371826171875,
    "value_loss": 2.4538772106170654,
    "entropy": 0.01943948632106185,
    "total_loss": -9709.925724755787
  },
  {
    "episode": 276,
    "avg_reward_per_step": 573.367370350809,
    "episode_length": 35,
    "policy_loss": -9541.369384765625,
    "value_loss": 2.3502010107040405,
    "entropy": 0.017981795594096184,
    "total_loss": -9539.026376473159
  },
  {
    "episode": 277,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9712.058837890625,
    "value_loss": 2.4543014764785767,
    "entropy": 0.017393966671079397,
    "total_loss": -9709.611494000816
  },
  {
    "episode": 278,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9711.756591796875,
    "value_loss": 2.4542314410209656,
    "entropy": 0.016405465081334114,
    "total_loss": -9709.308922541886
  },
  {
    "episode": 279,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9712.338134765625,
    "value_loss": 2.4541300535202026,
    "entropy": 0.015339231351390481,
    "total_loss": -9709.890140404645
  },
  {
    "episode": 280,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9712.180908203125,
    "value_loss": 2.4540711641311646,
    "entropy": 0.01385513273999095,
    "total_loss": -9709.73237909209
  },
  {
    "episode": 281,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9711.357421875,
    "value_loss": 2.454043745994568,
    "entropy": 0.01229561772197485,
    "total_loss": -9708.908296376094
  },
  {
    "episode": 282,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9710.39892578125,
    "value_loss": 2.454033374786377,
    "entropy": 0.010921073378995061,
    "total_loss": -9707.949260835816
  },
  {
    "episode": 283,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9709.54248046875,
    "value_loss": 2.4540294408798218,
    "entropy": 0.009717128705233335,
    "total_loss": -9707.092337879352
  },
  {
    "episode": 284,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9708.848388671875,
    "value_loss": 2.4540138840675354,
    "entropy": 0.008658652659505606,
    "total_loss": -9706.397838248871
  },
  {
    "episode": 285,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9708.28369140625,
    "value_loss": 2.453985273838043,
    "entropy": 0.0076925065368413925,
    "total_loss": -9705.832783135027
  },
  {
    "episode": 286,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9707.749755859375,
    "value_loss": 2.453939437866211,
    "entropy": 0.006848238757811487,
    "total_loss": -9705.298555717012
  },
  {
    "episode": 287,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9707.22607421875,
    "value_loss": 2.4538947343826294,
    "entropy": 0.006162583245895803,
    "total_loss": -9704.774644517665
  },
  {
    "episode": 288,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9706.684326171875,
    "value_loss": 2.453853130340576,
    "entropy": 0.005612243548966944,
    "total_loss": -9704.232717938954
  },
  {
    "episode": 289,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9706.114013671875,
    "value_loss": 2.453819155693054,
    "entropy": 0.0051564761670306325,
    "total_loss": -9703.66225710665
  },
  {
    "episode": 290,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9705.50830078125,
    "value_loss": 2.453792989253998,
    "entropy": 0.004772249259985983,
    "total_loss": -9703.0564166917
  },
  {
    "episode": 291,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9704.86083984375,
    "value_loss": 2.4537755250930786,
    "entropy": 0.004444754216820002,
    "total_loss": -9702.408842220344
  },
  {
    "episode": 292,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9704.193603515625,
    "value_loss": 2.453765571117401,
    "entropy": 0.004164366400800645,
    "total_loss": -9701.741503691068
  },
  {
    "episode": 293,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9703.501220703125,
    "value_loss": 2.4537593722343445,
    "entropy": 0.003919797425623983,
    "total_loss": -9701.049029249862
  },
  {
    "episode": 294,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9702.7978515625,
    "value_loss": 2.4537575244903564,
    "entropy": 0.00370311108417809,
    "total_loss": -9700.345575282443
  },
  {
    "episode": 295,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9702.0888671875,
    "value_loss": 2.4537585973739624,
    "entropy": 0.003510796057526022,
    "total_loss": -9699.63651290855
  },
  {
    "episode": 296,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9701.3759765625,
    "value_loss": 2.4537604451179504,
    "entropy": 0.003337034722790122,
    "total_loss": -9698.923550931271
  },
  {
    "episode": 297,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9700.64453125,
    "value_loss": 2.4537593126296997,
    "entropy": 0.003180510422680527,
    "total_loss": -9698.192044141539
  },
  {
    "episode": 298,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9699.8994140625,
    "value_loss": 2.453761875629425,
    "entropy": 0.0030382207478396595,
    "total_loss": -9697.44686747517
  },
  {
    "episode": 299,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9699.1337890625,
    "value_loss": 2.4537640810012817,
    "entropy": 0.00290723197394982,
    "total_loss": -9696.681187874288
  },
  {
    "episode": 300,
    "avg_reward_per_step": 590.2482475077977,
    "episode_length": 34,
    "policy_loss": -9698.35791015625,
    "value_loss": 2.453766882419586,
    "entropy": 0.0027881230344064534,
    "total_loss": -9695.905258523044
  }
]