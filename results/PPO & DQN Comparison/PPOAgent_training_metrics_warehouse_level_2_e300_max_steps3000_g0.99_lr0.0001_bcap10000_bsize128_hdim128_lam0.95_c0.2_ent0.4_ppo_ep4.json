[
  {
    "episode": 1,
    "avg_reward_per_step": 15.080760198869159,
    "episode_length": 1204,
    "policy_loss": -255.31574249267578,
    "value_loss": 0.5110376179218292,
    "entropy": 1.3558824956417084,
    "total_loss": -255.34705787301064
  },
  {
    "episode": 2,
    "avg_reward_per_step": 9.975312078188571,
    "episode_length": 1705,
    "policy_loss": -168.6791534423828,
    "value_loss": 0.5067242980003357,
    "entropy": 1.3543797731399536,
    "total_loss": -168.71418105363847
  },
  {
    "episode": 3,
    "avg_reward_per_step": 14.473471927403354,
    "episode_length": 1246,
    "policy_loss": -244.14302825927734,
    "value_loss": 0.5104671865701675,
    "entropy": 1.353575736284256,
    "total_loss": -244.17399136722088
  },
  {
    "episode": 4,
    "avg_reward_per_step": 17.26895360464453,
    "episode_length": 1073,
    "policy_loss": -291.47071838378906,
    "value_loss": 0.5129483491182327,
    "entropy": 1.355035811662674,
    "total_loss": -291.4997843593359
  },
  {
    "episode": 5,
    "avg_reward_per_step": 47.267069806493815,
    "episode_length": 410,
    "policy_loss": -800.4331817626953,
    "value_loss": 0.5392148494720459,
    "entropy": 1.3563430309295654,
    "total_loss": -800.4365041255951
  },
  {
    "episode": 6,
    "avg_reward_per_step": 26.878363944609703,
    "episode_length": 704,
    "policy_loss": -454.06634521484375,
    "value_loss": 0.5209661424160004,
    "entropy": 1.3472072184085846,
    "total_loss": -454.0842619597912
  },
  {
    "episode": 7,
    "avg_reward_per_step": 26.96658842362447,
    "episode_length": 700,
    "policy_loss": -454.6201629638672,
    "value_loss": 0.5209825485944748,
    "entropy": 1.3394186198711395,
    "total_loss": -454.63494786322116
  },
  {
    "episode": 8,
    "avg_reward_per_step": -2.067016535502804,
    "episode_length": 3000,
    "policy_loss": 34.79183578491211,
    "value_loss": 1.160755455493927,
    "entropy": 1.3272930085659027,
    "total_loss": 35.421674036979674
  },
  {
    "episode": 9,
    "avg_reward_per_step": 18.805398618312026,
    "episode_length": 984,
    "policy_loss": -316.19427490234375,
    "value_loss": 0.514053538441658,
    "entropy": 1.3225208520889282,
    "total_loss": -316.20922970473765
  },
  {
    "episode": 10,
    "avg_reward_per_step": 29.97398298173932,
    "episode_length": 638,
    "policy_loss": -504.9910430908203,
    "value_loss": 0.5237274914979935,
    "entropy": 1.3260761499404907,
    "total_loss": -504.9977460592985
  },
  {
    "episode": 11,
    "avg_reward_per_step": -2.0380318077912194,
    "episode_length": 3000,
    "policy_loss": 34.25738525390625,
    "value_loss": 1.2755607068538666,
    "entropy": 1.3252321481704712,
    "total_loss": 35.00285310149193
  },
  {
    "episode": 12,
    "avg_reward_per_step": 23.26509211647138,
    "episode_length": 788,
    "policy_loss": -392.4036331176758,
    "value_loss": 0.5174147188663483,
    "entropy": 1.3254943192005157,
    "total_loss": -392.41641612648965
  },
  {
    "episode": 13,
    "avg_reward_per_step": -2.1986307591725365,
    "episode_length": 3000,
    "policy_loss": 36.94929218292236,
    "value_loss": 1.312357634305954,
    "entropy": 1.3352600038051605,
    "total_loss": 37.72754581570625
  },
  {
    "episode": 14,
    "avg_reward_per_step": 32.83396723905184,
    "episode_length": 580,
    "policy_loss": -554.1619262695312,
    "value_loss": 0.5260132998228073,
    "entropy": 1.3450638353824615,
    "total_loss": -554.1739385038615
  },
  {
    "episode": 15,
    "avg_reward_per_step": 8.382829864753328,
    "episode_length": 1897,
    "policy_loss": -140.54217529296875,
    "value_loss": 0.5051930844783783,
    "entropy": 1.3431625664234161,
    "total_loss": -140.57424723505974
  },
  {
    "episode": 16,
    "avg_reward_per_step": 16.853430564499817,
    "episode_length": 1074,
    "policy_loss": -283.44734954833984,
    "value_loss": 0.5122348070144653,
    "entropy": 1.3529971539974213,
    "total_loss": -283.47631360292434
  },
  {
    "episode": 17,
    "avg_reward_per_step": -2.125602178945682,
    "episode_length": 3000,
    "policy_loss": 35.56929588317871,
    "value_loss": 1.4562468230724335,
    "entropy": 1.353564590215683,
    "total_loss": 36.48411687016487
  },
  {
    "episode": 18,
    "avg_reward_per_step": 13.6903450236376,
    "episode_length": 1283,
    "policy_loss": -230.33550262451172,
    "value_loss": 0.5095927715301514,
    "entropy": 1.3508862555027008,
    "total_loss": -230.36626435518264
  },
  {
    "episode": 19,
    "avg_reward_per_step": -1.844119806929311,
    "episode_length": 3000,
    "policy_loss": 30.804430961608887,
    "value_loss": 1.1467123627662659,
    "entropy": 1.3548825085163116,
    "total_loss": 31.409190320968627
  },
  {
    "episode": 20,
    "avg_reward_per_step": 16.196222108774784,
    "episode_length": 1135,
    "policy_loss": -272.3612365722656,
    "value_loss": 0.5119846612215042,
    "entropy": 1.3564570248126984,
    "total_loss": -272.3918347209692
  },
  {
    "episode": 21,
    "avg_reward_per_step": 31.515722967512414,
    "episode_length": 601,
    "policy_loss": -531.0456695556641,
    "value_loss": 0.5247294157743454,
    "entropy": 1.357636421918869,
    "total_loss": -531.0639947086572
  },
  {
    "episode": 22,
    "avg_reward_per_step": 39.09209790064397,
    "episode_length": 495,
    "policy_loss": -658.9290161132812,
    "value_loss": 0.5318074226379395,
    "entropy": 1.3550946414470673,
    "total_loss": -658.9392465472222
  },
  {
    "episode": 23,
    "avg_reward_per_step": 10.057008613624646,
    "episode_length": 1694,
    "policy_loss": -168.83237075805664,
    "value_loss": 0.5067798942327499,
    "entropy": 1.3503107130527496,
    "total_loss": -168.865715149045
  },
  {
    "episode": 24,
    "avg_reward_per_step": -1.9357717633726579,
    "episode_length": 3000,
    "policy_loss": 32.21641826629639,
    "value_loss": 1.4130131900310516,
    "entropy": 1.3524003624916077,
    "total_loss": 33.08847131133079
  },
  {
    "episode": 25,
    "avg_reward_per_step": 6.160268336249517,
    "episode_length": 2561,
    "policy_loss": -103.56281852722168,
    "value_loss": 0.5037808567285538,
    "entropy": 1.347476452589035,
    "total_loss": -103.59802825152875
  },
  {
    "episode": 26,
    "avg_reward_per_step": 12.701118605290443,
    "episode_length": 1400,
    "policy_loss": -213.5263786315918,
    "value_loss": 0.5089876353740692,
    "entropy": 1.3505703508853912,
    "total_loss": -213.55761913657187
  },
  {
    "episode": 27,
    "avg_reward_per_step": 32.531484048567876,
    "episode_length": 589,
    "policy_loss": -548.6290435791016,
    "value_loss": 0.525871604681015,
    "entropy": 1.3462404310703278,
    "total_loss": -548.6416681468487
  },
  {
    "episode": 28,
    "avg_reward_per_step": -2.1168786892947344,
    "episode_length": 3000,
    "policy_loss": 35.41646766662598,
    "value_loss": 1.3433427810668945,
    "entropy": 1.3431373238563538,
    "total_loss": 36.22255551815033
  },
  {
    "episode": 29,
    "avg_reward_per_step": 10.22689284853611,
    "episode_length": 1715,
    "policy_loss": -172.37427520751953,
    "value_loss": 0.5071370005607605,
    "entropy": 1.3364593982696533,
    "total_loss": -172.40172196626662
  },
  {
    "episode": 30,
    "avg_reward_per_step": 46.4046926563803,
    "episode_length": 418,
    "policy_loss": -784.9134368896484,
    "value_loss": 0.5385448932647705,
    "entropy": 1.3380979299545288,
    "total_loss": -784.9101311683655
  },
  {
    "episode": 31,
    "avg_reward_per_step": 26.329974617129444,
    "episode_length": 712,
    "policy_loss": -444.4918518066406,
    "value_loss": 0.5203190892934799,
    "entropy": 1.3393507301807404,
    "total_loss": -444.50727300941946
  },
  {
    "episode": 32,
    "avg_reward_per_step": -1.9013127536606655,
    "episode_length": 3000,
    "policy_loss": 31.56327247619629,
    "value_loss": 1.1976616382598877,
    "entropy": 1.3408997356891632,
    "total_loss": 32.224574220180514
  },
  {
    "episode": 33,
    "avg_reward_per_step": -2.0333310027133007,
    "episode_length": 3000,
    "policy_loss": 33.89504814147949,
    "value_loss": 1.092187762260437,
    "entropy": 1.3407487869262695,
    "total_loss": 34.450936388969424
  },
  {
    "episode": 34,
    "avg_reward_per_step": 19.558776285259867,
    "episode_length": 942,
    "policy_loss": -329.9131317138672,
    "value_loss": 0.5145974457263947,
    "entropy": 1.3287702202796936,
    "total_loss": -329.93004235625267
  },
  {
    "episode": 35,
    "avg_reward_per_step": 11.67609612553503,
    "episode_length": 1502,
    "policy_loss": -196.97203826904297,
    "value_loss": 0.5081918239593506,
    "entropy": 1.334663987159729,
    "total_loss": -196.99771203994752
  },
  {
    "episode": 36,
    "avg_reward_per_step": 16.019455299308344,
    "episode_length": 1133,
    "policy_loss": -270.1546173095703,
    "value_loss": 0.5117427855730057,
    "entropy": 1.3321546614170074,
    "total_loss": -270.17573638856413
  },
  {
    "episode": 37,
    "avg_reward_per_step": 6.772729115013023,
    "episode_length": 2340,
    "policy_loss": -113.99435997009277,
    "value_loss": 0.5041918903589249,
    "entropy": 1.3311955630779266,
    "total_loss": -114.02264630496502
  },
  {
    "episode": 38,
    "avg_reward_per_step": 12.556412897502918,
    "episode_length": 1399,
    "policy_loss": -211.28065872192383,
    "value_loss": 0.5087687969207764,
    "entropy": 1.330200970172882,
    "total_loss": -211.3039703130722
  },
  {
    "episode": 39,
    "avg_reward_per_step": -1.9574227493392067,
    "episode_length": 3000,
    "policy_loss": 32.82267379760742,
    "value_loss": 1.142455130815506,
    "entropy": 1.335181087255478,
    "total_loss": 33.431056493520735
  },
  {
    "episode": 40,
    "avg_reward_per_step": 44.77056577944819,
    "episode_length": 437,
    "policy_loss": -752.1391143798828,
    "value_loss": 0.5369975417852402,
    "entropy": 1.3375531435012817,
    "total_loss": -752.1371380954981
  },
  {
    "episode": 41,
    "avg_reward_per_step": 28.968624637430054,
    "episode_length": 660,
    "policy_loss": -488.52124786376953,
    "value_loss": 0.5227861851453781,
    "entropy": 1.3285697996616364,
    "total_loss": -488.5298895984888
  },
  {
    "episode": 42,
    "avg_reward_per_step": 6.289962347472931,
    "episode_length": 2438,
    "policy_loss": -106.19001960754395,
    "value_loss": 0.5037529766559601,
    "entropy": 1.3255779445171356,
    "total_loss": -106.21649780869484
  },
  {
    "episode": 43,
    "avg_reward_per_step": 16.009516787805573,
    "episode_length": 1092,
    "policy_loss": -269.9546813964844,
    "value_loss": 0.5112869739532471,
    "entropy": 1.3233596980571747,
    "total_loss": -269.972738301754
  },
  {
    "episode": 44,
    "avg_reward_per_step": 18.569046916851622,
    "episode_length": 981,
    "policy_loss": -314.3970184326172,
    "value_loss": 0.5137192159891129,
    "entropy": 1.319802463054657,
    "total_loss": -314.4112202018499
  },
  {
    "episode": 45,
    "avg_reward_per_step": 9.13670905522038,
    "episode_length": 1796,
    "policy_loss": -154.21207809448242,
    "value_loss": 0.50591079890728,
    "entropy": 1.310890018939972,
    "total_loss": -154.23052330315113
  },
  {
    "episode": 46,
    "avg_reward_per_step": 18.63594777796468,
    "episode_length": 958,
    "policy_loss": -316.40567779541016,
    "value_loss": 0.5134667605161667,
    "entropy": 1.3122860491275787,
    "total_loss": -316.41712545454504
  },
  {
    "episode": 47,
    "avg_reward_per_step": 29.927711993842074,
    "episode_length": 616,
    "policy_loss": -506.5539245605469,
    "value_loss": 0.5228349417448044,
    "entropy": 1.279631793498993,
    "total_loss": -506.5429423362017
  },
  {
    "episode": 48,
    "avg_reward_per_step": 28.28222277236639,
    "episode_length": 659,
    "policy_loss": -480.2177276611328,
    "value_loss": 0.521828830242157,
    "entropy": 1.2917868494987488,
    "total_loss": -480.21261357069017
  },
  {
    "episode": 49,
    "avg_reward_per_step": 7.372846364870619,
    "episode_length": 2059,
    "policy_loss": -124.25859451293945,
    "value_loss": 0.5043701827526093,
    "entropy": 1.274325966835022,
    "total_loss": -124.26395471692085
  },
  {
    "episode": 50,
    "avg_reward_per_step": 73.35033308354313,
    "episode_length": 268,
    "policy_loss": -1235.805419921875,
    "value_loss": 0.5646527707576752,
    "entropy": 1.2557378709316254,
    "total_loss": -1235.74306229949
  },
  {
    "episode": 51,
    "avg_reward_per_step": 15.59023698930012,
    "episode_length": 1130,
    "policy_loss": -262.78687286376953,
    "value_loss": 0.5110857635736465,
    "entropy": 1.2859376668930054,
    "total_loss": -262.7901621669531
  },
  {
    "episode": 52,
    "avg_reward_per_step": 88.10012591788038,
    "episode_length": 224,
    "policy_loss": -1492.4238586425781,
    "value_loss": 0.5798427909612656,
    "entropy": 1.2609752416610718,
    "total_loss": -1492.3484059482812
  },
  {
    "episode": 53,
    "avg_reward_per_step": 33.18333668956077,
    "episode_length": 565,
    "policy_loss": -562.6770324707031,
    "value_loss": 0.5259012281894684,
    "entropy": 1.2772771418094635,
    "total_loss": -562.6620420992374
  },
  {
    "episode": 54,
    "avg_reward_per_step": 20.702436937067798,
    "episode_length": 894,
    "policy_loss": -352.69691467285156,
    "value_loss": 0.5155123919248581,
    "entropy": 1.274246722459793,
    "total_loss": -352.6911009699106
  },
  {
    "episode": 55,
    "avg_reward_per_step": 21.185705589885938,
    "episode_length": 862,
    "policy_loss": -354.9864196777344,
    "value_loss": 0.5156281441450119,
    "entropy": 1.269805908203125,
    "total_loss": -354.9787138968706
  },
  {
    "episode": 56,
    "avg_reward_per_step": -2.0586517671196916,
    "episode_length": 3000,
    "policy_loss": 34.30354690551758,
    "value_loss": 1.102571427822113,
    "entropy": 1.273255616426468,
    "total_loss": 34.89681608676911
  },
  {
    "episode": 57,
    "avg_reward_per_step": -1.9290412033672406,
    "episode_length": 3000,
    "policy_loss": 32.36609363555908,
    "value_loss": 1.0305770933628082,
    "entropy": 1.2639224827289581,
    "total_loss": 32.891101735830304
  },
  {
    "episode": 58,
    "avg_reward_per_step": 14.318561239337162,
    "episode_length": 1247,
    "policy_loss": -240.77878952026367,
    "value_loss": 0.5101756602525711,
    "entropy": 1.2806127965450287,
    "total_loss": -240.7808589786291
  },
  {
    "episode": 59,
    "avg_reward_per_step": 31.194929314605357,
    "episode_length": 621,
    "policy_loss": -526.637939453125,
    "value_loss": 0.5249974578619003,
    "entropy": 1.2468904852867126,
    "total_loss": -526.6116981893778
  },
  {
    "episode": 60,
    "avg_reward_per_step": 33.744963450260016,
    "episode_length": 569,
    "policy_loss": -571.2794799804688,
    "value_loss": 0.5269426703453064,
    "entropy": 1.2639785706996918,
    "total_loss": -571.2581287384033
  },
  {
    "episode": 61,
    "avg_reward_per_step": 411.2816817854844,
    "episode_length": 49,
    "policy_loss": -6584.674560546875,
    "value_loss": 1.2461128532886505,
    "entropy": 1.209255188703537,
    "total_loss": -6583.912149769068
  },
  {
    "episode": 62,
    "avg_reward_per_step": 123.93441671725202,
    "episode_length": 160,
    "policy_loss": -2088.0253295898438,
    "value_loss": 0.6207311004400253,
    "entropy": 1.206949770450592,
    "total_loss": -2087.887378397584
  },
  {
    "episode": 63,
    "avg_reward_per_step": 47.93259534975356,
    "episode_length": 402,
    "policy_loss": -804.0744934082031,
    "value_loss": 0.5392639338970184,
    "entropy": 1.2017004787921906,
    "total_loss": -804.015909665823
  },
  {
    "episode": 64,
    "avg_reward_per_step": -2.068540493648845,
    "episode_length": 3000,
    "policy_loss": 34.439456939697266,
    "value_loss": 0.8961601406335831,
    "entropy": 1.2053130865097046,
    "total_loss": 34.853491845726964
  },
  {
    "episode": 65,
    "avg_reward_per_step": -1.9322406397766665,
    "episode_length": 3000,
    "policy_loss": 32.223952293395996,
    "value_loss": 0.8507326245307922,
    "entropy": 1.1948784589767456,
    "total_loss": 32.59673353433609
  },
  {
    "episode": 66,
    "avg_reward_per_step": -2.193797380499712,
    "episode_length": 3000,
    "policy_loss": 36.48131847381592,
    "value_loss": 0.970557451248169,
    "entropy": 1.192989468574524,
    "total_loss": 36.97468013763428
  },
  {
    "episode": 67,
    "avg_reward_per_step": 127.87956465920755,
    "episode_length": 156,
    "policy_loss": -2179.750732421875,
    "value_loss": 0.6263952702283859,
    "entropy": 1.1786260306835175,
    "total_loss": -2179.59578756392
  },
  {
    "episode": 68,
    "avg_reward_per_step": 23.662656222934828,
    "episode_length": 803,
    "policy_loss": -396.9322814941406,
    "value_loss": 0.5182813704013824,
    "entropy": 1.2303934395313263,
    "total_loss": -396.9061574995518
  },
  {
    "episode": 69,
    "avg_reward_per_step": -1.5525441712593584,
    "episode_length": 3000,
    "policy_loss": 25.798818111419678,
    "value_loss": 0.7263435274362564,
    "entropy": 1.2301443815231323,
    "total_loss": 26.033103886246682
  },
  {
    "episode": 70,
    "avg_reward_per_step": -1.6981569997982133,
    "episode_length": 3000,
    "policy_loss": 28.02847671508789,
    "value_loss": 0.8872800320386887,
    "entropy": 1.2286547720432281,
    "total_loss": 28.424294838309287
  },
  {
    "episode": 71,
    "avg_reward_per_step": -1.665096241104289,
    "episode_length": 3000,
    "policy_loss": 27.596664428710938,
    "value_loss": 0.8936927914619446,
    "entropy": 1.2394397854804993,
    "total_loss": 27.99458130598068
  },
  {
    "episode": 72,
    "avg_reward_per_step": 5.334550707794333,
    "episode_length": 2882,
    "policy_loss": -90.16984558105469,
    "value_loss": 0.5031947642564774,
    "entropy": 1.2411014437675476,
    "total_loss": -90.16309139430523
  },
  {
    "episode": 73,
    "avg_reward_per_step": 19.55251655888638,
    "episode_length": 961,
    "policy_loss": -329.6439514160156,
    "value_loss": 0.5149439871311188,
    "entropy": 1.2412462830543518,
    "total_loss": -329.62550594210626
  },
  {
    "episode": 74,
    "avg_reward_per_step": 20.748092743909375,
    "episode_length": 908,
    "policy_loss": -349.2176742553711,
    "value_loss": 0.5158390402793884,
    "entropy": 1.238038331270218,
    "total_loss": -349.1970505475998
  },
  {
    "episode": 75,
    "avg_reward_per_step": 10.85885339797623,
    "episode_length": 1642,
    "policy_loss": -183.43364334106445,
    "value_loss": 0.5076826363801956,
    "entropy": 1.2410385310649872,
    "total_loss": -183.42237611711025
  },
  {
    "episode": 76,
    "avg_reward_per_step": 10.202531355719744,
    "episode_length": 1708,
    "policy_loss": -172.03515625,
    "value_loss": 0.5070576369762421,
    "entropy": 1.2469375729560852,
    "total_loss": -172.0268736422062
  },
  {
    "episode": 77,
    "avg_reward_per_step": 10.38195357973667,
    "episode_length": 1692,
    "policy_loss": -175.3092041015625,
    "value_loss": 0.5073042213916779,
    "entropy": 1.2338439524173737,
    "total_loss": -175.29543746113777
  },
  {
    "episode": 78,
    "avg_reward_per_step": -1.533335053830561,
    "episode_length": 3000,
    "policy_loss": 25.345577716827393,
    "value_loss": 0.7560528516769409,
    "entropy": 1.2289596199989319,
    "total_loss": 25.610046720504762
  },
  {
    "episode": 79,
    "avg_reward_per_step": 11.21645572494479,
    "episode_length": 1561,
    "policy_loss": -189.48347854614258,
    "value_loss": 0.5078267604112625,
    "entropy": 1.2288315296173096,
    "total_loss": -189.46718439757825
  },
  {
    "episode": 80,
    "avg_reward_per_step": 7.723688301465442,
    "episode_length": 2170,
    "policy_loss": -130.22293853759766,
    "value_loss": 0.5051139444112778,
    "entropy": 1.2304522097110748,
    "total_loss": -130.2100054770708
  },
  {
    "episode": 81,
    "avg_reward_per_step": 8.317213815191723,
    "episode_length": 2050,
    "policy_loss": -140.37079620361328,
    "value_loss": 0.5056177973747253,
    "entropy": 1.2299593389034271,
    "total_loss": -140.35716214179993
  },
  {
    "episode": 82,
    "avg_reward_per_step": 5.739756152013109,
    "episode_length": 2725,
    "policy_loss": -97.17010688781738,
    "value_loss": 0.5035170316696167,
    "entropy": 1.2220702767372131,
    "total_loss": -97.15541796684265
  },
  {
    "episode": 83,
    "avg_reward_per_step": 23.839759088977093,
    "episode_length": 800,
    "policy_loss": -402.31846618652344,
    "value_loss": 0.5185674279928207,
    "entropy": 1.2256183922290802,
    "total_loss": -402.29014611542226
  },
  {
    "episode": 84,
    "avg_reward_per_step": -1.7002514489136131,
    "episode_length": 3000,
    "policy_loss": 27.880433559417725,
    "value_loss": 0.8345540761947632,
    "entropy": 1.2165315449237823,
    "total_loss": 28.228375017642975
  },
  {
    "episode": 85,
    "avg_reward_per_step": 14.694966209376533,
    "episode_length": 1252,
    "policy_loss": -248.1914405822754,
    "value_loss": 0.5108701139688492,
    "entropy": 1.212067186832428,
    "total_loss": -248.1653973430395
  },
  {
    "episode": 86,
    "avg_reward_per_step": 13.250755637928378,
    "episode_length": 1369,
    "policy_loss": -223.33720779418945,
    "value_loss": 0.5096343010663986,
    "entropy": 1.2212973535060883,
    "total_loss": -223.3160924345255
  },
  {
    "episode": 87,
    "avg_reward_per_step": 15.839606051561814,
    "episode_length": 1137,
    "policy_loss": -267.6896743774414,
    "value_loss": 0.5115155726671219,
    "entropy": 1.2055404484272003,
    "total_loss": -267.66037498414516
  },
  {
    "episode": 88,
    "avg_reward_per_step": -1.624173403874719,
    "episode_length": 3000,
    "policy_loss": 26.783632278442383,
    "value_loss": 0.8011994659900665,
    "entropy": 1.1996554136276245,
    "total_loss": 27.1049695789814
  },
  {
    "episode": 89,
    "avg_reward_per_step": 19.027158391937583,
    "episode_length": 991,
    "policy_loss": -320.8770446777344,
    "value_loss": 0.5145754516124725,
    "entropy": 1.2031733095645905,
    "total_loss": -320.8437385499477
  },
  {
    "episode": 90,
    "avg_reward_per_step": 13.297519846924816,
    "episode_length": 1336,
    "policy_loss": -224.31488418579102,
    "value_loss": 0.5094536542892456,
    "entropy": 1.1928564012050629,
    "total_loss": -224.2825730919838
  },
  {
    "episode": 91,
    "avg_reward_per_step": 25.470521442830513,
    "episode_length": 749,
    "policy_loss": -429.7096633911133,
    "value_loss": 0.5198945552110672,
    "entropy": 1.1895737648010254,
    "total_loss": -429.6655983418226
  },
  {
    "episode": 92,
    "avg_reward_per_step": 37.103174835615555,
    "episode_length": 526,
    "policy_loss": -625.6255950927734,
    "value_loss": 0.5302728712558746,
    "entropy": 1.193032681941986,
    "total_loss": -625.5725352942943
  },
  {
    "episode": 93,
    "avg_reward_per_step": 26.26102010638196,
    "episode_length": 731,
    "policy_loss": -442.05072021484375,
    "value_loss": 0.5207096189260483,
    "entropy": 1.1878034472465515,
    "total_loss": -442.0051319748163
  },
  {
    "episode": 94,
    "avg_reward_per_step": 29.41480232680759,
    "episode_length": 650,
    "policy_loss": -494.7592468261719,
    "value_loss": 0.5231739729642868,
    "entropy": 1.1995090544223785,
    "total_loss": -494.71587647497654
  },
  {
    "episode": 95,
    "avg_reward_per_step": 52.865040017278886,
    "episode_length": 370,
    "policy_loss": -894.37939453125,
    "value_loss": 0.5445830971002579,
    "entropy": 1.2005172669887543,
    "total_loss": -894.3150183409452
  },
  {
    "episode": 96,
    "avg_reward_per_step": 7.249924830513079,
    "episode_length": 2256,
    "policy_loss": -122.93245124816895,
    "value_loss": 0.5046972632408142,
    "entropy": 1.2170488238334656,
    "total_loss": -122.91457351446152
  },
  {
    "episode": 97,
    "avg_reward_per_step": -1.6757844394352999,
    "episode_length": 3000,
    "policy_loss": 27.511998176574707,
    "value_loss": 0.84626404941082,
    "entropy": 1.2235966920852661,
    "total_loss": 27.868823549151422
  },
  {
    "episode": 98,
    "avg_reward_per_step": 12.048490027379913,
    "episode_length": 1491,
    "policy_loss": -203.35155487060547,
    "value_loss": 0.5086379945278168,
    "entropy": 1.228125125169754,
    "total_loss": -203.33416692614554
  },
  {
    "episode": 99,
    "avg_reward_per_step": 13.355550792893952,
    "episode_length": 1359,
    "policy_loss": -225.32580184936523,
    "value_loss": 0.5097220242023468,
    "entropy": 1.238417536020279,
    "total_loss": -225.311446839571
  },
  {
    "episode": 100,
    "avg_reward_per_step": -1.6384146484901074,
    "episode_length": 3000,
    "policy_loss": 26.9815731048584,
    "value_loss": 0.8646448105573654,
    "entropy": 1.2383105158805847,
    "total_loss": 27.35089370906353
  },
  {
    "episode": 101,
    "avg_reward_per_step": 18.230027935850288,
    "episode_length": 1018,
    "policy_loss": -308.1012420654297,
    "value_loss": 0.5137477964162827,
    "entropy": 1.2519851326942444,
    "total_loss": -308.0882883220911
  },
  {
    "episode": 102,
    "avg_reward_per_step": 35.58911164132764,
    "episode_length": 546,
    "policy_loss": -601.6552276611328,
    "value_loss": 0.52884142100811,
    "entropy": 1.2409286797046661,
    "total_loss": -601.6227577120065
  },
  {
    "episode": 103,
    "avg_reward_per_step": -1.644062210084568,
    "episode_length": 3000,
    "policy_loss": 27.01602840423584,
    "value_loss": 0.8426766395568848,
    "entropy": 1.2363120019435883,
    "total_loss": 27.36418024301529
  },
  {
    "episode": 104,
    "avg_reward_per_step": 28.23320542290012,
    "episode_length": 672,
    "policy_loss": -476.47386932373047,
    "value_loss": 0.5221896469593048,
    "entropy": 1.24080428481102,
    "total_loss": -476.4480013906956
  },
  {
    "episode": 105,
    "avg_reward_per_step": 8.804582019785947,
    "episode_length": 1918,
    "policy_loss": -148.93615341186523,
    "value_loss": 0.5059288442134857,
    "entropy": 1.2443229854106903,
    "total_loss": -148.927953761816
  },
  {
    "episode": 106,
    "avg_reward_per_step": 49.42095905707245,
    "episode_length": 396,
    "policy_loss": -833.8899688720703,
    "value_loss": 0.5415135771036148,
    "entropy": 1.240564227104187,
    "total_loss": -833.8446809858084
  },
  {
    "episode": 107,
    "avg_reward_per_step": 59.10666057415634,
    "episode_length": 332,
    "policy_loss": -997.1974639892578,
    "value_loss": 0.5507201701402664,
    "entropy": 1.2530399560928345,
    "total_loss": -997.1479598015546
  },
  {
    "episode": 108,
    "avg_reward_per_step": 59.67849263576371,
    "episode_length": 331,
    "policy_loss": -1007.4483337402344,
    "value_loss": 0.5514873415231705,
    "entropy": 1.2327439486980438,
    "total_loss": -1007.3899439781904
  },
  {
    "episode": 109,
    "avg_reward_per_step": 16.358290819473666,
    "episode_length": 1119,
    "policy_loss": -277.2665786743164,
    "value_loss": 0.5120373070240021,
    "entropy": 1.2270773947238922,
    "total_loss": -277.24537232518196
  },
  {
    "episode": 110,
    "avg_reward_per_step": 11.332429890825294,
    "episode_length": 1544,
    "policy_loss": -191.36190032958984,
    "value_loss": 0.5078741312026978,
    "entropy": 1.2180279195308685,
    "total_loss": -191.3412373661995
  },
  {
    "episode": 111,
    "avg_reward_per_step": 14.069554207552175,
    "episode_length": 1282,
    "policy_loss": -237.2429542541504,
    "value_loss": 0.5102248787879944,
    "entropy": 1.2060610949993134,
    "total_loss": -237.21515381336212
  },
  {
    "episode": 112,
    "avg_reward_per_step": 83.73604123191743,
    "episode_length": 237,
    "policy_loss": -1415.4521179199219,
    "value_loss": 0.5754553526639938,
    "entropy": 1.1849797666072845,
    "total_loss": -1415.3506544739007
  },
  {
    "episode": 113,
    "avg_reward_per_step": 5.28687125763088,
    "episode_length": 2885,
    "policy_loss": -90.90188407897949,
    "value_loss": 0.5031788647174835,
    "entropy": 1.1877922117710114,
    "total_loss": -90.87382209897041
  },
  {
    "episode": 114,
    "avg_reward_per_step": -1.6245441996165009,
    "episode_length": 3000,
    "policy_loss": 26.49422788619995,
    "value_loss": 0.7481379806995392,
    "entropy": 1.1822521388530731,
    "total_loss": 26.76946501135826
  },
  {
    "episode": 115,
    "avg_reward_per_step": 8.35692000139707,
    "episode_length": 2071,
    "policy_loss": -140.93137741088867,
    "value_loss": 0.5057563185691833,
    "entropy": 1.1766530275344849,
    "total_loss": -140.8962823033333
  },
  {
    "episode": 116,
    "avg_reward_per_step": 5.289840235683145,
    "episode_length": 2941,
    "policy_loss": -89.73224639892578,
    "value_loss": 0.5032422244548798,
    "entropy": 1.172661155462265,
    "total_loss": -89.6980686366558
  },
  {
    "episode": 117,
    "avg_reward_per_step": 37.304299620291104,
    "episode_length": 521,
    "policy_loss": -629.2825622558594,
    "value_loss": 0.5303788632154465,
    "entropy": 1.172800898551941,
    "total_loss": -629.2213037520647
  },
  {
    "episode": 118,
    "avg_reward_per_step": 5.408551944611729,
    "episode_length": 2876,
    "policy_loss": -91.71043014526367,
    "value_loss": 0.5032974034547806,
    "entropy": 1.1762331426143646,
    "total_loss": -91.67762599885464
  },
  {
    "episode": 119,
    "avg_reward_per_step": 24.543141839872842,
    "episode_length": 781,
    "policy_loss": -413.61817932128906,
    "value_loss": 0.5192131251096725,
    "entropy": 1.1834548115730286,
    "total_loss": -413.5723481208086
  },
  {
    "episode": 120,
    "avg_reward_per_step": 20.889016588775938,
    "episode_length": 904,
    "policy_loss": -352.1976547241211,
    "value_loss": 0.5160657614469528,
    "entropy": 1.188957840204239,
    "total_loss": -352.15717209875584
  },
  {
    "episode": 121,
    "avg_reward_per_step": 64.59233940165706,
    "episode_length": 305,
    "policy_loss": -1089.9102783203125,
    "value_loss": 0.5559690892696381,
    "entropy": 1.1842741072177887,
    "total_loss": -1089.82801887393
  },
  {
    "episode": 122,
    "avg_reward_per_step": 23.101562907630093,
    "episode_length": 822,
    "policy_loss": -388.4963684082031,
    "value_loss": 0.5179711133241653,
    "entropy": 1.1859920024871826,
    "total_loss": -388.45279409587386
  },
  {
    "episode": 123,
    "avg_reward_per_step": 11.7305163768953,
    "episode_length": 1508,
    "policy_loss": -198.14025115966797,
    "value_loss": 0.508286863565445,
    "entropy": 1.1753891706466675,
    "total_loss": -198.10211996436118
  },
  {
    "episode": 124,
    "avg_reward_per_step": 12.108887046986773,
    "episode_length": 1487,
    "policy_loss": -204.98722457885742,
    "value_loss": 0.5087490826845169,
    "entropy": 1.1824451684951782,
    "total_loss": -204.95145356357096
  },
  {
    "episode": 125,
    "avg_reward_per_step": 7.715437911936558,
    "episode_length": 2214,
    "policy_loss": -130.57172393798828,
    "value_loss": 0.5052174925804138,
    "entropy": 1.1939550340175629,
    "total_loss": -130.5440884590149
  },
  {
    "episode": 126,
    "avg_reward_per_step": 7.815033933174916,
    "episode_length": 2165,
    "policy_loss": -132.1896209716797,
    "value_loss": 0.505247101187706,
    "entropy": 1.1949308514595032,
    "total_loss": -132.16234621107577
  },
  {
    "episode": 127,
    "avg_reward_per_step": 53.99713304129483,
    "episode_length": 365,
    "policy_loss": -911.087890625,
    "value_loss": 0.545716717839241,
    "entropy": 1.1919964849948883,
    "total_loss": -911.0189725011587
  },
  {
    "episode": 128,
    "avg_reward_per_step": 82.9416917608774,
    "episode_length": 238,
    "policy_loss": -1394.7273254394531,
    "value_loss": 0.5739764422178268,
    "entropy": 1.1968069076538086,
    "total_loss": -1394.6320717602969
  },
  {
    "episode": 129,
    "avg_reward_per_step": 67.54590220509502,
    "episode_length": 292,
    "policy_loss": -1141.8167114257812,
    "value_loss": 0.5591442883014679,
    "entropy": 1.180285096168518,
    "total_loss": -1141.7296811759472
  },
  {
    "episode": 130,
    "avg_reward_per_step": 8.444048236237144,
    "episode_length": 2027,
    "policy_loss": -142.4956817626953,
    "value_loss": 0.505750834941864,
    "entropy": 1.1800556182861328,
    "total_loss": -142.4619531750679
  },
  {
    "episode": 131,
    "avg_reward_per_step": 60.03689280206002,
    "episode_length": 331,
    "policy_loss": -1009.7316741943359,
    "value_loss": 0.5518884658813477,
    "entropy": 1.1849319636821747,
    "total_loss": -1009.6537585139274
  },
  {
    "episode": 132,
    "avg_reward_per_step": 21.6124784244595,
    "episode_length": 876,
    "policy_loss": -364.42391204833984,
    "value_loss": 0.5166490525007248,
    "entropy": 1.1843749284744263,
    "total_loss": -364.3810129672289
  },
  {
    "episode": 133,
    "avg_reward_per_step": 31.781682588591092,
    "episode_length": 603,
    "policy_loss": -535.2320556640625,
    "value_loss": 0.5252469480037689,
    "entropy": 1.1821250021457672,
    "total_loss": -535.1796587169171
  },
  {
    "episode": 134,
    "avg_reward_per_step": 32.20358610707554,
    "episode_length": 597,
    "policy_loss": -543.6702270507812,
    "value_loss": 0.5256819874048233,
    "entropy": 1.1822450459003448,
    "total_loss": -543.6174430817366
  },
  {
    "episode": 135,
    "avg_reward_per_step": 5.719075160073647,
    "episode_length": 2751,
    "policy_loss": -97.25427436828613,
    "value_loss": 0.5035360753536224,
    "entropy": 1.1847106218338013,
    "total_loss": -97.22462254166604
  },
  {
    "episode": 136,
    "avg_reward_per_step": 29.84830595252974,
    "episode_length": 650,
    "policy_loss": -502.9773941040039,
    "value_loss": 0.5240139365196228,
    "entropy": 1.175557404756546,
    "total_loss": -502.9236031293869
  },
  {
    "episode": 137,
    "avg_reward_per_step": 6.75394081578232,
    "episode_length": 2463,
    "policy_loss": -114.58752250671387,
    "value_loss": 0.5044442862272263,
    "entropy": 1.1769352555274963,
    "total_loss": -114.55385232269764
  },
  {
    "episode": 138,
    "avg_reward_per_step": 24.530278415747347,
    "episode_length": 776,
    "policy_loss": -414.6074523925781,
    "value_loss": 0.5191201567649841,
    "entropy": 1.1721010208129883,
    "total_loss": -414.55717264413835
  },
  {
    "episode": 139,
    "avg_reward_per_step": 23.67549354564152,
    "episode_length": 803,
    "policy_loss": -399.1603240966797,
    "value_loss": 0.5183875858783722,
    "entropy": 1.1828866302967072,
    "total_loss": -399.11509116292
  },
  {
    "episode": 140,
    "avg_reward_per_step": 32.677793033986106,
    "episode_length": 592,
    "policy_loss": -551.8133544921875,
    "value_loss": 0.5262357890605927,
    "entropy": 1.1731114387512207,
    "total_loss": -551.7563632786274
  },
  {
    "episode": 141,
    "avg_reward_per_step": 64.56520567997252,
    "episode_length": 306,
    "policy_loss": -1087.9055480957031,
    "value_loss": 0.556118369102478,
    "entropy": 1.1658665239810944,
    "total_loss": -1087.815776336193
  },
  {
    "episode": 142,
    "avg_reward_per_step": 16.032968966500558,
    "episode_length": 1158,
    "policy_loss": -270.2723617553711,
    "value_loss": 0.5119840502738953,
    "entropy": 1.1590588092803955,
    "total_loss": -270.22400122880936
  },
  {
    "episode": 143,
    "avg_reward_per_step": 21.891213224485142,
    "episode_length": 871,
    "policy_loss": -368.97438049316406,
    "value_loss": 0.5170075595378876,
    "entropy": 1.1471972167491913,
    "total_loss": -368.91625182032584
  },
  {
    "episode": 144,
    "avg_reward_per_step": 20.870659010075386,
    "episode_length": 908,
    "policy_loss": -353.09032440185547,
    "value_loss": 0.5160654336214066,
    "entropy": 1.1482045650482178,
    "total_loss": -353.0335407942533
  },
  {
    "episode": 145,
    "avg_reward_per_step": 13.255298036089664,
    "episode_length": 1387,
    "policy_loss": -224.12238311767578,
    "value_loss": 0.5097488462924957,
    "entropy": 1.1344661116600037,
    "total_loss": -224.06642071604728
  },
  {
    "episode": 146,
    "avg_reward_per_step": 28.818374618963443,
    "episode_length": 663,
    "policy_loss": -486.92486572265625,
    "value_loss": 0.5226413607597351,
    "entropy": 1.131361871957779,
    "total_loss": -486.8547691106796
  },
  {
    "episode": 147,
    "avg_reward_per_step": 12.528059158451093,
    "episode_length": 1426,
    "policy_loss": -211.8510856628418,
    "value_loss": 0.5089160650968552,
    "entropy": 1.1247622072696686,
    "total_loss": -211.79207448065281
  },
  {
    "episode": 148,
    "avg_reward_per_step": 87.3944535622412,
    "episode_length": 228,
    "policy_loss": -1473.4294128417969,
    "value_loss": 0.5792504251003265,
    "entropy": 1.1044052839279175,
    "total_loss": -1473.2919245302678
  },
  {
    "episode": 149,
    "avg_reward_per_step": 11.209474213773834,
    "episode_length": 1584,
    "policy_loss": -190.86677169799805,
    "value_loss": 0.5079266577959061,
    "entropy": 1.075369656085968,
    "total_loss": -190.78899290263652
  },
  {
    "episode": 150,
    "avg_reward_per_step": 29.169245295926594,
    "episode_length": 665,
    "policy_loss": -488.6606750488281,
    "value_loss": 0.5232796370983124,
    "entropy": 1.0569579303264618,
    "total_loss": -488.5601785838604
  },
  {
    "episode": 151,
    "avg_reward_per_step": 13.68960213224338,
    "episode_length": 1325,
    "policy_loss": -231.97749710083008,
    "value_loss": 0.5098810940980911,
    "entropy": 1.0223204493522644,
    "total_loss": -231.8765441864729
  },
  {
    "episode": 152,
    "avg_reward_per_step": 17.271829740871944,
    "episode_length": 1087,
    "policy_loss": -290.6016845703125,
    "value_loss": 0.5130499452352524,
    "entropy": 1.017646163702011,
    "total_loss": -290.49569309055806
  },
  {
    "episode": 153,
    "avg_reward_per_step": 37.917096164723105,
    "episode_length": 517,
    "policy_loss": -638.8865966796875,
    "value_loss": 0.5310607105493546,
    "entropy": 0.9996301233768463,
    "total_loss": -638.7553880184889
  },
  {
    "episode": 154,
    "avg_reward_per_step": 39.03210905030552,
    "episode_length": 499,
    "policy_loss": -660.4775085449219,
    "value_loss": 0.5318307727575302,
    "entropy": 1.0137579143047333,
    "total_loss": -660.3511809378863
  },
  {
    "episode": 155,
    "avg_reward_per_step": 31.267863877992152,
    "episode_length": 615,
    "policy_loss": -526.2029113769531,
    "value_loss": 0.5248236507177353,
    "entropy": 1.0525886416435242,
    "total_loss": -526.0991231828928
  },
  {
    "episode": 156,
    "avg_reward_per_step": 35.22245577282911,
    "episode_length": 552,
    "policy_loss": -595.3086547851562,
    "value_loss": 0.528457373380661,
    "entropy": 1.062550127506256,
    "total_loss": -595.2052174627781
  },
  {
    "episode": 157,
    "avg_reward_per_step": 29.24870208812671,
    "episode_length": 658,
    "policy_loss": -493.05765533447266,
    "value_loss": 0.5231238752603531,
    "entropy": 1.0838325321674347,
    "total_loss": -492.9680644720793
  },
  {
    "episode": 158,
    "avg_reward_per_step": 37.837420447750496,
    "episode_length": 511,
    "policy_loss": -637.4633941650391,
    "value_loss": 0.530470222234726,
    "entropy": 1.0955968499183655,
    "total_loss": -637.3711626827717
  },
  {
    "episode": 159,
    "avg_reward_per_step": 41.61273977025219,
    "episode_length": 469,
    "policy_loss": -701.9067993164062,
    "value_loss": 0.534472793340683,
    "entropy": 1.1057822406291962,
    "total_loss": -701.8146394193172
  },
  {
    "episode": 160,
    "avg_reward_per_step": 45.38775225128826,
    "episode_length": 431,
    "policy_loss": -766.0071258544922,
    "value_loss": 0.5377534627914429,
    "entropy": 1.1041263937950134,
    "total_loss": -765.9110229492187
  },
  {
    "episode": 161,
    "avg_reward_per_step": 24.645487867918504,
    "episode_length": 773,
    "policy_loss": -415.16685485839844,
    "value_loss": 0.5191561430692673,
    "entropy": 1.109404057264328,
    "total_loss": -415.0914603382349
  },
  {
    "episode": 162,
    "avg_reward_per_step": 67.42302573203845,
    "episode_length": 294,
    "policy_loss": -1137.6158447265625,
    "value_loss": 0.5592094510793686,
    "entropy": 1.127117097377777,
    "total_loss": -1137.5074821144342
  },
  {
    "episode": 163,
    "avg_reward_per_step": 15.94263226131562,
    "episode_length": 1159,
    "policy_loss": -268.3198013305664,
    "value_loss": 0.5117718279361725,
    "entropy": 1.1098574697971344,
    "total_loss": -268.25197249054906
  },
  {
    "episode": 164,
    "avg_reward_per_step": 35.647465469701515,
    "episode_length": 545,
    "policy_loss": -600.7964172363281,
    "value_loss": 0.528719961643219,
    "entropy": 1.1109992861747742,
    "total_loss": -600.7120969891548
  },
  {
    "episode": 165,
    "avg_reward_per_step": 22.571448154351145,
    "episode_length": 839,
    "policy_loss": -380.91436767578125,
    "value_loss": 0.5173910856246948,
    "entropy": 1.0968316495418549,
    "total_loss": -380.8357092499733
  },
  {
    "episode": 166,
    "avg_reward_per_step": 37.33236341545055,
    "episode_length": 520,
    "policy_loss": -628.5524597167969,
    "value_loss": 0.530253604054451,
    "entropy": 1.0862797498703003,
    "total_loss": -628.4567180126905
  },
  {
    "episode": 167,
    "avg_reward_per_step": 17.595876608237706,
    "episode_length": 1058,
    "policy_loss": -297.0010681152344,
    "value_loss": 0.5131861418485641,
    "entropy": 1.0924232602119446,
    "total_loss": -296.92485127747057
  },
  {
    "episode": 168,
    "avg_reward_per_step": 36.9332511979454,
    "episode_length": 522,
    "policy_loss": -622.3047180175781,
    "value_loss": 0.5296378880739212,
    "entropy": 1.1006317734718323,
    "total_loss": -622.2153328388929
  },
  {
    "episode": 169,
    "avg_reward_per_step": 56.895339009509435,
    "episode_length": 347,
    "policy_loss": -962.9901580810547,
    "value_loss": 0.548637717962265,
    "entropy": 1.0811426639556885,
    "total_loss": -962.8739774286747
  },
  {
    "episode": 170,
    "avg_reward_per_step": 66.50691858799203,
    "episode_length": 298,
    "policy_loss": -1121.8215026855469,
    "value_loss": 0.5581395030021667,
    "entropy": 1.0584137737751007,
    "total_loss": -1121.6867286920547
  },
  {
    "episode": 171,
    "avg_reward_per_step": 35.65550703810112,
    "episode_length": 548,
    "policy_loss": -603.3281707763672,
    "value_loss": 0.5290710777044296,
    "entropy": 1.0524017810821533,
    "total_loss": -603.2200604110956
  },
  {
    "episode": 172,
    "avg_reward_per_step": 51.723508663888346,
    "episode_length": 383,
    "policy_loss": -873.27587890625,
    "value_loss": 0.5438568592071533,
    "entropy": 1.0416215062141418,
    "total_loss": -873.1486706495285
  },
  {
    "episode": 173,
    "avg_reward_per_step": 135.15248691924603,
    "episode_length": 149,
    "policy_loss": -2317.3821411132812,
    "value_loss": 0.6375436782836914,
    "entropy": 1.0263698995113373,
    "total_loss": -2317.1551453948023
  },
  {
    "episode": 174,
    "avg_reward_per_step": 49.43252824505651,
    "episode_length": 397,
    "policy_loss": -823.2558898925781,
    "value_loss": 0.541241243481636,
    "entropy": 1.0555523037910461,
    "total_loss": -823.1368695706129
  },
  {
    "episode": 175,
    "avg_reward_per_step": 56.75494807573097,
    "episode_length": 345,
    "policy_loss": -957.4537353515625,
    "value_loss": 0.5482235103845596,
    "entropy": 1.0880827605724335,
    "total_loss": -957.3407449454069
  },
  {
    "episode": 176,
    "avg_reward_per_step": 57.21142277323551,
    "episode_length": 343,
    "policy_loss": -961.7308654785156,
    "value_loss": 0.5486353933811188,
    "entropy": 1.066474050283432,
    "total_loss": -961.6088197052479
  },
  {
    "episode": 177,
    "avg_reward_per_step": 96.14251311717526,
    "episode_length": 206,
    "policy_loss": -1624.2180480957031,
    "value_loss": 0.5888930112123489,
    "entropy": 1.0706822574138641,
    "total_loss": -1624.0574279874563
  },
  {
    "episode": 178,
    "avg_reward_per_step": 57.92581200192189,
    "episode_length": 340,
    "policy_loss": -975.8215637207031,
    "value_loss": 0.5494002848863602,
    "entropy": 1.0658345222473145,
    "total_loss": -975.6984972447157
  },
  {
    "episode": 179,
    "avg_reward_per_step": 57.15557685972767,
    "episode_length": 340,
    "policy_loss": -961.1727447509766,
    "value_loss": 0.5480011105537415,
    "entropy": 1.0732008814811707,
    "total_loss": -961.0540239930153
  },
  {
    "episode": 180,
    "avg_reward_per_step": 33.23361630583607,
    "episode_length": 567,
    "policy_loss": -559.2572479248047,
    "value_loss": 0.5260191112756729,
    "entropy": 1.0664567947387695,
    "total_loss": -559.1578115314245
  },
  {
    "episode": 181,
    "avg_reward_per_step": 82.34339535611879,
    "episode_length": 240,
    "policy_loss": -1389.3282775878906,
    "value_loss": 0.5742185860872269,
    "entropy": 1.081180065870285,
    "total_loss": -1389.1865310281514
  },
  {
    "episode": 182,
    "avg_reward_per_step": 87.05195521905428,
    "episode_length": 228,
    "policy_loss": -1484.2572021484375,
    "value_loss": 0.578953206539154,
    "entropy": 1.063327044248581,
    "total_loss": -1484.1035797595978
  },
  {
    "episode": 183,
    "avg_reward_per_step": 64.09343696744558,
    "episode_length": 305,
    "policy_loss": -1093.1534118652344,
    "value_loss": 0.5549929291009903,
    "entropy": 1.0419394671916962,
    "total_loss": -1093.0151947230102
  },
  {
    "episode": 184,
    "avg_reward_per_step": 74.09148704979069,
    "episode_length": 265,
    "policy_loss": -1281.2526550292969,
    "value_loss": 0.565096840262413,
    "entropy": 1.097090870141983,
    "total_loss": -1281.1263945370913
  },
  {
    "episode": 185,
    "avg_reward_per_step": 27.41177311420816,
    "episode_length": 709,
    "policy_loss": -455.58184814453125,
    "value_loss": 0.5220234990119934,
    "entropy": 0.990801215171814,
    "total_loss": -455.45614513158796
  },
  {
    "episode": 186,
    "avg_reward_per_step": 49.63937451669329,
    "episode_length": 394,
    "policy_loss": -836.4653625488281,
    "value_loss": 0.541668102145195,
    "entropy": 1.1015781164169312,
    "total_loss": -836.3643256932497
  },
  {
    "episode": 187,
    "avg_reward_per_step": 29.98536736611173,
    "episode_length": 648,
    "policy_loss": -507.7752456665039,
    "value_loss": 0.5242354273796082,
    "entropy": 1.0287993252277374,
    "total_loss": -507.66252996921537
  },
  {
    "episode": 188,
    "avg_reward_per_step": 16.784024331374034,
    "episode_length": 1137,
    "policy_loss": -283.6527557373047,
    "value_loss": 0.5129634439945221,
    "entropy": 1.069472312927246,
    "total_loss": -283.56758121848105
  },
  {
    "episode": 189,
    "avg_reward_per_step": 13.800086941550889,
    "episode_length": 1336,
    "policy_loss": -233.14748001098633,
    "value_loss": 0.5102490782737732,
    "entropy": 1.0694392621517181,
    "total_loss": -233.06500663757325
  },
  {
    "episode": 190,
    "avg_reward_per_step": 7.73094098532576,
    "episode_length": 2282,
    "policy_loss": -131.36637496948242,
    "value_loss": 0.5054467767477036,
    "entropy": 1.0694920122623444,
    "total_loss": -131.28872499763966
  },
  {
    "episode": 191,
    "avg_reward_per_step": 18.69576873336029,
    "episode_length": 1040,
    "policy_loss": -317.8209991455078,
    "value_loss": 0.5147869884967804,
    "entropy": 0.9503406435251236,
    "total_loss": -317.6863484144211
  },
  {
    "episode": 192,
    "avg_reward_per_step": 26.95871836964331,
    "episode_length": 728,
    "policy_loss": -456.5648727416992,
    "value_loss": 0.5218870788812637,
    "entropy": 0.9315135627985001,
    "total_loss": -456.41559108793734
  },
  {
    "episode": 193,
    "avg_reward_per_step": -0.8084397636249365,
    "episode_length": 3000,
    "policy_loss": 12.651526689529419,
    "value_loss": 0.791144534945488,
    "entropy": 0.9077998697757721,
    "total_loss": 13.079551276564597
  },
  {
    "episode": 194,
    "avg_reward_per_step": 7.716583594347865,
    "episode_length": 2292,
    "policy_loss": -130.97945404052734,
    "value_loss": 0.5054594427347183,
    "entropy": 1.0159166753292084,
    "total_loss": -130.88036126792431
  },
  {
    "episode": 195,
    "avg_reward_per_step": 23.62433999825621,
    "episode_length": 822,
    "policy_loss": -401.3350372314453,
    "value_loss": 0.5187517404556274,
    "entropy": 1.0234944820404053,
    "total_loss": -401.22568328380584
  },
  {
    "episode": 196,
    "avg_reward_per_step": 19.780271926168783,
    "episode_length": 984,
    "policy_loss": -336.4398880004883,
    "value_loss": 0.5157048553228378,
    "entropy": 0.9639248698949814,
    "total_loss": -336.30975309312345
  },
  {
    "episode": 197,
    "avg_reward_per_step": 21.262165326765476,
    "episode_length": 909,
    "policy_loss": -359.30760955810547,
    "value_loss": 0.5167946368455887,
    "entropy": 0.9784587919712067,
    "total_loss": -359.1821984380484
  },
  {
    "episode": 198,
    "avg_reward_per_step": 12.465473433991578,
    "episode_length": 1476,
    "policy_loss": -212.89051055908203,
    "value_loss": 0.5091942250728607,
    "entropy": 0.9977881461381912,
    "total_loss": -212.78043159246445
  },
  {
    "episode": 199,
    "avg_reward_per_step": 42.58426089757104,
    "episode_length": 461,
    "policy_loss": -718.1925964355469,
    "value_loss": 0.5353931933641434,
    "entropy": 0.9666179716587067,
    "total_loss": -718.0438504308462
  },
  {
    "episode": 200,
    "avg_reward_per_step": 71.12801376406928,
    "episode_length": 280,
    "policy_loss": -1205.8796081542969,
    "value_loss": 0.5631493628025055,
    "entropy": 0.9442624747753143,
    "total_loss": -1205.6941637814045
  },
  {
    "episode": 201,
    "avg_reward_per_step": 53.186720557020195,
    "episode_length": 373,
    "policy_loss": -896.6032562255859,
    "value_loss": 0.5455745756626129,
    "entropy": 0.957697406411171,
    "total_loss": -896.4407606124878
  },
  {
    "episode": 202,
    "avg_reward_per_step": 97.42896697686578,
    "episode_length": 206,
    "policy_loss": -1647.3539428710938,
    "value_loss": 0.5916591882705688,
    "entropy": 0.9356541484594345,
    "total_loss": -1647.136545342207
  },
  {
    "episode": 203,
    "avg_reward_per_step": 38.858084655383884,
    "episode_length": 507,
    "policy_loss": -653.8309020996094,
    "value_loss": 0.532202884554863,
    "entropy": 0.9468696266412735,
    "total_loss": -653.677447065711
  },
  {
    "episode": 204,
    "avg_reward_per_step": 61.62230017830904,
    "episode_length": 322,
    "policy_loss": -1053.9008178710938,
    "value_loss": 0.5533480942249298,
    "entropy": 0.9711707234382629,
    "total_loss": -1053.7359380662442
  },
  {
    "episode": 205,
    "avg_reward_per_step": 73.73202291130876,
    "episode_length": 271,
    "policy_loss": -1248.0310668945312,
    "value_loss": 0.5657968521118164,
    "entropy": 0.9760978668928146,
    "total_loss": -1247.8557091891767
  },
  {
    "episode": 206,
    "avg_reward_per_step": 34.76215117019771,
    "episode_length": 563,
    "policy_loss": -585.9847869873047,
    "value_loss": 0.5283149629831314,
    "entropy": 0.9807736575603485,
    "total_loss": -585.8487814873457
  },
  {
    "episode": 207,
    "avg_reward_per_step": 68.36173652260828,
    "episode_length": 292,
    "policy_loss": -1157.1746215820312,
    "value_loss": 0.560485914349556,
    "entropy": 0.9584969282150269,
    "total_loss": -1156.9975344389677
  },
  {
    "episode": 208,
    "avg_reward_per_step": 50.66366658759578,
    "episode_length": 390,
    "policy_loss": -858.2080230712891,
    "value_loss": 0.5427343994379044,
    "entropy": 1.0509657263755798,
    "total_loss": -858.0856749624014
  },
  {
    "episode": 209,
    "avg_reward_per_step": 51.80824227744133,
    "episode_length": 381,
    "policy_loss": -880.3789215087891,
    "value_loss": 0.5437242984771729,
    "entropy": 0.9819872230291367,
    "total_loss": -880.2279920995236
  },
  {
    "episode": 210,
    "avg_reward_per_step": 48.87923377344647,
    "episode_length": 406,
    "policy_loss": -827.0054168701172,
    "value_loss": 0.5416242927312851,
    "entropy": 0.950712040066719,
    "total_loss": -826.8440773934126
  },
  {
    "episode": 211,
    "avg_reward_per_step": 36.70614197617106,
    "episode_length": 532,
    "policy_loss": -625.1567535400391,
    "value_loss": 0.5299722701311111,
    "entropy": 1.0163144171237946,
    "total_loss": -625.0333070367575
  },
  {
    "episode": 212,
    "avg_reward_per_step": 36.57167765520904,
    "episode_length": 535,
    "policy_loss": -623.8242950439453,
    "value_loss": 0.5300416648387909,
    "entropy": 1.0711267590522766,
    "total_loss": -623.7227040827274
  },
  {
    "episode": 213,
    "avg_reward_per_step": 49.60554182056259,
    "episode_length": 400,
    "policy_loss": -838.8522491455078,
    "value_loss": 0.5421544313430786,
    "entropy": 0.9711963534355164,
    "total_loss": -838.6985732555389
  },
  {
    "episode": 214,
    "avg_reward_per_step": 12.151651679781752,
    "episode_length": 1536,
    "policy_loss": -205.83683395385742,
    "value_loss": 0.5090667754411697,
    "entropy": 0.9363274723291397,
    "total_loss": -205.70229816734792
  },
  {
    "episode": 215,
    "avg_reward_per_step": 92.34701568087596,
    "episode_length": 217,
    "policy_loss": -1572.9541931152344,
    "value_loss": 0.5859959423542023,
    "entropy": 0.9678185284137726,
    "total_loss": -1572.7553245842457
  },
  {
    "episode": 216,
    "avg_reward_per_step": 32.64691026542118,
    "episode_length": 602,
    "policy_loss": -547.9984130859375,
    "value_loss": 0.5266485959291458,
    "entropy": 0.9676032066345215,
    "total_loss": -547.8588057726622
  },
  {
    "episode": 217,
    "avg_reward_per_step": 62.59848835138754,
    "episode_length": 319,
    "policy_loss": -1064.7543640136719,
    "value_loss": 0.5550627261400223,
    "entropy": 0.9252251237630844,
    "total_loss": -1064.5693913370371
  },
  {
    "episode": 218,
    "avg_reward_per_step": 15.920993047797996,
    "episode_length": 1203,
    "policy_loss": -273.079833984375,
    "value_loss": 0.5123187303543091,
    "entropy": 0.9258445352315903,
    "total_loss": -272.9378530681133
  },
  {
    "episode": 219,
    "avg_reward_per_step": -0.8300602067283284,
    "episode_length": 3000,
    "policy_loss": 13.159499645233154,
    "value_loss": 0.6630702465772629,
    "entropy": 0.9149541258811951,
    "total_loss": 13.45658824145794
  },
  {
    "episode": 220,
    "avg_reward_per_step": 9.865823619509204,
    "episode_length": 1880,
    "policy_loss": -165.93528747558594,
    "value_loss": 0.5073545426130295,
    "entropy": 0.9688374102115631,
    "total_loss": -165.81546789705754
  },
  {
    "episode": 221,
    "avg_reward_per_step": 7.34673522069767,
    "episode_length": 2471,
    "policy_loss": -124.81415939331055,
    "value_loss": 0.5053457766771317,
    "entropy": 0.9348787218332291,
    "total_loss": -124.68276510536671
  },
  {
    "episode": 222,
    "avg_reward_per_step": -0.8616078028029166,
    "episode_length": 3000,
    "policy_loss": 13.437073230743408,
    "value_loss": 0.6409808993339539,
    "entropy": 0.9465555399656296,
    "total_loss": 13.699431914091111
  },
  {
    "episode": 223,
    "avg_reward_per_step": 35.01134312932279,
    "episode_length": 567,
    "policy_loss": -596.3523254394531,
    "value_loss": 0.529168426990509,
    "entropy": 0.938737541437149,
    "total_loss": -596.1986520290375
  },
  {
    "episode": 224,
    "avg_reward_per_step": 10.521275147852712,
    "episode_length": 1793,
    "policy_loss": -177.31439971923828,
    "value_loss": 0.5079657435417175,
    "entropy": 0.8708274662494659,
    "total_loss": -177.15476496219634
  },
  {
    "episode": 225,
    "avg_reward_per_step": 15.830016149109506,
    "episode_length": 1219,
    "policy_loss": -267.2964172363281,
    "value_loss": 0.5124017745256424,
    "entropy": 0.873833954334259,
    "total_loss": -267.13354904353616
  },
  {
    "episode": 226,
    "avg_reward_per_step": -0.7548930514030544,
    "episode_length": 3000,
    "policy_loss": 11.509851217269897,
    "value_loss": 0.753153994679451,
    "entropy": 0.8364466279745102,
    "total_loss": 11.928426560759544
  },
  {
    "episode": 227,
    "avg_reward_per_step": 20.444040446309096,
    "episode_length": 954,
    "policy_loss": -346.30323791503906,
    "value_loss": 0.5163432955741882,
    "entropy": 0.8813570737838745,
    "total_loss": -346.1394374489784
  },
  {
    "episode": 228,
    "avg_reward_per_step": 13.960869954200222,
    "episode_length": 1376,
    "policy_loss": -236.09717559814453,
    "value_loss": 0.5108553618192673,
    "entropy": 0.9179578423500061,
    "total_loss": -235.95350337326528
  },
  {
    "episode": 229,
    "avg_reward_per_step": 8.715949414851925,
    "episode_length": 2103,
    "policy_loss": -149.694091796875,
    "value_loss": 0.506418451666832,
    "entropy": 0.9429252296686172,
    "total_loss": -149.5648434370756
  },
  {
    "episode": 230,
    "avg_reward_per_step": 11.562518938620334,
    "episode_length": 1639,
    "policy_loss": -195.45362854003906,
    "value_loss": 0.5088012665510178,
    "entropy": 0.8880707323551178,
    "total_loss": -195.3000555664301
  },
  {
    "episode": 231,
    "avg_reward_per_step": 11.350170863537949,
    "episode_length": 1680,
    "policy_loss": -193.15285110473633,
    "value_loss": 0.5087373703718185,
    "entropy": 0.8651235848665237,
    "total_loss": -192.9901631683111
  },
  {
    "episode": 232,
    "avg_reward_per_step": 6.109944447834253,
    "episode_length": 2959,
    "policy_loss": -104.35122680664062,
    "value_loss": 0.5044136494398117,
    "entropy": 0.8996576368808746,
    "total_loss": -104.20667621195317
  },
  {
    "episode": 233,
    "avg_reward_per_step": 7.043322058910662,
    "episode_length": 2586,
    "policy_loss": -119.67806625366211,
    "value_loss": 0.5051616579294205,
    "entropy": 0.9462977796792984,
    "total_loss": -119.55142370760441
  },
  {
    "episode": 234,
    "avg_reward_per_step": -0.8980456986147664,
    "episode_length": 3000,
    "policy_loss": 13.819003343582153,
    "value_loss": 0.6915717273950577,
    "entropy": 0.9492020010948181,
    "total_loss": 14.130894270539283
  },
  {
    "episode": 235,
    "avg_reward_per_step": 11.403330061446145,
    "episode_length": 1645,
    "policy_loss": -194.23223876953125,
    "value_loss": 0.5086174756288528,
    "entropy": 0.9811610132455826,
    "total_loss": -194.11608569920062
  },
  {
    "episode": 236,
    "avg_reward_per_step": -0.7660632747256225,
    "episode_length": 3000,
    "policy_loss": 11.514736652374268,
    "value_loss": 0.6923054307699203,
    "entropy": 0.9468085169792175,
    "total_loss": 11.8283186763525
  },
  {
    "episode": 237,
    "avg_reward_per_step": -0.8033470502129959,
    "episode_length": 3000,
    "policy_loss": 12.169203519821167,
    "value_loss": 0.6716193854808807,
    "entropy": 0.9323514699935913,
    "total_loss": 12.46788231730461
  },
  {
    "episode": 238,
    "avg_reward_per_step": 18.630866284218882,
    "episode_length": 1035,
    "policy_loss": -316.100830078125,
    "value_loss": 0.5146846175193787,
    "entropy": 1.0079918503761292,
    "total_loss": -315.9893422007561
  },
  {
    "episode": 239,
    "avg_reward_per_step": 30.25109545838825,
    "episode_length": 652,
    "policy_loss": -513.5860595703125,
    "value_loss": 0.5248758792877197,
    "entropy": 0.987005352973938,
    "total_loss": -513.4559858322143
  },
  {
    "episode": 240,
    "avg_reward_per_step": 20.180728261261173,
    "episode_length": 963,
    "policy_loss": -340.9612274169922,
    "value_loss": 0.5159943848848343,
    "entropy": 0.9291753619909286,
    "total_loss": -340.81690317690374
  },
  {
    "episode": 241,
    "avg_reward_per_step": 25.103575028970468,
    "episode_length": 778,
    "policy_loss": -426.0396957397461,
    "value_loss": 0.5201914608478546,
    "entropy": 0.9402490258216858,
    "total_loss": -425.8956038892269
  },
  {
    "episode": 242,
    "avg_reward_per_step": 15.431408735957646,
    "episode_length": 1242,
    "policy_loss": -262.1605758666992,
    "value_loss": 0.5119725912809372,
    "entropy": 0.9258930087089539,
    "total_loss": -262.0189604789019
  },
  {
    "episode": 243,
    "avg_reward_per_step": 24.14958456871694,
    "episode_length": 805,
    "policy_loss": -412.31848907470703,
    "value_loss": 0.5192564278841019,
    "entropy": 0.9813904017210007,
    "total_loss": -412.19178880751133
  },
  {
    "episode": 244,
    "avg_reward_per_step": 13.856520243338755,
    "episode_length": 1363,
    "policy_loss": -237.71484756469727,
    "value_loss": 0.5105901956558228,
    "entropy": 0.9396082162857056,
    "total_loss": -237.58010065555573
  },
  {
    "episode": 245,
    "avg_reward_per_step": 57.83264288620544,
    "episode_length": 343,
    "policy_loss": -978.2469940185547,
    "value_loss": 0.5501141846179962,
    "entropy": 1.0331049263477325,
    "total_loss": -978.1101218044757
  },
  {
    "episode": 246,
    "avg_reward_per_step": 16.206076664210595,
    "episode_length": 1179,
    "policy_loss": -272.21057891845703,
    "value_loss": 0.5125100463628769,
    "entropy": 1.0002317279577255,
    "total_loss": -272.09816156327724
  },
  {
    "episode": 247,
    "avg_reward_per_step": 14.626457196380564,
    "episode_length": 1307,
    "policy_loss": -247.91935348510742,
    "value_loss": 0.5112943202257156,
    "entropy": 0.9662150889635086,
    "total_loss": -247.7945452004671
  },
  {
    "episode": 248,
    "avg_reward_per_step": 42.82321148081819,
    "episode_length": 462,
    "policy_loss": -731.2421417236328,
    "value_loss": 0.5359316319227219,
    "entropy": 0.9928054511547089,
    "total_loss": -731.103332272172
  },
  {
    "episode": 249,
    "avg_reward_per_step": 20.76822005396905,
    "episode_length": 929,
    "policy_loss": -353.158203125,
    "value_loss": 0.5164541006088257,
    "entropy": 1.0103561878204346,
    "total_loss": -353.04589149951937
  },
  {
    "episode": 250,
    "avg_reward_per_step": 86.04250808737693,
    "episode_length": 233,
    "policy_loss": -1449.8625183105469,
    "value_loss": 0.5788462311029434,
    "entropy": 1.0287094712257385,
    "total_loss": -1449.6951558679343
  },
  {
    "episode": 251,
    "avg_reward_per_step": 19.706904675951186,
    "episode_length": 984,
    "policy_loss": -333.10655975341797,
    "value_loss": 0.5155627280473709,
    "entropy": 0.9283892661333084,
    "total_loss": -332.9623527318239
  },
  {
    "episode": 252,
    "avg_reward_per_step": 128.18984692441418,
    "episode_length": 157,
    "policy_loss": -2190.5609130859375,
    "value_loss": 0.6286410838365555,
    "entropy": 1.0057722926139832,
    "total_loss": -2190.3345809191464
  },
  {
    "episode": 253,
    "avg_reward_per_step": 17.80918599029442,
    "episode_length": 1082,
    "policy_loss": -303.4194030761719,
    "value_loss": 0.5139258652925491,
    "entropy": 0.9615853577852249,
    "total_loss": -303.29011135399344
  },
  {
    "episode": 254,
    "avg_reward_per_step": 15.101802632895321,
    "episode_length": 1269,
    "policy_loss": -254.51659774780273,
    "value_loss": 0.5117413848638535,
    "entropy": 0.911933109164238,
    "total_loss": -254.36962960660458
  },
  {
    "episode": 255,
    "avg_reward_per_step": 10.101111670157206,
    "episode_length": 1837,
    "policy_loss": -173.54652404785156,
    "value_loss": 0.507529616355896,
    "entropy": 0.9792763441801071,
    "total_loss": -173.43070496916772
  },
  {
    "episode": 256,
    "avg_reward_per_step": 38.25235347860707,
    "episode_length": 514,
    "policy_loss": -648.3318481445312,
    "value_loss": 0.5316498279571533,
    "entropy": 0.9968443959951401,
    "total_loss": -648.1989360749722
  },
  {
    "episode": 257,
    "avg_reward_per_step": 26.147029862177128,
    "episode_length": 746,
    "policy_loss": -442.1986541748047,
    "value_loss": 0.5210338681936264,
    "entropy": 0.9878712743520737,
    "total_loss": -442.07276881635187
  },
  {
    "episode": 258,
    "avg_reward_per_step": 14.876459497986072,
    "episode_length": 1290,
    "policy_loss": -252.6281967163086,
    "value_loss": 0.5115787237882614,
    "entropy": 0.9229010045528412,
    "total_loss": -252.48577839434148
  },
  {
    "episode": 259,
    "avg_reward_per_step": 20.776415469141963,
    "episode_length": 938,
    "policy_loss": -353.5110092163086,
    "value_loss": 0.5164509862661362,
    "entropy": 0.9403901249170303,
    "total_loss": -353.3707142800093
  },
  {
    "episode": 260,
    "avg_reward_per_step": 43.01069707761188,
    "episode_length": 461,
    "policy_loss": -725.8459167480469,
    "value_loss": 0.5361710339784622,
    "entropy": 0.9331604540348053,
    "total_loss": -725.6830098956823
  },
  {
    "episode": 261,
    "avg_reward_per_step": 25.203042991724047,
    "episode_length": 771,
    "policy_loss": -426.1665344238281,
    "value_loss": 0.5201379209756851,
    "entropy": 0.9252327978610992,
    "total_loss": -426.01648962199687
  },
  {
    "episode": 262,
    "avg_reward_per_step": 61.29187436781415,
    "episode_length": 325,
    "policy_loss": -1035.8272705078125,
    "value_loss": 0.5533602088689804,
    "entropy": 0.9571187049150467,
    "total_loss": -1035.6567577809096
  },
  {
    "episode": 263,
    "avg_reward_per_step": 24.240639377366964,
    "episode_length": 802,
    "policy_loss": -410.50291442871094,
    "value_loss": 0.5193805992603302,
    "entropy": 0.9610953778028488,
    "total_loss": -410.3679719805717
  },
  {
    "episode": 264,
    "avg_reward_per_step": 60.84386313771731,
    "episode_length": 328,
    "policy_loss": -1032.3349304199219,
    "value_loss": 0.553201362490654,
    "entropy": 0.8827835321426392,
    "total_loss": -1032.1348424702883
  },
  {
    "episode": 265,
    "avg_reward_per_step": 9.008592559376392,
    "episode_length": 2038,
    "policy_loss": -154.00852584838867,
    "value_loss": 0.5066593438386917,
    "entropy": 0.8981834053993225,
    "total_loss": -153.86113986670972
  },
  {
    "episode": 266,
    "avg_reward_per_step": 28.488373100224287,
    "episode_length": 692,
    "policy_loss": -481.6216049194336,
    "value_loss": 0.523245319724083,
    "entropy": 0.9134320020675659,
    "total_loss": -481.4637324005365
  },
  {
    "episode": 267,
    "avg_reward_per_step": 25.685939931040018,
    "episode_length": 764,
    "policy_loss": -433.6400375366211,
    "value_loss": 0.5207468867301941,
    "entropy": 0.8721091747283936,
    "total_loss": -433.4681343197823
  },
  {
    "episode": 268,
    "avg_reward_per_step": 342.40684231010084,
    "episode_length": 59,
    "policy_loss": -5699.7757568359375,
    "value_loss": 1.0456808507442474,
    "entropy": 0.8770111501216888,
    "total_loss": -5699.080880445242
  },
  {
    "episode": 269,
    "avg_reward_per_step": 33.08411605901551,
    "episode_length": 595,
    "policy_loss": -554.2968902587891,
    "value_loss": 0.5272355377674103,
    "entropy": 0.8490189760923386,
    "total_loss": -554.1092623114586
  },
  {
    "episode": 270,
    "avg_reward_per_step": 10.562463213181287,
    "episode_length": 1748,
    "policy_loss": -179.58766555786133,
    "value_loss": 0.5077938288450241,
    "entropy": 0.7959473431110382,
    "total_loss": -179.3982506662607
  },
  {
    "episode": 271,
    "avg_reward_per_step": 48.17193029793422,
    "episode_length": 412,
    "policy_loss": -811.9948120117188,
    "value_loss": 0.5408083498477936,
    "entropy": 0.8153724074363708,
    "total_loss": -811.7801526248455
  },
  {
    "episode": 272,
    "avg_reward_per_step": 34.55791699293097,
    "episode_length": 570,
    "policy_loss": -585.4163055419922,
    "value_loss": 0.5283924490213394,
    "entropy": 0.8006947785615921,
    "total_loss": -585.2081910043955
  },
  {
    "episode": 273,
    "avg_reward_per_step": 22.32260514155527,
    "episode_length": 871,
    "policy_loss": -377.17881774902344,
    "value_loss": 0.5176831781864166,
    "entropy": 0.8052421659231186,
    "total_loss": -376.98323143720626
  },
  {
    "episode": 274,
    "avg_reward_per_step": 11.844244743889663,
    "episode_length": 1583,
    "policy_loss": -200.24322509765625,
    "value_loss": 0.5089237242937088,
    "entropy": 0.7976861894130707,
    "total_loss": -200.05337584912778
  },
  {
    "episode": 275,
    "avg_reward_per_step": 35.38099241046074,
    "episode_length": 557,
    "policy_loss": -597.7308502197266,
    "value_loss": 0.5291876196861267,
    "entropy": 0.7731365263462067,
    "total_loss": -597.5109172105789
  },
  {
    "episode": 276,
    "avg_reward_per_step": 19.94935796069418,
    "episode_length": 969,
    "policy_loss": -339.46095275878906,
    "value_loss": 0.5157554000616074,
    "entropy": 0.7915753275156021,
    "total_loss": -339.2618274897337
  },
  {
    "episode": 277,
    "avg_reward_per_step": 118.92238408670336,
    "episode_length": 169,
    "policy_loss": -2028.6875610351562,
    "value_loss": 0.6172697395086288,
    "entropy": 0.7707592695951462,
    "total_loss": -2028.3785950034858
  },
  {
    "episode": 278,
    "avg_reward_per_step": 44.26077044563439,
    "episode_length": 446,
    "policy_loss": -746.4969635009766,
    "value_loss": 0.5370064079761505,
    "entropy": 0.7903574705123901,
    "total_loss": -746.2761000812054
  },
  {
    "episode": 279,
    "avg_reward_per_step": 396.0928005112308,
    "episode_length": 51,
    "policy_loss": -6469.015869140625,
    "value_loss": 1.2019051611423492,
    "entropy": 0.879439115524292,
    "total_loss": -6468.165739625692
  },
  {
    "episode": 280,
    "avg_reward_per_step": 112.35111978900352,
    "episode_length": 179,
    "policy_loss": -1895.4526672363281,
    "value_loss": 0.609009861946106,
    "entropy": 0.7847555130720139,
    "total_loss": -1895.1575595796107
  },
  {
    "episode": 281,
    "avg_reward_per_step": 354.171675308002,
    "episode_length": 57,
    "policy_loss": -5865.5950927734375,
    "value_loss": 1.0776619911193848,
    "entropy": 0.8022193163633347,
    "total_loss": -5864.838318508863
  },
  {
    "episode": 282,
    "avg_reward_per_step": 156.43123940260358,
    "episode_length": 129,
    "policy_loss": -2657.8447265625,
    "value_loss": 0.6663396060466766,
    "entropy": 0.720301941037178,
    "total_loss": -2657.466507732868
  },
  {
    "episode": 283,
    "avg_reward_per_step": 99.95052826643698,
    "episode_length": 200,
    "policy_loss": -1702.5194091796875,
    "value_loss": 0.5944717824459076,
    "entropy": 0.783624067902565,
    "total_loss": -1702.2383870244025
  },
  {
    "episode": 284,
    "avg_reward_per_step": 404.0848946998338,
    "episode_length": 50,
    "policy_loss": -6541.6846923828125,
    "value_loss": 1.2256281971931458,
    "entropy": 0.6230474710464478,
    "total_loss": -6540.708283174038
  },
  {
    "episode": 285,
    "avg_reward_per_step": 78.99584582426507,
    "episode_length": 253,
    "policy_loss": -1338.4735107421875,
    "value_loss": 0.571106806397438,
    "entropy": 0.6827873587608337,
    "total_loss": -1338.1755188792945
  },
  {
    "episode": 286,
    "avg_reward_per_step": 419.6787680353577,
    "episode_length": 48,
    "policy_loss": -6835.8890380859375,
    "value_loss": 1.2750959396362305,
    "entropy": 0.7332112640142441,
    "total_loss": -6834.907226651907
  },
  {
    "episode": 287,
    "avg_reward_per_step": 30.064239711396755,
    "episode_length": 652,
    "policy_loss": -501.59178924560547,
    "value_loss": 0.524243637919426,
    "entropy": 0.644806906580925,
    "total_loss": -501.3254683703184
  },
  {
    "episode": 288,
    "avg_reward_per_step": 195.9073482154305,
    "episode_length": 103,
    "policy_loss": -3316.4509887695312,
    "value_loss": 0.7281806319952011,
    "entropy": 0.6275364011526108,
    "total_loss": -3315.973822697997
  },
  {
    "episode": 289,
    "avg_reward_per_step": 16.555724742459944,
    "episode_length": 1153,
    "policy_loss": -280.8283233642578,
    "value_loss": 0.5128564387559891,
    "entropy": 0.5661613345146179,
    "total_loss": -280.54193145930765
  },
  {
    "episode": 290,
    "avg_reward_per_step": 37.992821217530725,
    "episode_length": 518,
    "policy_loss": -641.4389343261719,
    "value_loss": 0.5313678979873657,
    "entropy": 0.5784848630428314,
    "total_loss": -641.1389603734017
  },
  {
    "episode": 291,
    "avg_reward_per_step": 70.34590108409752,
    "episode_length": 283,
    "policy_loss": -1190.4147033691406,
    "value_loss": 0.5620408058166504,
    "entropy": 0.5745851993560791,
    "total_loss": -1190.0824966430664
  },
  {
    "episode": 292,
    "avg_reward_per_step": 175.29738054422674,
    "episode_length": 115,
    "policy_loss": -2959.7399291992188,
    "value_loss": 0.6929339319467545,
    "entropy": 0.5303110033273697,
    "total_loss": -2959.259119668603
  },
  {
    "episode": 293,
    "avg_reward_per_step": 43.297847456973734,
    "episode_length": 455,
    "policy_loss": -732.4515686035156,
    "value_loss": 0.5359441488981247,
    "entropy": 0.5185115933418274,
    "total_loss": -732.1230290919542
  },
  {
    "episode": 294,
    "avg_reward_per_step": 163.72050611570353,
    "episode_length": 123,
    "policy_loss": -2759.3944091796875,
    "value_loss": 0.6749374866485596,
    "entropy": 0.5003113448619843,
    "total_loss": -2758.9195962309836
  },
  {
    "episode": 295,
    "avg_reward_per_step": 118.2944718826477,
    "episode_length": 170,
    "policy_loss": -2014.8392944335938,
    "value_loss": 0.6158381253480911,
    "entropy": 0.5389068573713303,
    "total_loss": -2014.4390190511942
  },
  {
    "episode": 296,
    "avg_reward_per_step": 104.92485531679078,
    "episode_length": 191,
    "policy_loss": -1770.3580932617188,
    "value_loss": 0.5999303013086319,
    "entropy": 0.5178659111261368,
    "total_loss": -1769.9653093248605
  },
  {
    "episode": 297,
    "avg_reward_per_step": 16.607428364178528,
    "episode_length": 1147,
    "policy_loss": -281.521240234375,
    "value_loss": 0.5128098130226135,
    "entropy": 0.45027004927396774,
    "total_loss": -281.18853844106195
  },
  {
    "episode": 298,
    "avg_reward_per_step": 81.77313557465624,
    "episode_length": 244,
    "policy_loss": -1380.4665832519531,
    "value_loss": 0.5742028504610062,
    "entropy": 0.46695996820926666,
    "total_loss": -1380.0791643887758
  },
  {
    "episode": 299,
    "avg_reward_per_step": 23.480869628239482,
    "episode_length": 823,
    "policy_loss": -398.48535919189453,
    "value_loss": 0.5186053663492203,
    "entropy": 0.42652713507413864,
    "total_loss": -398.13736467957494
  },
  {
    "episode": 300,
    "avg_reward_per_step": 62.77481228949586,
    "episode_length": 317,
    "policy_loss": -1059.4535827636719,
    "value_loss": 0.5542698502540588,
    "entropy": 0.4566008523106575,
    "total_loss": -1059.0819532543421
  }
]