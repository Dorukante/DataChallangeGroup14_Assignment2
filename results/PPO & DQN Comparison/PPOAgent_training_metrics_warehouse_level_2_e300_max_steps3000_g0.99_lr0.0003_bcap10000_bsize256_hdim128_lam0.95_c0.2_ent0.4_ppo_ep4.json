[
  {
    "episode": 1,
    "avg_reward_per_step": 8.958005310212803,
    "episode_length": 1939,
    "policy_loss": -156.60294723510742,
    "value_loss": 0.5061419606208801,
    "entropy": 1.3645961582660675,
    "total_loss": -156.64264373779298
  },
  {
    "episode": 2,
    "avg_reward_per_step": 17.53368700985889,
    "episode_length": 1063,
    "policy_loss": -301.3393020629883,
    "value_loss": 0.5132250487804413,
    "entropy": 1.3293780088424683,
    "total_loss": -301.35782821774484
  },
  {
    "episode": 3,
    "avg_reward_per_step": 32.043490589609824,
    "episode_length": 602,
    "policy_loss": -548.3095397949219,
    "value_loss": 0.5256016552448273,
    "entropy": 1.265553057193756,
    "total_loss": -548.2901593625545
  },
  {
    "episode": 4,
    "avg_reward_per_step": -1.4070554893422105,
    "episode_length": 3000,
    "policy_loss": 23.69850444793701,
    "value_loss": 0.7416520118713379,
    "entropy": 1.2070501744747162,
    "total_loss": 23.95733639001846
  },
  {
    "episode": 5,
    "avg_reward_per_step": -1.4605681885578992,
    "episode_length": 3000,
    "policy_loss": 24.462687015533447,
    "value_loss": 0.7817970812320709,
    "entropy": 1.1803903579711914,
    "total_loss": 24.77232795357704
  },
  {
    "episode": 6,
    "avg_reward_per_step": 8.699157638261887,
    "episode_length": 1977,
    "policy_loss": -147.18845748901367,
    "value_loss": 0.5058836042881012,
    "entropy": 1.13515704870224,
    "total_loss": -147.13663670420647
  },
  {
    "episode": 7,
    "avg_reward_per_step": -1.4054571921351304,
    "episode_length": 3000,
    "policy_loss": 23.65051031112671,
    "value_loss": 0.7436961084604263,
    "entropy": 1.104817658662796,
    "total_loss": 23.952279356122016
  },
  {
    "episode": 8,
    "avg_reward_per_step": 9.111810202167312,
    "episode_length": 1911,
    "policy_loss": -154.24847030639648,
    "value_loss": 0.5062457323074341,
    "entropy": 1.0934127569198608,
    "total_loss": -154.179589676857
  },
  {
    "episode": 9,
    "avg_reward_per_step": 19.065984086539267,
    "episode_length": 986,
    "policy_loss": -325.4918518066406,
    "value_loss": 0.514445498585701,
    "entropy": 1.071498543024063,
    "total_loss": -325.40600572526455
  },
  {
    "episode": 10,
    "avg_reward_per_step": -1.5121134273216155,
    "episode_length": 3000,
    "policy_loss": 25.367299556732178,
    "value_loss": 0.6991112381219864,
    "entropy": 1.0325149893760681,
    "total_loss": 25.653404799103736
  },
  {
    "episode": 11,
    "avg_reward_per_step": 6.810594546514525,
    "episode_length": 2425,
    "policy_loss": -114.96917152404785,
    "value_loss": 0.5043843984603882,
    "entropy": 0.9832990914583206,
    "total_loss": -114.85810676217079
  },
  {
    "episode": 12,
    "avg_reward_per_step": -1.6565693276132691,
    "episode_length": 3000,
    "policy_loss": 27.83386754989624,
    "value_loss": 0.6616859585046768,
    "entropy": 0.9647660106420517,
    "total_loss": 28.109647104144095
  },
  {
    "episode": 13,
    "avg_reward_per_step": 8.710595303948981,
    "episode_length": 2027,
    "policy_loss": -148.26744842529297,
    "value_loss": 0.5060331672430038,
    "entropy": 0.9490330666303635,
    "total_loss": -148.1410284847021
  },
  {
    "episode": 14,
    "avg_reward_per_step": 14.31075094011319,
    "episode_length": 1285,
    "policy_loss": -242.94659805297852,
    "value_loss": 0.5104712396860123,
    "entropy": 0.8921846300363541,
    "total_loss": -242.79300066530703
  },
  {
    "episode": 15,
    "avg_reward_per_step": 19.010675311748447,
    "episode_length": 993,
    "policy_loss": -319.1553649902344,
    "value_loss": 0.5143639594316483,
    "entropy": 0.854614719748497,
    "total_loss": -318.98284691870214
  },
  {
    "episode": 16,
    "avg_reward_per_step": -1.5771093512889531,
    "episode_length": 3000,
    "policy_loss": 26.329355239868164,
    "value_loss": 0.6384055614471436,
    "entropy": 0.8747693002223969,
    "total_loss": 26.61785308122635
  },
  {
    "episode": 17,
    "avg_reward_per_step": 79.46246295303786,
    "episode_length": 250,
    "policy_loss": -1345.6382751464844,
    "value_loss": 0.5708905905485153,
    "entropy": 0.8690706640481949,
    "total_loss": -1345.4150128215551
  },
  {
    "episode": 18,
    "avg_reward_per_step": 9.295291505115816,
    "episode_length": 1915,
    "policy_loss": -156.57000732421875,
    "value_loss": 0.5065046548843384,
    "entropy": 0.9222138077020645,
    "total_loss": -156.43238819241523
  },
  {
    "episode": 19,
    "avg_reward_per_step": 68.44672683580083,
    "episode_length": 291,
    "policy_loss": -1155.8187255859375,
    "value_loss": 0.5604523420333862,
    "entropy": 0.9363528788089752,
    "total_loss": -1155.6328143954277
  },
  {
    "episode": 20,
    "avg_reward_per_step": 57.90345297668262,
    "episode_length": 342,
    "policy_loss": -987.7536315917969,
    "value_loss": 0.5494324713945389,
    "entropy": 0.9748490899801254,
    "total_loss": -987.5941387563944
  },
  {
    "episode": 21,
    "avg_reward_per_step": -1.9128144854845113,
    "episode_length": 3000,
    "policy_loss": 31.93526840209961,
    "value_loss": 0.8889456242322922,
    "entropy": 0.9544242024421692,
    "total_loss": 32.442444345355035
  },
  {
    "episode": 22,
    "avg_reward_per_step": -1.7524430822149812,
    "episode_length": 3000,
    "policy_loss": 28.78959369659424,
    "value_loss": 0.7562368214130402,
    "entropy": 0.9474200010299683,
    "total_loss": 29.16686251759529
  },
  {
    "episode": 23,
    "avg_reward_per_step": 41.16940063156172,
    "episode_length": 472,
    "policy_loss": -697.1778869628906,
    "value_loss": 0.5337433069944382,
    "entropy": 0.9798303991556168,
    "total_loss": -697.0360758155584
  },
  {
    "episode": 24,
    "avg_reward_per_step": 11.965673826522346,
    "episode_length": 1455,
    "policy_loss": -209.29879760742188,
    "value_loss": 0.5083156228065491,
    "entropy": 1.0134978741407394,
    "total_loss": -209.19588113427162
  },
  {
    "episode": 25,
    "avg_reward_per_step": 51.033455038065,
    "episode_length": 382,
    "policy_loss": -861.7481842041016,
    "value_loss": 0.5424987971782684,
    "entropy": 1.076739490032196,
    "total_loss": -861.6363812029361
  },
  {
    "episode": 26,
    "avg_reward_per_step": -2.114131184252275,
    "episode_length": 3000,
    "policy_loss": 35.01943778991699,
    "value_loss": 0.8961309790611267,
    "entropy": 1.1050801575183868,
    "total_loss": 35.473536705970766
  },
  {
    "episode": 27,
    "avg_reward_per_step": -2.0440784593477934,
    "episode_length": 3000,
    "policy_loss": 33.89944648742676,
    "value_loss": 0.8901729732751846,
    "entropy": 1.1438143253326416,
    "total_loss": 34.332093730568886
  },
  {
    "episode": 28,
    "avg_reward_per_step": 100.48077278176922,
    "episode_length": 198,
    "policy_loss": -1709.4968566894531,
    "value_loss": 0.5947946161031723,
    "entropy": 1.1957401633262634,
    "total_loss": -1709.3803581386805
  },
  {
    "episode": 29,
    "avg_reward_per_step": 164.8468042398732,
    "episode_length": 122,
    "policy_loss": -2802.2120361328125,
    "value_loss": 0.6794559955596924,
    "entropy": 1.1455521285533905,
    "total_loss": -2801.990800988674
  },
  {
    "episode": 30,
    "avg_reward_per_step": 73.23557088731438,
    "episode_length": 270,
    "policy_loss": -1246.8089599609375,
    "value_loss": 0.5647701472043991,
    "entropy": 1.1181768476963043,
    "total_loss": -1246.6914605528116
  },
  {
    "episode": 31,
    "avg_reward_per_step": 107.56922976244157,
    "episode_length": 185,
    "policy_loss": -1811.1190490722656,
    "value_loss": 0.6024166643619537,
    "entropy": 1.209519624710083,
    "total_loss": -1811.0004402577877
  },
  {
    "episode": 32,
    "avg_reward_per_step": 27.12972876326879,
    "episode_length": 708,
    "policy_loss": -462.0665588378906,
    "value_loss": 0.5213108509778976,
    "entropy": 1.063564956188202,
    "total_loss": -461.97067396938803
  },
  {
    "episode": 33,
    "avg_reward_per_step": 18.212566810466154,
    "episode_length": 1031,
    "policy_loss": -312.4429473876953,
    "value_loss": 0.5138942450284958,
    "entropy": 1.037881463766098,
    "total_loss": -312.3442057281733
  },
  {
    "episode": 34,
    "avg_reward_per_step": -1.3941179494960743,
    "episode_length": 3000,
    "policy_loss": 22.500030040740967,
    "value_loss": 0.6469528079032898,
    "entropy": 0.9992708414793015,
    "total_loss": 22.747274512052535
  },
  {
    "episode": 35,
    "avg_reward_per_step": 12.697053684408282,
    "episode_length": 1435,
    "policy_loss": -216.22780227661133,
    "value_loss": 0.5092977732419968,
    "entropy": 0.9529143869876862,
    "total_loss": -216.0996702581644
  },
  {
    "episode": 36,
    "avg_reward_per_step": 7.298804385261783,
    "episode_length": 2288,
    "policy_loss": -123.75344276428223,
    "value_loss": 0.5048433542251587,
    "entropy": 0.9495213627815247,
    "total_loss": -123.62840795516968
  },
  {
    "episode": 37,
    "avg_reward_per_step": 22.775359970580485,
    "episode_length": 842,
    "policy_loss": -385.8854751586914,
    "value_loss": 0.5178658664226532,
    "entropy": 0.9049458354711533,
    "total_loss": -385.7295876264572
  },
  {
    "episode": 38,
    "avg_reward_per_step": 25.587628346930426,
    "episode_length": 756,
    "policy_loss": -435.0135192871094,
    "value_loss": 0.5202870219945908,
    "entropy": 0.88169065117836,
    "total_loss": -434.84590852558614
  },
  {
    "episode": 39,
    "avg_reward_per_step": 12.4727768103619,
    "episode_length": 1481,
    "policy_loss": -210.48426818847656,
    "value_loss": 0.509208083152771,
    "entropy": 0.8439291566610336,
    "total_loss": -210.3126317679882
  },
  {
    "episode": 40,
    "avg_reward_per_step": 9.294298149383723,
    "episode_length": 1901,
    "policy_loss": -156.9215087890625,
    "value_loss": 0.5065475106239319,
    "entropy": 0.8208355158567429,
    "total_loss": -156.74329548478127
  },
  {
    "episode": 41,
    "avg_reward_per_step": 19.761184229438875,
    "episode_length": 973,
    "policy_loss": -332.9064025878906,
    "value_loss": 0.515322744846344,
    "entropy": 0.7958467602729797,
    "total_loss": -332.70941854715346
  },
  {
    "episode": 42,
    "avg_reward_per_step": 24.219424681989263,
    "episode_length": 785,
    "policy_loss": -409.3071594238281,
    "value_loss": 0.5187472254037857,
    "entropy": 0.7813644856214523,
    "total_loss": -409.10095799267293
  },
  {
    "episode": 43,
    "avg_reward_per_step": 9.925476591290305,
    "episode_length": 1796,
    "policy_loss": -167.68420791625977,
    "value_loss": 0.5071051567792892,
    "entropy": 0.7612989097833633,
    "total_loss": -167.48162232339382
  },
  {
    "episode": 44,
    "avg_reward_per_step": 11.587171943222105,
    "episode_length": 1567,
    "policy_loss": -195.67543411254883,
    "value_loss": 0.5084015280008316,
    "entropy": 0.7647741883993149,
    "total_loss": -195.4729422599077
  },
  {
    "episode": 45,
    "avg_reward_per_step": 48.40014984032863,
    "episode_length": 410,
    "policy_loss": -821.2034759521484,
    "value_loss": 0.5407560169696808,
    "entropy": 0.787140429019928,
    "total_loss": -820.9775761067867
  },
  {
    "episode": 46,
    "avg_reward_per_step": 134.4093572669967,
    "episode_length": 149,
    "policy_loss": -2310.537109375,
    "value_loss": 0.6346132755279541,
    "entropy": 0.7708855271339417,
    "total_loss": -2310.2108503103254
  },
  {
    "episode": 47,
    "avg_reward_per_step": 33.23248099855016,
    "episode_length": 592,
    "policy_loss": -549.5238037109375,
    "value_loss": 0.5269880145788193,
    "entropy": 0.608991265296936,
    "total_loss": -549.2404122024775
  },
  {
    "episode": 48,
    "avg_reward_per_step": 6.776521632447616,
    "episode_length": 2696,
    "policy_loss": -113.56695747375488,
    "value_loss": 0.5049218088388443,
    "entropy": 0.5350048542022705,
    "total_loss": -113.27603760659694
  },
  {
    "episode": 49,
    "avg_reward_per_step": -0.6242252393037957,
    "episode_length": 3000,
    "policy_loss": 9.634745836257935,
    "value_loss": 0.5105462223291397,
    "entropy": 0.5032937377691269,
    "total_loss": 9.943974563479424
  },
  {
    "episode": 50,
    "avg_reward_per_step": 8.368342023816245,
    "episode_length": 2279,
    "policy_loss": -142.5164794921875,
    "value_loss": 0.5063704997301102,
    "entropy": 0.5020009130239487,
    "total_loss": -142.21090935766696
  },
  {
    "episode": 51,
    "avg_reward_per_step": 6.455151595113523,
    "episode_length": 2840,
    "policy_loss": -111.1303539276123,
    "value_loss": 0.5047124773263931,
    "entropy": 0.5180935263633728,
    "total_loss": -110.83287886083126
  },
  {
    "episode": 52,
    "avg_reward_per_step": 91.30555124956125,
    "episode_length": 221,
    "policy_loss": -1544.7385559082031,
    "value_loss": 0.584541067481041,
    "entropy": 0.5776682198047638,
    "total_loss": -1544.385082128644
  },
  {
    "episode": 53,
    "avg_reward_per_step": 76.06095550606501,
    "episode_length": 264,
    "policy_loss": -1276.8717041015625,
    "value_loss": 0.5680511742830276,
    "entropy": 0.5520087033510208,
    "total_loss": -1276.52445640862
  },
  {
    "episode": 54,
    "avg_reward_per_step": 14.430654213048904,
    "episode_length": 1345,
    "policy_loss": -246.20901107788086,
    "value_loss": 0.5112595558166504,
    "entropy": 0.571305125951767,
    "total_loss": -245.92627357244493
  },
  {
    "episode": 55,
    "avg_reward_per_step": 55.88945095911643,
    "episode_length": 354,
    "policy_loss": -946.5031890869141,
    "value_loss": 0.5475997030735016,
    "entropy": 0.6201166957616806,
    "total_loss": -946.2036360621453
  },
  {
    "episode": 56,
    "avg_reward_per_step": 66.17975971135192,
    "episode_length": 301,
    "policy_loss": -1122.793212890625,
    "value_loss": 0.5577796548604965,
    "entropy": 0.6265277415513992,
    "total_loss": -1122.486044332385
  },
  {
    "episode": 57,
    "avg_reward_per_step": 127.92544212672739,
    "episode_length": 157,
    "policy_loss": -2172.8501586914062,
    "value_loss": 0.6269534230232239,
    "entropy": 0.5966676771640778,
    "total_loss": -2172.4618723392487
  },
  {
    "episode": 58,
    "avg_reward_per_step": 142.37185464801084,
    "episode_length": 141,
    "policy_loss": -2413.2535400390625,
    "value_loss": 0.6455224305391312,
    "entropy": 0.6004052013158798,
    "total_loss": -2412.8481796890496
  },
  {
    "episode": 59,
    "avg_reward_per_step": 82.11171407648727,
    "episode_length": 243,
    "policy_loss": -1396.5199279785156,
    "value_loss": 0.5738690197467804,
    "entropy": 0.5747235864400864,
    "total_loss": -1396.175948393345
  },
  {
    "episode": 60,
    "avg_reward_per_step": 155.02166015013026,
    "episode_length": 130,
    "policy_loss": -2621.533935546875,
    "value_loss": 0.66350357234478,
    "entropy": 0.6016979962587357,
    "total_loss": -2621.111111173034
  },
  {
    "episode": 61,
    "avg_reward_per_step": 61.780692231792685,
    "episode_length": 321,
    "policy_loss": -1041.4179992675781,
    "value_loss": 0.5533975958824158,
    "entropy": 0.5881883651018143,
    "total_loss": -1041.0998770177364
  },
  {
    "episode": 62,
    "avg_reward_per_step": 94.26975910212147,
    "episode_length": 212,
    "policy_loss": -1606.68408203125,
    "value_loss": 0.5873889923095703,
    "entropy": 0.5665335804224014,
    "total_loss": -1606.3233064711094
  },
  {
    "episode": 63,
    "avg_reward_per_step": 88.65277128362024,
    "episode_length": 226,
    "policy_loss": -1503.9864807128906,
    "value_loss": 0.5811830908060074,
    "entropy": 0.58076211810112,
    "total_loss": -1503.637602469325
  },
  {
    "episode": 64,
    "avg_reward_per_step": 78.54910648440614,
    "episode_length": 254,
    "policy_loss": -1332.0022888183594,
    "value_loss": 0.5702697187662125,
    "entropy": 0.5577176660299301,
    "total_loss": -1331.6551061660052
  },
  {
    "episode": 65,
    "avg_reward_per_step": 133.95371268230355,
    "episode_length": 150,
    "policy_loss": -2263.3113403320312,
    "value_loss": 0.634368821978569,
    "entropy": 0.5459167659282684,
    "total_loss": -2262.895338216424
  },
  {
    "episode": 66,
    "avg_reward_per_step": 88.51395867597107,
    "episode_length": 226,
    "policy_loss": -1509.3630676269531,
    "value_loss": 0.5811431556940079,
    "entropy": 0.512024849653244,
    "total_loss": -1508.9867344111203
  },
  {
    "episode": 67,
    "avg_reward_per_step": 87.96108334950513,
    "episode_length": 227,
    "policy_loss": -1489.154052734375,
    "value_loss": 0.5807411670684814,
    "entropy": 0.5626987665891647,
    "total_loss": -1488.7983910739422
  },
  {
    "episode": 68,
    "avg_reward_per_step": 66.0799463943509,
    "episode_length": 302,
    "policy_loss": -1118.5362243652344,
    "value_loss": 0.5576213598251343,
    "entropy": 0.4945816099643707,
    "total_loss": -1118.176435649395
  },
  {
    "episode": 69,
    "avg_reward_per_step": 124.48593690319248,
    "episode_length": 161,
    "policy_loss": -2129.8132934570312,
    "value_loss": 0.622890830039978,
    "entropy": 0.5492571443319321,
    "total_loss": -2129.410105484724
  },
  {
    "episode": 70,
    "avg_reward_per_step": 75.45183934463918,
    "episode_length": 264,
    "policy_loss": -1281.7522583007812,
    "value_loss": 0.567409411072731,
    "entropy": 0.5584597438573837,
    "total_loss": -1281.4082327872516
  },
  {
    "episode": 71,
    "avg_reward_per_step": 66.92594621238969,
    "episode_length": 298,
    "policy_loss": -1131.1136779785156,
    "value_loss": 0.55889792740345,
    "entropy": 0.5278440713882446,
    "total_loss": -1130.7659176796674
  },
  {
    "episode": 72,
    "avg_reward_per_step": 480.385323126378,
    "episode_length": 42,
    "policy_loss": -7567.052001953125,
    "value_loss": 1.4864806532859802,
    "entropy": 0.4117724299430847,
    "total_loss": -7565.730230271816
  },
  {
    "episode": 73,
    "avg_reward_per_step": 197.68486507209207,
    "episode_length": 102,
    "policy_loss": -3325.7430419921875,
    "value_loss": 0.7310588210821152,
    "entropy": 0.4514234811067581,
    "total_loss": -3325.192552563548
  },
  {
    "episode": 74,
    "avg_reward_per_step": 126.40787251303755,
    "episode_length": 159,
    "policy_loss": -2133.5701904296875,
    "value_loss": 0.6250017434358597,
    "entropy": 0.44198888540267944,
    "total_loss": -2133.1219842404125
  },
  {
    "episode": 75,
    "avg_reward_per_step": 157.37470138272985,
    "episode_length": 128,
    "policy_loss": -2643.8619384765625,
    "value_loss": 0.6662106812000275,
    "entropy": 0.4379214942455292,
    "total_loss": -2643.370896393061
  },
  {
    "episode": 76,
    "avg_reward_per_step": 85.07503620135753,
    "episode_length": 235,
    "policy_loss": -1432.8700866699219,
    "value_loss": 0.5772051513195038,
    "entropy": 0.4793238416314125,
    "total_loss": -1432.4846110552548
  },
  {
    "episode": 77,
    "avg_reward_per_step": 154.57762501127365,
    "episode_length": 130,
    "policy_loss": -2608.955322265625,
    "value_loss": 0.6621275842189789,
    "entropy": 0.43500708788633347,
    "total_loss": -2608.4671975165606
  },
  {
    "episode": 78,
    "avg_reward_per_step": 137.7052319462574,
    "episode_length": 146,
    "policy_loss": -2321.17724609375,
    "value_loss": 0.6394967287778854,
    "entropy": 0.41219381242990494,
    "total_loss": -2320.702626889944
  },
  {
    "episode": 79,
    "avg_reward_per_step": 138.4359256598003,
    "episode_length": 145,
    "policy_loss": -2335.182373046875,
    "value_loss": 0.6402279883623123,
    "entropy": 0.4282267987728119,
    "total_loss": -2334.713435778022
  },
  {
    "episode": 80,
    "avg_reward_per_step": 157.23817323475336,
    "episode_length": 128,
    "policy_loss": -2652.3661499023438,
    "value_loss": 0.6660083532333374,
    "entropy": 0.39607585221529007,
    "total_loss": -2651.8585718899967
  },
  {
    "episode": 81,
    "avg_reward_per_step": 144.83102399895333,
    "episode_length": 139,
    "policy_loss": -2442.0144653320312,
    "value_loss": 0.648884192109108,
    "entropy": 0.38554632663726807,
    "total_loss": -2441.519799670577
  },
  {
    "episode": 82,
    "avg_reward_per_step": 127.24043472093109,
    "episode_length": 158,
    "policy_loss": -2145.4578247070312,
    "value_loss": 0.6256773918867111,
    "entropy": 0.3405134677886963,
    "total_loss": -2144.96835270226
  },
  {
    "episode": 83,
    "avg_reward_per_step": 149.2220333899662,
    "episode_length": 135,
    "policy_loss": -2520.3660888671875,
    "value_loss": 0.6550894528627396,
    "entropy": 0.3239372819662094,
    "total_loss": -2519.8405743271114
  },
  {
    "episode": 84,
    "avg_reward_per_step": 149.19795366820526,
    "episode_length": 135,
    "policy_loss": -2526.1901245117188,
    "value_loss": 0.6548848450183868,
    "entropy": 0.3000785633921623,
    "total_loss": -2525.6552710920573
  },
  {
    "episode": 85,
    "avg_reward_per_step": 140.72616725939744,
    "episode_length": 143,
    "policy_loss": -2363.8798828125,
    "value_loss": 0.643389493227005,
    "entropy": 0.3840840756893158,
    "total_loss": -2363.3901269495486
  },
  {
    "episode": 86,
    "avg_reward_per_step": 151.3447976327072,
    "episode_length": 133,
    "policy_loss": -2563.036865234375,
    "value_loss": 0.658010721206665,
    "entropy": 0.34262894093990326,
    "total_loss": -2562.5159060895444
  },
  {
    "episode": 87,
    "avg_reward_per_step": 154.62837180840413,
    "episode_length": 130,
    "policy_loss": -2607.4624633789062,
    "value_loss": 0.6621664464473724,
    "entropy": 0.33844225108623505,
    "total_loss": -2606.9356738328934
  },
  {
    "episode": 88,
    "avg_reward_per_step": 147.9092790225169,
    "episode_length": 136,
    "policy_loss": -2492.6931762695312,
    "value_loss": 0.6530671417713165,
    "entropy": 0.38761938363313675,
    "total_loss": -2492.1951568812133
  },
  {
    "episode": 89,
    "avg_reward_per_step": 158.37868545845697,
    "episode_length": 127,
    "policy_loss": -2671.394287109375,
    "value_loss": 0.6673308312892914,
    "entropy": 0.3487541228532791,
    "total_loss": -2670.866457927227
  },
  {
    "episode": 90,
    "avg_reward_per_step": 117.69800042255011,
    "episode_length": 171,
    "policy_loss": -1989.1272583007812,
    "value_loss": 0.6148816794157028,
    "entropy": 0.32618138939142227,
    "total_loss": -1988.6428491771221
  },
  {
    "episode": 91,
    "avg_reward_per_step": 158.46849274009745,
    "episode_length": 127,
    "policy_loss": -2676.149658203125,
    "value_loss": 0.667791411280632,
    "entropy": 0.26682233065366745,
    "total_loss": -2675.5885957241057
  },
  {
    "episode": 92,
    "avg_reward_per_step": 151.55586109394102,
    "episode_length": 133,
    "policy_loss": -2573.368896484375,
    "value_loss": 0.6584187895059586,
    "entropy": 0.26917462795972824,
    "total_loss": -2572.818147546053
  },
  {
    "episode": 93,
    "avg_reward_per_step": 158.60870100107635,
    "episode_length": 127,
    "policy_loss": -2668.2427978515625,
    "value_loss": 0.66806760430336,
    "entropy": 0.2651352062821388,
    "total_loss": -2667.680784329772
  },
  {
    "episode": 94,
    "avg_reward_per_step": 154.78344791574114,
    "episode_length": 130,
    "policy_loss": -2605.8165893554688,
    "value_loss": 0.662268877029419,
    "entropy": 0.28082869946956635,
    "total_loss": -2605.266651958227
  },
  {
    "episode": 95,
    "avg_reward_per_step": 158.30753213787372,
    "episode_length": 127,
    "policy_loss": -2668.1810913085938,
    "value_loss": 0.6673017591238022,
    "entropy": 0.20379432290792465,
    "total_loss": -2667.5953072786333
  },
  {
    "episode": 96,
    "avg_reward_per_step": 154.6057630676887,
    "episode_length": 130,
    "policy_loss": -2602.4513549804688,
    "value_loss": 0.6620403379201889,
    "entropy": 0.23723441362380981,
    "total_loss": -2601.884208407998
  },
  {
    "episode": 97,
    "avg_reward_per_step": 158.50877409679552,
    "episode_length": 127,
    "policy_loss": -2670.9088134765625,
    "value_loss": 0.6677911728620529,
    "entropy": 0.2561532333493233,
    "total_loss": -2670.34348359704
  },
  {
    "episode": 98,
    "avg_reward_per_step": 163.91298898445663,
    "episode_length": 123,
    "policy_loss": -2770.3008422851562,
    "value_loss": 0.6757216155529022,
    "entropy": 0.2440509907901287,
    "total_loss": -2769.7227410659193
  },
  {
    "episode": 99,
    "avg_reward_per_step": 138.62981859763244,
    "episode_length": 145,
    "policy_loss": -2329.7137451171875,
    "value_loss": 0.639890268445015,
    "entropy": 0.2660774439573288,
    "total_loss": -2329.1802858263254
  },
  {
    "episode": 100,
    "avg_reward_per_step": 99.73712023101828,
    "episode_length": 201,
    "policy_loss": -1687.7837524414062,
    "value_loss": 0.5931480079889297,
    "entropy": 0.2478303462266922,
    "total_loss": -1687.289736571908
  },
  {
    "episode": 101,
    "avg_reward_per_step": 161.09533412233552,
    "episode_length": 125,
    "policy_loss": -2711.7564697265625,
    "value_loss": 0.6715732514858246,
    "entropy": 0.23025824129581451,
    "total_loss": -2711.176999771595
  },
  {
    "episode": 102,
    "avg_reward_per_step": 157.48649349587052,
    "episode_length": 128,
    "policy_loss": -2652.2713012695312,
    "value_loss": 0.6666376441717148,
    "entropy": 0.26303982734680176,
    "total_loss": -2651.7098795562983
  },
  {
    "episode": 103,
    "avg_reward_per_step": 158.58021318223885,
    "episode_length": 127,
    "policy_loss": -2671.1620483398438,
    "value_loss": 0.6679031252861023,
    "entropy": 0.23600102216005325,
    "total_loss": -2670.588545623422
  },
  {
    "episode": 104,
    "avg_reward_per_step": 160.89161666697817,
    "episode_length": 125,
    "policy_loss": -2707.7827758789062,
    "value_loss": 0.6707992404699326,
    "entropy": 0.25314749777317047,
    "total_loss": -2707.2132356375455
  },
  {
    "episode": 105,
    "avg_reward_per_step": 159.89678506051595,
    "episode_length": 126,
    "policy_loss": -2703.478759765625,
    "value_loss": 0.6694869995117188,
    "entropy": 0.21043897792696953,
    "total_loss": -2702.893448357284
  },
  {
    "episode": 106,
    "avg_reward_per_step": 158.55608964964892,
    "episode_length": 127,
    "policy_loss": -2670.0858764648438,
    "value_loss": 0.6677778363227844,
    "entropy": 0.21554365754127502,
    "total_loss": -2669.5043160915375
  },
  {
    "episode": 107,
    "avg_reward_per_step": 158.49748213551493,
    "episode_length": 127,
    "policy_loss": -2667.4111328125,
    "value_loss": 0.6675991863012314,
    "entropy": 0.21274832636117935,
    "total_loss": -2666.828632956743
  },
  {
    "episode": 108,
    "avg_reward_per_step": 166.40491197364375,
    "episode_length": 121,
    "policy_loss": -2804.6279907226562,
    "value_loss": 0.6789948791265488,
    "entropy": 0.1783253774046898,
    "total_loss": -2804.0203259944915
  },
  {
    "episode": 109,
    "avg_reward_per_step": 165.10251746439206,
    "episode_length": 122,
    "policy_loss": -2778.70458984375,
    "value_loss": 0.6769156754016876,
    "entropy": 0.16189447045326233,
    "total_loss": -2778.0924319565297
  },
  {
    "episode": 110,
    "avg_reward_per_step": 158.55592789824598,
    "episode_length": 127,
    "policy_loss": -2670.3759155273438,
    "value_loss": 0.6677315086126328,
    "entropy": 0.22115712985396385,
    "total_loss": -2669.7966468706727
  },
  {
    "episode": 111,
    "avg_reward_per_step": 160.943367778485,
    "episode_length": 125,
    "policy_loss": -2715.9409790039062,
    "value_loss": 0.6709897965192795,
    "entropy": 0.19152925536036491,
    "total_loss": -2715.346600909531
  },
  {
    "episode": 112,
    "avg_reward_per_step": 162.33295622346992,
    "episode_length": 124,
    "policy_loss": -2738.7652587890625,
    "value_loss": 0.6730785071849823,
    "entropy": 0.18901534751057625,
    "total_loss": -2738.167786420882
  },
  {
    "episode": 113,
    "avg_reward_per_step": 162.33916132543052,
    "episode_length": 124,
    "policy_loss": -2733.563232421875,
    "value_loss": 0.6730108559131622,
    "entropy": 0.1788843534886837,
    "total_loss": -2732.961775307357
  },
  {
    "episode": 114,
    "avg_reward_per_step": 159.69153114804547,
    "episode_length": 126,
    "policy_loss": -2686.1984252929688,
    "value_loss": 0.6691514402627945,
    "entropy": 0.1931954212486744,
    "total_loss": -2685.6065520212055
  },
  {
    "episode": 115,
    "avg_reward_per_step": 63.05839319894755,
    "episode_length": 315,
    "policy_loss": -1057.2627563476562,
    "value_loss": 0.5542173981666565,
    "entropy": 0.24588435888290405,
    "total_loss": -1056.8068926930428
  },
  {
    "episode": 116,
    "avg_reward_per_step": 165.09509469124504,
    "episode_length": 122,
    "policy_loss": -2768.6918334960938,
    "value_loss": 0.6771148294210434,
    "entropy": 0.17780988663434982,
    "total_loss": -2768.0858426213263
  },
  {
    "episode": 117,
    "avg_reward_per_step": 165.1511571655329,
    "episode_length": 122,
    "policy_loss": -2781.1979370117188,
    "value_loss": 0.6772303283214569,
    "entropy": 0.26379795372486115,
    "total_loss": -2780.626225864887
  },
  {
    "episode": 118,
    "avg_reward_per_step": 166.51443763127173,
    "episode_length": 121,
    "policy_loss": -2800.7799682617188,
    "value_loss": 0.6788782626390457,
    "entropy": 0.20101464167237282,
    "total_loss": -2800.181495855749
  },
  {
    "episode": 119,
    "avg_reward_per_step": 168.1234132834505,
    "episode_length": 120,
    "policy_loss": -2828.8900756835938,
    "value_loss": 0.6814285069704056,
    "entropy": 0.1728820689022541,
    "total_loss": -2828.2778000041844
  },
  {
    "episode": 120,
    "avg_reward_per_step": 166.62501574742436,
    "episode_length": 121,
    "policy_loss": -2807.1974487304688,
    "value_loss": 0.6791395395994186,
    "entropy": 0.15957143157720566,
    "total_loss": -2806.5821377635
  },
  {
    "episode": 121,
    "avg_reward_per_step": 64.39908695626102,
    "episode_length": 309,
    "policy_loss": -1082.59326171875,
    "value_loss": 0.55544613301754,
    "entropy": 0.19107899069786072,
    "total_loss": -1082.1142471820117
  },
  {
    "episode": 122,
    "avg_reward_per_step": 161.35483523608298,
    "episode_length": 125,
    "policy_loss": -2716.1467895507812,
    "value_loss": 0.6716136187314987,
    "entropy": 0.1636279784142971,
    "total_loss": -2715.5406271234156
  },
  {
    "episode": 123,
    "avg_reward_per_step": 162.43480207045042,
    "episode_length": 124,
    "policy_loss": -2728.78173828125,
    "value_loss": 0.6731132119894028,
    "entropy": 0.15662720426917076,
    "total_loss": -2728.1712759509683
  },
  {
    "episode": 124,
    "avg_reward_per_step": 163.67848457389192,
    "episode_length": 123,
    "policy_loss": -2745.2102661132812,
    "value_loss": 0.6746675223112106,
    "entropy": 0.15602368861436844,
    "total_loss": -2744.598008066416
  },
  {
    "episode": 125,
    "avg_reward_per_step": 148.98656506103038,
    "episode_length": 135,
    "policy_loss": -2508.3525390625,
    "value_loss": 0.6537653356790543,
    "entropy": 0.14835736900568008,
    "total_loss": -2507.758116674423
  },
  {
    "episode": 126,
    "avg_reward_per_step": 162.26264204421275,
    "episode_length": 124,
    "policy_loss": -2722.3919067382812,
    "value_loss": 0.6726315468549728,
    "entropy": 0.12808329612016678,
    "total_loss": -2721.770508509874
  },
  {
    "episode": 127,
    "avg_reward_per_step": 163.80675280365872,
    "episode_length": 123,
    "policy_loss": -2750.9683837890625,
    "value_loss": 0.67464978992939,
    "entropy": 0.1309238187968731,
    "total_loss": -2750.346103526652
  },
  {
    "episode": 128,
    "avg_reward_per_step": 160.90409676835966,
    "episode_length": 125,
    "policy_loss": -2711.4640502929688,
    "value_loss": 0.6706306785345078,
    "entropy": 0.16239134594798088,
    "total_loss": -2710.8583761528134
  },
  {
    "episode": 129,
    "avg_reward_per_step": 160.89216807538983,
    "episode_length": 125,
    "policy_loss": -2700.4529418945312,
    "value_loss": 0.6705487370491028,
    "entropy": 0.12594998627901077,
    "total_loss": -2699.832773151994
  },
  {
    "episode": 130,
    "avg_reward_per_step": 158.56924990829557,
    "episode_length": 127,
    "policy_loss": -2669.1605834960938,
    "value_loss": 0.6674045622348785,
    "entropy": 0.1601623222231865,
    "total_loss": -2668.5572438627482
  },
  {
    "episode": 131,
    "avg_reward_per_step": 165.10529873695256,
    "episode_length": 122,
    "policy_loss": -2779.571533203125,
    "value_loss": 0.6767769753932953,
    "entropy": 0.15555455908179283,
    "total_loss": -2778.9569780513643
  },
  {
    "episode": 132,
    "avg_reward_per_step": 162.21874859560506,
    "episode_length": 124,
    "policy_loss": -2710.7937622070312,
    "value_loss": 0.672337606549263,
    "entropy": 0.16352532804012299,
    "total_loss": -2710.186834731698
  },
  {
    "episode": 133,
    "avg_reward_per_step": 162.06612756009164,
    "episode_length": 124,
    "policy_loss": -2729.2835083007812,
    "value_loss": 0.6718809455633163,
    "entropy": 0.14852599427103996,
    "total_loss": -2728.671037752926
  },
  {
    "episode": 134,
    "avg_reward_per_step": 163.6198655792116,
    "episode_length": 123,
    "policy_loss": -2740.734375,
    "value_loss": 0.6743768006563187,
    "entropy": 0.14050626754760742,
    "total_loss": -2740.1162007063626
  },
  {
    "episode": 135,
    "avg_reward_per_step": 135.5725229342424,
    "episode_length": 148,
    "policy_loss": -2270.6444702148438,
    "value_loss": 0.6356391906738281,
    "entropy": 0.13522711023688316,
    "total_loss": -2270.0629218682648
  },
  {
    "episode": 136,
    "avg_reward_per_step": 144.17337274249556,
    "episode_length": 139,
    "policy_loss": -2431.4181518554688,
    "value_loss": 0.646862268447876,
    "entropy": 0.16251388937234879,
    "total_loss": -2430.83629514277
  },
  {
    "episode": 137,
    "avg_reward_per_step": 143.40429272189112,
    "episode_length": 140,
    "policy_loss": -2410.365966796875,
    "value_loss": 0.6459620743989944,
    "entropy": 0.11057755164802074,
    "total_loss": -2409.764235743135
  },
  {
    "episode": 138,
    "avg_reward_per_step": 145.48986441017814,
    "episode_length": 138,
    "policy_loss": -2446.5787963867188,
    "value_loss": 0.6487344056367874,
    "entropy": 0.10092901438474655,
    "total_loss": -2445.970433586836
  },
  {
    "episode": 139,
    "avg_reward_per_step": 159.6101776101171,
    "episode_length": 126,
    "policy_loss": -2679.4671020507812,
    "value_loss": 0.6684810966253281,
    "entropy": 0.09941559098660946,
    "total_loss": -2678.8383871905507
  },
  {
    "episode": 140,
    "avg_reward_per_step": 163.6262322834019,
    "episode_length": 123,
    "policy_loss": -2749.2636108398438,
    "value_loss": 0.6742953658103943,
    "entropy": 0.11990943737328053,
    "total_loss": -2748.637279248983
  },
  {
    "episode": 141,
    "avg_reward_per_step": 161.1008242982659,
    "episode_length": 125,
    "policy_loss": -2717.0271606445312,
    "value_loss": 0.670747309923172,
    "entropy": 0.14161798730492592,
    "total_loss": -2716.41306052953
  },
  {
    "episode": 142,
    "avg_reward_per_step": 155.50018571119767,
    "episode_length": 129,
    "policy_loss": -2604.7613525390625,
    "value_loss": 0.6621955335140228,
    "entropy": 0.12449737079441547,
    "total_loss": -2604.1489559538663
  },
  {
    "episode": 143,
    "avg_reward_per_step": 154.7270787680554,
    "episode_length": 130,
    "policy_loss": -2572.5236206054688,
    "value_loss": 0.6615873426198959,
    "entropy": 0.11583821289241314,
    "total_loss": -2571.908368548006
  },
  {
    "episode": 144,
    "avg_reward_per_step": 157.06760601191874,
    "episode_length": 128,
    "policy_loss": -2648.330078125,
    "value_loss": 0.6647906005382538,
    "entropy": 0.11980306543409824,
    "total_loss": -2647.713208750635
  },
  {
    "episode": 145,
    "avg_reward_per_step": 139.66362234478993,
    "episode_length": 144,
    "policy_loss": -2340.8788452148438,
    "value_loss": 0.6412025094032288,
    "entropy": 0.13591941073536873,
    "total_loss": -2340.2920104697346
  },
  {
    "episode": 146,
    "avg_reward_per_step": 160.83966924311363,
    "episode_length": 125,
    "policy_loss": -2712.9203491210938,
    "value_loss": 0.6700447052717209,
    "entropy": 0.13294219598174095,
    "total_loss": -2712.3034812942146
  },
  {
    "episode": 147,
    "avg_reward_per_step": 140.55260840003183,
    "episode_length": 143,
    "policy_loss": -2368.8002319335938,
    "value_loss": 0.6422527432441711,
    "entropy": 0.12694155797362328,
    "total_loss": -2368.208755813539
  },
  {
    "episode": 148,
    "avg_reward_per_step": 133.88860089342987,
    "episode_length": 150,
    "policy_loss": -2248.7678833007812,
    "value_loss": 0.6334464848041534,
    "entropy": 0.15261643379926682,
    "total_loss": -2248.195483389497
  },
  {
    "episode": 149,
    "avg_reward_per_step": 152.3000672411349,
    "episode_length": 132,
    "policy_loss": -2557.1869506835938,
    "value_loss": 0.6579118371009827,
    "entropy": 0.11781631223857403,
    "total_loss": -2556.576165371388
  },
  {
    "episode": 150,
    "avg_reward_per_step": 77.30446670996695,
    "episode_length": 258,
    "policy_loss": -1292.6205444335938,
    "value_loss": 0.5679086297750473,
    "entropy": 0.11495156586170197,
    "total_loss": -1292.0986164301635
  },
  {
    "episode": 151,
    "avg_reward_per_step": 122.7689679774984,
    "episode_length": 163,
    "policy_loss": -2068.734375,
    "value_loss": 0.6189456582069397,
    "entropy": 0.1713295876979828,
    "total_loss": -2068.1839611768723
  },
  {
    "episode": 152,
    "avg_reward_per_step": 159.77028547908316,
    "episode_length": 126,
    "policy_loss": -2678.8990478515625,
    "value_loss": 0.6685982048511505,
    "entropy": 0.1308874487876892,
    "total_loss": -2678.2828046262266
  },
  {
    "episode": 153,
    "avg_reward_per_step": 143.715606211119,
    "episode_length": 140,
    "policy_loss": -2415.8026733398438,
    "value_loss": 0.646476998925209,
    "entropy": 0.11025490798056126,
    "total_loss": -2415.2002983041107
  },
  {
    "episode": 154,
    "avg_reward_per_step": 154.54264422576117,
    "episode_length": 130,
    "policy_loss": -2581.231689453125,
    "value_loss": 0.6608246713876724,
    "entropy": 0.10143908485770226,
    "total_loss": -2580.6114404156806
  },
  {
    "episode": 155,
    "avg_reward_per_step": 149.96060566554954,
    "episode_length": 134,
    "policy_loss": -2523.1068725585938,
    "value_loss": 0.6545914858579636,
    "entropy": 0.09570510685443878,
    "total_loss": -2522.4905631154775
  },
  {
    "episode": 156,
    "avg_reward_per_step": 149.99847988077954,
    "episode_length": 134,
    "policy_loss": -2516.1127319335938,
    "value_loss": 0.6545990705490112,
    "entropy": 0.12235909514129162,
    "total_loss": -2515.5070765011014
  },
  {
    "episode": 157,
    "avg_reward_per_step": 143.6928752671737,
    "episode_length": 140,
    "policy_loss": -2404.2454223632812,
    "value_loss": 0.6463405340909958,
    "entropy": 0.11023768223822117,
    "total_loss": -2403.6431769020855
  },
  {
    "episode": 158,
    "avg_reward_per_step": 144.1030348016462,
    "episode_length": 139,
    "policy_loss": -2420.4271240234375,
    "value_loss": 0.6460506618022919,
    "entropy": 0.09654788300395012,
    "total_loss": -2419.819692514837
  },
  {
    "episode": 159,
    "avg_reward_per_step": 151.05285300332145,
    "episode_length": 133,
    "policy_loss": -2525.5401000976562,
    "value_loss": 0.6558924168348312,
    "entropy": 0.0851236842572689,
    "total_loss": -2524.9182571545243
  },
  {
    "episode": 160,
    "avg_reward_per_step": 125.09340230359909,
    "episode_length": 161,
    "policy_loss": -2102.6734619140625,
    "value_loss": 0.6225629150867462,
    "entropy": 0.14397886022925377,
    "total_loss": -2102.1084905430675
  },
  {
    "episode": 161,
    "avg_reward_per_step": 151.2041505926812,
    "episode_length": 133,
    "policy_loss": -2538.490234375,
    "value_loss": 0.6562333852052689,
    "entropy": 0.08706188015639782,
    "total_loss": -2537.868825741857
  },
  {
    "episode": 162,
    "avg_reward_per_step": 151.06352679048172,
    "episode_length": 133,
    "policy_loss": -2533.1602783203125,
    "value_loss": 0.6558878272771835,
    "entropy": 0.08281116187572479,
    "total_loss": -2532.537514957786
  },
  {
    "episode": 163,
    "avg_reward_per_step": 151.18502916181478,
    "episode_length": 133,
    "policy_loss": -2533.658203125,
    "value_loss": 0.6561578661203384,
    "entropy": 0.08875199966132641,
    "total_loss": -2533.0375460587443
  },
  {
    "episode": 164,
    "avg_reward_per_step": 153.52190501749124,
    "episode_length": 131,
    "policy_loss": -2572.0110473632812,
    "value_loss": 0.6593073457479477,
    "entropy": 0.09072902053594589,
    "total_loss": -2571.3880316257478
  },
  {
    "episode": 165,
    "avg_reward_per_step": 150.09766249200516,
    "episode_length": 134,
    "policy_loss": -2532.7188110351562,
    "value_loss": 0.6546665132045746,
    "entropy": 0.09070023335516453,
    "total_loss": -2532.100424615294
  },
  {
    "episode": 166,
    "avg_reward_per_step": 150.08114968703845,
    "episode_length": 134,
    "policy_loss": -2506.7981567382812,
    "value_loss": 0.6545905023813248,
    "entropy": 0.09632288292050362,
    "total_loss": -2506.1820953890683
  },
  {
    "episode": 167,
    "avg_reward_per_step": 470.07291637896947,
    "episode_length": 43,
    "policy_loss": -7365.93701171875,
    "value_loss": 1.4499834775924683,
    "entropy": 0.10851064883172512,
    "total_loss": -7364.53043250069
  },
  {
    "episode": 168,
    "avg_reward_per_step": 126.00377667274601,
    "episode_length": 160,
    "policy_loss": -2114.4192504882812,
    "value_loss": 0.6236127614974976,
    "entropy": 0.11052492447197437,
    "total_loss": -2113.8398476965726
  },
  {
    "episode": 169,
    "avg_reward_per_step": 152.357672207039,
    "episode_length": 132,
    "policy_loss": -2560.7066040039062,
    "value_loss": 0.6575648337602615,
    "entropy": 0.08789438381791115,
    "total_loss": -2560.084196923673
  },
  {
    "episode": 170,
    "avg_reward_per_step": 122.50642902111609,
    "episode_length": 164,
    "policy_loss": -2046.3584289550781,
    "value_loss": 0.6186828464269638,
    "entropy": 0.0888416450470686,
    "total_loss": -2045.77528276667
  },
  {
    "episode": 171,
    "avg_reward_per_step": 126.05832278087954,
    "episode_length": 160,
    "policy_loss": -2108.2769775390625,
    "value_loss": 0.623652845621109,
    "entropy": 0.1078905425965786,
    "total_loss": -2107.69648091048
  },
  {
    "episode": 172,
    "avg_reward_per_step": 154.83493173710198,
    "episode_length": 130,
    "policy_loss": -2596.3792114257812,
    "value_loss": 0.6611460149288177,
    "entropy": 0.13441846892237663,
    "total_loss": -2595.771832798421
  },
  {
    "episode": 173,
    "avg_reward_per_step": 127.69797095274073,
    "episode_length": 158,
    "policy_loss": -2139.444580078125,
    "value_loss": 0.6257254183292389,
    "entropy": 0.1329580433666706,
    "total_loss": -2138.8720378771422
  },
  {
    "episode": 174,
    "avg_reward_per_step": 125.53265487037287,
    "episode_length": 161,
    "policy_loss": -2105.8587646484375,
    "value_loss": 0.6231636255979538,
    "entropy": 0.14705166965723038,
    "total_loss": -2105.2944216907026
  },
  {
    "episode": 175,
    "avg_reward_per_step": 154.8041919715879,
    "episode_length": 130,
    "policy_loss": -2598.4932250976562,
    "value_loss": 0.6609722673892975,
    "entropy": 0.13741584867238998,
    "total_loss": -2597.887219169736
  },
  {
    "episode": 176,
    "avg_reward_per_step": 149.99752393211782,
    "episode_length": 134,
    "policy_loss": -2505.7129516601562,
    "value_loss": 0.6540078520774841,
    "entropy": 0.10688700899481773,
    "total_loss": -2505.1016986116765
  },
  {
    "episode": 177,
    "avg_reward_per_step": 134.42910200582907,
    "episode_length": 150,
    "policy_loss": -2252.170166015625,
    "value_loss": 0.6339199095964432,
    "entropy": 0.1387215368449688,
    "total_loss": -2251.5917347207665
  },
  {
    "episode": 178,
    "avg_reward_per_step": 55.24060479201183,
    "episode_length": 362,
    "policy_loss": -923.6783447265625,
    "value_loss": 0.5457497835159302,
    "entropy": 0.10425862856209278,
    "total_loss": -923.1742983944714
  },
  {
    "episode": 179,
    "avg_reward_per_step": 48.52793842087144,
    "episode_length": 412,
    "policy_loss": -804.8497924804688,
    "value_loss": 0.5393777191638947,
    "entropy": 0.10205754265189171,
    "total_loss": -804.3512377783657
  },
  {
    "episode": 180,
    "avg_reward_per_step": 80.02166500889757,
    "episode_length": 252,
    "policy_loss": -1335.4990844726562,
    "value_loss": 0.5708352476358414,
    "entropy": 0.11353281885385513,
    "total_loss": -1334.9736623525619
  },
  {
    "episode": 181,
    "avg_reward_per_step": 46.338804247242614,
    "episode_length": 433,
    "policy_loss": -769.700927734375,
    "value_loss": 0.5375582873821259,
    "entropy": 0.12004159577190876,
    "total_loss": -769.2113860853017
  },
  {
    "episode": 182,
    "avg_reward_per_step": 80.3352096640041,
    "episode_length": 250,
    "policy_loss": -1342.0705261230469,
    "value_loss": 0.5708013325929642,
    "entropy": 0.12706265598535538,
    "total_loss": -1341.550549852848
  },
  {
    "episode": 183,
    "avg_reward_per_step": 87.5351508751137,
    "episode_length": 230,
    "policy_loss": -1463.4232482910156,
    "value_loss": 0.578656330704689,
    "entropy": 0.1461499147117138,
    "total_loss": -1462.9030519261955
  },
  {
    "episode": 184,
    "avg_reward_per_step": 126.10004722027733,
    "episode_length": 160,
    "policy_loss": -2111.2033081054688,
    "value_loss": 0.6233424991369247,
    "entropy": 0.10498836264014244,
    "total_loss": -2110.621960951388
  },
  {
    "episode": 185,
    "avg_reward_per_step": 146.8965610907352,
    "episode_length": 137,
    "policy_loss": -2463.9649658203125,
    "value_loss": 0.6497988253831863,
    "entropy": 0.1219364944845438,
    "total_loss": -2463.363941592723
  },
  {
    "episode": 186,
    "avg_reward_per_step": 143.74133072052672,
    "episode_length": 140,
    "policy_loss": -2403.1134643554688,
    "value_loss": 0.6454470902681351,
    "entropy": 0.15298832207918167,
    "total_loss": -2402.5292125940323
  },
  {
    "episode": 187,
    "avg_reward_per_step": 128.5401603483267,
    "episode_length": 156,
    "policy_loss": -2148.8068237304688,
    "value_loss": 0.6253449767827988,
    "entropy": 0.12344378605484962,
    "total_loss": -2148.230856268108
  },
  {
    "episode": 188,
    "avg_reward_per_step": 146.93042878624848,
    "episode_length": 137,
    "policy_loss": -2457.313232421875,
    "value_loss": 0.6497911065816879,
    "entropy": 0.11964455991983414,
    "total_loss": -2456.7112991392614
  },
  {
    "episode": 189,
    "avg_reward_per_step": 158.55291157849413,
    "episode_length": 127,
    "policy_loss": -2646.2614135742188,
    "value_loss": 0.6655569970607758,
    "entropy": 0.07721840217709541,
    "total_loss": -2645.626743938029
  },
  {
    "episode": 190,
    "avg_reward_per_step": 122.72765345989323,
    "episode_length": 164,
    "policy_loss": -2053.7770080566406,
    "value_loss": 0.6185786873102188,
    "entropy": 0.09585603140294552,
    "total_loss": -2053.1967717818916
  },
  {
    "episode": 191,
    "avg_reward_per_step": 114.29708174861562,
    "episode_length": 175,
    "policy_loss": -1910.5285339355469,
    "value_loss": 0.6077053397893906,
    "entropy": 0.14643384143710136,
    "total_loss": -1909.9794021323323
  },
  {
    "episode": 192,
    "avg_reward_per_step": 146.6504299499611,
    "episode_length": 137,
    "policy_loss": -2453.8579711914062,
    "value_loss": 0.6489807814359665,
    "entropy": 0.10124463587999344,
    "total_loss": -2453.2494882643223
  },
  {
    "episode": 193,
    "avg_reward_per_step": 122.892443772071,
    "episode_length": 163,
    "policy_loss": -2050.1867065429688,
    "value_loss": 0.6181638985872269,
    "entropy": 0.1118615623563528,
    "total_loss": -2049.6132872693242
  },
  {
    "episode": 194,
    "avg_reward_per_step": 152.34663731229213,
    "episode_length": 132,
    "policy_loss": -2547.794189453125,
    "value_loss": 0.6568162739276886,
    "entropy": 0.1262261737138033,
    "total_loss": -2547.1878636486827
  },
  {
    "episode": 195,
    "avg_reward_per_step": 157.00635669892347,
    "episode_length": 128,
    "policy_loss": -2624.2179565429688,
    "value_loss": 0.6630360931158066,
    "entropy": 0.1238804068416357,
    "total_loss": -2623.6044726125897
  },
  {
    "episode": 196,
    "avg_reward_per_step": 118.15533968521675,
    "episode_length": 170,
    "policy_loss": -1970.3283081054688,
    "value_loss": 0.6127491891384125,
    "entropy": 0.1336519680917263,
    "total_loss": -1969.769019703567
  },
  {
    "episode": 197,
    "avg_reward_per_step": 123.34360358526784,
    "episode_length": 163,
    "policy_loss": -2054.385498046875,
    "value_loss": 0.6190844476222992,
    "entropy": 0.13530399650335312,
    "total_loss": -2053.820535197854
  },
  {
    "episode": 198,
    "avg_reward_per_step": 114.39865636553135,
    "episode_length": 176,
    "policy_loss": -1908.6249694824219,
    "value_loss": 0.6083282381296158,
    "entropy": 0.1523204706609249,
    "total_loss": -1908.0775694325566
  },
  {
    "episode": 199,
    "avg_reward_per_step": 131.72475527956414,
    "episode_length": 153,
    "policy_loss": -2197.3919677734375,
    "value_loss": 0.6298442035913467,
    "entropy": 0.0906611941754818,
    "total_loss": -2196.7983880475163
  },
  {
    "episode": 200,
    "avg_reward_per_step": 149.0560006734251,
    "episode_length": 135,
    "policy_loss": -2489.2465209960938,
    "value_loss": 0.6523487716913223,
    "entropy": 0.08133969083428383,
    "total_loss": -2488.6267081007363
  },
  {
    "episode": 201,
    "avg_reward_per_step": 130.02648950420468,
    "episode_length": 155,
    "policy_loss": -2168.1951904296875,
    "value_loss": 0.6276268810033798,
    "entropy": 0.08684110268950462,
    "total_loss": -2167.60229998976
  },
  {
    "episode": 202,
    "avg_reward_per_step": 154.68089123526778,
    "episode_length": 130,
    "policy_loss": -2568.0443115234375,
    "value_loss": 0.6597563773393631,
    "entropy": 0.09445268660783768,
    "total_loss": -2567.4223362207413
  },
  {
    "episode": 203,
    "avg_reward_per_step": 147.8831841039349,
    "episode_length": 136,
    "policy_loss": -2467.2042236328125,
    "value_loss": 0.6504636704921722,
    "entropy": 0.08722999319434166,
    "total_loss": -2466.588651959598
  },
  {
    "episode": 204,
    "avg_reward_per_step": 134.97821133779343,
    "episode_length": 149,
    "policy_loss": -2250.249755859375,
    "value_loss": 0.6335013955831528,
    "entropy": 0.09348227269947529,
    "total_loss": -2249.6536473728715
  },
  {
    "episode": 205,
    "avg_reward_per_step": 142.96950477894865,
    "episode_length": 140,
    "policy_loss": -2384.8369140625,
    "value_loss": 0.6430162489414215,
    "entropy": 0.09303425997495651,
    "total_loss": -2384.2311115175485
  },
  {
    "episode": 206,
    "avg_reward_per_step": 115.78688407752797,
    "episode_length": 174,
    "policy_loss": -1925.7574157714844,
    "value_loss": 0.6101701855659485,
    "entropy": 0.10879676602780819,
    "total_loss": -1925.1907642923295
  },
  {
    "episode": 207,
    "avg_reward_per_step": 126.14086729985392,
    "episode_length": 160,
    "policy_loss": -2103.9212646484375,
    "value_loss": 0.6228126436471939,
    "entropy": 0.09894531220197678,
    "total_loss": -2103.338030129671
  },
  {
    "episode": 208,
    "avg_reward_per_step": 129.74280776068363,
    "episode_length": 155,
    "policy_loss": -2163.728759765625,
    "value_loss": 0.6265461146831512,
    "entropy": 0.07822090573608875,
    "total_loss": -2163.1335020132365
  },
  {
    "episode": 209,
    "avg_reward_per_step": 152.49890906710138,
    "episode_length": 132,
    "policy_loss": -2537.964111328125,
    "value_loss": 0.6565201431512833,
    "entropy": 0.08500158041715622,
    "total_loss": -2537.3415918171404
  },
  {
    "episode": 210,
    "avg_reward_per_step": 150.07601761000953,
    "episode_length": 134,
    "policy_loss": -2503.5586547851562,
    "value_loss": 0.6531770080327988,
    "entropy": 0.07868921384215355,
    "total_loss": -2502.9369534626603
  },
  {
    "episode": 211,
    "avg_reward_per_step": 150.02793074533182,
    "episode_length": 134,
    "policy_loss": -2498.5847778320312,
    "value_loss": 0.6530402600765228,
    "entropy": 0.08212325908243656,
    "total_loss": -2497.964586875588
  },
  {
    "episode": 212,
    "avg_reward_per_step": 152.41805300238698,
    "episode_length": 132,
    "policy_loss": -2540.5473022460938,
    "value_loss": 0.6564178019762039,
    "entropy": 0.08576365560293198,
    "total_loss": -2539.925189906359
  },
  {
    "episode": 213,
    "avg_reward_per_step": 155.89803498416978,
    "episode_length": 129,
    "policy_loss": -2593.3917236328125,
    "value_loss": 0.6610841602087021,
    "entropy": 0.07066925801336765,
    "total_loss": -2592.7589071758093
  },
  {
    "episode": 214,
    "avg_reward_per_step": 153.5243072237377,
    "episode_length": 131,
    "policy_loss": -2568.3832397460938,
    "value_loss": 0.6576915681362152,
    "entropy": 0.08403997123241425,
    "total_loss": -2567.7591641664503
  },
  {
    "episode": 215,
    "avg_reward_per_step": 138.96114184338435,
    "episode_length": 145,
    "policy_loss": -2312.7013549804688,
    "value_loss": 0.6385127305984497,
    "entropy": 0.08759268745779991,
    "total_loss": -2312.0978793248532
  },
  {
    "episode": 216,
    "avg_reward_per_step": 262.01398981116256,
    "episode_length": 77,
    "policy_loss": -4339.804931640625,
    "value_loss": 0.8484078645706177,
    "entropy": 0.0328457010909915,
    "total_loss": -4338.969662056491
  },
  {
    "episode": 217,
    "avg_reward_per_step": 156.95120750960527,
    "episode_length": 128,
    "policy_loss": -2612.358154296875,
    "value_loss": 0.6621186882257462,
    "entropy": 0.05308920703828335,
    "total_loss": -2611.7172712914644
  },
  {
    "episode": 218,
    "avg_reward_per_step": 157.2242135220809,
    "episode_length": 128,
    "policy_loss": -2613.6715087890625,
    "value_loss": 0.66280297935009,
    "entropy": 0.06056517921388149,
    "total_loss": -2613.032931881398
  },
  {
    "episode": 219,
    "avg_reward_per_step": 153.5297278038688,
    "episode_length": 131,
    "policy_loss": -2557.554443359375,
    "value_loss": 0.6573934108018875,
    "entropy": 0.08428290858864784,
    "total_loss": -2556.9307631120087
  },
  {
    "episode": 220,
    "avg_reward_per_step": 155.9086132252297,
    "episode_length": 129,
    "policy_loss": -2588.8558349609375,
    "value_loss": 0.6607553958892822,
    "entropy": 0.053939154371619225,
    "total_loss": -2588.216655226797
  },
  {
    "episode": 221,
    "avg_reward_per_step": 157.24736548554512,
    "episode_length": 128,
    "policy_loss": -2619.5553588867188,
    "value_loss": 0.6627239435911179,
    "entropy": 0.0627718111500144,
    "total_loss": -2618.9177436675877
  },
  {
    "episode": 222,
    "avg_reward_per_step": 154.73039115677625,
    "episode_length": 130,
    "policy_loss": -2574.6614990234375,
    "value_loss": 0.6590209901332855,
    "entropy": 0.06830159947276115,
    "total_loss": -2574.0297986730934
  },
  {
    "episode": 223,
    "avg_reward_per_step": 155.9135958310486,
    "episode_length": 129,
    "policy_loss": -2597.6134033203125,
    "value_loss": 0.66060571372509,
    "entropy": 0.05907662119716406,
    "total_loss": -2596.9764282550664
  },
  {
    "episode": 224,
    "avg_reward_per_step": 157.10753746443487,
    "episode_length": 128,
    "policy_loss": -2612.3739013671875,
    "value_loss": 0.6621296256780624,
    "entropy": 0.060912469401955605,
    "total_loss": -2611.73613672927
  },
  {
    "episode": 225,
    "avg_reward_per_step": 146.8979624594684,
    "episode_length": 137,
    "policy_loss": -2443.3072509765625,
    "value_loss": 0.648291826248169,
    "entropy": 0.07143856585025787,
    "total_loss": -2442.6875345766543
  },
  {
    "episode": 226,
    "avg_reward_per_step": 154.70425944753717,
    "episode_length": 130,
    "policy_loss": -2571.4815063476562,
    "value_loss": 0.6587046235799789,
    "entropy": 0.057802057825028896,
    "total_loss": -2570.845922547206
  },
  {
    "episode": 227,
    "avg_reward_per_step": 152.22552008909517,
    "episode_length": 132,
    "policy_loss": -2532.5977172851562,
    "value_loss": 0.6549955010414124,
    "entropy": 0.06666306033730507,
    "total_loss": -2531.9693870082497
  },
  {
    "episode": 228,
    "avg_reward_per_step": 150.89879242314717,
    "episode_length": 133,
    "policy_loss": -2504.2442016601562,
    "value_loss": 0.6528528928756714,
    "entropy": 0.07272171042859554,
    "total_loss": -2503.620437451452
  },
  {
    "episode": 229,
    "avg_reward_per_step": 155.99914070176183,
    "episode_length": 129,
    "policy_loss": -2588.8385009765625,
    "value_loss": 0.6604035496711731,
    "entropy": 0.07665791735053062,
    "total_loss": -2588.2087605938314
  },
  {
    "episode": 230,
    "avg_reward_per_step": 154.70351226795654,
    "episode_length": 130,
    "policy_loss": -2565.0908813476562,
    "value_loss": 0.6584766060113907,
    "entropy": 0.07447607070207596,
    "total_loss": -2564.4621951699255
  },
  {
    "episode": 231,
    "avg_reward_per_step": 159.6825669256949,
    "episode_length": 126,
    "policy_loss": -2652.6292114257812,
    "value_loss": 0.6653502583503723,
    "entropy": 0.07355059310793877,
    "total_loss": -2651.9932814046742
  },
  {
    "episode": 232,
    "avg_reward_per_step": 155.91274698768663,
    "episode_length": 129,
    "policy_loss": -2591.4512939453125,
    "value_loss": 0.6601235866546631,
    "entropy": 0.052261595614254475,
    "total_loss": -2590.8120749969034
  },
  {
    "episode": 233,
    "avg_reward_per_step": 161.0365675243535,
    "episode_length": 125,
    "policy_loss": -2672.1984252929688,
    "value_loss": 0.6673363447189331,
    "entropy": 0.07103427685797215,
    "total_loss": -2671.559502658993
  },
  {
    "episode": 234,
    "avg_reward_per_step": 157.12474572325746,
    "episode_length": 128,
    "policy_loss": -2606.7505493164062,
    "value_loss": 0.6616755425930023,
    "entropy": 0.049769895151257515,
    "total_loss": -2606.108781731874
  },
  {
    "episode": 235,
    "avg_reward_per_step": 152.2689045392867,
    "episode_length": 132,
    "policy_loss": -2532.7919311523438,
    "value_loss": 0.6548450589179993,
    "entropy": 0.076637277379632,
    "total_loss": -2532.1677410043776
  },
  {
    "episode": 236,
    "avg_reward_per_step": 155.91274698768663,
    "episode_length": 129,
    "policy_loss": -2587.0958862304688,
    "value_loss": 0.6598463207483292,
    "entropy": 0.05097639374434948,
    "total_loss": -2586.456430467218
  },
  {
    "episode": 237,
    "avg_reward_per_step": 157.29435496420695,
    "episode_length": 128,
    "policy_loss": -2611.1981811523438,
    "value_loss": 0.661904513835907,
    "entropy": 0.054732244461774826,
    "total_loss": -2610.5581695362926
  },
  {
    "episode": 238,
    "avg_reward_per_step": 161.1600661555877,
    "episode_length": 125,
    "policy_loss": -2672.1620483398438,
    "value_loss": 0.6673265248537064,
    "entropy": 0.06446393020451069,
    "total_loss": -2671.520507387072
  },
  {
    "episode": 239,
    "avg_reward_per_step": 151.06697109982622,
    "episode_length": 133,
    "policy_loss": -2503.1484985351562,
    "value_loss": 0.6527910679578781,
    "entropy": 0.05573216825723648,
    "total_loss": -2502.5180003345013
  },
  {
    "episode": 240,
    "avg_reward_per_step": 155.9135958310486,
    "episode_length": 129,
    "policy_loss": -2587.0835571289062,
    "value_loss": 0.6596783548593521,
    "entropy": 0.05408165790140629,
    "total_loss": -2586.4455114372076
  },
  {
    "episode": 241,
    "avg_reward_per_step": 155.93825793967238,
    "episode_length": 129,
    "policy_loss": -2585.19970703125,
    "value_loss": 0.6596290618181229,
    "entropy": 0.06265402026474476,
    "total_loss": -2584.5651395775376
  },
  {
    "episode": 242,
    "avg_reward_per_step": 155.89749551800455,
    "episode_length": 129,
    "policy_loss": -2589.212646484375,
    "value_loss": 0.6595965623855591,
    "entropy": 0.054189933463931084,
    "total_loss": -2588.574725895375
  },
  {
    "episode": 243,
    "avg_reward_per_step": 262.01398981116256,
    "episode_length": 77,
    "policy_loss": -4325.8367919921875,
    "value_loss": 0.8466021120548248,
    "entropy": 0.0322473905980587,
    "total_loss": -4325.003088836372
  },
  {
    "episode": 244,
    "avg_reward_per_step": 146.799374497677,
    "episode_length": 137,
    "policy_loss": -2413.3998413085938,
    "value_loss": 0.6469755321741104,
    "entropy": 0.07915367186069489,
    "total_loss": -2412.784527245164
  },
  {
    "episode": 245,
    "avg_reward_per_step": 137.77993067152659,
    "episode_length": 146,
    "policy_loss": -2278.8438720703125,
    "value_loss": 0.6352416574954987,
    "entropy": 0.0674302838742733,
    "total_loss": -2278.2356025263666
  },
  {
    "episode": 246,
    "avg_reward_per_step": 155.7559466546293,
    "episode_length": 129,
    "policy_loss": -2576.3496704101562,
    "value_loss": 0.6590358912944794,
    "entropy": 0.0738100316375494,
    "total_loss": -2575.720158531517
  },
  {
    "episode": 247,
    "avg_reward_per_step": 155.92019033630083,
    "episode_length": 129,
    "policy_loss": -2577.120361328125,
    "value_loss": 0.6594617664813995,
    "entropy": 0.053067877888679504,
    "total_loss": -2576.482126712799
  },
  {
    "episode": 248,
    "avg_reward_per_step": 151.24065571841075,
    "episode_length": 133,
    "policy_loss": -2506.9664916992188,
    "value_loss": 0.6528904885053635,
    "entropy": 0.07007577270269394,
    "total_loss": -2506.3416315197946
  },
  {
    "episode": 249,
    "avg_reward_per_step": 141.8281620119435,
    "episode_length": 142,
    "policy_loss": -2336.8665771484375,
    "value_loss": 0.6405264288187027,
    "entropy": 0.07927728444337845,
    "total_loss": -2336.257761633396
  },
  {
    "episode": 250,
    "avg_reward_per_step": 262.01398981116256,
    "episode_length": 77,
    "policy_loss": -4319.0521240234375,
    "value_loss": 0.8461557030677795,
    "entropy": 0.033064099960029125,
    "total_loss": -4318.219193960354
  },
  {
    "episode": 251,
    "avg_reward_per_step": 137.03001584093442,
    "episode_length": 147,
    "policy_loss": -2264.05224609375,
    "value_loss": 0.6339764595031738,
    "entropy": 0.06530296057462692,
    "total_loss": -2263.4443908184767
  },
  {
    "episode": 252,
    "avg_reward_per_step": 157.21601651749404,
    "episode_length": 128,
    "policy_loss": -2589.0780029296875,
    "value_loss": 0.6606809198856354,
    "entropy": 0.05452764220535755,
    "total_loss": -2588.439133066684
  },
  {
    "episode": 253,
    "avg_reward_per_step": 154.71936645085245,
    "episode_length": 130,
    "policy_loss": -2557.9945678710938,
    "value_loss": 0.6573555171489716,
    "entropy": 0.06881094165146351,
    "total_loss": -2557.3647367306053
  },
  {
    "episode": 254,
    "avg_reward_per_step": 262.01398981116256,
    "episode_length": 77,
    "policy_loss": -4318.548828125,
    "value_loss": 0.8457882851362228,
    "entropy": 0.03061197977513075,
    "total_loss": -4317.715284631774
  },
  {
    "episode": 255,
    "avg_reward_per_step": 154.71936645085245,
    "episode_length": 130,
    "policy_loss": -2556.7854614257812,
    "value_loss": 0.6571168005466461,
    "entropy": 0.05903219897300005,
    "total_loss": -2556.1519575048237
  },
  {
    "episode": 256,
    "avg_reward_per_step": 148.81896823380293,
    "episode_length": 135,
    "policy_loss": -2443.4588623046875,
    "value_loss": 0.6487473398447037,
    "entropy": 0.06818031333386898,
    "total_loss": -2442.8373870901764
  },
  {
    "episode": 257,
    "avg_reward_per_step": 134.17217409534172,
    "episode_length": 150,
    "policy_loss": -2200.2506713867188,
    "value_loss": 0.6298893094062805,
    "entropy": 0.06756111420691013,
    "total_loss": -2199.6478065229953
  },
  {
    "episode": 258,
    "avg_reward_per_step": 157.08201397822305,
    "episode_length": 128,
    "policy_loss": -2595.7061767578125,
    "value_loss": 0.6602858453989029,
    "entropy": 0.05196764785796404,
    "total_loss": -2595.0666779715566
  },
  {
    "episode": 259,
    "avg_reward_per_step": 157.1458178795935,
    "episode_length": 128,
    "policy_loss": -2596.2676391601562,
    "value_loss": 0.6603811085224152,
    "entropy": 0.05167621932923794,
    "total_loss": -2595.6279285393657
  },
  {
    "episode": 260,
    "avg_reward_per_step": 157.12614348223423,
    "episode_length": 128,
    "policy_loss": -2595.112548828125,
    "value_loss": 0.6601927876472473,
    "entropy": 0.05186257977038622,
    "total_loss": -2594.473101072386
  },
  {
    "episode": 261,
    "avg_reward_per_step": 157.12560111434718,
    "episode_length": 128,
    "policy_loss": -2592.0718383789062,
    "value_loss": 0.6601421684026718,
    "entropy": 0.051272409968078136,
    "total_loss": -2591.4322051744907
  },
  {
    "episode": 262,
    "avg_reward_per_step": 157.10753746443487,
    "episode_length": 128,
    "policy_loss": -2591.4462890625,
    "value_loss": 0.6599184423685074,
    "entropy": 0.04978328291326761,
    "total_loss": -2590.806283933297
  },
  {
    "episode": 263,
    "avg_reward_per_step": 148.9204064060102,
    "episode_length": 135,
    "policy_loss": -2461.9110717773438,
    "value_loss": 0.6486057937145233,
    "entropy": 0.061907293274998665,
    "total_loss": -2461.287228900939
  },
  {
    "episode": 264,
    "avg_reward_per_step": 135.98119198962806,
    "episode_length": 148,
    "policy_loss": -2240.9889526367188,
    "value_loss": 0.6317224949598312,
    "entropy": 0.05639520846307278,
    "total_loss": -2240.3797882251442
  },
  {
    "episode": 265,
    "avg_reward_per_step": 262.01398981116256,
    "episode_length": 77,
    "policy_loss": -4312.2354736328125,
    "value_loss": 0.8448607921600342,
    "entropy": 0.04032989498227835,
    "total_loss": -4311.406744798645
  },
  {
    "episode": 266,
    "avg_reward_per_step": 155.9151913074449,
    "episode_length": 129,
    "policy_loss": -2574.098876953125,
    "value_loss": 0.6580588072538376,
    "entropy": 0.054642967879772186,
    "total_loss": -2573.462675333023
  },
  {
    "episode": 267,
    "avg_reward_per_step": 158.36111926722475,
    "episode_length": 127,
    "policy_loss": -2611.6846923828125,
    "value_loss": 0.6612742692232132,
    "entropy": 0.06748018972575665,
    "total_loss": -2611.0504101894794
  },
  {
    "episode": 268,
    "avg_reward_per_step": 157.12338898014934,
    "episode_length": 128,
    "policy_loss": -2591.084228515625,
    "value_loss": 0.6597084701061249,
    "entropy": 0.03955491632223129,
    "total_loss": -2590.440342012048
  },
  {
    "episode": 269,
    "avg_reward_per_step": 157.12474572325746,
    "episode_length": 128,
    "policy_loss": -2587.2255249023438,
    "value_loss": 0.6596143543720245,
    "entropy": 0.04495565965771675,
    "total_loss": -2586.5838928118346
  },
  {
    "episode": 270,
    "avg_reward_per_step": 155.91274698768663,
    "episode_length": 129,
    "policy_loss": -2568.642578125,
    "value_loss": 0.6578471213579178,
    "entropy": 0.04316829238086939,
    "total_loss": -2568.0019983205943
  },
  {
    "episode": 271,
    "avg_reward_per_step": 155.91295457496184,
    "episode_length": 129,
    "policy_loss": -2568.7127075195312,
    "value_loss": 0.6576986163854599,
    "entropy": 0.057081313803792,
    "total_loss": -2568.0778414286674
  },
  {
    "episode": 272,
    "avg_reward_per_step": 158.2382826067282,
    "episode_length": 127,
    "policy_loss": -2609.0775146484375,
    "value_loss": 0.6605515033006668,
    "entropy": 0.06507119070738554,
    "total_loss": -2608.44299162142
  },
  {
    "episode": 273,
    "avg_reward_per_step": 262.01398981116256,
    "episode_length": 77,
    "policy_loss": -4306.073974609375,
    "value_loss": 0.8441915363073349,
    "entropy": 0.03264151606708765,
    "total_loss": -4305.242839679495
  },
  {
    "episode": 274,
    "avg_reward_per_step": 159.50619786342355,
    "episode_length": 126,
    "policy_loss": -2625.4334716796875,
    "value_loss": 0.6621423661708832,
    "entropy": 0.05936854425817728,
    "total_loss": -2624.79507673122
  },
  {
    "episode": 275,
    "avg_reward_per_step": 262.1379445733777,
    "episode_length": 77,
    "policy_loss": -4311.4891357421875,
    "value_loss": 0.8445052206516266,
    "entropy": 0.03497621929273009,
    "total_loss": -4310.658621009253
  },
  {
    "episode": 276,
    "avg_reward_per_step": 155.9128289054221,
    "episode_length": 129,
    "policy_loss": -2568.9957275390625,
    "value_loss": 0.657310888171196,
    "entropy": 0.051117509603500366,
    "total_loss": -2568.358863654733
  },
  {
    "episode": 277,
    "avg_reward_per_step": 162.3214110043128,
    "episode_length": 124,
    "policy_loss": -2671.241943359375,
    "value_loss": 0.6664213687181473,
    "entropy": 0.06430155783891678,
    "total_loss": -2670.6012426137922
  },
  {
    "episode": 278,
    "avg_reward_per_step": 158.48243026021825,
    "episode_length": 127,
    "policy_loss": -2607.4647827148438,
    "value_loss": 0.6610949635505676,
    "entropy": 0.04741713311523199,
    "total_loss": -2606.8226546045394
  },
  {
    "episode": 279,
    "avg_reward_per_step": 161.07869645848473,
    "episode_length": 125,
    "policy_loss": -2648.8068237304688,
    "value_loss": 0.6645215898752213,
    "entropy": 0.040813397616147995,
    "total_loss": -2648.15862749964
  },
  {
    "episode": 280,
    "avg_reward_per_step": 158.48243026021825,
    "episode_length": 127,
    "policy_loss": -2604.746826171875,
    "value_loss": 0.6609330028295517,
    "entropy": 0.04514694772660732,
    "total_loss": -2604.103951948136
  },
  {
    "episode": 281,
    "avg_reward_per_step": 161.07869645848473,
    "episode_length": 125,
    "policy_loss": -2645.3848876953125,
    "value_loss": 0.6643452644348145,
    "entropy": 0.04023097828030586,
    "total_loss": -2644.73663482219
  },
  {
    "episode": 282,
    "avg_reward_per_step": 158.48243026021825,
    "episode_length": 127,
    "policy_loss": -2602.5897827148438,
    "value_loss": 0.6607948243618011,
    "entropy": 0.042224498465657234,
    "total_loss": -2601.945877689868
  },
  {
    "episode": 283,
    "avg_reward_per_step": 158.48243026021825,
    "episode_length": 127,
    "policy_loss": -2602.4131469726562,
    "value_loss": 0.6607180237770081,
    "entropy": 0.04139739740639925,
    "total_loss": -2601.7689879078416
  },
  {
    "episode": 284,
    "avg_reward_per_step": 161.06064136011696,
    "episode_length": 125,
    "policy_loss": -2644.9218139648438,
    "value_loss": 0.6641341000795364,
    "entropy": 0.04292318411171436,
    "total_loss": -2644.274849138409
  },
  {
    "episode": 285,
    "avg_reward_per_step": 159.81555142639175,
    "episode_length": 126,
    "policy_loss": -2629.284423828125,
    "value_loss": 0.6624156385660172,
    "entropy": 0.04700672626495361,
    "total_loss": -2628.640810880065
  },
  {
    "episode": 286,
    "avg_reward_per_step": 154.5333287357871,
    "episode_length": 130,
    "policy_loss": -2540.8793334960938,
    "value_loss": 0.6551478505134583,
    "entropy": 0.07209323532879353,
    "total_loss": -2540.2530229397116
  },
  {
    "episode": 287,
    "avg_reward_per_step": 162.34833912663984,
    "episode_length": 124,
    "policy_loss": -2665.1600952148438,
    "value_loss": 0.6655903160572052,
    "entropy": 0.05866617150604725,
    "total_loss": -2664.517971367389
  },
  {
    "episode": 288,
    "avg_reward_per_step": 161.06066697077748,
    "episode_length": 125,
    "policy_loss": -2660.9566650390625,
    "value_loss": 0.6636508256196976,
    "entropy": 0.045660234056413174,
    "total_loss": -2660.3112783070655
  },
  {
    "episode": 289,
    "avg_reward_per_step": 162.32143682149024,
    "episode_length": 124,
    "policy_loss": -2658.1653442382812,
    "value_loss": 0.6653402745723724,
    "entropy": 0.05740734376013279,
    "total_loss": -2657.522966901213
  },
  {
    "episode": 290,
    "avg_reward_per_step": 162.34427610615847,
    "episode_length": 124,
    "policy_loss": -2647.3480834960938,
    "value_loss": 0.6653286665678024,
    "entropy": 0.0673098023980856,
    "total_loss": -2646.709678750485
  },
  {
    "episode": 291,
    "avg_reward_per_step": 146.85325272477164,
    "episode_length": 137,
    "policy_loss": -2411.2064819335938,
    "value_loss": 0.6438567191362381,
    "entropy": 0.07158549502491951,
    "total_loss": -2410.5912594124675
  },
  {
    "episode": 292,
    "avg_reward_per_step": 158.38644531864102,
    "episode_length": 127,
    "policy_loss": -2606.4671020507812,
    "value_loss": 0.659224346280098,
    "entropy": 0.06774172000586987,
    "total_loss": -2605.8349743925037
  },
  {
    "episode": 293,
    "avg_reward_per_step": 155.91590223758934,
    "episode_length": 129,
    "policy_loss": -2549.4497680664062,
    "value_loss": 0.6563083380460739,
    "entropy": 0.06000668089836836,
    "total_loss": -2548.8174624007197
  },
  {
    "episode": 294,
    "avg_reward_per_step": 157.0197405779742,
    "episode_length": 128,
    "policy_loss": -2516.8090209960938,
    "value_loss": 0.657523438334465,
    "entropy": 0.07281550392508507,
    "total_loss": -2516.180623759329
  },
  {
    "episode": 295,
    "avg_reward_per_step": 162.3491631458346,
    "episode_length": 124,
    "policy_loss": -2662.2372436523438,
    "value_loss": 0.665326327085495,
    "entropy": 0.053491647355258465,
    "total_loss": -2661.5933139842004
  },
  {
    "episode": 296,
    "avg_reward_per_step": 158.3069214900177,
    "episode_length": 127,
    "policy_loss": -2582.419677734375,
    "value_loss": 0.6591688543558121,
    "entropy": 0.06399847287684679,
    "total_loss": -2581.7861082691697
  },
  {
    "episode": 297,
    "avg_reward_per_step": 163.8560223765822,
    "episode_length": 123,
    "policy_loss": -2685.2073974609375,
    "value_loss": 0.6672427356243134,
    "entropy": 0.038770440965890884,
    "total_loss": -2684.5556629016996
  },
  {
    "episode": 298,
    "avg_reward_per_step": 163.8364951692824,
    "episode_length": 123,
    "policy_loss": -2685.945556640625,
    "value_loss": 0.667091503739357,
    "entropy": 0.03162275208160281,
    "total_loss": -2685.2911142377184
  },
  {
    "episode": 299,
    "avg_reward_per_step": 163.82907241618676,
    "episode_length": 123,
    "policy_loss": -2680.537353515625,
    "value_loss": 0.6670006066560745,
    "entropy": 0.026457186322659254,
    "total_loss": -2679.880935783498
  },
  {
    "episode": 300,
    "avg_reward_per_step": 163.8364951692824,
    "episode_length": 123,
    "policy_loss": -2685.3322143554688,
    "value_loss": 0.6667773127555847,
    "entropy": 0.03479508310556412,
    "total_loss": -2684.6793550759553
  }
]