[
  {
    "episode": 1,
    "avg_reward_per_step": -2.784420983342087,
    "episode_length": 3000,
    "policy_loss": 25.17641019821167,
    "value_loss": 1.2150003015995026,
    "entropy": 1.3523229360580444,
    "total_loss": 25.850481325387953
  },
  {
    "episode": 2,
    "avg_reward_per_step": 22.355538266130363,
    "episode_length": 827,
    "policy_loss": -208.0363883972168,
    "value_loss": 0.5085322260856628,
    "entropy": 1.3445159196853638,
    "total_loss": -208.06566253900527
  },
  {
    "episode": 3,
    "avg_reward_per_step": -2.272216443504737,
    "episode_length": 3000,
    "policy_loss": 20.816895484924316,
    "value_loss": 1.2594181895256042,
    "entropy": 1.3543446063995361,
    "total_loss": 21.534575831890105
  },
  {
    "episode": 4,
    "avg_reward_per_step": 18.94041623825392,
    "episode_length": 940,
    "policy_loss": -177.77988052368164,
    "value_loss": 0.5069245845079422,
    "entropy": 1.346094697713852,
    "total_loss": -177.81139381825923
  },
  {
    "episode": 5,
    "avg_reward_per_step": 23.356904872249594,
    "episode_length": 770,
    "policy_loss": -217.35423278808594,
    "value_loss": 0.5086523592472076,
    "entropy": 1.3149235248565674,
    "total_loss": -217.37154983878136
  },
  {
    "episode": 6,
    "avg_reward_per_step": 8.086634048298018,
    "episode_length": 1843,
    "policy_loss": -76.49053764343262,
    "value_loss": 0.5023729354143143,
    "entropy": 1.3235443234443665,
    "total_loss": -76.51758243739604
  },
  {
    "episode": 7,
    "avg_reward_per_step": 28.31713100909592,
    "episode_length": 642,
    "policy_loss": -262.49483489990234,
    "value_loss": 0.5106793493032455,
    "entropy": 1.3015292286872864,
    "total_loss": -262.504767242074
  },
  {
    "episode": 8,
    "avg_reward_per_step": 5.85021411647827,
    "episode_length": 1797,
    "policy_loss": -55.93043231964111,
    "value_loss": 0.5010733306407928,
    "entropy": 1.3113340139389038,
    "total_loss": -55.95389259457588
  },
  {
    "episode": 9,
    "avg_reward_per_step": 2.771991466144918,
    "episode_length": 2268,
    "policy_loss": -28.214183807373047,
    "value_loss": 0.500164195895195,
    "entropy": 1.3294786512851715,
    "total_loss": -28.24581107199192
  },
  {
    "episode": 10,
    "avg_reward_per_step": 4.518138402143337,
    "episode_length": 1877,
    "policy_loss": -43.280235290527344,
    "value_loss": 0.5005725473165512,
    "entropy": 1.326769083738327,
    "total_loss": -43.310370376706125
  },
  {
    "episode": 11,
    "avg_reward_per_step": 34.42478665643513,
    "episode_length": 504,
    "policy_loss": -320.74005126953125,
    "value_loss": 0.5123202055692673,
    "entropy": 1.3074278235435486,
    "total_loss": -320.7507021933794
  },
  {
    "episode": 12,
    "avg_reward_per_step": -4.729280470903802,
    "episode_length": 3000,
    "policy_loss": 43.07091426849365,
    "value_loss": 1.52909654378891,
    "entropy": 1.3191673159599304,
    "total_loss": 44.07234388589859
  },
  {
    "episode": 13,
    "avg_reward_per_step": 23.052976251902248,
    "episode_length": 764,
    "policy_loss": -215.58193588256836,
    "value_loss": 0.5083404332399368,
    "entropy": 1.311834990978241,
    "total_loss": -215.5983294457197
  },
  {
    "episode": 14,
    "avg_reward_per_step": -3.049340927284037,
    "episode_length": 3000,
    "policy_loss": 27.585251331329346,
    "value_loss": 1.2248843312263489,
    "entropy": 1.305782675743103,
    "total_loss": 28.287822592258454
  },
  {
    "episode": 15,
    "avg_reward_per_step": 28.890098700003435,
    "episode_length": 655,
    "policy_loss": -267.32848358154297,
    "value_loss": 0.511434406042099,
    "entropy": 1.303105503320694,
    "total_loss": -267.33829137682915
  },
  {
    "episode": 16,
    "avg_reward_per_step": 8.852739485480871,
    "episode_length": 1877,
    "policy_loss": -82.79887008666992,
    "value_loss": 0.5029819905757904,
    "entropy": 1.3023304343223572,
    "total_loss": -82.81682026982307
  },
  {
    "episode": 17,
    "avg_reward_per_step": 59.35212247417414,
    "episode_length": 329,
    "policy_loss": -552.3039245605469,
    "value_loss": 0.5249785333871841,
    "entropy": 1.2958323955535889,
    "total_loss": -552.2972789853811
  },
  {
    "episode": 18,
    "avg_reward_per_step": 31.132140462695475,
    "episode_length": 588,
    "policy_loss": -290.39735412597656,
    "value_loss": 0.5118509382009506,
    "entropy": 1.2719353437423706,
    "total_loss": -290.3942773252726
  },
  {
    "episode": 19,
    "avg_reward_per_step": 25.953693917426065,
    "episode_length": 681,
    "policy_loss": -243.76853942871094,
    "value_loss": 0.5094846934080124,
    "entropy": 1.2605909407138824,
    "total_loss": -243.76329111158847
  },
  {
    "episode": 20,
    "avg_reward_per_step": 56.549856575613695,
    "episode_length": 332,
    "policy_loss": -520.1082916259766,
    "value_loss": 0.5226994901895523,
    "entropy": 1.2313523292541504,
    "total_loss": -520.0781330674887
  },
  {
    "episode": 21,
    "avg_reward_per_step": 9.362916299491452,
    "episode_length": 1210,
    "policy_loss": -87.3438949584961,
    "value_loss": 0.5019288212060928,
    "entropy": 1.189728170633316,
    "total_loss": -87.31785740554332
  },
  {
    "episode": 22,
    "avg_reward_per_step": 3.09959949773448,
    "episode_length": 2166,
    "policy_loss": -28.53670883178711,
    "value_loss": 0.5002444088459015,
    "entropy": 1.1978694796562195,
    "total_loss": -28.515612214803696
  },
  {
    "episode": 23,
    "avg_reward_per_step": 4.001560555764588,
    "episode_length": 1918,
    "policy_loss": -37.29967975616455,
    "value_loss": 0.500424325466156,
    "entropy": 1.1638746559619904,
    "total_loss": -37.26480529308319
  },
  {
    "episode": 24,
    "avg_reward_per_step": 5.397778451712316,
    "episode_length": 1744,
    "policy_loss": -50.06950664520264,
    "value_loss": 0.500844269990921,
    "entropy": 1.1841018497943878,
    "total_loss": -50.04230311512947
  },
  {
    "episode": 25,
    "avg_reward_per_step": 16.475505551098717,
    "episode_length": 835,
    "policy_loss": -152.63318634033203,
    "value_loss": 0.5044013857841492,
    "entropy": 1.142185091972351,
    "total_loss": -152.58565899133683
  },
  {
    "episode": 26,
    "avg_reward_per_step": 14.469857369839849,
    "episode_length": 904,
    "policy_loss": -133.79208374023438,
    "value_loss": 0.5036176890134811,
    "entropy": 1.1429431736469269,
    "total_loss": -133.74564332067968
  },
  {
    "episode": 27,
    "avg_reward_per_step": 11.758802982987657,
    "episode_length": 1053,
    "policy_loss": -110.68317031860352,
    "value_loss": 0.5027276128530502,
    "entropy": 1.133531630039215,
    "total_loss": -110.63385535776615
  },
  {
    "episode": 28,
    "avg_reward_per_step": 7.27250228555161,
    "episode_length": 1492,
    "policy_loss": -66.9799861907959,
    "value_loss": 0.501406729221344,
    "entropy": 1.1572616398334503,
    "total_loss": -66.94148411750794
  },
  {
    "episode": 29,
    "avg_reward_per_step": -0.7096947951020465,
    "episode_length": 2710,
    "policy_loss": 6.26537549495697,
    "value_loss": 0.49984751641750336,
    "entropy": 1.1215927004814148,
    "total_loss": 6.3165859311819075
  },
  {
    "episode": 30,
    "avg_reward_per_step": 81.5320399643862,
    "episode_length": 240,
    "policy_loss": -755.7778778076172,
    "value_loss": 0.5350832790136337,
    "entropy": 1.2546890079975128,
    "total_loss": -755.7446701318025
  },
  {
    "episode": 31,
    "avg_reward_per_step": 1.9653012943938555,
    "episode_length": 2464,
    "policy_loss": -18.49928569793701,
    "value_loss": 0.5000177472829819,
    "entropy": 1.1942560970783234,
    "total_loss": -18.47697038948536
  },
  {
    "episode": 32,
    "avg_reward_per_step": 16.761877508516996,
    "episode_length": 887,
    "policy_loss": -155.08734512329102,
    "value_loss": 0.5049380660057068,
    "entropy": 1.1282885074615479,
    "total_loss": -155.03372246026993
  },
  {
    "episode": 33,
    "avg_reward_per_step": 23.394793508713125,
    "episode_length": 666,
    "policy_loss": -217.93925094604492,
    "value_loss": 0.5073260068893433,
    "entropy": 1.1276129186153412,
    "total_loss": -217.8829701066017
  },
  {
    "episode": 34,
    "avg_reward_per_step": 25.674035975525673,
    "episode_length": 670,
    "policy_loss": -239.52700424194336,
    "value_loss": 0.5090759694576263,
    "entropy": 1.2036473453044891,
    "total_loss": -239.49938721060752
  },
  {
    "episode": 35,
    "avg_reward_per_step": 9.066981754333609,
    "episode_length": 1546,
    "policy_loss": -85.99942970275879,
    "value_loss": 0.5024799704551697,
    "entropy": 1.1845378577709198,
    "total_loss": -85.97076487541199
  },
  {
    "episode": 36,
    "avg_reward_per_step": 24.747339542090323,
    "episode_length": 705,
    "policy_loss": -231.81044387817383,
    "value_loss": 0.5088735222816467,
    "entropy": 1.1541659832000732,
    "total_loss": -231.76323674917222
  },
  {
    "episode": 37,
    "avg_reward_per_step": 21.323070653623073,
    "episode_length": 889,
    "policy_loss": -201.42330932617188,
    "value_loss": 0.5084019601345062,
    "entropy": 1.1684396862983704,
    "total_loss": -201.38228324055672
  },
  {
    "episode": 38,
    "avg_reward_per_step": 44.090528707273414,
    "episode_length": 440,
    "policy_loss": -419.54618072509766,
    "value_loss": 0.5181248188018799,
    "entropy": 1.0730036199092865,
    "total_loss": -419.45725735425947
  },
  {
    "episode": 39,
    "avg_reward_per_step": 38.421823123820616,
    "episode_length": 473,
    "policy_loss": -363.28382110595703,
    "value_loss": 0.5145329982042313,
    "entropy": 0.9153965711593628,
    "total_loss": -363.1354467362165
  },
  {
    "episode": 40,
    "avg_reward_per_step": 46.69044534843805,
    "episode_length": 388,
    "policy_loss": -437.0735321044922,
    "value_loss": 0.5177448093891144,
    "entropy": 0.9314828515052795,
    "total_loss": -436.9283804357052
  },
  {
    "episode": 41,
    "avg_reward_per_step": 49.31668853419547,
    "episode_length": 381,
    "policy_loss": -453.3126220703125,
    "value_loss": 0.5196126252412796,
    "entropy": 0.9149228185415268,
    "total_loss": -453.15897857248785
  },
  {
    "episode": 42,
    "avg_reward_per_step": -3.812502095719806,
    "episode_length": 2547,
    "policy_loss": 34.30178165435791,
    "value_loss": 0.5005766749382019,
    "entropy": 0.6942373216152191,
    "total_loss": 34.52466340065003
  },
  {
    "episode": 43,
    "avg_reward_per_step": 132.54759901030084,
    "episode_length": 150,
    "policy_loss": -1235.6206359863281,
    "value_loss": 0.5608003437519073,
    "entropy": 0.9970828294754028,
    "total_loss": -1235.4586687743663
  },
  {
    "episode": 44,
    "avg_reward_per_step": 1.1016944123760124,
    "episode_length": 1464,
    "policy_loss": -9.17721700668335,
    "value_loss": 0.4996989890933037,
    "entropy": 0.6130795329809189,
    "total_loss": -8.922749830782413
  },
  {
    "episode": 45,
    "avg_reward_per_step": -0.9248138485499543,
    "episode_length": 1845,
    "policy_loss": 7.939871072769165,
    "value_loss": 0.49976426362991333,
    "entropy": 0.6819026619195938,
    "total_loss": 8.16687427163124
  },
  {
    "episode": 46,
    "avg_reward_per_step": 0.45267412623632824,
    "episode_length": 1480,
    "policy_loss": -4.588702082633972,
    "value_loss": 0.49967116117477417,
    "entropy": 0.6148394495248795,
    "total_loss": -4.33496670126915
  },
  {
    "episode": 47,
    "avg_reward_per_step": 183.06801664446718,
    "episode_length": 109,
    "policy_loss": -1696.5144958496094,
    "value_loss": 0.5888367891311646,
    "entropy": 0.9574925154447556,
    "total_loss": -1696.308656066656
  },
  {
    "episode": 48,
    "avg_reward_per_step": -13.737455947460434,
    "episode_length": 3000,
    "policy_loss": 126.22758674621582,
    "value_loss": 2.773723602294922,
    "entropy": 0.5782102048397064,
    "total_loss": 128.77002626657486
  },
  {
    "episode": 49,
    "avg_reward_per_step": -14.145191039784425,
    "episode_length": 3000,
    "policy_loss": 129.56646728515625,
    "value_loss": 2.9797080755233765,
    "entropy": 0.45836667716503143,
    "total_loss": 132.36282868981363
  },
  {
    "episode": 50,
    "avg_reward_per_step": 247.04253709742875,
    "episode_length": 81,
    "policy_loss": -2291.2460327148438,
    "value_loss": 0.6289447396993637,
    "entropy": 0.4643769636750221,
    "total_loss": -2290.8028387606146
  },
  {
    "episode": 51,
    "avg_reward_per_step": -14.559178012514817,
    "episode_length": 3000,
    "policy_loss": 133.09159469604492,
    "value_loss": 2.7743066549301147,
    "entropy": 0.6406621485948563,
    "total_loss": 135.6096364915371
  },
  {
    "episode": 52,
    "avg_reward_per_step": -16.47465224744242,
    "episode_length": 3000,
    "policy_loss": 150.54559707641602,
    "value_loss": 4.439802289009094,
    "entropy": 0.5910746455192566,
    "total_loss": 154.7489695072174
  },
  {
    "episode": 53,
    "avg_reward_per_step": -13.229306989137836,
    "episode_length": 3000,
    "policy_loss": 120.55697441101074,
    "value_loss": 3.946284294128418,
    "entropy": 0.9492491185665131,
    "total_loss": 124.12355905771255
  },
  {
    "episode": 54,
    "avg_reward_per_step": -7.05992989346268,
    "episode_length": 2681,
    "policy_loss": 64.04316139221191,
    "value_loss": 0.5025555938482285,
    "entropy": 0.69146429002285,
    "total_loss": 64.269131270051
  },
  {
    "episode": 55,
    "avg_reward_per_step": 231.88339889262895,
    "episode_length": 86,
    "policy_loss": -2140.6689453125,
    "value_loss": 0.618506595492363,
    "entropy": 0.69571852684021,
    "total_loss": -2140.3287261277437
  },
  {
    "episode": 56,
    "avg_reward_per_step": -13.246997710013142,
    "episode_length": 3000,
    "policy_loss": 120.83783912658691,
    "value_loss": 2.8995415568351746,
    "entropy": 0.5937319248914719,
    "total_loss": 123.4998879134655
  },
  {
    "episode": 57,
    "avg_reward_per_step": 5.874469935189945,
    "episode_length": 2168,
    "policy_loss": -54.57041549682617,
    "value_loss": 0.501461997628212,
    "entropy": 0.1922616958618164,
    "total_loss": -54.145858177542685
  },
  {
    "episode": 58,
    "avg_reward_per_step": 273.73936219517924,
    "episode_length": 73,
    "policy_loss": -2541.74951171875,
    "value_loss": 0.6468671411275864,
    "entropy": 0.6397037655115128,
    "total_loss": -2541.358526083827
  },
  {
    "episode": 59,
    "avg_reward_per_step": 42.43505754750574,
    "episode_length": 464,
    "policy_loss": -391.18990325927734,
    "value_loss": 0.5177811831235886,
    "entropy": 0.15741170197725296,
    "total_loss": -390.73508675694467
  },
  {
    "episode": 60,
    "avg_reward_per_step": 33.091311981750344,
    "episode_length": 595,
    "policy_loss": -304.49828338623047,
    "value_loss": 0.5137909948825836,
    "entropy": 0.16394910588860512,
    "total_loss": -304.0500720337033
  },
  {
    "episode": 61,
    "avg_reward_per_step": -5.058219121269814,
    "episode_length": 2655,
    "policy_loss": 45.31753635406494,
    "value_loss": 0.501160740852356,
    "entropy": 0.23764971643686295,
    "total_loss": 45.72363720834255
  },
  {
    "episode": 62,
    "avg_reward_per_step": 43.81651971420795,
    "episode_length": 451,
    "policy_loss": -403.3730239868164,
    "value_loss": 0.5184473246335983,
    "entropy": 0.1669650375843048,
    "total_loss": -402.9213626772165
  },
  {
    "episode": 63,
    "avg_reward_per_step": -8.73208483482065,
    "episode_length": 3000,
    "policy_loss": 79.22537231445312,
    "value_loss": 1.185410350561142,
    "entropy": 0.6727776229381561,
    "total_loss": 80.141671615839
  },
  {
    "episode": 64,
    "avg_reward_per_step": -3.9331146205100587,
    "episode_length": 1890,
    "policy_loss": 35.10846710205078,
    "value_loss": 0.5002901256084442,
    "entropy": 0.24331464990973473,
    "total_loss": 35.51143136769533
  },
  {
    "episode": 65,
    "avg_reward_per_step": 3.034929543426356,
    "episode_length": 1135,
    "policy_loss": -29.760735034942627,
    "value_loss": 0.499781958758831,
    "entropy": 0.3100338354706764,
    "total_loss": -29.384966610372068
  },
  {
    "episode": 66,
    "avg_reward_per_step": -10.827422193141688,
    "episode_length": 3000,
    "policy_loss": 98.36153602600098,
    "value_loss": 1.5907754004001617,
    "entropy": 0.6225448995828629,
    "total_loss": 99.703293466568
  },
  {
    "episode": 67,
    "avg_reward_per_step": 10.871430237442592,
    "episode_length": 833,
    "policy_loss": -102.7668571472168,
    "value_loss": 0.5015453398227692,
    "entropy": 0.35072582960128784,
    "total_loss": -102.40560213923455
  },
  {
    "episode": 68,
    "avg_reward_per_step": 18.231422441755495,
    "episode_length": 631,
    "policy_loss": -171.0070343017578,
    "value_loss": 0.5038188695907593,
    "entropy": 0.3612189367413521,
    "total_loss": -170.6477030068636
  },
  {
    "episode": 69,
    "avg_reward_per_step": 11.543897669015527,
    "episode_length": 844,
    "policy_loss": -116.39302635192871,
    "value_loss": 0.5018772333860397,
    "entropy": 0.4944160357117653,
    "total_loss": -116.08891553282737
  },
  {
    "episode": 70,
    "avg_reward_per_step": -7.793398162530641,
    "episode_length": 2669,
    "policy_loss": 70.9776840209961,
    "value_loss": 0.503134235739708,
    "entropy": 0.44457999616861343,
    "total_loss": 71.30298625826836
  },
  {
    "episode": 71,
    "avg_reward_per_step": 96.5186486395637,
    "episode_length": 191,
    "policy_loss": -921.5831298828125,
    "value_loss": 0.5391763895750046,
    "entropy": 0.8883692026138306,
    "total_loss": -921.399301174283
  },
  {
    "episode": 72,
    "avg_reward_per_step": 25.519255056284376,
    "episode_length": 517,
    "policy_loss": -236.01409912109375,
    "value_loss": 0.5064780116081238,
    "entropy": 0.5097107142210007,
    "total_loss": -235.71150539517402
  },
  {
    "episode": 73,
    "avg_reward_per_step": 4.351594508648795,
    "episode_length": 1257,
    "policy_loss": -41.40784549713135,
    "value_loss": 0.5001703798770905,
    "entropy": 0.6049977093935013,
    "total_loss": -41.149674201011656
  },
  {
    "episode": 74,
    "avg_reward_per_step": 18.029658154473132,
    "episode_length": 844,
    "policy_loss": -167.8964614868164,
    "value_loss": 0.5055553466081619,
    "entropy": 0.813274011015892,
    "total_loss": -167.7162157446146
  },
  {
    "episode": 75,
    "avg_reward_per_step": 7.078916535091529,
    "episode_length": 945,
    "policy_loss": -67.29941940307617,
    "value_loss": 0.5005174875259399,
    "entropy": 0.5253346711397171,
    "total_loss": -67.00903578400612
  },
  {
    "episode": 76,
    "avg_reward_per_step": -11.073944397377405,
    "episode_length": 3000,
    "policy_loss": 100.18997001647949,
    "value_loss": 2.460693895816803,
    "entropy": 0.7821702212095261,
    "total_loss": 102.33779582381248
  },
  {
    "episode": 77,
    "avg_reward_per_step": 15.63022554687639,
    "episode_length": 963,
    "policy_loss": -144.57731246948242,
    "value_loss": 0.5047788023948669,
    "entropy": 0.9830694049596786,
    "total_loss": -144.46576142907142
  },
  {
    "episode": 78,
    "avg_reward_per_step": 25.39083172476858,
    "episode_length": 579,
    "policy_loss": -235.61423873901367,
    "value_loss": 0.5074435770511627,
    "entropy": 0.7718204408884048,
    "total_loss": -235.41552333831788
  },
  {
    "episode": 79,
    "avg_reward_per_step": 6.956071439725722,
    "episode_length": 1174,
    "policy_loss": -65.62282180786133,
    "value_loss": 0.5008544623851776,
    "entropy": 0.7873397618532181,
    "total_loss": -65.43690325021744
  },
  {
    "episode": 80,
    "avg_reward_per_step": 82.8438251903626,
    "episode_length": 235,
    "policy_loss": -779.2863006591797,
    "value_loss": 0.535448282957077,
    "entropy": 0.6337282955646515,
    "total_loss": -779.0043436944485
  },
  {
    "episode": 81,
    "avg_reward_per_step": 60.41913101266503,
    "episode_length": 296,
    "policy_loss": -553.9901580810547,
    "value_loss": 0.5229781121015549,
    "entropy": 0.8131480515003204,
    "total_loss": -553.7924391895533
  },
  {
    "episode": 82,
    "avg_reward_per_step": -12.213020434198969,
    "episode_length": 3000,
    "policy_loss": 110.79827308654785,
    "value_loss": 2.5824496150016785,
    "entropy": 0.6227023005485535,
    "total_loss": 113.1316417813301
  },
  {
    "episode": 83,
    "avg_reward_per_step": -13.775680915863173,
    "episode_length": 3000,
    "policy_loss": 124.97883033752441,
    "value_loss": 3.28828364610672,
    "entropy": 0.5658343881368637,
    "total_loss": 128.04078022837638
  },
  {
    "episode": 84,
    "avg_reward_per_step": -13.500049476438942,
    "episode_length": 3000,
    "policy_loss": 122.34791564941406,
    "value_loss": 2.832128882408142,
    "entropy": 0.5752401798963547,
    "total_loss": 124.94994845986366
  },
  {
    "episode": 85,
    "avg_reward_per_step": -15.024220039840769,
    "episode_length": 3000,
    "policy_loss": 136.20450592041016,
    "value_loss": 3.760355055332184,
    "entropy": 0.3789876475930214,
    "total_loss": 139.81326591670512
  },
  {
    "episode": 86,
    "avg_reward_per_step": 126.37287842328423,
    "episode_length": 157,
    "policy_loss": -1175.3865356445312,
    "value_loss": 0.5579054355621338,
    "entropy": 0.898751974105835,
    "total_loss": -1175.1881309986115
  },
  {
    "episode": 87,
    "avg_reward_per_step": 78.48493253013409,
    "episode_length": 246,
    "policy_loss": -726.5648498535156,
    "value_loss": 0.533227875828743,
    "entropy": 0.616891622543335,
    "total_loss": -726.2783786267042
  },
  {
    "episode": 88,
    "avg_reward_per_step": -4.1549963007285875,
    "episode_length": 2493,
    "policy_loss": 35.31678771972656,
    "value_loss": 0.500611811876297,
    "entropy": 0.6704947650432587,
    "total_loss": 35.54920162558555
  },
  {
    "episode": 89,
    "avg_reward_per_step": 25.750480031671326,
    "episode_length": 692,
    "policy_loss": -240.52729415893555,
    "value_loss": 0.5097682029008865,
    "entropy": 1.1125544011592865,
    "total_loss": -240.46254771649836
  },
  {
    "episode": 90,
    "avg_reward_per_step": -13.366638427592266,
    "episode_length": 3000,
    "policy_loss": 120.77947044372559,
    "value_loss": 3.116972327232361,
    "entropy": 0.600145235657692,
    "total_loss": 123.65638467669487
  },
  {
    "episode": 91,
    "avg_reward_per_step": 53.651457665379525,
    "episode_length": 317,
    "policy_loss": -497.1792755126953,
    "value_loss": 0.5191793292760849,
    "entropy": 0.50739536434412,
    "total_loss": -496.86305432915685
  },
  {
    "episode": 92,
    "avg_reward_per_step": 465.66936057535884,
    "episode_length": 43,
    "policy_loss": -4283.3121337890625,
    "value_loss": 0.8131101280450821,
    "entropy": 0.4292503520846367,
    "total_loss": -4282.670723801852
  },
  {
    "episode": 93,
    "avg_reward_per_step": -14.980891917007654,
    "episode_length": 3000,
    "policy_loss": 135.89243698120117,
    "value_loss": 3.711514472961426,
    "entropy": 0.2636456601321697,
    "total_loss": 139.49849319010974
  },
  {
    "episode": 94,
    "avg_reward_per_step": 7.525746221964866,
    "episode_length": 927,
    "policy_loss": -72.87410163879395,
    "value_loss": 0.5006615370512009,
    "entropy": 0.21247197315096855,
    "total_loss": -72.45842889100314
  },
  {
    "episode": 95,
    "avg_reward_per_step": 13.418129632821971,
    "episode_length": 1435,
    "policy_loss": -125.82804107666016,
    "value_loss": 0.5056267231702805,
    "entropy": 0.05728937964886427,
    "total_loss": -125.34533010534942
  },
  {
    "episode": 96,
    "avg_reward_per_step": 7.620877778214747,
    "episode_length": 1486,
    "policy_loss": -72.71293449401855,
    "value_loss": 0.5016832649707794,
    "entropy": 0.1423741802573204,
    "total_loss": -72.2682009011507
  },
  {
    "episode": 97,
    "avg_reward_per_step": -17.210082542206838,
    "episode_length": 3000,
    "policy_loss": 155.35931015014648,
    "value_loss": 6.11704421043396,
    "entropy": 0.08786332421004772,
    "total_loss": 161.44120903089643
  },
  {
    "episode": 98,
    "avg_reward_per_step": -5.930665267299539,
    "episode_length": 2736,
    "policy_loss": 51.7373685836792,
    "value_loss": 0.5015794485807419,
    "entropy": 0.11809735372662544,
    "total_loss": 52.191709090769294
  },
  {
    "episode": 99,
    "avg_reward_per_step": 23.348631837172025,
    "episode_length": 840,
    "policy_loss": -217.52413940429688,
    "value_loss": 0.5098709315061569,
    "entropy": 0.05391612183302641,
    "total_loss": -217.03583492152393
  },
  {
    "episode": 100,
    "avg_reward_per_step": 14.731396282278588,
    "episode_length": 854,
    "policy_loss": -138.72013473510742,
    "value_loss": 0.5036422461271286,
    "entropy": 0.1390431672334671,
    "total_loss": -138.2721097558737
  },
  {
    "episode": 101,
    "avg_reward_per_step": -0.5216023487682323,
    "episode_length": 1965,
    "policy_loss": 1.449495941400528,
    "value_loss": 0.4997249096632004,
    "entropy": 0.13322491571307182,
    "total_loss": 1.8959308847784997
  },
  {
    "episode": 102,
    "avg_reward_per_step": 15.3667690992586,
    "episode_length": 1262,
    "policy_loss": -144.26123046875,
    "value_loss": 0.506486102938652,
    "entropy": 0.05360848642885685,
    "total_loss": -143.7761877603829
  },
  {
    "episode": 103,
    "avg_reward_per_step": -6.135208725353355,
    "episode_length": 2199,
    "policy_loss": 52.47444152832031,
    "value_loss": 0.5012904107570648,
    "entropy": 0.1467287465929985,
    "total_loss": 52.917040440440175
  },
  {
    "episode": 104,
    "avg_reward_per_step": 6.732964486178139,
    "episode_length": 1279,
    "policy_loss": -65.66044044494629,
    "value_loss": 0.5009885430335999,
    "entropy": 0.17321520298719406,
    "total_loss": -65.22873798310756
  },
  {
    "episode": 105,
    "avg_reward_per_step": 7.301897655745267,
    "episode_length": 1078,
    "policy_loss": -70.9205207824707,
    "value_loss": 0.5008790493011475,
    "entropy": 0.1796293668448925,
    "total_loss": -70.49149347990752
  },
  {
    "episode": 106,
    "avg_reward_per_step": 17.25507039160531,
    "episode_length": 1128,
    "policy_loss": -162.20002365112305,
    "value_loss": 0.5072645246982574,
    "entropy": 0.06081509869545698,
    "total_loss": -161.71708516590297
  },
  {
    "episode": 107,
    "avg_reward_per_step": 13.315908710422505,
    "episode_length": 877,
    "policy_loss": -127.91067504882812,
    "value_loss": 0.5029632747173309,
    "entropy": 0.2814749628305435,
    "total_loss": -127.52030175924301
  },
  {
    "episode": 108,
    "avg_reward_per_step": 35.51866418698182,
    "episode_length": 456,
    "policy_loss": -331.6543731689453,
    "value_loss": 0.5119173228740692,
    "entropy": 0.4021046832203865,
    "total_loss": -331.3032977193594
  },
  {
    "episode": 109,
    "avg_reward_per_step": 52.161380371642544,
    "episode_length": 336,
    "policy_loss": -484.6343307495117,
    "value_loss": 0.5193720906972885,
    "entropy": 0.424831360578537,
    "total_loss": -484.28489120304585
  },
  {
    "episode": 110,
    "avg_reward_per_step": -15.153461293087362,
    "episode_length": 3000,
    "policy_loss": 136.08106994628906,
    "value_loss": 3.2503010630607605,
    "entropy": 0.15062304958701134,
    "total_loss": 139.271121789515
  },
  {
    "episode": 111,
    "avg_reward_per_step": -7.254917555686133,
    "episode_length": 2500,
    "policy_loss": 63.46659755706787,
    "value_loss": 0.5022744089365005,
    "entropy": 0.20500576123595238,
    "total_loss": 63.88686966150999
  },
  {
    "episode": 112,
    "avg_reward_per_step": 6.235989065595386,
    "episode_length": 2638,
    "policy_loss": -60.523475646972656,
    "value_loss": 0.5023868083953857,
    "entropy": 0.12931111827492714,
    "total_loss": -60.07281328588724
  },
  {
    "episode": 113,
    "avg_reward_per_step": -15.767088634801178,
    "episode_length": 3000,
    "policy_loss": 141.50068283081055,
    "value_loss": 3.205119252204895,
    "entropy": 0.18117563426494598,
    "total_loss": 144.63333182930947
  },
  {
    "episode": 114,
    "avg_reward_per_step": 89.79327769181334,
    "episode_length": 205,
    "policy_loss": -839.2618713378906,
    "value_loss": 0.5364557951688766,
    "entropy": 0.4193326532840729,
    "total_loss": -838.8931486040353
  },
  {
    "episode": 115,
    "avg_reward_per_step": 44.80518523718478,
    "episode_length": 384,
    "policy_loss": -421.7644577026367,
    "value_loss": 0.5163634866476059,
    "entropy": 0.34066279232501984,
    "total_loss": -421.38435933291913
  },
  {
    "episode": 116,
    "avg_reward_per_step": 9.957204860362632,
    "episode_length": 971,
    "policy_loss": -95.9030647277832,
    "value_loss": 0.5017604976892471,
    "entropy": 0.20216666907072067,
    "total_loss": -95.48217089772224
  },
  {
    "episode": 117,
    "avg_reward_per_step": 9.349197642551582,
    "episode_length": 1135,
    "policy_loss": -89.09899520874023,
    "value_loss": 0.5019538700580597,
    "entropy": 0.15252050384879112,
    "total_loss": -88.6580495402217
  },
  {
    "episode": 118,
    "avg_reward_per_step": -15.295903424750113,
    "episode_length": 3000,
    "policy_loss": 136.92272567749023,
    "value_loss": 3.8538438081741333,
    "entropy": 0.2203993760049343,
    "total_loss": 140.68840973526238
  },
  {
    "episode": 119,
    "avg_reward_per_step": 8.559849014202976,
    "episode_length": 1164,
    "policy_loss": -83.78220558166504,
    "value_loss": 0.5016910284757614,
    "entropy": 0.173692487180233,
    "total_loss": -83.34999154806137
  },
  {
    "episode": 120,
    "avg_reward_per_step": -12.865575600334616,
    "episode_length": 3000,
    "policy_loss": 114.44282722473145,
    "value_loss": 1.7557272613048553,
    "entropy": 0.29372863471508026,
    "total_loss": 116.08106303215027
  },
  {
    "episode": 121,
    "avg_reward_per_step": 54.16755355222653,
    "episode_length": 367,
    "policy_loss": -504.24298095703125,
    "value_loss": 0.523608848452568,
    "entropy": 0.10203410126268864,
    "total_loss": -503.76018574908375
  },
  {
    "episode": 122,
    "avg_reward_per_step": 27.605253533801978,
    "episode_length": 603,
    "policy_loss": -258.19889068603516,
    "value_loss": 0.5097307860851288,
    "entropy": 0.3209296241402626,
    "total_loss": -257.81753174960613
  },
  {
    "episode": 123,
    "avg_reward_per_step": 165.13547361382484,
    "episode_length": 121,
    "policy_loss": -1528.844970703125,
    "value_loss": 0.5790454149246216,
    "entropy": 0.16472452506422997,
    "total_loss": -1528.3318150982261
  },
  {
    "episode": 124,
    "avg_reward_per_step": 88.72910523498739,
    "episode_length": 216,
    "policy_loss": -829.8941345214844,
    "value_loss": 0.5379509478807449,
    "entropy": 0.41771572828292847,
    "total_loss": -829.5232698649168
  },
  {
    "episode": 125,
    "avg_reward_per_step": -4.936436203177044,
    "episode_length": 2419,
    "policy_loss": 41.42636680603027,
    "value_loss": 0.5007739961147308,
    "entropy": 0.3735688179731369,
    "total_loss": 41.77771327495575
  },
  {
    "episode": 126,
    "avg_reward_per_step": 17.945299470479465,
    "episode_length": 751,
    "policy_loss": -170.42438507080078,
    "value_loss": 0.5051440298557281,
    "entropy": 0.4885730519890785,
    "total_loss": -170.11467026174068
  },
  {
    "episode": 127,
    "avg_reward_per_step": 27.93331062308498,
    "episode_length": 512,
    "policy_loss": -262.2963333129883,
    "value_loss": 0.5083158761262894,
    "entropy": 0.5577902495861053,
    "total_loss": -262.01113353669643
  },
  {
    "episode": 128,
    "avg_reward_per_step": 124.07311454282603,
    "episode_length": 155,
    "policy_loss": -1184.64404296875,
    "value_loss": 0.5547134876251221,
    "entropy": 0.5630581006407738,
    "total_loss": -1184.3145527213812
  },
  {
    "episode": 129,
    "avg_reward_per_step": 91.7421009740228,
    "episode_length": 216,
    "policy_loss": -847.9398803710938,
    "value_loss": 0.5407000482082367,
    "entropy": 0.44600939750671387,
    "total_loss": -847.5775840818882
  },
  {
    "episode": 130,
    "avg_reward_per_step": 90.0752071839487,
    "episode_length": 216,
    "policy_loss": -834.7970275878906,
    "value_loss": 0.5391460508108139,
    "entropy": 0.5717048943042755,
    "total_loss": -834.4865634948015
  },
  {
    "episode": 131,
    "avg_reward_per_step": 73.99725899414226,
    "episode_length": 252,
    "policy_loss": -686.0859985351562,
    "value_loss": 0.530303105711937,
    "entropy": 0.5314406454563141,
    "total_loss": -685.7682716876268
  },
  {
    "episode": 132,
    "avg_reward_per_step": 70.4925805586946,
    "episode_length": 272,
    "policy_loss": -667.1417999267578,
    "value_loss": 0.529847577214241,
    "entropy": 0.5621339529752731,
    "total_loss": -666.8368059307337
  },
  {
    "episode": 133,
    "avg_reward_per_step": -3.3216641392037825,
    "episode_length": 2493,
    "policy_loss": 27.400877952575684,
    "value_loss": 0.5002942681312561,
    "entropy": 0.4451602175831795,
    "total_loss": 27.72310813367367
  },
  {
    "episode": 134,
    "avg_reward_per_step": 12.441494049082051,
    "episode_length": 913,
    "policy_loss": -117.97603416442871,
    "value_loss": 0.5029155910015106,
    "entropy": 0.3564630448818207,
    "total_loss": -117.61570379137993
  },
  {
    "episode": 135,
    "avg_reward_per_step": 40.84055541861926,
    "episode_length": 430,
    "policy_loss": -380.25988006591797,
    "value_loss": 0.5153448134660721,
    "entropy": 0.2527894824743271,
    "total_loss": -379.8456510454416
  },
  {
    "episode": 136,
    "avg_reward_per_step": 0.2719300253064169,
    "episode_length": 1633,
    "policy_loss": -7.123710632324219,
    "value_loss": 0.49988631904125214,
    "entropy": 0.43005435913801193,
    "total_loss": -6.795846056938172
  },
  {
    "episode": 137,
    "avg_reward_per_step": 23.947426784708654,
    "episode_length": 641,
    "policy_loss": -224.69187927246094,
    "value_loss": 0.5079267770051956,
    "entropy": 0.5970247834920883,
    "total_loss": -224.42276240885258
  },
  {
    "episode": 138,
    "avg_reward_per_step": 17.269127074694335,
    "episode_length": 829,
    "policy_loss": -163.01971435546875,
    "value_loss": 0.50532166659832,
    "entropy": 0.4450429826974869,
    "total_loss": -162.69240988194943
  },
  {
    "episode": 139,
    "avg_reward_per_step": 43.68789615132399,
    "episode_length": 443,
    "policy_loss": -410.09300994873047,
    "value_loss": 0.5187577307224274,
    "entropy": 0.6160954535007477,
    "total_loss": -409.82069039940836
  },
  {
    "episode": 140,
    "avg_reward_per_step": 38.43976485617979,
    "episode_length": 494,
    "policy_loss": -357.64786529541016,
    "value_loss": 0.5160164684057236,
    "entropy": 0.6167152523994446,
    "total_loss": -357.3785349279642
  },
  {
    "episode": 141,
    "avg_reward_per_step": 66.19826070791932,
    "episode_length": 296,
    "policy_loss": -613.3747711181641,
    "value_loss": 0.5289017111063004,
    "entropy": 0.5647822618484497,
    "total_loss": -613.0717823117972
  },
  {
    "episode": 142,
    "avg_reward_per_step": -10.404011492526767,
    "episode_length": 3000,
    "policy_loss": 91.48809814453125,
    "value_loss": 1.660280704498291,
    "entropy": 0.5229947566986084,
    "total_loss": 92.93918094635009
  },
  {
    "episode": 143,
    "avg_reward_per_step": 17.30910052347624,
    "episode_length": 958,
    "policy_loss": -164.6043586730957,
    "value_loss": 0.5064611434936523,
    "entropy": 0.5362821370363235,
    "total_loss": -164.31241038441658
  },
  {
    "episode": 144,
    "avg_reward_per_step": 17.403973584462765,
    "episode_length": 1032,
    "policy_loss": -164.07854080200195,
    "value_loss": 0.5072040408849716,
    "entropy": 0.5021075904369354,
    "total_loss": -163.77217979729176
  },
  {
    "episode": 145,
    "avg_reward_per_step": 25.182247667739436,
    "episode_length": 617,
    "policy_loss": -236.58582305908203,
    "value_loss": 0.5082920044660568,
    "entropy": 0.5435328930616379,
    "total_loss": -236.29494421184063
  },
  {
    "episode": 146,
    "avg_reward_per_step": 55.279787509780704,
    "episode_length": 325,
    "policy_loss": -514.4043426513672,
    "value_loss": 0.5215245932340622,
    "entropy": 0.4368388280272484,
    "total_loss": -514.057553589344
  },
  {
    "episode": 147,
    "avg_reward_per_step": 37.34634509693071,
    "episode_length": 475,
    "policy_loss": -348.4322814941406,
    "value_loss": 0.514316737651825,
    "entropy": 0.38291386514902115,
    "total_loss": -348.0711303025484
  },
  {
    "episode": 148,
    "avg_reward_per_step": -0.761291270799684,
    "episode_length": 3000,
    "policy_loss": 3.286890983581543,
    "value_loss": 0.612123116850853,
    "entropy": 0.41537491232156754,
    "total_loss": 3.732864135503769
  },
  {
    "episode": 149,
    "avg_reward_per_step": 9.8897690754961,
    "episode_length": 1887,
    "policy_loss": -94.8234806060791,
    "value_loss": 0.5047253966331482,
    "entropy": 0.39952169358730316,
    "total_loss": -94.47856388688088
  },
  {
    "episode": 150,
    "avg_reward_per_step": -0.5858825993646387,
    "episode_length": 3000,
    "policy_loss": 1.4950203895568848,
    "value_loss": 0.4759328216314316,
    "entropy": 0.40974799543619156,
    "total_loss": 1.8070540130138397
  },
  {
    "episode": 151,
    "avg_reward_per_step": 9.325171789664118,
    "episode_length": 1664,
    "policy_loss": -91.04139518737793,
    "value_loss": 0.5033847242593765,
    "entropy": 0.38499901443719864,
    "total_loss": -90.69201006889344
  },
  {
    "episode": 152,
    "avg_reward_per_step": 13.823692623639436,
    "episode_length": 1257,
    "policy_loss": -131.58638381958008,
    "value_loss": 0.5055598169565201,
    "entropy": 0.3922376334667206,
    "total_loss": -131.23771905601023
  },
  {
    "episode": 153,
    "avg_reward_per_step": 5.971237332167561,
    "episode_length": 2974,
    "policy_loss": -59.330201148986816,
    "value_loss": 0.5029257982969284,
    "entropy": 0.4144725650548935,
    "total_loss": -58.99306437671184
  },
  {
    "episode": 154,
    "avg_reward_per_step": -0.6153267187792388,
    "episode_length": 3000,
    "policy_loss": 1.5667713284492493,
    "value_loss": 0.4802110567688942,
    "entropy": 0.4529484063386917,
    "total_loss": 1.8658030226826667
  },
  {
    "episode": 155,
    "avg_reward_per_step": 29.992613237745893,
    "episode_length": 615,
    "policy_loss": -281.59078216552734,
    "value_loss": 0.512233778834343,
    "entropy": 0.46758944541215897,
    "total_loss": -281.26558416485784
  },
  {
    "episode": 156,
    "avg_reward_per_step": 18.83825868481076,
    "episode_length": 1010,
    "policy_loss": -178.68025970458984,
    "value_loss": 0.5080865621566772,
    "entropy": 0.4875798374414444,
    "total_loss": -178.36720507740975
  },
  {
    "episode": 157,
    "avg_reward_per_step": 7.713961949073003,
    "episode_length": 2377,
    "policy_loss": -75.9072380065918,
    "value_loss": 0.5035937279462814,
    "entropy": 0.5278365910053253,
    "total_loss": -75.61477891504765
  },
  {
    "episode": 158,
    "avg_reward_per_step": 13.665017750956407,
    "episode_length": 1200,
    "policy_loss": -130.3028450012207,
    "value_loss": 0.5051821619272232,
    "entropy": 0.5447745025157928,
    "total_loss": -130.0155726402998
  },
  {
    "episode": 159,
    "avg_reward_per_step": 57.625162200316396,
    "episode_length": 331,
    "policy_loss": -543.9597930908203,
    "value_loss": 0.5240718126296997,
    "entropy": 0.48270244896411896,
    "total_loss": -543.6288022577762
  },
  {
    "episode": 160,
    "avg_reward_per_step": 23.706243092065456,
    "episode_length": 690,
    "policy_loss": -223.84942245483398,
    "value_loss": 0.5083635300397873,
    "entropy": 0.3491319492459297,
    "total_loss": -223.48071170449256
  },
  {
    "episode": 161,
    "avg_reward_per_step": 166.32026429018933,
    "episode_length": 120,
    "policy_loss": -1555.3053894042969,
    "value_loss": 0.5799718797206879,
    "entropy": 0.5282978862524033,
    "total_loss": -1554.936736679077
  },
  {
    "episode": 162,
    "avg_reward_per_step": 36.11042657158565,
    "episode_length": 461,
    "policy_loss": -338.8206787109375,
    "value_loss": 0.5128411203622818,
    "entropy": 0.29710230976343155,
    "total_loss": -338.4266785144806
  },
  {
    "episode": 163,
    "avg_reward_per_step": 67.27561633486705,
    "episode_length": 264,
    "policy_loss": -633.6311187744141,
    "value_loss": 0.5258445143699646,
    "entropy": 0.4022449254989624,
    "total_loss": -633.2661722302437
  },
  {
    "episode": 164,
    "avg_reward_per_step": 35.9320298979823,
    "episode_length": 475,
    "policy_loss": -335.86182403564453,
    "value_loss": 0.5131267458200455,
    "entropy": 0.5974238216876984,
    "total_loss": -335.58766681849954
  },
  {
    "episode": 165,
    "avg_reward_per_step": 42.21610924207528,
    "episode_length": 417,
    "policy_loss": -393.50343322753906,
    "value_loss": 0.5159908086061478,
    "entropy": 0.32664044201374054,
    "total_loss": -393.1180985957384
  },
  {
    "episode": 166,
    "avg_reward_per_step": 15.235717933216447,
    "episode_length": 931,
    "policy_loss": -144.87931060791016,
    "value_loss": 0.5047151148319244,
    "entropy": 0.4850925952196121,
    "total_loss": -144.5686325311661
  },
  {
    "episode": 167,
    "avg_reward_per_step": -12.24870921218919,
    "episode_length": 3000,
    "policy_loss": 107.70610809326172,
    "value_loss": 1.8243254125118256,
    "entropy": 0.36984823644161224,
    "total_loss": 109.3824942111969
  },
  {
    "episode": 168,
    "avg_reward_per_step": 217.08817651460734,
    "episode_length": 92,
    "policy_loss": -2009.0154113769531,
    "value_loss": 0.6099060475826263,
    "entropy": 0.5432482063770294,
    "total_loss": -2008.6228046119213
  },
  {
    "episode": 169,
    "avg_reward_per_step": 33.57512146877919,
    "episode_length": 503,
    "policy_loss": -314.78661346435547,
    "value_loss": 0.5121552497148514,
    "entropy": 0.2844296917319298,
    "total_loss": -314.3882300913334
  },
  {
    "episode": 170,
    "avg_reward_per_step": 57.19221965538818,
    "episode_length": 315,
    "policy_loss": -536.9979858398438,
    "value_loss": 0.5222464203834534,
    "entropy": 0.510525293648243,
    "total_loss": -536.6799495369196
  },
  {
    "episode": 171,
    "avg_reward_per_step": 21.45332753697803,
    "episode_length": 695,
    "policy_loss": -202.65646743774414,
    "value_loss": 0.5067743957042694,
    "entropy": 0.2347487173974514,
    "total_loss": -202.24359252899885
  },
  {
    "episode": 172,
    "avg_reward_per_step": 191.7268497384995,
    "episode_length": 104,
    "policy_loss": -1773.8099975585938,
    "value_loss": 0.5945982784032822,
    "entropy": 0.4585764706134796,
    "total_loss": -1773.3988298684358
  },
  {
    "episode": 173,
    "avg_reward_per_step": 199.57923379247663,
    "episode_length": 100,
    "policy_loss": -1877.1325073242188,
    "value_loss": 0.5993478298187256,
    "entropy": 0.6345768868923187,
    "total_loss": -1876.786990249157
  },
  {
    "episode": 174,
    "avg_reward_per_step": -14.566971971928412,
    "episode_length": 3000,
    "policy_loss": 129.02117919921875,
    "value_loss": 1.9067381620407104,
    "entropy": 0.21960940212011337,
    "total_loss": 130.84007360041142
  },
  {
    "episode": 175,
    "avg_reward_per_step": 129.71121725598962,
    "episode_length": 154,
    "policy_loss": -1199.5711669921875,
    "value_loss": 0.560209259390831,
    "entropy": 0.15740395709872246,
    "total_loss": -1199.0739193156362
  },
  {
    "episode": 176,
    "avg_reward_per_step": 22.523964583566684,
    "episode_length": 607,
    "policy_loss": -212.72002410888672,
    "value_loss": 0.5064869970083237,
    "entropy": 0.3023484870791435,
    "total_loss": -212.33447650671005
  },
  {
    "episode": 177,
    "avg_reward_per_step": -12.976925971060515,
    "episode_length": 3000,
    "policy_loss": 114.01462173461914,
    "value_loss": 1.8862802386283875,
    "entropy": 0.1400945708155632,
    "total_loss": 115.8448641449213
  },
  {
    "episode": 178,
    "avg_reward_per_step": -4.140951178464503,
    "episode_length": 3000,
    "policy_loss": 32.777649879455566,
    "value_loss": 0.6684213131666183,
    "entropy": 0.045430622063577175,
    "total_loss": 33.427898943796755
  },
  {
    "episode": 179,
    "avg_reward_per_step": -15.128046679856409,
    "episode_length": 3000,
    "policy_loss": 133.6676788330078,
    "value_loss": 2.301177680492401,
    "entropy": 0.21154645830392838,
    "total_loss": 135.88423793017864
  },
  {
    "episode": 180,
    "avg_reward_per_step": 165.21055009773931,
    "episode_length": 121,
    "policy_loss": -1529.2691955566406,
    "value_loss": 0.5796930938959122,
    "entropy": 0.14744791015982628,
    "total_loss": -1528.7484816268086
  },
  {
    "episode": 181,
    "avg_reward_per_step": -2.782191399041134,
    "episode_length": 3000,
    "policy_loss": 19.912062644958496,
    "value_loss": 0.5630031377077103,
    "entropy": 0.042095587588846684,
    "total_loss": 20.458227547630667
  },
  {
    "episode": 182,
    "avg_reward_per_step": -15.2800800544677,
    "episode_length": 3000,
    "policy_loss": 134.6911964416504,
    "value_loss": 2.5249003767967224,
    "entropy": 0.24809686467051506,
    "total_loss": 137.1168580725789
  },
  {
    "episode": 183,
    "avg_reward_per_step": 38.49019528141348,
    "episode_length": 514,
    "policy_loss": -360.24766540527344,
    "value_loss": 0.5168456137180328,
    "entropy": 0.07773004285991192,
    "total_loss": -359.7619118086994
  },
  {
    "episode": 184,
    "avg_reward_per_step": -14.322052272684449,
    "episode_length": 3000,
    "policy_loss": 125.70045852661133,
    "value_loss": 1.4210370779037476,
    "entropy": 0.23159069195389748,
    "total_loss": 127.02885932773351
  },
  {
    "episode": 185,
    "avg_reward_per_step": -12.624038408539485,
    "episode_length": 3000,
    "policy_loss": 110.00662040710449,
    "value_loss": 1.7784420251846313,
    "entropy": 0.2867100387811661,
    "total_loss": 111.67037841677666
  },
  {
    "episode": 186,
    "avg_reward_per_step": -0.7311751562964552,
    "episode_length": 3000,
    "policy_loss": 0.4187782108783722,
    "value_loss": 0.504970982670784,
    "entropy": 0.03760562650859356,
    "total_loss": 0.9087069429457187
  },
  {
    "episode": 187,
    "avg_reward_per_step": -3.0702731775744656,
    "episode_length": 3000,
    "policy_loss": 21.759280681610107,
    "value_loss": 0.5941682010889053,
    "entropy": 0.0413427846506238,
    "total_loss": 22.336911768838764
  },
  {
    "episode": 188,
    "avg_reward_per_step": -0.5510675834986999,
    "episode_length": 3000,
    "policy_loss": -1.50361368060112,
    "value_loss": 0.47909781336784363,
    "entropy": 0.02883500698953867,
    "total_loss": -1.0360498700290919
  },
  {
    "episode": 189,
    "avg_reward_per_step": -17.152660879923953,
    "episode_length": 3000,
    "policy_loss": 151.2004051208496,
    "value_loss": 2.7498467564582825,
    "entropy": 0.23018014803528786,
    "total_loss": 153.8581798180938
  },
  {
    "episode": 190,
    "avg_reward_per_step": -0.5444197492725178,
    "episode_length": 3000,
    "policy_loss": -1.3404968678951263,
    "value_loss": 0.428414948284626,
    "entropy": 0.03600667230784893,
    "total_loss": -0.9264845885336399
  },
  {
    "episode": 191,
    "avg_reward_per_step": -0.5577357340836394,
    "episode_length": 3000,
    "policy_loss": -1.0919614136219025,
    "value_loss": 0.44824448227882385,
    "entropy": 0.03656980209052563,
    "total_loss": -0.6583448521792888
  },
  {
    "episode": 192,
    "avg_reward_per_step": -0.5644324901912464,
    "episode_length": 3000,
    "policy_loss": -0.8891235738992691,
    "value_loss": 0.4570699855685234,
    "entropy": 0.03882350027561188,
    "total_loss": -0.4475829884409904
  },
  {
    "episode": 193,
    "avg_reward_per_step": -0.5571152056649405,
    "episode_length": 3000,
    "policy_loss": -0.858913853764534,
    "value_loss": 0.45248105376958847,
    "entropy": 0.03478274494409561,
    "total_loss": -0.42034589797258376
  },
  {
    "episode": 194,
    "avg_reward_per_step": -0.5450072199245545,
    "episode_length": 3000,
    "policy_loss": -0.8629641830921173,
    "value_loss": 0.44476468116045,
    "entropy": 0.03499048762023449,
    "total_loss": -0.4321956969797611
  },
  {
    "episode": 195,
    "avg_reward_per_step": -2.675122691790532,
    "episode_length": 3000,
    "policy_loss": 18.806414127349854,
    "value_loss": 0.6400367766618729,
    "entropy": 0.054255603812634945,
    "total_loss": 19.42474866248667
  },
  {
    "episode": 196,
    "avg_reward_per_step": -0.6612652357277851,
    "episode_length": 3000,
    "policy_loss": 0.35820916295051575,
    "value_loss": 0.5100340247154236,
    "entropy": 0.03324761614203453,
    "total_loss": 0.8549441412091255
  },
  {
    "episode": 197,
    "avg_reward_per_step": -1.031221637012325,
    "episode_length": 3000,
    "policy_loss": 3.7798920273780823,
    "value_loss": 0.5316673070192337,
    "entropy": 0.03750953637063503,
    "total_loss": 4.296555519849062
  },
  {
    "episode": 198,
    "avg_reward_per_step": -0.5510890630097407,
    "episode_length": 3000,
    "policy_loss": -0.6412250399589539,
    "value_loss": 0.4511798918247223,
    "entropy": 0.036140600219368935,
    "total_loss": -0.20450138822197914
  },
  {
    "episode": 199,
    "avg_reward_per_step": -10.94552436671482,
    "episode_length": 3000,
    "policy_loss": 94.70735168457031,
    "value_loss": 1.1336164772510529,
    "entropy": 0.03753001056611538,
    "total_loss": 95.82595615759492
  },
  {
    "episode": 200,
    "avg_reward_per_step": -0.5510881761496692,
    "episode_length": 3000,
    "policy_loss": -0.5764124542474747,
    "value_loss": 0.4500211104750633,
    "entropy": 0.03282929491251707,
    "total_loss": -0.13952306173741819
  },
  {
    "episode": 201,
    "avg_reward_per_step": -0.5710903992197587,
    "episode_length": 3000,
    "policy_loss": -0.35074620693922043,
    "value_loss": 0.4608081206679344,
    "entropy": 0.03376052435487509,
    "total_loss": 0.09655770398676396
  },
  {
    "episode": 202,
    "avg_reward_per_step": -16.669633222463563,
    "episode_length": 3000,
    "policy_loss": 147.4681053161621,
    "value_loss": 2.1895825266838074,
    "entropy": 0.2600504457950592,
    "total_loss": 149.5536676645279
  },
  {
    "episode": 203,
    "avg_reward_per_step": -3.721234090688841,
    "episode_length": 3000,
    "policy_loss": 28.582375049591064,
    "value_loss": 0.7335529178380966,
    "entropy": 0.043538037687540054,
    "total_loss": 29.298512752354146
  },
  {
    "episode": 204,
    "avg_reward_per_step": -0.5644121431263889,
    "episode_length": 3000,
    "policy_loss": -0.4378511905670166,
    "value_loss": 0.45215725898742676,
    "entropy": 0.03861404024064541,
    "total_loss": -0.0011395476758480072
  },
  {
    "episode": 205,
    "avg_reward_per_step": -1.1778263778977296,
    "episode_length": 3000,
    "policy_loss": 5.200973629951477,
    "value_loss": 0.5301816016435623,
    "entropy": 0.03848585020750761,
    "total_loss": 5.715760891512036
  },
  {
    "episode": 206,
    "avg_reward_per_step": -12.443096177216717,
    "episode_length": 3000,
    "policy_loss": 108.65322494506836,
    "value_loss": 1.5352864861488342,
    "entropy": 0.2418508194386959,
    "total_loss": 110.09177110344172
  },
  {
    "episode": 207,
    "avg_reward_per_step": -0.5510946072991016,
    "episode_length": 3000,
    "policy_loss": -0.5707384794950485,
    "value_loss": 0.4463657885789871,
    "entropy": 0.04200795665383339,
    "total_loss": -0.14117587357759476
  },
  {
    "episode": 208,
    "avg_reward_per_step": 17.796101694906795,
    "episode_length": 1096,
    "policy_loss": -169.43176651000977,
    "value_loss": 0.5076422840356827,
    "entropy": 0.029655733611434698,
    "total_loss": -168.93598651941866
  },
  {
    "episode": 209,
    "avg_reward_per_step": -0.5377483528214708,
    "episode_length": 3000,
    "policy_loss": -0.6106645911931992,
    "value_loss": 0.4342026934027672,
    "entropy": 0.03967274818569422,
    "total_loss": -0.19233099706470966
  },
  {
    "episode": 210,
    "avg_reward_per_step": -7.364080160213426,
    "episode_length": 3000,
    "policy_loss": 62.043028831481934,
    "value_loss": 0.7563695460557938,
    "entropy": 0.04399917088449001,
    "total_loss": 62.78179870918393
  },
  {
    "episode": 211,
    "avg_reward_per_step": 370.71491362662795,
    "episode_length": 54,
    "policy_loss": -3430.70947265625,
    "value_loss": 0.723587304353714,
    "entropy": 0.3900812417268753,
    "total_loss": -3430.141917848587
  },
  {
    "episode": 212,
    "avg_reward_per_step": -0.5676554380216856,
    "episode_length": 3000,
    "policy_loss": -0.25093211978673935,
    "value_loss": 0.45341071486473083,
    "entropy": 0.030628301203250885,
    "total_loss": 0.19022727459669114
  },
  {
    "episode": 213,
    "avg_reward_per_step": -17.754691050217783,
    "episode_length": 3000,
    "policy_loss": 157.50320434570312,
    "value_loss": 2.4615783095359802,
    "entropy": 0.13224754855036736,
    "total_loss": 159.91188363581895
  },
  {
    "episode": 214,
    "avg_reward_per_step": -8.78411755145539,
    "episode_length": 3000,
    "policy_loss": 75.10500717163086,
    "value_loss": 0.8812142908573151,
    "entropy": 0.031497365329414606,
    "total_loss": 75.97362251635641
  },
  {
    "episode": 215,
    "avg_reward_per_step": -2.6568994340831646,
    "episode_length": 3000,
    "policy_loss": 18.82606840133667,
    "value_loss": 0.6280599236488342,
    "entropy": 0.03377950005233288,
    "total_loss": 19.44061652496457
  },
  {
    "episode": 216,
    "avg_reward_per_step": -0.5410667232482848,
    "episode_length": 3000,
    "policy_loss": -0.5959000140428543,
    "value_loss": 0.4297500029206276,
    "entropy": 0.026717484928667545,
    "total_loss": -0.17683700509369374
  },
  {
    "episode": 217,
    "avg_reward_per_step": 8.269804387239367,
    "episode_length": 2288,
    "policy_loss": -81.7818832397461,
    "value_loss": 0.5038328021764755,
    "entropy": 0.02380882715806365,
    "total_loss": -81.28757396843284
  },
  {
    "episode": 218,
    "avg_reward_per_step": -0.5544088988097892,
    "episode_length": 3000,
    "policy_loss": -0.376759871840477,
    "value_loss": 0.4190330430865288,
    "entropy": 0.03316537290811539,
    "total_loss": 0.02900702208280563
  },
  {
    "episode": 219,
    "avg_reward_per_step": -0.557758100075137,
    "episode_length": 3000,
    "policy_loss": -0.3006364479660988,
    "value_loss": 0.4213034436106682,
    "entropy": 0.02809808449819684,
    "total_loss": 0.10942776184529066
  },
  {
    "episode": 220,
    "avg_reward_per_step": -0.5377336569814346,
    "episode_length": 3000,
    "policy_loss": -0.4522455558180809,
    "value_loss": 0.4431016072630882,
    "entropy": 0.023668859619647264,
    "total_loss": -0.018611492402851582
  },
  {
    "episode": 221,
    "avg_reward_per_step": -0.5377461958241186,
    "episode_length": 3000,
    "policy_loss": -0.40354345738887787,
    "value_loss": 0.44037123024463654,
    "entropy": 0.02473861863836646,
    "total_loss": 0.026932325400412082
  },
  {
    "episode": 222,
    "avg_reward_per_step": -0.5398535774662738,
    "episode_length": 3000,
    "policy_loss": -0.3336111456155777,
    "value_loss": 0.43664275109767914,
    "entropy": 0.029106864240020514,
    "total_loss": 0.09138885978609324
  },
  {
    "episode": 223,
    "avg_reward_per_step": -0.5377461957723539,
    "episode_length": 3000,
    "policy_loss": -0.29123012721538544,
    "value_loss": 0.4326190873980522,
    "entropy": 0.027445840183645487,
    "total_loss": 0.1304106241092086
  },
  {
    "episode": 224,
    "avg_reward_per_step": -2.074471432250667,
    "episode_length": 3000,
    "policy_loss": 13.800143480300903,
    "value_loss": 0.5520850718021393,
    "entropy": 0.03829807508736849,
    "total_loss": 14.336909322068095
  },
  {
    "episode": 225,
    "avg_reward_per_step": -0.5577658952982811,
    "episode_length": 3000,
    "policy_loss": -0.052562554366886616,
    "value_loss": 0.43383800983428955,
    "entropy": 0.03011482860893011,
    "total_loss": 0.3692295240238309
  },
  {
    "episode": 226,
    "avg_reward_per_step": -8.854323067335592,
    "episode_length": 3000,
    "policy_loss": 76.0310001373291,
    "value_loss": 0.8517872393131256,
    "entropy": 0.03783203195780516,
    "total_loss": 76.8676545638591
  },
  {
    "episode": 227,
    "avg_reward_per_step": -1.2844999770535284,
    "episode_length": 3000,
    "policy_loss": 6.606166481971741,
    "value_loss": 0.5350196659564972,
    "entropy": 0.039072985760867596,
    "total_loss": 7.1255569536238905
  },
  {
    "episode": 228,
    "avg_reward_per_step": -0.8579117385166233,
    "episode_length": 3000,
    "policy_loss": 2.641494035720825,
    "value_loss": 0.5113148093223572,
    "entropy": 0.03218722436577082,
    "total_loss": 3.139933955296874
  },
  {
    "episode": 229,
    "avg_reward_per_step": -0.5544129617246727,
    "episode_length": 3000,
    "policy_loss": -0.23395443335175514,
    "value_loss": 0.45697275549173355,
    "entropy": 0.025441450998187065,
    "total_loss": 0.21284174174070358
  },
  {
    "episode": 230,
    "avg_reward_per_step": -5.594206434373572,
    "episode_length": 3000,
    "policy_loss": 46.078792572021484,
    "value_loss": 0.6635235249996185,
    "entropy": 0.03224023338407278,
    "total_loss": 46.72942000366747
  },
  {
    "episode": 231,
    "avg_reward_per_step": -0.5710990992251753,
    "episode_length": 3000,
    "policy_loss": 0.04306303150951862,
    "value_loss": 0.41774191707372665,
    "entropy": 0.03563376609236002,
    "total_loss": 0.44655144214630127
  },
  {
    "episode": 232,
    "avg_reward_per_step": -0.5609350021774816,
    "episode_length": 3000,
    "policy_loss": -0.13414033874869347,
    "value_loss": 0.45114409178495407,
    "entropy": 0.022428445052355528,
    "total_loss": 0.3080323750153184
  },
  {
    "episode": 233,
    "avg_reward_per_step": -3.201088054381831,
    "episode_length": 3000,
    "policy_loss": 24.100898265838623,
    "value_loss": 0.5649705082178116,
    "entropy": 0.0354574816301465,
    "total_loss": 24.651685781404375
  },
  {
    "episode": 234,
    "avg_reward_per_step": -0.5543616213495001,
    "episode_length": 3000,
    "policy_loss": -0.152586217969656,
    "value_loss": 0.4408727139234543,
    "entropy": 0.025767204351723194,
    "total_loss": 0.277979614213109
  },
  {
    "episode": 235,
    "avg_reward_per_step": -0.567696866822071,
    "episode_length": 3000,
    "policy_loss": 0.0052927067736163735,
    "value_loss": 0.41921984404325485,
    "entropy": 0.028555076103657484,
    "total_loss": 0.4130905203754082
  },
  {
    "episode": 236,
    "avg_reward_per_step": -6.424242128825148,
    "episode_length": 3000,
    "policy_loss": 53.64278316497803,
    "value_loss": 0.7175521105527878,
    "entropy": 0.03661131765693426,
    "total_loss": 54.345690748468044
  },
  {
    "episode": 237,
    "avg_reward_per_step": -0.577724867504238,
    "episode_length": 3000,
    "policy_loss": 0.04815726634114981,
    "value_loss": 0.4333277940750122,
    "entropy": 0.023999496828764677,
    "total_loss": 0.47188526168465617
  },
  {
    "episode": 238,
    "avg_reward_per_step": 16.97389885210874,
    "episode_length": 1147,
    "policy_loss": -161.59722137451172,
    "value_loss": 0.5075848698616028,
    "entropy": 0.03221651911735535,
    "total_loss": -161.10252311229706
  },
  {
    "episode": 239,
    "avg_reward_per_step": -0.541055481680918,
    "episode_length": 3000,
    "policy_loss": -0.2947506159543991,
    "value_loss": 0.41777244210243225,
    "entropy": 0.025483925361186266,
    "total_loss": 0.11282825600355864
  },
  {
    "episode": 240,
    "avg_reward_per_step": -0.564438633987827,
    "episode_length": 3000,
    "policy_loss": -0.09838181175291538,
    "value_loss": 0.4224715530872345,
    "entropy": 0.027981907594949007,
    "total_loss": 0.3128969782963395
  },
  {
    "episode": 241,
    "avg_reward_per_step": -0.5444155943472581,
    "episode_length": 3000,
    "policy_loss": -0.23404566198587418,
    "value_loss": 0.4217095524072647,
    "entropy": 0.027139503974467516,
    "total_loss": 0.17680808883160354
  },
  {
    "episode": 242,
    "avg_reward_per_step": -4.517578287937537,
    "episode_length": 3000,
    "policy_loss": 36.211286544799805,
    "value_loss": 0.6213722079992294,
    "entropy": 0.03778688795864582,
    "total_loss": 36.81754399761557
  },
  {
    "episode": 243,
    "avg_reward_per_step": -6.460905234037524,
    "episode_length": 3000,
    "policy_loss": 53.99977111816406,
    "value_loss": 0.7260778397321701,
    "entropy": 0.03935027401894331,
    "total_loss": 54.710108848288655
  },
  {
    "episode": 244,
    "avg_reward_per_step": -0.6978325814439102,
    "episode_length": 3000,
    "policy_loss": 1.1619526147842407,
    "value_loss": 0.4780651777982712,
    "entropy": 0.03285863343626261,
    "total_loss": 1.626874339208007
  },
  {
    "episode": 245,
    "avg_reward_per_step": -0.550974220813922,
    "episode_length": 3000,
    "policy_loss": -0.20155905559659004,
    "value_loss": 0.4191255271434784,
    "entropy": 0.028240615036338568,
    "total_loss": 0.2062702255323529
  },
  {
    "episode": 246,
    "avg_reward_per_step": -0.554405257624762,
    "episode_length": 3000,
    "policy_loss": -0.10972299985587597,
    "value_loss": 0.3891633301973343,
    "entropy": 0.03175803832709789,
    "total_loss": 0.26673711501061914
  },
  {
    "episode": 247,
    "avg_reward_per_step": 35.41200470273677,
    "episode_length": 558,
    "policy_loss": -331.47056579589844,
    "value_loss": 0.5153888165950775,
    "entropy": 0.031786078587174416,
    "total_loss": -330.9678914107382
  },
  {
    "episode": 248,
    "avg_reward_per_step": 28.43582605688659,
    "episode_length": 693,
    "policy_loss": -267.1223449707031,
    "value_loss": 0.512489840388298,
    "entropy": 0.037590060383081436,
    "total_loss": -266.62489115446806
  },
  {
    "episode": 249,
    "avg_reward_per_step": -0.5577413745080001,
    "episode_length": 3000,
    "policy_loss": -0.11539298854768276,
    "value_loss": 0.420742891728878,
    "entropy": 0.025486592669039965,
    "total_loss": 0.2951552661135793
  },
  {
    "episode": 250,
    "avg_reward_per_step": -0.5510777585247347,
    "episode_length": 3000,
    "policy_loss": -0.16472069174051285,
    "value_loss": 0.4171135127544403,
    "entropy": 0.026215449906885624,
    "total_loss": 0.2419066410511732
  },
  {
    "episode": 251,
    "avg_reward_per_step": -10.250830914601687,
    "episode_length": 3000,
    "policy_loss": 88.7436294555664,
    "value_loss": 1.0573488175868988,
    "entropy": 0.03489972371608019,
    "total_loss": 89.78701838366688
  },
  {
    "episode": 252,
    "avg_reward_per_step": -0.5444030555539706,
    "episode_length": 3000,
    "policy_loss": -0.21986214071512222,
    "value_loss": 0.42504092305898666,
    "entropy": 0.02377659920603037,
    "total_loss": 0.1956681426614523
  },
  {
    "episode": 253,
    "avg_reward_per_step": -0.5510840294804513,
    "episode_length": 3000,
    "policy_loss": -0.17874553799629211,
    "value_loss": 0.415259413421154,
    "entropy": 0.027343438006937504,
    "total_loss": 0.22557650022208692
  },
  {
    "episode": 254,
    "avg_reward_per_step": 55.98599283780958,
    "episode_length": 355,
    "policy_loss": -520.5410766601562,
    "value_loss": 0.5245440751314163,
    "entropy": 0.04077837988734245,
    "total_loss": -520.0328439369798
  },
  {
    "episode": 255,
    "avg_reward_per_step": -1.5043962700828275,
    "episode_length": 3000,
    "policy_loss": 8.590450763702393,
    "value_loss": 0.5374648869037628,
    "entropy": 0.031097959727048874,
    "total_loss": 9.115476466715336
  },
  {
    "episode": 256,
    "avg_reward_per_step": -13.46387346250584,
    "episode_length": 3000,
    "policy_loss": 118.35098075866699,
    "value_loss": 1.9153926372528076,
    "entropy": 0.1949881985783577,
    "total_loss": 120.18837811648845
  },
  {
    "episode": 257,
    "avg_reward_per_step": -0.5543316630094924,
    "episode_length": 3000,
    "policy_loss": -0.11562140472233295,
    "value_loss": 0.4041638895869255,
    "entropy": 0.034469958394765854,
    "total_loss": 0.27475450150668623
  },
  {
    "episode": 258,
    "avg_reward_per_step": -0.5744085824024036,
    "episode_length": 3000,
    "policy_loss": 0.040016550570726395,
    "value_loss": 0.4137417748570442,
    "entropy": 0.027266025077551603,
    "total_loss": 0.44285191539674995
  },
  {
    "episode": 259,
    "avg_reward_per_step": -1.1345074023289774,
    "episode_length": 3000,
    "policy_loss": 5.069748044013977,
    "value_loss": 0.5200830847024918,
    "entropy": 0.03766975272446871,
    "total_loss": 5.574763227626681
  },
  {
    "episode": 260,
    "avg_reward_per_step": -4.044497009745896,
    "episode_length": 3000,
    "policy_loss": 31.684528827667236,
    "value_loss": 0.7668281197547913,
    "entropy": 0.042072330601513386,
    "total_loss": 32.43452801518142
  },
  {
    "episode": 261,
    "avg_reward_per_step": 21.490668840998424,
    "episode_length": 912,
    "policy_loss": -204.0198097229004,
    "value_loss": 0.5094526559114456,
    "entropy": 0.030061771627515554,
    "total_loss": -203.52238177563996
  },
  {
    "episode": 262,
    "avg_reward_per_step": -0.5644350831553121,
    "episode_length": 3000,
    "policy_loss": -0.2047901675105095,
    "value_loss": 0.3971301093697548,
    "entropy": 0.03444688394665718,
    "total_loss": 0.17856118828058243
  },
  {
    "episode": 263,
    "avg_reward_per_step": -0.564427503650137,
    "episode_length": 3000,
    "policy_loss": -0.21759943291544914,
    "value_loss": 0.40604403614997864,
    "entropy": 0.04352833144366741,
    "total_loss": 0.17103327065706253
  },
  {
    "episode": 264,
    "avg_reward_per_step": 54.535434408021594,
    "episode_length": 364,
    "policy_loss": -507.4950256347656,
    "value_loss": 0.5238370001316071,
    "entropy": 0.049257492646574974,
    "total_loss": -506.99089163169265
  },
  {
    "episode": 265,
    "avg_reward_per_step": 62.957365371589894,
    "episode_length": 316,
    "policy_loss": -585.3153381347656,
    "value_loss": 0.5277528315782547,
    "entropy": 0.05685820709913969,
    "total_loss": -584.810328586027
  },
  {
    "episode": 266,
    "avg_reward_per_step": -5.974320345401643,
    "episode_length": 3000,
    "policy_loss": 49.39822959899902,
    "value_loss": 0.7522103935480118,
    "entropy": 0.05851808935403824,
    "total_loss": 50.12703275680542
  },
  {
    "episode": 267,
    "avg_reward_per_step": -10.030852531642582,
    "episode_length": 3000,
    "policy_loss": 86.55302047729492,
    "value_loss": 0.9586606919765472,
    "entropy": 0.051230465061962605,
    "total_loss": 87.49118898324669
  },
  {
    "episode": 268,
    "avg_reward_per_step": -0.5710897898177679,
    "episode_length": 3000,
    "policy_loss": -0.15433821827173233,
    "value_loss": 0.40682169049978256,
    "entropy": 0.04056822322309017,
    "total_loss": 0.23625618293881417
  },
  {
    "episode": 269,
    "avg_reward_per_step": -14.164398291551803,
    "episode_length": 3000,
    "policy_loss": 124.43293762207031,
    "value_loss": 1.3134017586708069,
    "entropy": 0.05209999717772007,
    "total_loss": 125.72549938187004
  },
  {
    "episode": 270,
    "avg_reward_per_step": -2.0844806921966987,
    "episode_length": 3000,
    "policy_loss": 13.662302732467651,
    "value_loss": 0.5673837512731552,
    "entropy": 0.056064280681312084,
    "total_loss": 14.207260771468281
  },
  {
    "episode": 271,
    "avg_reward_per_step": 4.065806132303281,
    "episode_length": 2113,
    "policy_loss": -43.5653076171875,
    "value_loss": 0.5008857697248459,
    "entropy": 0.05503040086477995,
    "total_loss": -43.08643400780856
  },
  {
    "episode": 272,
    "avg_reward_per_step": 3.5989902971225063,
    "episode_length": 2622,
    "policy_loss": -39.10090160369873,
    "value_loss": 0.5009341686964035,
    "entropy": 0.06262710876762867,
    "total_loss": -38.62501827850938
  },
  {
    "episode": 273,
    "avg_reward_per_step": -13.157454042680612,
    "episode_length": 3000,
    "policy_loss": 115.14354515075684,
    "value_loss": 1.9723016619682312,
    "entropy": 0.4025043919682503,
    "total_loss": 116.95484505593777
  },
  {
    "episode": 274,
    "avg_reward_per_step": 1.8697098732824484,
    "episode_length": 2116,
    "policy_loss": -23.63636064529419,
    "value_loss": 0.5001528859138489,
    "entropy": 0.0738010834902525,
    "total_loss": -23.16572819277644
  },
  {
    "episode": 275,
    "avg_reward_per_step": 2.3966530867382443,
    "episode_length": 1685,
    "policy_loss": -28.327234268188477,
    "value_loss": 0.5001125037670135,
    "entropy": 0.08519736304879189,
    "total_loss": -27.86120070964098
  },
  {
    "episode": 276,
    "avg_reward_per_step": 11.158698517341683,
    "episode_length": 1144,
    "policy_loss": -109.04255867004395,
    "value_loss": 0.5031892508268356,
    "entropy": 0.10724793933331966,
    "total_loss": -108.58226859495043
  },
  {
    "episode": 277,
    "avg_reward_per_step": 2.161475659382824,
    "episode_length": 2293,
    "policy_loss": -26.653693199157715,
    "value_loss": 0.5002272725105286,
    "entropy": 0.10382537171244621,
    "total_loss": -26.194996075332163
  },
  {
    "episode": 278,
    "avg_reward_per_step": -11.65829617439971,
    "episode_length": 3000,
    "policy_loss": 100.95287132263184,
    "value_loss": 1.4529186487197876,
    "entropy": 0.4543122723698616,
    "total_loss": 102.22406506240368
  },
  {
    "episode": 279,
    "avg_reward_per_step": 18.0936942889289,
    "episode_length": 784,
    "policy_loss": -173.05672073364258,
    "value_loss": 0.5055423676967621,
    "entropy": 0.14973155036568642,
    "total_loss": -172.6110709860921
  },
  {
    "episode": 280,
    "avg_reward_per_step": -10.233672973350908,
    "episode_length": 3000,
    "policy_loss": 87.86175537109375,
    "value_loss": 1.5858728289604187,
    "entropy": 0.6014476269483566,
    "total_loss": 89.20704914927482
  },
  {
    "episode": 281,
    "avg_reward_per_step": 15.690839455316873,
    "episode_length": 908,
    "policy_loss": -152.00835037231445,
    "value_loss": 0.5049878358840942,
    "entropy": 0.18040706589818,
    "total_loss": -151.57552536278962
  },
  {
    "episode": 282,
    "avg_reward_per_step": 17.944161655867028,
    "episode_length": 696,
    "policy_loss": -171.86741638183594,
    "value_loss": 0.5046810954809189,
    "entropy": 0.221261166036129,
    "total_loss": -171.45123975276948
  },
  {
    "episode": 283,
    "avg_reward_per_step": -12.647921788617719,
    "episode_length": 3000,
    "policy_loss": 109.87704467773438,
    "value_loss": 1.7395799160003662,
    "entropy": 0.3897421061992645,
    "total_loss": 111.46072775125504
  },
  {
    "episode": 284,
    "avg_reward_per_step": 9.991901011232153,
    "episode_length": 1313,
    "policy_loss": -98.57304573059082,
    "value_loss": 0.5032393336296082,
    "entropy": 0.47296202182769775,
    "total_loss": -98.2589912056923
  },
  {
    "episode": 285,
    "avg_reward_per_step": 21.108970402524402,
    "episode_length": 818,
    "policy_loss": -200.12116622924805,
    "value_loss": 0.5087678581476212,
    "entropy": 0.6434547007083893,
    "total_loss": -199.8697802513838
  },
  {
    "episode": 286,
    "avg_reward_per_step": 50.145087707441235,
    "episode_length": 368,
    "policy_loss": -471.03450775146484,
    "value_loss": 0.5203636139631271,
    "entropy": 0.2258882075548172,
    "total_loss": -470.60449942052367
  },
  {
    "episode": 287,
    "avg_reward_per_step": 31.207900135941617,
    "episode_length": 599,
    "policy_loss": -293.8050079345703,
    "value_loss": 0.5137273818254471,
    "entropy": 0.6465212106704712,
    "total_loss": -293.54988903701303
  },
  {
    "episode": 288,
    "avg_reward_per_step": 46.44425785257506,
    "episode_length": 386,
    "policy_loss": -435.5371780395508,
    "value_loss": 0.5182469040155411,
    "entropy": 0.2885168045759201,
    "total_loss": -435.1343378573656
  },
  {
    "episode": 289,
    "avg_reward_per_step": 46.70995355647165,
    "episode_length": 383,
    "policy_loss": -439.98316192626953,
    "value_loss": 0.518224835395813,
    "entropy": 0.3244415372610092,
    "total_loss": -439.59471370577813
  },
  {
    "episode": 290,
    "avg_reward_per_step": 23.665871142089937,
    "episode_length": 700,
    "policy_loss": -225.37971115112305,
    "value_loss": 0.5085993409156799,
    "entropy": 0.21804748475551605,
    "total_loss": -224.95833080410958
  },
  {
    "episode": 291,
    "avg_reward_per_step": 22.80657403876856,
    "episode_length": 741,
    "policy_loss": -219.26569366455078,
    "value_loss": 0.5085765272378922,
    "entropy": 0.2708346024155617,
    "total_loss": -218.8654509782791
  },
  {
    "episode": 292,
    "avg_reward_per_step": 108.42700441332389,
    "episode_length": 184,
    "policy_loss": -1005.7008514404297,
    "value_loss": 0.5495473891496658,
    "entropy": 0.20080699026584625,
    "total_loss": -1005.2316268473863
  },
  {
    "episode": 293,
    "avg_reward_per_step": -11.615274450961754,
    "episode_length": 3000,
    "policy_loss": 100.20047378540039,
    "value_loss": 1.7373421490192413,
    "entropy": 0.2951962277293205,
    "total_loss": 101.81973744332791
  },
  {
    "episode": 294,
    "avg_reward_per_step": 9.460666324347303,
    "episode_length": 1217,
    "policy_loss": -93.74294853210449,
    "value_loss": 0.5028494894504547,
    "entropy": 0.3712628185749054,
    "total_loss": -93.388604170084
  },
  {
    "episode": 295,
    "avg_reward_per_step": 45.089318371887586,
    "episode_length": 371,
    "policy_loss": -425.69622802734375,
    "value_loss": 0.5163056701421738,
    "entropy": 0.29555895924568176,
    "total_loss": -425.2981459408999
  },
  {
    "episode": 296,
    "avg_reward_per_step": -3.0709469020996796,
    "episode_length": 2877,
    "policy_loss": 20.99979257583618,
    "value_loss": 0.5003893822431564,
    "entropy": 0.29655756801366806,
    "total_loss": 21.381558930873872
  },
  {
    "episode": 297,
    "avg_reward_per_step": 163.59907833393714,
    "episode_length": 122,
    "policy_loss": -1519.0466918945312,
    "value_loss": 0.578377977013588,
    "entropy": 0.18723170459270477,
    "total_loss": -1518.5432065993548
  },
  {
    "episode": 298,
    "avg_reward_per_step": 47.88254161355014,
    "episode_length": 387,
    "policy_loss": -448.72727966308594,
    "value_loss": 0.5195890814065933,
    "entropy": 0.24818966537714005,
    "total_loss": -448.3069664478302
  },
  {
    "episode": 299,
    "avg_reward_per_step": 196.0934064904446,
    "episode_length": 102,
    "policy_loss": -1813.3395080566406,
    "value_loss": 0.5972043126821518,
    "entropy": 0.12096214666962624,
    "total_loss": -1812.7906886026262
  },
  {
    "episode": 300,
    "avg_reward_per_step": 35.258432861662534,
    "episode_length": 474,
    "policy_loss": -333.58814239501953,
    "value_loss": 0.5128073394298553,
    "entropy": 0.21771977841854095,
    "total_loss": -333.1624229669571
  }
]