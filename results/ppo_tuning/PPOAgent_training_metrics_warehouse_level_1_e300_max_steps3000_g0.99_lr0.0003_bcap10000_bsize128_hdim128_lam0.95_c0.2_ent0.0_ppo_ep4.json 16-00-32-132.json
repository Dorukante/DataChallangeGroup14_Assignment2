[
  {
    "episode": 1,
    "avg_reward_per_step": 11.132709237787278,
    "episode_length": 1401,
    "policy_loss": -193.51065063476562,
    "value_loss": 0.5068565905094147,
    "entropy": 1.3751296401023865,
    "total_loss": -193.0037940442562
  },
  {
    "episode": 2,
    "avg_reward_per_step": 18.78098173252737,
    "episode_length": 886,
    "policy_loss": -322.253662109375,
    "value_loss": 0.5125782340764999,
    "entropy": 1.3760773241519928,
    "total_loss": -321.7410838752985
  },
  {
    "episode": 3,
    "avg_reward_per_step": -3.7326533846561882,
    "episode_length": 3000,
    "policy_loss": 62.67142200469971,
    "value_loss": 1.650819718837738,
    "entropy": 1.3614571392536163,
    "total_loss": 64.32224172353745
  },
  {
    "episode": 4,
    "avg_reward_per_step": 4.740093764265455,
    "episode_length": 1931,
    "policy_loss": -83.08126068115234,
    "value_loss": 0.5015162080526352,
    "entropy": 1.3314266502857208,
    "total_loss": -82.57974447309971
  },
  {
    "episode": 5,
    "avg_reward_per_step": 26.473608177675015,
    "episode_length": 640,
    "policy_loss": -453.9618911743164,
    "value_loss": 0.5182424336671829,
    "entropy": 1.296362817287445,
    "total_loss": -453.4436487406492
  },
  {
    "episode": 6,
    "avg_reward_per_step": -5.371205890493219,
    "episode_length": 3000,
    "policy_loss": 90.15090942382812,
    "value_loss": 2.0817372798919678,
    "entropy": 1.2799090445041656,
    "total_loss": 92.23264670372009
  },
  {
    "episode": 7,
    "avg_reward_per_step": 53.827913500730794,
    "episode_length": 341,
    "policy_loss": -911.1759185791016,
    "value_loss": 0.5422521829605103,
    "entropy": 1.2490632236003876,
    "total_loss": -910.633666396141
  },
  {
    "episode": 8,
    "avg_reward_per_step": 52.60528944229606,
    "episode_length": 358,
    "policy_loss": -890.0310821533203,
    "value_loss": 0.5428448021411896,
    "entropy": 1.251657485961914,
    "total_loss": -889.4882373511791
  },
  {
    "episode": 9,
    "avg_reward_per_step": 43.851664825615984,
    "episode_length": 413,
    "policy_loss": -756.1290130615234,
    "value_loss": 0.5334424674510956,
    "entropy": 1.2933057248592377,
    "total_loss": -755.5955705940723
  },
  {
    "episode": 10,
    "avg_reward_per_step": 37.545117576963364,
    "episode_length": 510,
    "policy_loss": -634.0700531005859,
    "value_loss": 0.5301974564790726,
    "entropy": 1.310907930135727,
    "total_loss": -633.5398556441069
  },
  {
    "episode": 11,
    "avg_reward_per_step": 9.910244956457788,
    "episode_length": 1677,
    "policy_loss": -166.20105743408203,
    "value_loss": 0.5065426677465439,
    "entropy": 1.2940977811813354,
    "total_loss": -165.6945147663355
  },
  {
    "episode": 12,
    "avg_reward_per_step": -2.4705005638318536,
    "episode_length": 3000,
    "policy_loss": 41.18167495727539,
    "value_loss": 1.7613673210144043,
    "entropy": 1.2908712327480316,
    "total_loss": 42.943042278289795
  },
  {
    "episode": 13,
    "avg_reward_per_step": 15.300268543003305,
    "episode_length": 1152,
    "policy_loss": -259.2565612792969,
    "value_loss": 0.5108448415994644,
    "entropy": 1.2735870778560638,
    "total_loss": -258.7457164376974
  },
  {
    "episode": 14,
    "avg_reward_per_step": 22.663791145411505,
    "episode_length": 806,
    "policy_loss": -385.58534240722656,
    "value_loss": 0.5169020891189575,
    "entropy": 1.2587200999259949,
    "total_loss": -385.0684403181076
  },
  {
    "episode": 15,
    "avg_reward_per_step": 68.31997759503041,
    "episode_length": 286,
    "policy_loss": -1160.4945068359375,
    "value_loss": 0.5595700889825821,
    "entropy": 1.223591148853302,
    "total_loss": -1159.934936746955
  },
  {
    "episode": 16,
    "avg_reward_per_step": 8.750216926900906,
    "episode_length": 1748,
    "policy_loss": -147.89617919921875,
    "value_loss": 0.5052625387907028,
    "entropy": 1.2211717069149017,
    "total_loss": -147.39091666042805
  },
  {
    "episode": 17,
    "avg_reward_per_step": 5.40324122249698,
    "episode_length": 2597,
    "policy_loss": -91.10880661010742,
    "value_loss": 0.5029338449239731,
    "entropy": 1.1851396560668945,
    "total_loss": -90.60587276518345
  },
  {
    "episode": 18,
    "avg_reward_per_step": 6.068079131996899,
    "episode_length": 2422,
    "policy_loss": -103.08647155761719,
    "value_loss": 0.5034883320331573,
    "entropy": 1.193378061056137,
    "total_loss": -102.58298322558403
  },
  {
    "episode": 19,
    "avg_reward_per_step": 24.223985237289323,
    "episode_length": 760,
    "policy_loss": -414.1281280517578,
    "value_loss": 0.5183353126049042,
    "entropy": 1.1843424439430237,
    "total_loss": -413.6097927391529
  },
  {
    "episode": 20,
    "avg_reward_per_step": 58.71420234441053,
    "episode_length": 327,
    "policy_loss": -1003.5599060058594,
    "value_loss": 0.5492603033781052,
    "entropy": 1.1992464065551758,
    "total_loss": -1003.0106457024813
  },
  {
    "episode": 21,
    "avg_reward_per_step": 34.78202888267044,
    "episode_length": 515,
    "policy_loss": -590.9357299804688,
    "value_loss": 0.5259126424789429,
    "entropy": 1.1735912561416626,
    "total_loss": -590.4098173379898
  },
  {
    "episode": 22,
    "avg_reward_per_step": 10.292548662392047,
    "episode_length": 1208,
    "policy_loss": -175.2976188659668,
    "value_loss": 0.5048839449882507,
    "entropy": 1.1168366968631744,
    "total_loss": -174.79273492097855
  },
  {
    "episode": 23,
    "avg_reward_per_step": 21.15656042569906,
    "episode_length": 779,
    "policy_loss": -356.44348907470703,
    "value_loss": 0.5140291750431061,
    "entropy": 1.0883060693740845,
    "total_loss": -355.9294598996639
  },
  {
    "episode": 24,
    "avg_reward_per_step": 16.510035308409762,
    "episode_length": 846,
    "policy_loss": -279.04480743408203,
    "value_loss": 0.5091336667537689,
    "entropy": 1.0275216698646545,
    "total_loss": -278.53567376732826
  },
  {
    "episode": 25,
    "avg_reward_per_step": 31.721337454144834,
    "episode_length": 539,
    "policy_loss": -542.0169677734375,
    "value_loss": 0.5223554223775864,
    "entropy": 1.0726967453956604,
    "total_loss": -541.4946123510599
  },
  {
    "episode": 26,
    "avg_reward_per_step": 15.935252188255252,
    "episode_length": 918,
    "policy_loss": -272.2607879638672,
    "value_loss": 0.5091586410999298,
    "entropy": 1.1090656518936157,
    "total_loss": -271.75162932276726
  },
  {
    "episode": 27,
    "avg_reward_per_step": 79.47785060292338,
    "episode_length": 241,
    "policy_loss": -1351.4498901367188,
    "value_loss": 0.5690521150827408,
    "entropy": 1.1363734900951385,
    "total_loss": -1350.880838021636
  },
  {
    "episode": 28,
    "avg_reward_per_step": 66.11411889320898,
    "episode_length": 292,
    "policy_loss": -1137.9017028808594,
    "value_loss": 0.5567075461149216,
    "entropy": 1.0747866034507751,
    "total_loss": -1137.3449953347445
  },
  {
    "episode": 29,
    "avg_reward_per_step": 33.28444172581515,
    "episode_length": 524,
    "policy_loss": -563.7280120849609,
    "value_loss": 0.5239124298095703,
    "entropy": 0.9222758412361145,
    "total_loss": -563.2040996551514
  },
  {
    "episode": 30,
    "avg_reward_per_step": 10.365161363039869,
    "episode_length": 1294,
    "policy_loss": -176.25965881347656,
    "value_loss": 0.5053936839103699,
    "entropy": 0.9095479249954224,
    "total_loss": -175.7542651295662
  },
  {
    "episode": 31,
    "avg_reward_per_step": 59.928329663458,
    "episode_length": 319,
    "policy_loss": -1018.925048828125,
    "value_loss": 0.550075352191925,
    "entropy": 0.9326555877923965,
    "total_loss": -1018.3749734759331
  },
  {
    "episode": 32,
    "avg_reward_per_step": 56.48002114731205,
    "episode_length": 338,
    "policy_loss": -952.0344085693359,
    "value_loss": 0.5469222664833069,
    "entropy": 0.8872085809707642,
    "total_loss": -951.4874863028526
  },
  {
    "episode": 33,
    "avg_reward_per_step": 42.259163459800575,
    "episode_length": 452,
    "policy_loss": -712.4103851318359,
    "value_loss": 0.534191831946373,
    "entropy": 0.8635236322879791,
    "total_loss": -711.8761932998896
  },
  {
    "episode": 34,
    "avg_reward_per_step": 29.549053047982504,
    "episode_length": 596,
    "policy_loss": -502.9412612915039,
    "value_loss": 0.5213421881198883,
    "entropy": 0.8318914175033569,
    "total_loss": -502.419919103384
  },
  {
    "episode": 35,
    "avg_reward_per_step": 30.51503044199606,
    "episode_length": 630,
    "policy_loss": -521.2843627929688,
    "value_loss": 0.5244192779064178,
    "entropy": 0.8108730465173721,
    "total_loss": -520.7599435150623
  },
  {
    "episode": 36,
    "avg_reward_per_step": 75.5629449884873,
    "episode_length": 260,
    "policy_loss": -1303.0548706054688,
    "value_loss": 0.566789984703064,
    "entropy": 0.8927891105413437,
    "total_loss": -1302.4880806207657
  },
  {
    "episode": 37,
    "avg_reward_per_step": 33.532128553542215,
    "episode_length": 557,
    "policy_loss": -559.9188690185547,
    "value_loss": 0.5261506885290146,
    "entropy": 0.8953732550144196,
    "total_loss": -559.3927183300257
  },
  {
    "episode": 38,
    "avg_reward_per_step": 90.24613294825362,
    "episode_length": 216,
    "policy_loss": -1550.2950744628906,
    "value_loss": 0.5818379521369934,
    "entropy": 0.8983833938837051,
    "total_loss": -1549.7132365107536
  },
  {
    "episode": 39,
    "avg_reward_per_step": 30.638629957395516,
    "episode_length": 585,
    "policy_loss": -516.4195861816406,
    "value_loss": 0.5226524770259857,
    "entropy": 0.8447585701942444,
    "total_loss": -515.8969337046146
  },
  {
    "episode": 40,
    "avg_reward_per_step": 122.55190509715672,
    "episode_length": 159,
    "policy_loss": -2080.3523559570312,
    "value_loss": 0.6184529513120651,
    "entropy": 0.8828232437372208,
    "total_loss": -2079.733903005719
  },
  {
    "episode": 41,
    "avg_reward_per_step": 74.6146200257384,
    "episode_length": 262,
    "policy_loss": -1260.900634765625,
    "value_loss": 0.5656644701957703,
    "entropy": 0.8989690244197845,
    "total_loss": -1260.3349702954292
  },
  {
    "episode": 42,
    "avg_reward_per_step": 7.74758006979733,
    "episode_length": 1412,
    "policy_loss": -131.36693572998047,
    "value_loss": 0.5031283497810364,
    "entropy": 0.7923891395330429,
    "total_loss": -130.86380738019943
  },
  {
    "episode": 43,
    "avg_reward_per_step": 37.21886322172299,
    "episode_length": 465,
    "policy_loss": -629.2361755371094,
    "value_loss": 0.5265056043863297,
    "entropy": 0.7932189255952835,
    "total_loss": -628.709669932723
  },
  {
    "episode": 44,
    "avg_reward_per_step": 22.512792407638315,
    "episode_length": 746,
    "policy_loss": -382.89554595947266,
    "value_loss": 0.5152450650930405,
    "entropy": 0.832594022154808,
    "total_loss": -382.3803008943796
  },
  {
    "episode": 45,
    "avg_reward_per_step": 57.123627418268015,
    "episode_length": 333,
    "policy_loss": -979.6936340332031,
    "value_loss": 0.5471942275762558,
    "entropy": 0.8746983259916306,
    "total_loss": -979.1464398056269
  },
  {
    "episode": 46,
    "avg_reward_per_step": 70.20913503502803,
    "episode_length": 279,
    "policy_loss": -1181.7001037597656,
    "value_loss": 0.5613909065723419,
    "entropy": 0.8222870826721191,
    "total_loss": -1181.1387128531933
  },
  {
    "episode": 47,
    "avg_reward_per_step": 219.4650964094595,
    "episode_length": 91,
    "policy_loss": -3757.6746215820312,
    "value_loss": 0.767310693860054,
    "entropy": 0.890331506729126,
    "total_loss": -3756.907310888171
  },
  {
    "episode": 48,
    "avg_reward_per_step": 30.70529822498249,
    "episode_length": 590,
    "policy_loss": -518.0131530761719,
    "value_loss": 0.5229573547840118,
    "entropy": 0.8940563350915909,
    "total_loss": -517.4901957213879
  },
  {
    "episode": 49,
    "avg_reward_per_step": 17.966923269105045,
    "episode_length": 1006,
    "policy_loss": -307.8177947998047,
    "value_loss": 0.5131160169839859,
    "entropy": 0.9458795934915543,
    "total_loss": -307.3046787828207
  },
  {
    "episode": 50,
    "avg_reward_per_step": 24.875169440877812,
    "episode_length": 742,
    "policy_loss": -417.68385314941406,
    "value_loss": 0.518821656703949,
    "entropy": 0.9678990542888641,
    "total_loss": -417.1650314927101
  },
  {
    "episode": 51,
    "avg_reward_per_step": 17.671889003924974,
    "episode_length": 999,
    "policy_loss": -298.10938262939453,
    "value_loss": 0.5125783681869507,
    "entropy": 0.9619924873113632,
    "total_loss": -297.5968042612076
  },
  {
    "episode": 52,
    "avg_reward_per_step": 81.8094795803387,
    "episode_length": 238,
    "policy_loss": -1385.5071716308594,
    "value_loss": 0.5726608037948608,
    "entropy": 0.9438997805118561,
    "total_loss": -1384.9345108270645
  },
  {
    "episode": 53,
    "avg_reward_per_step": 67.43003686927484,
    "episode_length": 292,
    "policy_loss": -1148.9525146484375,
    "value_loss": 0.559034451842308,
    "entropy": 0.9075632989406586,
    "total_loss": -1148.3934801965952
  },
  {
    "episode": 54,
    "avg_reward_per_step": 80.53977992962737,
    "episode_length": 245,
    "policy_loss": -1359.2390441894531,
    "value_loss": 0.5725035518407822,
    "entropy": 0.9620843231678009,
    "total_loss": -1358.6665406376123
  },
  {
    "episode": 55,
    "avg_reward_per_step": 9.89544684747732,
    "episode_length": 1455,
    "policy_loss": -165.39411544799805,
    "value_loss": 0.5055453777313232,
    "entropy": 0.9518076479434967,
    "total_loss": -164.88857007026672
  },
  {
    "episode": 56,
    "avg_reward_per_step": 63.20268410932565,
    "episode_length": 311,
    "policy_loss": -1073.4993286132812,
    "value_loss": 0.5546591430902481,
    "entropy": 0.921497255563736,
    "total_loss": -1072.944669470191
  },
  {
    "episode": 57,
    "avg_reward_per_step": 22.940195109275336,
    "episode_length": 792,
    "policy_loss": -386.4138412475586,
    "value_loss": 0.5169647186994553,
    "entropy": 0.9433247447013855,
    "total_loss": -385.89687652885914
  },
  {
    "episode": 58,
    "avg_reward_per_step": 79.69395271758869,
    "episode_length": 246,
    "policy_loss": -1349.2467041015625,
    "value_loss": 0.5712912082672119,
    "entropy": 0.8973097950220108,
    "total_loss": -1348.6754128932953
  },
  {
    "episode": 59,
    "avg_reward_per_step": 141.59921704299398,
    "episode_length": 140,
    "policy_loss": -2393.6102905273438,
    "value_loss": 0.6445038616657257,
    "entropy": 0.911881297826767,
    "total_loss": -2392.965786665678
  },
  {
    "episode": 60,
    "avg_reward_per_step": 53.104982443838374,
    "episode_length": 368,
    "policy_loss": -903.6038665771484,
    "value_loss": 0.5449480265378952,
    "entropy": 0.9390998333692551,
    "total_loss": -903.0589185506105
  },
  {
    "episode": 61,
    "avg_reward_per_step": 69.0554505388919,
    "episode_length": 279,
    "policy_loss": -1160.0653076171875,
    "value_loss": 0.5591559708118439,
    "entropy": 0.9937312453985214,
    "total_loss": -1159.5061516463757
  },
  {
    "episode": 62,
    "avg_reward_per_step": 8.893336048793135,
    "episode_length": 1750,
    "policy_loss": -150.31315994262695,
    "value_loss": 0.5054187327623367,
    "entropy": 1.0130293369293213,
    "total_loss": -149.80774120986462
  },
  {
    "episode": 63,
    "avg_reward_per_step": 125.814434028014,
    "episode_length": 158,
    "policy_loss": -2134.1251831054688,
    "value_loss": 0.6247034966945648,
    "entropy": 0.9854400902986526,
    "total_loss": -2133.500479608774
  },
  {
    "episode": 64,
    "avg_reward_per_step": 43.23061662019675,
    "episode_length": 446,
    "policy_loss": -738.71435546875,
    "value_loss": 0.5354650467634201,
    "entropy": 0.981439083814621,
    "total_loss": -738.1788904219866
  },
  {
    "episode": 65,
    "avg_reward_per_step": 10.244239746792978,
    "episode_length": 1683,
    "policy_loss": -169.4247589111328,
    "value_loss": 0.5069798529148102,
    "entropy": 0.9815813601016998,
    "total_loss": -168.917779058218
  },
  {
    "episode": 66,
    "avg_reward_per_step": 22.411212640656224,
    "episode_length": 834,
    "policy_loss": -382.4474182128906,
    "value_loss": 0.5171095281839371,
    "entropy": 0.9774841368198395,
    "total_loss": -381.9303086847067
  },
  {
    "episode": 67,
    "avg_reward_per_step": 18.765704393869754,
    "episode_length": 979,
    "policy_loss": -315.5173873901367,
    "value_loss": 0.5139490216970444,
    "entropy": 1.0032717883586884,
    "total_loss": -315.0034383684397
  },
  {
    "episode": 68,
    "avg_reward_per_step": 12.359173668387227,
    "episode_length": 1434,
    "policy_loss": -207.5996437072754,
    "value_loss": 0.508725181221962,
    "entropy": 1.0357593595981598,
    "total_loss": -207.09091852605343
  },
  {
    "episode": 69,
    "avg_reward_per_step": -1.686608053514922,
    "episode_length": 3000,
    "policy_loss": 28.340644359588623,
    "value_loss": 1.4224720895290375,
    "entropy": 1.0372048318386078,
    "total_loss": 29.76311644911766
  },
  {
    "episode": 70,
    "avg_reward_per_step": 26.59994609344429,
    "episode_length": 702,
    "policy_loss": -453.87386322021484,
    "value_loss": 0.5204198509454727,
    "entropy": 1.0172840356826782,
    "total_loss": -453.35344336926937
  },
  {
    "episode": 71,
    "avg_reward_per_step": 22.105879609486376,
    "episode_length": 847,
    "policy_loss": -373.3730697631836,
    "value_loss": 0.5168898105621338,
    "entropy": 1.0198949575424194,
    "total_loss": -372.85617995262146
  },
  {
    "episode": 72,
    "avg_reward_per_step": 60.38676889635343,
    "episode_length": 320,
    "policy_loss": -1023.6591644287109,
    "value_loss": 0.551207959651947,
    "entropy": 1.0236836373806,
    "total_loss": -1023.107956469059
  },
  {
    "episode": 73,
    "avg_reward_per_step": 32.55907206962564,
    "episode_length": 580,
    "policy_loss": -565.2600402832031,
    "value_loss": 0.5256128013134003,
    "entropy": 1.0427294969558716,
    "total_loss": -564.7344274818897
  },
  {
    "episode": 74,
    "avg_reward_per_step": 32.44507191609027,
    "episode_length": 554,
    "policy_loss": -554.8343048095703,
    "value_loss": 0.5241637229919434,
    "entropy": 1.0668842196464539,
    "total_loss": -554.3101410865784
  },
  {
    "episode": 75,
    "avg_reward_per_step": 29.391897296980495,
    "episode_length": 599,
    "policy_loss": -510.46732330322266,
    "value_loss": 0.5212859660387039,
    "entropy": 1.0673403143882751,
    "total_loss": -509.94603733718395
  },
  {
    "episode": 76,
    "avg_reward_per_step": 1.6108261526829464,
    "episode_length": 2911,
    "policy_loss": -27.331539630889893,
    "value_loss": 0.5001458823680878,
    "entropy": 1.0442492365837097,
    "total_loss": -26.831393748521805
  },
  {
    "episode": 77,
    "avg_reward_per_step": 13.831829665302179,
    "episode_length": 1031,
    "policy_loss": -232.36102676391602,
    "value_loss": 0.5078092217445374,
    "entropy": 1.0148385167121887,
    "total_loss": -231.85321754217148
  },
  {
    "episode": 78,
    "avg_reward_per_step": -7.5504259427600955,
    "episode_length": 3000,
    "policy_loss": 126.4879093170166,
    "value_loss": 2.18648761510849,
    "entropy": 0.9723355770111084,
    "total_loss": 128.6743969321251
  },
  {
    "episode": 79,
    "avg_reward_per_step": 26.82221995083057,
    "episode_length": 624,
    "policy_loss": -461.7518768310547,
    "value_loss": 0.518370509147644,
    "entropy": 0.9992641061544418,
    "total_loss": -461.23350632190704
  },
  {
    "episode": 80,
    "avg_reward_per_step": 21.033258603870223,
    "episode_length": 751,
    "policy_loss": -349.5668716430664,
    "value_loss": 0.5133183896541595,
    "entropy": 0.9631670117378235,
    "total_loss": -349.05355325341225
  },
  {
    "episode": 81,
    "avg_reward_per_step": -5.802054257704158,
    "episode_length": 3000,
    "policy_loss": 96.87235260009766,
    "value_loss": 1.908031016588211,
    "entropy": 0.9503153413534164,
    "total_loss": 98.78038361668587
  },
  {
    "episode": 82,
    "avg_reward_per_step": 8.243993846973645,
    "episode_length": 1533,
    "policy_loss": -140.5513916015625,
    "value_loss": 0.504047229886055,
    "entropy": 0.9455782622098923,
    "total_loss": -140.04734437167645
  },
  {
    "episode": 83,
    "avg_reward_per_step": 62.29338932068963,
    "episode_length": 310,
    "policy_loss": -1055.2703857421875,
    "value_loss": 0.5530383288860321,
    "entropy": 0.9327640682458878,
    "total_loss": -1054.7173474133015
  },
  {
    "episode": 84,
    "avg_reward_per_step": 28.924526564486875,
    "episode_length": 624,
    "policy_loss": -487.7144088745117,
    "value_loss": 0.521612361073494,
    "entropy": 0.9601852595806122,
    "total_loss": -487.1927965134382
  },
  {
    "episode": 85,
    "avg_reward_per_step": 11.67072232208881,
    "episode_length": 1448,
    "policy_loss": -198.834228515625,
    "value_loss": 0.5079618096351624,
    "entropy": 0.9939911961555481,
    "total_loss": -198.32626670598984
  },
  {
    "episode": 86,
    "avg_reward_per_step": 39.239082406071624,
    "episode_length": 473,
    "policy_loss": -666.2418823242188,
    "value_loss": 0.5307421684265137,
    "entropy": 1.0018865466117859,
    "total_loss": -665.7111401557922
  },
  {
    "episode": 87,
    "avg_reward_per_step": 91.15998037932236,
    "episode_length": 214,
    "policy_loss": -1555.5366821289062,
    "value_loss": 0.58311927318573,
    "entropy": 1.0145698189735413,
    "total_loss": -1554.9535628557205
  },
  {
    "episode": 88,
    "avg_reward_per_step": 61.16524293763175,
    "episode_length": 308,
    "policy_loss": -1044.3361206054688,
    "value_loss": 0.5506835132837296,
    "entropy": 1.028090476989746,
    "total_loss": -1043.785437092185
  },
  {
    "episode": 89,
    "avg_reward_per_step": 43.68538736359404,
    "episode_length": 440,
    "policy_loss": -739.9423675537109,
    "value_loss": 0.5359848439693451,
    "entropy": 0.9991839230060577,
    "total_loss": -739.4063827097416
  },
  {
    "episode": 90,
    "avg_reward_per_step": 21.882183669013493,
    "episode_length": 856,
    "policy_loss": -374.38928985595703,
    "value_loss": 0.5168561339378357,
    "entropy": 0.9833301305770874,
    "total_loss": -373.8724337220192
  },
  {
    "episode": 91,
    "avg_reward_per_step": 14.077256728861876,
    "episode_length": 1258,
    "policy_loss": -235.90299224853516,
    "value_loss": 0.5101139694452286,
    "entropy": 0.9196485728025436,
    "total_loss": -235.39287827908993
  },
  {
    "episode": 92,
    "avg_reward_per_step": 13.041348837307149,
    "episode_length": 1402,
    "policy_loss": -220.42766952514648,
    "value_loss": 0.5096497088670731,
    "entropy": 0.9172897040843964,
    "total_loss": -219.9180198162794
  },
  {
    "episode": 93,
    "avg_reward_per_step": 32.01221418194414,
    "episode_length": 602,
    "policy_loss": -551.0271606445312,
    "value_loss": 0.5257449746131897,
    "entropy": 0.9189081192016602,
    "total_loss": -550.5014156699181
  },
  {
    "episode": 94,
    "avg_reward_per_step": -1.7302798097029315,
    "episode_length": 3000,
    "policy_loss": 28.441351890563965,
    "value_loss": 1.1668196022510529,
    "entropy": 0.9288035333156586,
    "total_loss": 29.608171492815018
  },
  {
    "episode": 95,
    "avg_reward_per_step": 18.54693903519657,
    "episode_length": 939,
    "policy_loss": -317.35479736328125,
    "value_loss": 0.5131729394197464,
    "entropy": 0.9331979900598526,
    "total_loss": -316.8416244238615
  },
  {
    "episode": 96,
    "avg_reward_per_step": 40.40821100840386,
    "episode_length": 456,
    "policy_loss": -690.3518829345703,
    "value_loss": 0.5315956920385361,
    "entropy": 0.9547721147537231,
    "total_loss": -689.8202872425318
  },
  {
    "episode": 97,
    "avg_reward_per_step": 48.86217791143204,
    "episode_length": 387,
    "policy_loss": -829.6607208251953,
    "value_loss": 0.5398267060518265,
    "entropy": 0.9916609823703766,
    "total_loss": -829.1208941191435
  },
  {
    "episode": 98,
    "avg_reward_per_step": 22.53008676790581,
    "episode_length": 753,
    "policy_loss": -381.68470764160156,
    "value_loss": 0.5156939923763275,
    "entropy": 1.0109657049179077,
    "total_loss": -381.16901364922523
  },
  {
    "episode": 99,
    "avg_reward_per_step": -4.5303449886848,
    "episode_length": 3000,
    "policy_loss": 74.9090633392334,
    "value_loss": 1.6858859956264496,
    "entropy": 1.006371170282364,
    "total_loss": 76.59494933485985
  },
  {
    "episode": 100,
    "avg_reward_per_step": 63.05820470077755,
    "episode_length": 310,
    "policy_loss": -1077.7674255371094,
    "value_loss": 0.5546332895755768,
    "entropy": 1.00139681994915,
    "total_loss": -1077.2127922475338
  },
  {
    "episode": 101,
    "avg_reward_per_step": 9.645411251705514,
    "episode_length": 1670,
    "policy_loss": -165.06737518310547,
    "value_loss": 0.5062568932771683,
    "entropy": 1.0017505884170532,
    "total_loss": -164.5611182898283
  },
  {
    "episode": 102,
    "avg_reward_per_step": 6.304124988511542,
    "episode_length": 2346,
    "policy_loss": -106.81682014465332,
    "value_loss": 0.5037242472171783,
    "entropy": 0.9928601682186127,
    "total_loss": -106.31309589743614
  },
  {
    "episode": 103,
    "avg_reward_per_step": 124.73371725482605,
    "episode_length": 160,
    "policy_loss": -2144.627197265625,
    "value_loss": 0.6239957362413406,
    "entropy": 1.0115844011306763,
    "total_loss": -2144.0032015293837
  },
  {
    "episode": 104,
    "avg_reward_per_step": 11.870242189154977,
    "episode_length": 1455,
    "policy_loss": -202.1150360107422,
    "value_loss": 0.5083131343126297,
    "entropy": 0.9957799017429352,
    "total_loss": -201.60672287642956
  },
  {
    "episode": 105,
    "avg_reward_per_step": 62.99660173428512,
    "episode_length": 313,
    "policy_loss": -1071.9140014648438,
    "value_loss": 0.5550194978713989,
    "entropy": 0.9756244570016861,
    "total_loss": -1071.3589819669724
  },
  {
    "episode": 106,
    "avg_reward_per_step": 18.002376273622062,
    "episode_length": 1016,
    "policy_loss": -306.1269836425781,
    "value_loss": 0.5134328305721283,
    "entropy": 1.0026821196079254,
    "total_loss": -305.613550812006
  },
  {
    "episode": 107,
    "avg_reward_per_step": 4.5427196654876125,
    "episode_length": 2804,
    "policy_loss": -78.85250473022461,
    "value_loss": 0.502275139093399,
    "entropy": 0.9799749553203583,
    "total_loss": -78.35022959113121
  },
  {
    "episode": 108,
    "avg_reward_per_step": 13.666941909948248,
    "episode_length": 1288,
    "policy_loss": -232.42167282104492,
    "value_loss": 0.5097542405128479,
    "entropy": 0.9654187113046646,
    "total_loss": -231.91191858053207
  },
  {
    "episode": 109,
    "avg_reward_per_step": 79.74954300348392,
    "episode_length": 248,
    "policy_loss": -1362.2140197753906,
    "value_loss": 0.5718279331922531,
    "entropy": 0.954036757349968,
    "total_loss": -1361.6421918421984
  },
  {
    "episode": 110,
    "avg_reward_per_step": 123.11163529841767,
    "episode_length": 162,
    "policy_loss": -2102.764404296875,
    "value_loss": 0.6214824616909027,
    "entropy": 0.971403032541275,
    "total_loss": -2102.142921835184
  },
  {
    "episode": 111,
    "avg_reward_per_step": 11.974438924379113,
    "episode_length": 1435,
    "policy_loss": -202.96181869506836,
    "value_loss": 0.5083604156970978,
    "entropy": 0.9871928691864014,
    "total_loss": -202.45345827937126
  },
  {
    "episode": 112,
    "avg_reward_per_step": 17.1363688688785,
    "episode_length": 1073,
    "policy_loss": -290.0882873535156,
    "value_loss": 0.5128599554300308,
    "entropy": 0.9902151972055435,
    "total_loss": -289.5754273980856
  },
  {
    "episode": 113,
    "avg_reward_per_step": 11.785474911943131,
    "episode_length": 1479,
    "policy_loss": -199.68052673339844,
    "value_loss": 0.508280336856842,
    "entropy": 0.9925894886255264,
    "total_loss": -199.1722463965416
  },
  {
    "episode": 114,
    "avg_reward_per_step": 10.53814652842508,
    "episode_length": 1581,
    "policy_loss": -178.86814498901367,
    "value_loss": 0.5070377588272095,
    "entropy": 0.9981579929590225,
    "total_loss": -178.36110723018646
  },
  {
    "episode": 115,
    "avg_reward_per_step": 73.69540364869275,
    "episode_length": 264,
    "policy_loss": -1266.094482421875,
    "value_loss": 0.564751148223877,
    "entropy": 0.9803209006786346,
    "total_loss": -1265.5297312736511
  },
  {
    "episode": 116,
    "avg_reward_per_step": 118.83732313519444,
    "episode_length": 166,
    "policy_loss": -2025.6137390136719,
    "value_loss": 0.6153807044029236,
    "entropy": 1.0032141506671906,
    "total_loss": -2024.998358309269
  },
  {
    "episode": 117,
    "avg_reward_per_step": 22.856679914310185,
    "episode_length": 784,
    "policy_loss": -384.2143783569336,
    "value_loss": 0.5168002545833588,
    "entropy": 0.9943648129701614,
    "total_loss": -383.69757810235023
  },
  {
    "episode": 118,
    "avg_reward_per_step": 35.98968505723856,
    "episode_length": 544,
    "policy_loss": -615.6494903564453,
    "value_loss": 0.5296569615602493,
    "entropy": 0.9986815005540848,
    "total_loss": -615.1198333948851
  },
  {
    "episode": 119,
    "avg_reward_per_step": 26.090178418068447,
    "episode_length": 727,
    "policy_loss": -441.0759048461914,
    "value_loss": 0.5204774290323257,
    "entropy": 0.9928410202264786,
    "total_loss": -440.5554274171591
  },
  {
    "episode": 120,
    "avg_reward_per_step": 19.72016213010152,
    "episode_length": 950,
    "policy_loss": -332.45550537109375,
    "value_loss": 0.5151241719722748,
    "entropy": 0.9936048239469528,
    "total_loss": -331.9403811991215
  },
  {
    "episode": 121,
    "avg_reward_per_step": 109.67532635989333,
    "episode_length": 180,
    "policy_loss": -1862.5653381347656,
    "value_loss": 0.6048644781112671,
    "entropy": 0.9813284128904343,
    "total_loss": -1861.9604736566544
  },
  {
    "episode": 122,
    "avg_reward_per_step": 17.47268861217634,
    "episode_length": 1076,
    "policy_loss": -296.8871383666992,
    "value_loss": 0.5134227573871613,
    "entropy": 0.9709763675928116,
    "total_loss": -296.37371560931206
  },
  {
    "episode": 123,
    "avg_reward_per_step": -1.3204145701426386,
    "episode_length": 3000,
    "policy_loss": 20.800471782684326,
    "value_loss": 1.1303880214691162,
    "entropy": 0.9528665840625763,
    "total_loss": 21.930859804153442
  },
  {
    "episode": 124,
    "avg_reward_per_step": 19.678691530038353,
    "episode_length": 958,
    "policy_loss": -333.60953521728516,
    "value_loss": 0.5153267681598663,
    "entropy": 0.9646323919296265,
    "total_loss": -333.0942084491253
  },
  {
    "episode": 125,
    "avg_reward_per_step": -1.659955923675377,
    "episode_length": 3000,
    "policy_loss": 26.339152336120605,
    "value_loss": 1.0452563762664795,
    "entropy": 0.9536044597625732,
    "total_loss": 27.384408712387085
  },
  {
    "episode": 126,
    "avg_reward_per_step": 68.48796260222828,
    "episode_length": 290,
    "policy_loss": -1160.5508117675781,
    "value_loss": 0.5608988404273987,
    "entropy": 0.9520853012800217,
    "total_loss": -1159.9899129271507
  },
  {
    "episode": 127,
    "avg_reward_per_step": 152.9068780144529,
    "episode_length": 130,
    "policy_loss": -2622.6995849609375,
    "value_loss": 0.6604125201702118,
    "entropy": 0.8879679590463638,
    "total_loss": -2622.0391724407673
  },
  {
    "episode": 128,
    "avg_reward_per_step": 36.31573680631641,
    "episode_length": 529,
    "policy_loss": -607.0144500732422,
    "value_loss": 0.5294674038887024,
    "entropy": 0.8741935044527054,
    "total_loss": -606.4849826693535
  },
  {
    "episode": 129,
    "avg_reward_per_step": 138.48439480611043,
    "episode_length": 144,
    "policy_loss": -2379.0358276367188,
    "value_loss": 0.6414387971162796,
    "entropy": 0.8514252156019211,
    "total_loss": -2378.3943888396025
  },
  {
    "episode": 130,
    "avg_reward_per_step": 112.62546447684743,
    "episode_length": 174,
    "policy_loss": -1927.9268188476562,
    "value_loss": 0.6065196692943573,
    "entropy": 0.7925232797861099,
    "total_loss": -1927.320299178362
  },
  {
    "episode": 131,
    "avg_reward_per_step": 263.4573276467158,
    "episode_length": 76,
    "policy_loss": -4511.6446533203125,
    "value_loss": 0.8544596433639526,
    "entropy": 0.746799498796463,
    "total_loss": -4510.790193676949
  },
  {
    "episode": 132,
    "avg_reward_per_step": 14.40807260738547,
    "episode_length": 1264,
    "policy_loss": -246.9863510131836,
    "value_loss": 0.5107431709766388,
    "entropy": 0.753945454955101,
    "total_loss": -246.47560784220695
  },
  {
    "episode": 133,
    "avg_reward_per_step": 58.12206741919877,
    "episode_length": 336,
    "policy_loss": -984.3108367919922,
    "value_loss": 0.5497652590274811,
    "entropy": 0.7301591485738754,
    "total_loss": -983.7610715329647
  },
  {
    "episode": 134,
    "avg_reward_per_step": 66.12854373815506,
    "episode_length": 287,
    "policy_loss": -1124.5813598632812,
    "value_loss": 0.5554557591676712,
    "entropy": 0.7438214123249054,
    "total_loss": -1124.0259041041136
  },
  {
    "episode": 135,
    "avg_reward_per_step": 179.5256767326248,
    "episode_length": 111,
    "policy_loss": -3035.4756469726562,
    "value_loss": 0.6999795734882355,
    "entropy": 0.7440205961465836,
    "total_loss": -3034.775667399168
  },
  {
    "episode": 136,
    "avg_reward_per_step": 140.64055815529292,
    "episode_length": 142,
    "policy_loss": -2400.4795532226562,
    "value_loss": 0.644133448600769,
    "entropy": 0.7568386942148209,
    "total_loss": -2399.8354197740555
  },
  {
    "episode": 137,
    "avg_reward_per_step": 33.98013113717843,
    "episode_length": 552,
    "policy_loss": -576.9823455810547,
    "value_loss": 0.5267696976661682,
    "entropy": 0.7512479722499847,
    "total_loss": -576.4555758833885
  },
  {
    "episode": 138,
    "avg_reward_per_step": 179.4125547528815,
    "episode_length": 111,
    "policy_loss": -3060.9402465820312,
    "value_loss": 0.6995769888162613,
    "entropy": 0.6788412034511566,
    "total_loss": -3060.240669593215
  },
  {
    "episode": 139,
    "avg_reward_per_step": 29.29740174084187,
    "episode_length": 644,
    "policy_loss": -496.6054153442383,
    "value_loss": 0.5230568796396255,
    "entropy": 0.6865984499454498,
    "total_loss": -496.08235846459866
  },
  {
    "episode": 140,
    "avg_reward_per_step": 72.35470224160977,
    "episode_length": 273,
    "policy_loss": -1226.8410949707031,
    "value_loss": 0.5641583800315857,
    "entropy": 0.6742078214883804,
    "total_loss": -1226.2769365906715
  },
  {
    "episode": 141,
    "avg_reward_per_step": 21.62089430954143,
    "episode_length": 866,
    "policy_loss": -365.89502716064453,
    "value_loss": 0.5167259275913239,
    "entropy": 0.6579914540052414,
    "total_loss": -365.3783012330532
  },
  {
    "episode": 142,
    "avg_reward_per_step": 14.193322399661614,
    "episode_length": 1271,
    "policy_loss": -241.62804794311523,
    "value_loss": 0.5104562789201736,
    "entropy": 0.6856694370508194,
    "total_loss": -241.11759166419506
  },
  {
    "episode": 143,
    "avg_reward_per_step": 30.075763708985587,
    "episode_length": 628,
    "policy_loss": -509.92205810546875,
    "value_loss": 0.5236769467592239,
    "entropy": 0.6692302972078323,
    "total_loss": -509.3983811587095
  },
  {
    "episode": 144,
    "avg_reward_per_step": 21.57500937962886,
    "episode_length": 880,
    "policy_loss": -365.7838668823242,
    "value_loss": 0.5168984979391098,
    "entropy": 0.6858115494251251,
    "total_loss": -365.2669683843851
  },
  {
    "episode": 145,
    "avg_reward_per_step": 61.44622857883327,
    "episode_length": 322,
    "policy_loss": -1044.2353515625,
    "value_loss": 0.5536832362413406,
    "entropy": 0.6649050563573837,
    "total_loss": -1043.6816683262587
  },
  {
    "episode": 146,
    "avg_reward_per_step": 84.2361371242121,
    "episode_length": 236,
    "policy_loss": -1439.1140441894531,
    "value_loss": 0.5770844668149948,
    "entropy": 0.5864865481853485,
    "total_loss": -1438.5369597226381
  },
  {
    "episode": 147,
    "avg_reward_per_step": 88.77862138313657,
    "episode_length": 220,
    "policy_loss": -1500.2841491699219,
    "value_loss": 0.5802364498376846,
    "entropy": 0.7120611220598221,
    "total_loss": -1499.7039127200842
  },
  {
    "episode": 148,
    "avg_reward_per_step": 24.617889576048025,
    "episode_length": 737,
    "policy_loss": -415.5676040649414,
    "value_loss": 0.5184225738048553,
    "entropy": 0.7026820629835129,
    "total_loss": -415.04918149113655
  },
  {
    "episode": 149,
    "avg_reward_per_step": 125.43261118222493,
    "episode_length": 158,
    "policy_loss": -2131.5076904296875,
    "value_loss": 0.6239837557077408,
    "entropy": 0.6102882474660873,
    "total_loss": -2130.8837066739798
  },
  {
    "episode": 150,
    "avg_reward_per_step": 162.79833097634184,
    "episode_length": 122,
    "policy_loss": -2775.1715087890625,
    "value_loss": 0.6744720041751862,
    "entropy": 0.5875390619039536,
    "total_loss": -2774.4970367848873
  },
  {
    "episode": 151,
    "avg_reward_per_step": 173.9016346658888,
    "episode_length": 114,
    "policy_loss": -2999.5341796875,
    "value_loss": 0.6909338682889938,
    "entropy": 0.6527059078216553,
    "total_loss": -2998.843245819211
  },
  {
    "episode": 152,
    "avg_reward_per_step": 153.34093807932024,
    "episode_length": 129,
    "policy_loss": -2613.5259399414062,
    "value_loss": 0.660428911447525,
    "entropy": 0.6187153160572052,
    "total_loss": -2612.8655110299587
  },
  {
    "episode": 153,
    "avg_reward_per_step": -8.073761812656173,
    "episode_length": 3000,
    "policy_loss": 133.22073364257812,
    "value_loss": 1.5622808635234833,
    "entropy": 0.6126897782087326,
    "total_loss": 134.7830145061016
  },
  {
    "episode": 154,
    "avg_reward_per_step": 170.8184155405521,
    "episode_length": 116,
    "policy_loss": -2894.43359375,
    "value_loss": 0.6857568025588989,
    "entropy": 0.5627418905496597,
    "total_loss": -2893.747836947441
  },
  {
    "episode": 155,
    "avg_reward_per_step": 96.07037059693562,
    "episode_length": 202,
    "policy_loss": -1627.9983520507812,
    "value_loss": 0.5875736325979233,
    "entropy": 0.5227051675319672,
    "total_loss": -1627.4107784181833
  },
  {
    "episode": 156,
    "avg_reward_per_step": 274.6180475450805,
    "episode_length": 73,
    "policy_loss": -4633.9168701171875,
    "value_loss": 0.8779542744159698,
    "entropy": 0.4625975862145424,
    "total_loss": -4633.0389158427715
  },
  {
    "episode": 157,
    "avg_reward_per_step": 102.02179435252913,
    "episode_length": 187,
    "policy_loss": -1729.1957092285156,
    "value_loss": 0.5917138457298279,
    "entropy": 0.5462394207715988,
    "total_loss": -1728.6039953827858
  },
  {
    "episode": 158,
    "avg_reward_per_step": 3.7515687291883477,
    "episode_length": 1407,
    "policy_loss": -66.30329132080078,
    "value_loss": 0.5004976540803909,
    "entropy": 0.49929287284612656,
    "total_loss": -65.80279366672039
  },
  {
    "episode": 159,
    "avg_reward_per_step": 278.3578820067488,
    "episode_length": 72,
    "policy_loss": -4694.960205078125,
    "value_loss": 0.8864818960428238,
    "entropy": 0.4691150411963463,
    "total_loss": -4694.073723182082
  },
  {
    "episode": 160,
    "avg_reward_per_step": 116.62376703242931,
    "episode_length": 164,
    "policy_loss": -1973.5902404785156,
    "value_loss": 0.6088551729917526,
    "entropy": 0.5527764111757278,
    "total_loss": -1972.9813853055239
  },
  {
    "episode": 161,
    "avg_reward_per_step": 59.92234788216519,
    "episode_length": 304,
    "policy_loss": -1011.748046875,
    "value_loss": 0.5477505028247833,
    "entropy": 0.5412198156118393,
    "total_loss": -1011.2002963721752
  },
  {
    "episode": 162,
    "avg_reward_per_step": 70.57641938119943,
    "episode_length": 266,
    "policy_loss": -1208.7562255859375,
    "value_loss": 0.5588461011648178,
    "entropy": 0.4767666831612587,
    "total_loss": -1208.1973794847727
  },
  {
    "episode": 163,
    "avg_reward_per_step": 185.91132931770352,
    "episode_length": 107,
    "policy_loss": -3190.236328125,
    "value_loss": 0.709804579615593,
    "entropy": 0.4596572667360306,
    "total_loss": -3189.5265235453844
  },
  {
    "episode": 164,
    "avg_reward_per_step": -11.735080307310946,
    "episode_length": 3000,
    "policy_loss": 194.52762603759766,
    "value_loss": 2.314662277698517,
    "entropy": 0.47392551600933075,
    "total_loss": 196.84228831529617
  },
  {
    "episode": 165,
    "avg_reward_per_step": 20.750190992794305,
    "episode_length": 705,
    "policy_loss": -352.1042938232422,
    "value_loss": 0.5122885555028915,
    "entropy": 0.503340482711792,
    "total_loss": -351.5920052677393
  },
  {
    "episode": 166,
    "avg_reward_per_step": 7.37074561214591,
    "episode_length": 1165,
    "policy_loss": -127.8200454711914,
    "value_loss": 0.5022754967212677,
    "entropy": 0.5118316262960434,
    "total_loss": -127.31776997447014
  },
  {
    "episode": 167,
    "avg_reward_per_step": 4.484484566828066,
    "episode_length": 1442,
    "policy_loss": -78.35655403137207,
    "value_loss": 0.5009508728981018,
    "entropy": 0.522749125957489,
    "total_loss": -77.85560315847397
  },
  {
    "episode": 168,
    "avg_reward_per_step": 20.72314841631861,
    "episode_length": 715,
    "policy_loss": -355.89356994628906,
    "value_loss": 0.5124755650758743,
    "entropy": 0.5256669372320175,
    "total_loss": -355.3810943812132
  },
  {
    "episode": 169,
    "avg_reward_per_step": 98.78087403901789,
    "episode_length": 196,
    "policy_loss": -1670.690673828125,
    "value_loss": 0.590613603591919,
    "entropy": 0.5749696791172028,
    "total_loss": -1670.100060224533
  },
  {
    "episode": 170,
    "avg_reward_per_step": 62.148732328995564,
    "episode_length": 296,
    "policy_loss": -1085.2255554199219,
    "value_loss": 0.5498587787151337,
    "entropy": 0.48209235817193985,
    "total_loss": -1084.6756966412067
  },
  {
    "episode": 171,
    "avg_reward_per_step": 16.292582583772976,
    "episode_length": 929,
    "policy_loss": -279.9476089477539,
    "value_loss": 0.5100268125534058,
    "entropy": 0.5058247894048691,
    "total_loss": -279.4375821352005
  },
  {
    "episode": 172,
    "avg_reward_per_step": 28.97652544788472,
    "episode_length": 600,
    "policy_loss": -495.9780502319336,
    "value_loss": 0.5208438485860825,
    "entropy": 0.5158016681671143,
    "total_loss": -495.4572063833475
  },
  {
    "episode": 173,
    "avg_reward_per_step": 68.51942574305745,
    "episode_length": 279,
    "policy_loss": -1167.140625,
    "value_loss": 0.5582219213247299,
    "entropy": 0.5140135735273361,
    "total_loss": -1166.5824030786753
  },
  {
    "episode": 174,
    "avg_reward_per_step": 176.8663805689175,
    "episode_length": 113,
    "policy_loss": -2997.5256958007812,
    "value_loss": 0.6963080316781998,
    "entropy": 0.5112478882074356,
    "total_loss": -2996.829387769103
  },
  {
    "episode": 175,
    "avg_reward_per_step": 49.666116783845105,
    "episode_length": 384,
    "policy_loss": -847.9790649414062,
    "value_loss": 0.5408083647489548,
    "entropy": 0.4764886572957039,
    "total_loss": -847.4382565766573
  },
  {
    "episode": 176,
    "avg_reward_per_step": 46.28086015590953,
    "episode_length": 414,
    "policy_loss": -781.5975646972656,
    "value_loss": 0.5379843264818192,
    "entropy": 0.4917921796441078,
    "total_loss": -781.0595803707838
  },
  {
    "episode": 177,
    "avg_reward_per_step": 62.11568634219045,
    "episode_length": 315,
    "policy_loss": -1051.4871215820312,
    "value_loss": 0.5535776764154434,
    "entropy": 0.4771997258067131,
    "total_loss": -1050.9335439056158
  },
  {
    "episode": 178,
    "avg_reward_per_step": 35.235448766291576,
    "episode_length": 549,
    "policy_loss": -601.2631988525391,
    "value_loss": 0.5287952572107315,
    "entropy": 0.4518406018614769,
    "total_loss": -600.7344035953283
  },
  {
    "episode": 179,
    "avg_reward_per_step": 132.36888767136216,
    "episode_length": 151,
    "policy_loss": -2252.3839721679688,
    "value_loss": 0.6336167305707932,
    "entropy": 0.4768604710698128,
    "total_loss": -2251.750355437398
  },
  {
    "episode": 180,
    "avg_reward_per_step": 75.46092564516957,
    "episode_length": 260,
    "policy_loss": -1273.8115234375,
    "value_loss": 0.5670007318258286,
    "entropy": 0.43202461302280426,
    "total_loss": -1273.2445227056742
  },
  {
    "episode": 181,
    "avg_reward_per_step": 56.184773594991675,
    "episode_length": 352,
    "policy_loss": -958.16943359375,
    "value_loss": 0.5486945956945419,
    "entropy": 0.41088567674160004,
    "total_loss": -957.6207389980555
  },
  {
    "episode": 182,
    "avg_reward_per_step": 29.07361810938505,
    "episode_length": 666,
    "policy_loss": -493.01177978515625,
    "value_loss": 0.5235710144042969,
    "entropy": 0.4277290925383568,
    "total_loss": -492.48820877075195
  },
  {
    "episode": 183,
    "avg_reward_per_step": 30.54622672755566,
    "episode_length": 627,
    "policy_loss": -521.5385894775391,
    "value_loss": 0.5245121270418167,
    "entropy": 0.4174056053161621,
    "total_loss": -521.0140773504972
  },
  {
    "episode": 184,
    "avg_reward_per_step": 142.87580168081467,
    "episode_length": 140,
    "policy_loss": -2415.753173828125,
    "value_loss": 0.6476558595895767,
    "entropy": 0.394580602645874,
    "total_loss": -2415.1055179685354
  },
  {
    "episode": 185,
    "avg_reward_per_step": 76.77292904975124,
    "episode_length": 258,
    "policy_loss": -1300.4734497070312,
    "value_loss": 0.5690580755472183,
    "entropy": 0.4396732822060585,
    "total_loss": -1299.904391631484
  },
  {
    "episode": 186,
    "avg_reward_per_step": 16.140588537167776,
    "episode_length": 1159,
    "policy_loss": -274.62561798095703,
    "value_loss": 0.5124054849147797,
    "entropy": 0.3828253373503685,
    "total_loss": -274.11321249604225
  },
  {
    "episode": 187,
    "avg_reward_per_step": 100.07935681126501,
    "episode_length": 199,
    "policy_loss": -1714.5615539550781,
    "value_loss": 0.5945892333984375,
    "entropy": 0.35659558326005936,
    "total_loss": -1713.9669647216797
  },
  {
    "episode": 188,
    "avg_reward_per_step": 41.55320566465438,
    "episode_length": 469,
    "policy_loss": -709.8704528808594,
    "value_loss": 0.5345616787672043,
    "entropy": 0.38404468446969986,
    "total_loss": -709.3358912020922
  },
  {
    "episode": 189,
    "avg_reward_per_step": 39.85328240021415,
    "episode_length": 489,
    "policy_loss": -677.4146728515625,
    "value_loss": 0.5330643802881241,
    "entropy": 0.3818389102816582,
    "total_loss": -676.8816084712744
  },
  {
    "episode": 190,
    "avg_reward_per_step": 103.90029468513922,
    "episode_length": 192,
    "policy_loss": -1764.5760192871094,
    "value_loss": 0.5989286750555038,
    "entropy": 0.35710321366786957,
    "total_loss": -1763.9770906120539
  },
  {
    "episode": 191,
    "avg_reward_per_step": 33.43170544637537,
    "episode_length": 579,
    "policy_loss": -573.1107788085938,
    "value_loss": 0.5271755158901215,
    "entropy": 0.3636985197663307,
    "total_loss": -572.5836032927036
  },
  {
    "episode": 192,
    "avg_reward_per_step": 104.42212187988562,
    "episode_length": 191,
    "policy_loss": -1764.9259338378906,
    "value_loss": 0.5994565337896347,
    "entropy": 0.3327394649386406,
    "total_loss": -1764.326477304101
  },
  {
    "episode": 193,
    "avg_reward_per_step": 10.056069710180536,
    "episode_length": 1603,
    "policy_loss": -172.38140106201172,
    "value_loss": 0.5065796375274658,
    "entropy": 0.33985909074544907,
    "total_loss": -171.87482142448425
  },
  {
    "episode": 194,
    "avg_reward_per_step": 178.41466117124227,
    "episode_length": 112,
    "policy_loss": -3028.362548828125,
    "value_loss": 0.6986429542303085,
    "entropy": 0.2597026973962784,
    "total_loss": -3027.6639058738947
  },
  {
    "episode": 195,
    "avg_reward_per_step": 199.83757150451288,
    "episode_length": 100,
    "policy_loss": -3369.9979248046875,
    "value_loss": 0.733029842376709,
    "entropy": 0.29885607957839966,
    "total_loss": -3369.264894962311
  },
  {
    "episode": 196,
    "avg_reward_per_step": 119.78922275041036,
    "episode_length": 166,
    "policy_loss": -2036.82958984375,
    "value_loss": 0.6172421276569366,
    "entropy": 0.2650189623236656,
    "total_loss": -2036.212347716093
  },
  {
    "episode": 197,
    "avg_reward_per_step": 88.73865561127023,
    "episode_length": 223,
    "policy_loss": -1508.4992370605469,
    "value_loss": 0.5815390944480896,
    "entropy": 0.30651603639125824,
    "total_loss": -1507.9176979660988
  },
  {
    "episode": 198,
    "avg_reward_per_step": 278.09275265955773,
    "episode_length": 72,
    "policy_loss": -4680.5760498046875,
    "value_loss": 0.8856201767921448,
    "entropy": 0.25372840091586113,
    "total_loss": -4679.690429627895
  },
  {
    "episode": 199,
    "avg_reward_per_step": 15.531084122028266,
    "episode_length": 1166,
    "policy_loss": -265.1259307861328,
    "value_loss": 0.5114990025758743,
    "entropy": 0.291569784283638,
    "total_loss": -264.61443178355694
  },
  {
    "episode": 200,
    "avg_reward_per_step": 200.23019599921824,
    "episode_length": 100,
    "policy_loss": -3394.3981323242188,
    "value_loss": 0.7341929376125336,
    "entropy": 0.26299064606428146,
    "total_loss": -3393.663939386606
  },
  {
    "episode": 201,
    "avg_reward_per_step": -2.8275734536726613,
    "episode_length": 3000,
    "policy_loss": 45.35395526885986,
    "value_loss": 1.0349611639976501,
    "entropy": 0.29257384687662125,
    "total_loss": 46.38891643285751
  },
  {
    "episode": 202,
    "avg_reward_per_step": 18.455682442942994,
    "episode_length": 923,
    "policy_loss": -316.2770462036133,
    "value_loss": 0.5128055065870285,
    "entropy": 0.30193883925676346,
    "total_loss": -315.76424069702625
  },
  {
    "episode": 203,
    "avg_reward_per_step": 114.8538050781726,
    "episode_length": 173,
    "policy_loss": -1946.4588928222656,
    "value_loss": 0.611184149980545,
    "entropy": 0.2533460855484009,
    "total_loss": -1945.847708672285
  },
  {
    "episode": 204,
    "avg_reward_per_step": 74.70354595428662,
    "episode_length": 254,
    "policy_loss": -1276.6748046875,
    "value_loss": 0.5634071230888367,
    "entropy": 0.2628263309597969,
    "total_loss": -1276.1113975644112
  },
  {
    "episode": 205,
    "avg_reward_per_step": 298.8318025553283,
    "episode_length": 67,
    "policy_loss": -4992.687255859375,
    "value_loss": 0.9329724013805389,
    "entropy": 0.2577727735042572,
    "total_loss": -4991.7542834579945
  },
  {
    "episode": 206,
    "avg_reward_per_step": 206.39593607461455,
    "episode_length": 97,
    "policy_loss": -3490.3259887695312,
    "value_loss": 0.7444611042737961,
    "entropy": 0.29064930975437164,
    "total_loss": -3489.5815276652575
  },
  {
    "episode": 207,
    "avg_reward_per_step": 10.580833165076829,
    "episode_length": 1124,
    "policy_loss": -180.58282852172852,
    "value_loss": 0.5048159807920456,
    "entropy": 0.24143171682953835,
    "total_loss": -180.07801254093647
  },
  {
    "episode": 208,
    "avg_reward_per_step": 303.56407598854685,
    "episode_length": 66,
    "policy_loss": -5090.6817626953125,
    "value_loss": 0.944549486041069,
    "entropy": 0.19491223990917206,
    "total_loss": -5089.737213209271
  },
  {
    "episode": 209,
    "avg_reward_per_step": 76.45189901713195,
    "episode_length": 260,
    "policy_loss": -1293.6561889648438,
    "value_loss": 0.5687700062990189,
    "entropy": 0.151218231767416,
    "total_loss": -1293.0874189585447
  },
  {
    "episode": 210,
    "avg_reward_per_step": 220.29020844931281,
    "episode_length": 91,
    "policy_loss": -3793.75390625,
    "value_loss": 0.7698747366666794,
    "entropy": 0.2329489104449749,
    "total_loss": -3792.9840315133333
  },
  {
    "episode": 211,
    "avg_reward_per_step": 308.439818116624,
    "episode_length": 65,
    "policy_loss": -5118.3404541015625,
    "value_loss": 0.9561188369989395,
    "entropy": 0.1498664915561676,
    "total_loss": -5117.384335264564
  },
  {
    "episode": 212,
    "avg_reward_per_step": 220.33202280895497,
    "episode_length": 91,
    "policy_loss": -3739.2010498046875,
    "value_loss": 0.7701196819543839,
    "entropy": 0.20585009455680847,
    "total_loss": -3738.430930122733
  },
  {
    "episode": 213,
    "avg_reward_per_step": 290.3922793406988,
    "episode_length": 69,
    "policy_loss": -4809.67578125,
    "value_loss": 0.9134920090436935,
    "entropy": 0.17242250964045525,
    "total_loss": -4808.762289240956
  },
  {
    "episode": 214,
    "avg_reward_per_step": 217.81468650823305,
    "episode_length": 92,
    "policy_loss": -3680.5720825195312,
    "value_loss": 0.7654174715280533,
    "entropy": 0.2070743292570114,
    "total_loss": -3679.806665048003
  },
  {
    "episode": 215,
    "avg_reward_per_step": 308.8207313822626,
    "episode_length": 65,
    "policy_loss": -5211.6182861328125,
    "value_loss": 0.9571260213851929,
    "entropy": 0.16140273213386536,
    "total_loss": -5210.661160111427
  },
  {
    "episode": 216,
    "avg_reward_per_step": 303.7657494327043,
    "episode_length": 66,
    "policy_loss": -5040.55712890625,
    "value_loss": 0.9449216276407242,
    "entropy": 0.12444777600467205,
    "total_loss": -5039.612207278609
  },
  {
    "episode": 217,
    "avg_reward_per_step": 106.8393116885538,
    "episode_length": 184,
    "policy_loss": -1809.0548706054688,
    "value_loss": 0.6004820764064789,
    "entropy": 0.24242845177650452,
    "total_loss": -1808.4543885290623
  },
  {
    "episode": 218,
    "avg_reward_per_step": 192.60284180275687,
    "episode_length": 104,
    "policy_loss": -3285.3978271484375,
    "value_loss": 0.7213224768638611,
    "entropy": 0.10751751437783241,
    "total_loss": -3284.6765046715736
  },
  {
    "episode": 219,
    "avg_reward_per_step": 204.33196317011024,
    "episode_length": 98,
    "policy_loss": -3420.9662475585938,
    "value_loss": 0.7410257905721664,
    "entropy": 0.18278062716126442,
    "total_loss": -3420.2252217680216
  },
  {
    "episode": 220,
    "avg_reward_per_step": 303.5994479275309,
    "episode_length": 66,
    "policy_loss": -5072.109619140625,
    "value_loss": 0.9442238509654999,
    "entropy": 0.1314426138997078,
    "total_loss": -5071.1653952896595
  },
  {
    "episode": 221,
    "avg_reward_per_step": 313.12830416904086,
    "episode_length": 64,
    "policy_loss": -5235.6583251953125,
    "value_loss": 0.9673773944377899,
    "entropy": 0.1357322596013546,
    "total_loss": -5234.690947800875
  },
  {
    "episode": 222,
    "avg_reward_per_step": 194.3387887790952,
    "episode_length": 103,
    "policy_loss": -3274.7849731445312,
    "value_loss": 0.7239644229412079,
    "entropy": 0.1713562197983265,
    "total_loss": -3274.06100872159
  },
  {
    "episode": 223,
    "avg_reward_per_step": 303.6433646367147,
    "episode_length": 66,
    "policy_loss": -5045.3331298828125,
    "value_loss": 0.9448159486055374,
    "entropy": 0.08763507753610611,
    "total_loss": -5044.388313934207
  },
  {
    "episode": 224,
    "avg_reward_per_step": 117.32633570029923,
    "episode_length": 164,
    "policy_loss": -1997.1627197265625,
    "value_loss": 0.6092680394649506,
    "entropy": 0.21662793308496475,
    "total_loss": -1996.5534516870975
  },
  {
    "episode": 225,
    "avg_reward_per_step": 141.91441737283463,
    "episode_length": 139,
    "policy_loss": -2401.3478393554688,
    "value_loss": 0.6432596892118454,
    "entropy": 0.1343558356165886,
    "total_loss": -2400.704579666257
  },
  {
    "episode": 226,
    "avg_reward_per_step": 108.50665772684306,
    "episode_length": 176,
    "policy_loss": -1839.1834716796875,
    "value_loss": 0.5983042269945145,
    "entropy": 0.13882189989089966,
    "total_loss": -1838.585167452693
  },
  {
    "episode": 227,
    "avg_reward_per_step": 73.43784080163447,
    "episode_length": 254,
    "policy_loss": -1243.2505798339844,
    "value_loss": 0.5607660710811615,
    "entropy": 0.16761107370257378,
    "total_loss": -1242.6898137629032
  },
  {
    "episode": 228,
    "avg_reward_per_step": -17.186121131621988,
    "episode_length": 3000,
    "policy_loss": 286.17991638183594,
    "value_loss": 4.106037735939026,
    "entropy": 0.08509849011898041,
    "total_loss": 290.28595411777496
  },
  {
    "episode": 229,
    "avg_reward_per_step": 3.4890882544239004,
    "episode_length": 1099,
    "policy_loss": -62.142831802368164,
    "value_loss": 0.5001688599586487,
    "entropy": 0.13041742891073227,
    "total_loss": -61.642662942409515
  },
  {
    "episode": 230,
    "avg_reward_per_step": 290.5121657066853,
    "episode_length": 69,
    "policy_loss": -4877.0821533203125,
    "value_loss": 0.9141188561916351,
    "entropy": 0.09652122296392918,
    "total_loss": -4876.168034464121
  },
  {
    "episode": 231,
    "avg_reward_per_step": 294.9651671959695,
    "episode_length": 68,
    "policy_loss": -4955.12353515625,
    "value_loss": 0.9241040050983429,
    "entropy": 0.09596337750554085,
    "total_loss": -4954.199431151152
  },
  {
    "episode": 232,
    "avg_reward_per_step": -16.4899032853519,
    "episode_length": 3000,
    "policy_loss": 274.7821273803711,
    "value_loss": 3.468682646751404,
    "entropy": 0.0711709763854742,
    "total_loss": 278.2508100271225
  },
  {
    "episode": 233,
    "avg_reward_per_step": 299.25052166023,
    "episode_length": 67,
    "policy_loss": -4955.5167236328125,
    "value_loss": 0.9345212578773499,
    "entropy": 0.09250185638666153,
    "total_loss": -4954.582202374935
  },
  {
    "episode": 234,
    "avg_reward_per_step": 308.5005702664001,
    "episode_length": 65,
    "policy_loss": -5154.6533203125,
    "value_loss": 0.9565002769231796,
    "entropy": 0.08079168759286404,
    "total_loss": -5153.696820035577
  },
  {
    "episode": 235,
    "avg_reward_per_step": 215.43799685930009,
    "episode_length": 93,
    "policy_loss": -3630.9383544921875,
    "value_loss": 0.7608094215393066,
    "entropy": 0.11128188110888004,
    "total_loss": -3630.177545070648
  },
  {
    "episode": 236,
    "avg_reward_per_step": 298.6398885573022,
    "episode_length": 67,
    "policy_loss": -5034.6075439453125,
    "value_loss": 0.9327773302793503,
    "entropy": 0.09433692134916782,
    "total_loss": -5033.674766615033
  },
  {
    "episode": 237,
    "avg_reward_per_step": 215.46835429764081,
    "episode_length": 93,
    "policy_loss": -3636.7276611328125,
    "value_loss": 0.7608521729707718,
    "entropy": 0.14116596803069115,
    "total_loss": -3635.9668089598417
  },
  {
    "episode": 238,
    "avg_reward_per_step": 147.86759064989764,
    "episode_length": 135,
    "policy_loss": -2511.003662109375,
    "value_loss": 0.6543377190828323,
    "entropy": 0.1347692906856537,
    "total_loss": -2510.349324390292
  },
  {
    "episode": 239,
    "avg_reward_per_step": -18.028576533696974,
    "episode_length": 3000,
    "policy_loss": 299.21700286865234,
    "value_loss": 6.341746926307678,
    "entropy": 0.043925187550485134,
    "total_loss": 305.55874979496
  },
  {
    "episode": 240,
    "avg_reward_per_step": 298.7676723412405,
    "episode_length": 67,
    "policy_loss": -5013.777099609375,
    "value_loss": 0.9333185404539108,
    "entropy": 0.09184896014630795,
    "total_loss": -5012.843781068921
  },
  {
    "episode": 241,
    "avg_reward_per_step": 290.31554582953623,
    "episode_length": 69,
    "policy_loss": -4850.4854736328125,
    "value_loss": 0.9134422391653061,
    "entropy": 0.09504173323512077,
    "total_loss": -4849.572031393647
  },
  {
    "episode": 242,
    "avg_reward_per_step": -18.062417186517507,
    "episode_length": 3000,
    "policy_loss": 299.1751708984375,
    "value_loss": 5.976781725883484,
    "entropy": 0.077147226780653,
    "total_loss": 305.151952624321
  },
  {
    "episode": 243,
    "avg_reward_per_step": -17.825590871016264,
    "episode_length": 3000,
    "policy_loss": 294.91261291503906,
    "value_loss": 5.346618890762329,
    "entropy": 0.08634716644883156,
    "total_loss": 300.2592318058014
  },
  {
    "episode": 244,
    "avg_reward_per_step": -17.081508352804377,
    "episode_length": 3000,
    "policy_loss": 281.9984817504883,
    "value_loss": 3.901278793811798,
    "entropy": 0.10231541469693184,
    "total_loss": 285.8997605443001
  },
  {
    "episode": 245,
    "avg_reward_per_step": -16.265097531791927,
    "episode_length": 3000,
    "policy_loss": 267.9503860473633,
    "value_loss": 3.2867122292518616,
    "entropy": 0.1225200667977333,
    "total_loss": 271.23709827661514
  },
  {
    "episode": 246,
    "avg_reward_per_step": 294.7284007673211,
    "episode_length": 68,
    "policy_loss": -4948.92724609375,
    "value_loss": 0.9243776798248291,
    "entropy": 0.11208933591842651,
    "total_loss": -4948.002868413925
  },
  {
    "episode": 247,
    "avg_reward_per_step": 298.87544902792314,
    "episode_length": 67,
    "policy_loss": -4998.3533935546875,
    "value_loss": 0.9338118582963943,
    "entropy": 0.120522515848279,
    "total_loss": -4997.419581696391
  },
  {
    "episode": 248,
    "avg_reward_per_step": -14.479277008908163,
    "episode_length": 3000,
    "policy_loss": 237.02663040161133,
    "value_loss": 2.3326300978660583,
    "entropy": 0.15547706559300423,
    "total_loss": 239.3592604994774
  },
  {
    "episode": 249,
    "avg_reward_per_step": -12.94570179921362,
    "episode_length": 3000,
    "policy_loss": 211.05825805664062,
    "value_loss": 1.8649866878986359,
    "entropy": 0.15685122460126877,
    "total_loss": 212.92324474453926
  },
  {
    "episode": 250,
    "avg_reward_per_step": 294.42982089076713,
    "episode_length": 68,
    "policy_loss": -4907.9617919921875,
    "value_loss": 0.9242672473192215,
    "entropy": 0.11534086428582668,
    "total_loss": -4907.037524744868
  },
  {
    "episode": 251,
    "avg_reward_per_step": 285.6292223097385,
    "episode_length": 70,
    "policy_loss": -4779.9560546875,
    "value_loss": 0.9035619050264359,
    "entropy": 0.12534661404788494,
    "total_loss": -4779.052492782474
  },
  {
    "episode": 252,
    "avg_reward_per_step": -13.30014778782633,
    "episode_length": 3000,
    "policy_loss": 216.09172821044922,
    "value_loss": 2.016744017601013,
    "entropy": 0.17475388944149017,
    "total_loss": 218.10847222805023
  },
  {
    "episode": 253,
    "avg_reward_per_step": 290.4153452864944,
    "episode_length": 69,
    "policy_loss": -4838.188232421875,
    "value_loss": 0.9150674194097519,
    "entropy": 0.09633924439549446,
    "total_loss": -4837.273165002465
  },
  {
    "episode": 254,
    "avg_reward_per_step": -11.00678248371544,
    "episode_length": 3000,
    "policy_loss": 177.21095657348633,
    "value_loss": 1.501610904932022,
    "entropy": 0.19068893045186996,
    "total_loss": 178.71256747841835
  },
  {
    "episode": 255,
    "avg_reward_per_step": 70.7089977217122,
    "episode_length": 270,
    "policy_loss": -1209.3596801757812,
    "value_loss": 0.5605588406324387,
    "entropy": 0.17163826897740364,
    "total_loss": -1208.7991213351488
  },
  {
    "episode": 256,
    "avg_reward_per_step": -9.383672779381293,
    "episode_length": 3000,
    "policy_loss": 150.16259765625,
    "value_loss": 1.3060117065906525,
    "entropy": 0.17147104814648628,
    "total_loss": 151.46860936284065
  },
  {
    "episode": 257,
    "avg_reward_per_step": 285.9893052187967,
    "episode_length": 70,
    "policy_loss": -4774.7479248046875,
    "value_loss": 0.9046227931976318,
    "entropy": 0.10263586789369583,
    "total_loss": -4773.84330201149
  },
  {
    "episode": 258,
    "avg_reward_per_step": 2.6959833949677714,
    "episode_length": 1633,
    "policy_loss": -54.601027488708496,
    "value_loss": 0.49985695630311966,
    "entropy": 0.1734888032078743,
    "total_loss": -54.101170532405376
  },
  {
    "episode": 259,
    "avg_reward_per_step": 290.4153452864944,
    "episode_length": 69,
    "policy_loss": -4831.2218017578125,
    "value_loss": 0.9152568280696869,
    "entropy": 0.08380752801895142,
    "total_loss": -4830.306544929743
  },
  {
    "episode": 260,
    "avg_reward_per_step": -9.280247345089805,
    "episode_length": 3000,
    "policy_loss": 148.18741607666016,
    "value_loss": 1.1932098865509033,
    "entropy": 0.15071460977196693,
    "total_loss": 149.38062596321106
  },
  {
    "episode": 261,
    "avg_reward_per_step": 294.5515748356246,
    "episode_length": 68,
    "policy_loss": -4939.3272705078125,
    "value_loss": 0.9245264977216721,
    "entropy": 0.08057630620896816,
    "total_loss": -4938.402744010091
  },
  {
    "episode": 262,
    "avg_reward_per_step": -13.46152076619793,
    "episode_length": 3000,
    "policy_loss": 218.08632278442383,
    "value_loss": 1.8808837532997131,
    "entropy": 0.10479643940925598,
    "total_loss": 219.96720653772354
  },
  {
    "episode": 263,
    "avg_reward_per_step": -17.163487652730165,
    "episode_length": 3000,
    "policy_loss": 279.6045227050781,
    "value_loss": 4.523755311965942,
    "entropy": 0.07848648354411125,
    "total_loss": 284.12827801704407
  },
  {
    "episode": 264,
    "avg_reward_per_step": -18.04216102744538,
    "episode_length": 3000,
    "policy_loss": 293.7123031616211,
    "value_loss": 5.416664242744446,
    "entropy": 0.06433969736099243,
    "total_loss": 299.12896740436554
  },
  {
    "episode": 265,
    "avg_reward_per_step": 298.61567756244426,
    "episode_length": 67,
    "policy_loss": -4998.8975830078125,
    "value_loss": 0.9348960965871811,
    "entropy": 0.0961829125881195,
    "total_loss": -4997.962686911225
  },
  {
    "episode": 266,
    "avg_reward_per_step": 294.8004352659956,
    "episode_length": 68,
    "policy_loss": -4970.0469970703125,
    "value_loss": 0.9258938729763031,
    "entropy": 0.0837513767182827,
    "total_loss": -4969.121103197336
  },
  {
    "episode": 267,
    "avg_reward_per_step": 289.8859442848984,
    "episode_length": 69,
    "policy_loss": -4873.1761474609375,
    "value_loss": 0.9141575247049332,
    "entropy": 0.12135561741888523,
    "total_loss": -4872.261989936233
  },
  {
    "episode": 268,
    "avg_reward_per_step": 294.68686166309044,
    "episode_length": 68,
    "policy_loss": -4949.11962890625,
    "value_loss": 0.9256278872489929,
    "entropy": 0.08267501555383205,
    "total_loss": -4948.194001019001
  },
  {
    "episode": 269,
    "avg_reward_per_step": 159.33298838587106,
    "episode_length": 125,
    "policy_loss": -2722.6248168945312,
    "value_loss": 0.6708604246377945,
    "entropy": 0.08143656142055988,
    "total_loss": -2721.9539564698935
  },
  {
    "episode": 270,
    "avg_reward_per_step": -17.621137903433937,
    "episode_length": 3000,
    "policy_loss": 284.88159942626953,
    "value_loss": 4.404355406761169,
    "entropy": 0.05929465964436531,
    "total_loss": 289.2859548330307
  },
  {
    "episode": 271,
    "avg_reward_per_step": 307.88138247313356,
    "episode_length": 65,
    "policy_loss": -5117.895751953125,
    "value_loss": 0.9572142958641052,
    "entropy": 0.08269743993878365,
    "total_loss": -5116.938537657261
  },
  {
    "episode": 272,
    "avg_reward_per_step": 299.09263571776347,
    "episode_length": 67,
    "policy_loss": -4987.5902099609375,
    "value_loss": 0.9359825402498245,
    "entropy": 0.0687650702893734,
    "total_loss": -4986.654227420688
  },
  {
    "episode": 273,
    "avg_reward_per_step": 188.61533057807767,
    "episode_length": 106,
    "policy_loss": -3239.4345092773438,
    "value_loss": 0.7170166671276093,
    "entropy": 0.07342838495969772,
    "total_loss": -3238.717492610216
  },
  {
    "episode": 274,
    "avg_reward_per_step": 57.48891859030673,
    "episode_length": 345,
    "policy_loss": -981.4332580566406,
    "value_loss": 0.5503658354282379,
    "entropy": 0.07205305434763432,
    "total_loss": -980.8828922212124
  },
  {
    "episode": 275,
    "avg_reward_per_step": 112.03740450497502,
    "episode_length": 178,
    "policy_loss": -1904.8600158691406,
    "value_loss": 0.6089294105768204,
    "entropy": 0.09134862013161182,
    "total_loss": -1904.2510864585638
  },
  {
    "episode": 276,
    "avg_reward_per_step": 294.8686638384277,
    "episode_length": 68,
    "policy_loss": -4954.877685546875,
    "value_loss": 0.9268124252557755,
    "entropy": 0.08505662530660629,
    "total_loss": -4953.950873121619
  },
  {
    "episode": 277,
    "avg_reward_per_step": 190.49084626786023,
    "episode_length": 105,
    "policy_loss": -3224.20654296875,
    "value_loss": 0.7202308177947998,
    "entropy": 0.06357640400528908,
    "total_loss": -3223.486312150955
  },
  {
    "episode": 278,
    "avg_reward_per_step": 308.2686556864519,
    "episode_length": 65,
    "policy_loss": -5113.9332275390625,
    "value_loss": 0.95815210044384,
    "entropy": 0.06471514329314232,
    "total_loss": -5112.975075438619
  },
  {
    "episode": 279,
    "avg_reward_per_step": -18.73210319815538,
    "episode_length": 3000,
    "policy_loss": 302.6905212402344,
    "value_loss": 5.876558542251587,
    "entropy": 0.03735031746327877,
    "total_loss": 308.56707978248596
  },
  {
    "episode": 280,
    "avg_reward_per_step": -19.741646341745057,
    "episode_length": 3000,
    "policy_loss": 319.16798400878906,
    "value_loss": 14.2364981174469,
    "entropy": 0.021180931013077497,
    "total_loss": 333.40448212623596
  },
  {
    "episode": 281,
    "avg_reward_per_step": 56.01558433573417,
    "episode_length": 354,
    "policy_loss": -966.9700012207031,
    "value_loss": 0.5491371601819992,
    "entropy": 0.07648157700896263,
    "total_loss": -966.4208640605211
  },
  {
    "episode": 282,
    "avg_reward_per_step": -19.375040905969318,
    "episode_length": 3000,
    "policy_loss": 311.76434326171875,
    "value_loss": 9.142387628555298,
    "entropy": 0.028579930774867535,
    "total_loss": 320.90673089027405
  },
  {
    "episode": 283,
    "avg_reward_per_step": 286.0072250278728,
    "episode_length": 70,
    "policy_loss": -4780.96142578125,
    "value_loss": 0.9068094342947006,
    "entropy": 0.09475043043494225,
    "total_loss": -4780.054616346955
  },
  {
    "episode": 284,
    "avg_reward_per_step": 90.49600575368258,
    "episode_length": 220,
    "policy_loss": -1550.0199584960938,
    "value_loss": 0.5844774097204208,
    "entropy": 0.07333482801914215,
    "total_loss": -1549.4354810863733
  },
  {
    "episode": 285,
    "avg_reward_per_step": 51.09896390620634,
    "episode_length": 388,
    "policy_loss": -878.6111907958984,
    "value_loss": 0.5444263815879822,
    "entropy": 0.0827421098947525,
    "total_loss": -878.0667644143105
  },
  {
    "episode": 286,
    "avg_reward_per_step": 42.84099514501549,
    "episode_length": 462,
    "policy_loss": -738.7207336425781,
    "value_loss": 0.5367509424686432,
    "entropy": 0.08664824441075325,
    "total_loss": -738.1839827001095
  },
  {
    "episode": 287,
    "avg_reward_per_step": 41.77127624652412,
    "episode_length": 474,
    "policy_loss": -720.4240570068359,
    "value_loss": 0.5357793867588043,
    "entropy": 0.08213422074913979,
    "total_loss": -719.8882776200771
  },
  {
    "episode": 288,
    "avg_reward_per_step": 294.46700915360657,
    "episode_length": 68,
    "policy_loss": -4907.728515625,
    "value_loss": 0.9265701621770859,
    "entropy": 0.08839412964880466,
    "total_loss": -4906.801945462823
  },
  {
    "episode": 289,
    "avg_reward_per_step": 294.300907656709,
    "episode_length": 68,
    "policy_loss": -4910.6942138671875,
    "value_loss": 0.9258285313844681,
    "entropy": 0.0823726262897253,
    "total_loss": -4909.768385335803
  },
  {
    "episode": 290,
    "avg_reward_per_step": 298.72716351192634,
    "episode_length": 67,
    "policy_loss": -5003.3231201171875,
    "value_loss": 0.9368134140968323,
    "entropy": 0.06563592795282602,
    "total_loss": -5002.386306703091
  },
  {
    "episode": 291,
    "avg_reward_per_step": 290.4768190497134,
    "episode_length": 69,
    "policy_loss": -4860.5989990234375,
    "value_loss": 0.9177493453025818,
    "entropy": 0.05277678184211254,
    "total_loss": -4859.681249678135
  },
  {
    "episode": 292,
    "avg_reward_per_step": 161.29051415214875,
    "episode_length": 124,
    "policy_loss": -2740.510498046875,
    "value_loss": 0.6757053583860397,
    "entropy": 0.06739387288689613,
    "total_loss": -2739.834792688489
  },
  {
    "episode": 293,
    "avg_reward_per_step": 298.77893894550834,
    "episode_length": 67,
    "policy_loss": -4978.9976806640625,
    "value_loss": 0.9366536885499954,
    "entropy": 0.05581800825893879,
    "total_loss": -4978.0610269755125
  },
  {
    "episode": 294,
    "avg_reward_per_step": 299.2544320085284,
    "episode_length": 67,
    "policy_loss": -4983.79541015625,
    "value_loss": 0.938161700963974,
    "entropy": 0.05172537639737129,
    "total_loss": -4982.857248455286
  },
  {
    "episode": 295,
    "avg_reward_per_step": 299.2544320085284,
    "episode_length": 67,
    "policy_loss": -4983.118408203125,
    "value_loss": 0.9381982535123825,
    "entropy": 0.04759972635656595,
    "total_loss": -4982.180209949613
  },
  {
    "episode": 296,
    "avg_reward_per_step": 303.470449806946,
    "episode_length": 66,
    "policy_loss": -5051.1702880859375,
    "value_loss": 0.9480944871902466,
    "entropy": 0.06005960423499346,
    "total_loss": -5050.222193598747
  },
  {
    "episode": 297,
    "avg_reward_per_step": 290.4768190497134,
    "episode_length": 69,
    "policy_loss": -4843.02294921875,
    "value_loss": 0.917812705039978,
    "entropy": 0.028710097540169954,
    "total_loss": -4842.10513651371
  },
  {
    "episode": 298,
    "avg_reward_per_step": 290.2242837792794,
    "episode_length": 69,
    "policy_loss": -4842.5433349609375,
    "value_loss": 0.9168289750814438,
    "entropy": 0.052260152995586395,
    "total_loss": -4841.626505985856
  },
  {
    "episode": 299,
    "avg_reward_per_step": 298.77893894550834,
    "episode_length": 67,
    "policy_loss": -4972.00048828125,
    "value_loss": 0.9368091970682144,
    "entropy": 0.05066597554832697,
    "total_loss": -4971.063679084182
  },
  {
    "episode": 300,
    "avg_reward_per_step": 298.77893894550834,
    "episode_length": 67,
    "policy_loss": -4973.7335205078125,
    "value_loss": 0.9368577599525452,
    "entropy": 0.04910417925566435,
    "total_loss": -4972.79666274786
  }
]