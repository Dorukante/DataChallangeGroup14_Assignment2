[
  {
    "episode": 1,
    "avg_reward_per_step": 8.61200008605878,
    "episode_length": 1612,
    "policy_loss": -147.14971160888672,
    "value_loss": 0.5046263337135315,
    "entropy": 1.3749262690544128,
    "total_loss": -147.19505578279495
  },
  {
    "episode": 2,
    "avg_reward_per_step": 76.27501739983255,
    "episode_length": 252,
    "policy_loss": -1289.5224609375,
    "value_loss": 0.5660735368728638,
    "entropy": 1.378719687461853,
    "total_loss": -1289.507875275612
  },
  {
    "episode": 3,
    "avg_reward_per_step": 6.465086634511462,
    "episode_length": 1880,
    "policy_loss": -109.17239379882812,
    "value_loss": 0.502958208322525,
    "entropy": 1.3788926601409912,
    "total_loss": -109.220992654562
  },
  {
    "episode": 4,
    "avg_reward_per_step": 48.71834871547434,
    "episode_length": 386,
    "policy_loss": -824.2675476074219,
    "value_loss": 0.5391559600830078,
    "entropy": 1.371774971485138,
    "total_loss": -824.2771016359329
  },
  {
    "episode": 5,
    "avg_reward_per_step": 4.287355602601302,
    "episode_length": 2685,
    "policy_loss": -72.69404983520508,
    "value_loss": 0.5018232762813568,
    "entropy": 1.3779629468917847,
    "total_loss": -72.74341173768043
  },
  {
    "episode": 6,
    "avg_reward_per_step": 200.6146726828343,
    "episode_length": 99,
    "policy_loss": -3386.20361328125,
    "value_loss": 0.7332919538021088,
    "entropy": 1.370354413986206,
    "total_loss": -3386.0184630930426
  },
  {
    "episode": 7,
    "avg_reward_per_step": 269.8271407433381,
    "episode_length": 74,
    "policy_loss": -4512.821533203125,
    "value_loss": 0.8670819401741028,
    "entropy": 1.3741573095321655,
    "total_loss": -4512.504114186764
  },
  {
    "episode": 8,
    "avg_reward_per_step": 7.623241348233815,
    "episode_length": 1612,
    "policy_loss": -127.94568252563477,
    "value_loss": 0.5035221874713898,
    "entropy": 1.3731488585472107,
    "total_loss": -127.99141988158226
  },
  {
    "episode": 9,
    "avg_reward_per_step": 1.6180577867755923,
    "episode_length": 2851,
    "policy_loss": -27.588918685913086,
    "value_loss": 0.5001237690448761,
    "entropy": 1.368763506412506,
    "total_loss": -27.63630031943321
  },
  {
    "episode": 10,
    "avg_reward_per_step": 22.11511129156776,
    "episode_length": 754,
    "policy_loss": -372.9839324951172,
    "value_loss": 0.5148922204971313,
    "entropy": 1.3625145554542542,
    "total_loss": -373.01404609680174
  },
  {
    "episode": 11,
    "avg_reward_per_step": -3.5965799133637435,
    "episode_length": 3000,
    "policy_loss": 60.34947967529297,
    "value_loss": 1.7277761697769165,
    "entropy": 1.3608771562576294,
    "total_loss": 61.53290498256683
  },
  {
    "episode": 12,
    "avg_reward_per_step": 240.34938105668212,
    "episode_length": 83,
    "policy_loss": -4026.74658203125,
    "value_loss": 0.8052321672439575,
    "entropy": 1.3522754311561584,
    "total_loss": -4026.4822600364687
  },
  {
    "episode": 13,
    "avg_reward_per_step": 11.514254493784863,
    "episode_length": 1200,
    "policy_loss": -193.6652069091797,
    "value_loss": 0.5061839818954468,
    "entropy": 1.3476068377494812,
    "total_loss": -193.69806566238404
  },
  {
    "episode": 14,
    "avg_reward_per_step": -5.1491087517053185,
    "episode_length": 3000,
    "policy_loss": 86.43571472167969,
    "value_loss": 2.0765515565872192,
    "entropy": 1.345542073249817,
    "total_loss": 87.97404944896698
  },
  {
    "episode": 15,
    "avg_reward_per_step": 9.00321991655061,
    "episode_length": 1388,
    "policy_loss": -151.4703369140625,
    "value_loss": 0.5042439103126526,
    "entropy": 1.3447691798210144,
    "total_loss": -151.50400067567824
  },
  {
    "episode": 16,
    "avg_reward_per_step": 38.20230809584909,
    "episode_length": 467,
    "policy_loss": -643.3391418457031,
    "value_loss": 0.5284023582935333,
    "entropy": 1.3358968496322632,
    "total_loss": -643.3450982272625
  },
  {
    "episode": 17,
    "avg_reward_per_step": 0.9674213024956833,
    "episode_length": 2785,
    "policy_loss": -16.28831386566162,
    "value_loss": 0.4999113529920578,
    "entropy": 1.3488554954528809,
    "total_loss": -16.327944710850716
  },
  {
    "episode": 18,
    "avg_reward_per_step": 35.732489167296336,
    "episode_length": 511,
    "policy_loss": -602.2080383300781,
    "value_loss": 0.5272383093833923,
    "entropy": 1.3331428170204163,
    "total_loss": -602.2140571475029
  },
  {
    "episode": 19,
    "avg_reward_per_step": 5.067508363375146,
    "episode_length": 1818,
    "policy_loss": -85.48839950561523,
    "value_loss": 0.5016361176967621,
    "entropy": 1.341202437877655,
    "total_loss": -85.52324436306954
  },
  {
    "episode": 20,
    "avg_reward_per_step": 6.046544530301782,
    "episode_length": 1809,
    "policy_loss": -101.9254264831543,
    "value_loss": 0.5024256706237793,
    "entropy": 1.3482884764671326,
    "total_loss": -101.96231620311737
  },
  {
    "episode": 21,
    "avg_reward_per_step": 3.891639690791632,
    "episode_length": 2423,
    "policy_loss": -65.7447509765625,
    "value_loss": 0.501282274723053,
    "entropy": 1.3491280674934387,
    "total_loss": -65.78311992883683
  },
  {
    "episode": 22,
    "avg_reward_per_step": 6.9871373409879824,
    "episode_length": 1589,
    "policy_loss": -117.79705047607422,
    "value_loss": 0.5028682947158813,
    "entropy": 1.3382591605186462,
    "total_loss": -117.8294858455658
  },
  {
    "episode": 23,
    "avg_reward_per_step": 26.98832575118336,
    "episode_length": 620,
    "policy_loss": -454.8369903564453,
    "value_loss": 0.5183399617671967,
    "entropy": 1.3399217128753662,
    "total_loss": -454.85461907982824
  },
  {
    "episode": 24,
    "avg_reward_per_step": 12.859071536407436,
    "episode_length": 1257,
    "policy_loss": -216.7955322265625,
    "value_loss": 0.5082332193851471,
    "entropy": 1.3417125344276428,
    "total_loss": -216.82398402094842
  },
  {
    "episode": 25,
    "avg_reward_per_step": 68.68409923425482,
    "episode_length": 277,
    "policy_loss": -1157.562255859375,
    "value_loss": 0.5579091310501099,
    "entropy": 1.335500955581665,
    "total_loss": -1157.5385471105576
  },
  {
    "episode": 26,
    "avg_reward_per_step": 23.80508155836551,
    "episode_length": 673,
    "policy_loss": -401.67298889160156,
    "value_loss": 0.515349805355072,
    "entropy": 1.3338811993598938,
    "total_loss": -401.69119156599044
  },
  {
    "episode": 27,
    "avg_reward_per_step": 21.28277449321673,
    "episode_length": 767,
    "policy_loss": -358.98716735839844,
    "value_loss": 0.5139880180358887,
    "entropy": 1.3205112218856812,
    "total_loss": -359.00138382911683
  },
  {
    "episode": 28,
    "avg_reward_per_step": 16.50720508462302,
    "episode_length": 1034,
    "policy_loss": -278.8986511230469,
    "value_loss": 0.5112636089324951,
    "entropy": 1.338813602924347,
    "total_loss": -278.9229129552841
  },
  {
    "episode": 29,
    "avg_reward_per_step": 15.689363550919117,
    "episode_length": 905,
    "policy_loss": -264.3839111328125,
    "value_loss": 0.5086707174777985,
    "entropy": 1.3232088088989258,
    "total_loss": -264.4045239388943
  },
  {
    "episode": 30,
    "avg_reward_per_step": 40.101651010984824,
    "episode_length": 475,
    "policy_loss": -675.7449035644531,
    "value_loss": 0.5321909785270691,
    "entropy": 1.3161798119544983,
    "total_loss": -675.7391845107079
  },
  {
    "episode": 31,
    "avg_reward_per_step": 2.2839970897633473,
    "episode_length": 2710,
    "policy_loss": -38.66732597351074,
    "value_loss": 0.5003785490989685,
    "entropy": 1.324051558971405,
    "total_loss": -38.69656804800034
  },
  {
    "episode": 32,
    "avg_reward_per_step": -5.862135654265958,
    "episode_length": 3000,
    "policy_loss": 98.33295440673828,
    "value_loss": 2.4949313402175903,
    "entropy": 1.3198930621147156,
    "total_loss": 100.29992852210998
  },
  {
    "episode": 33,
    "avg_reward_per_step": 20.557137276629778,
    "episode_length": 878,
    "policy_loss": -346.0054931640625,
    "value_loss": 0.5149827897548676,
    "entropy": 1.2947739362716675,
    "total_loss": -346.0084199488163
  },
  {
    "episode": 34,
    "avg_reward_per_step": 4.869223592485011,
    "episode_length": 1987,
    "policy_loss": -82.21809387207031,
    "value_loss": 0.5016714036464691,
    "entropy": 1.315132200717926,
    "total_loss": -82.24247534871101
  },
  {
    "episode": 35,
    "avg_reward_per_step": 266.7059783337482,
    "episode_length": 75,
    "policy_loss": -4456.02001953125,
    "value_loss": 0.8607609868049622,
    "entropy": 1.301957905292511,
    "total_loss": -4455.680041706562
  },
  {
    "episode": 36,
    "avg_reward_per_step": 17.565678772699858,
    "episode_length": 856,
    "policy_loss": -296.7792205810547,
    "value_loss": 0.510403573513031,
    "entropy": 1.3011149168014526,
    "total_loss": -296.7892629742622
  },
  {
    "episode": 37,
    "avg_reward_per_step": 3.6485446543079876,
    "episode_length": 2062,
    "policy_loss": -61.446346282958984,
    "value_loss": 0.5008729100227356,
    "entropy": 1.2796245217323303,
    "total_loss": -61.45732318162918
  },
  {
    "episode": 38,
    "avg_reward_per_step": 181.18646899590826,
    "episode_length": 110,
    "policy_loss": -3050.4205322265625,
    "value_loss": 0.7021700441837311,
    "entropy": 1.2601736783981323,
    "total_loss": -3050.222431653738
  },
  {
    "episode": 39,
    "avg_reward_per_step": -6.617567275330859,
    "episode_length": 3000,
    "policy_loss": 110.98471069335938,
    "value_loss": 2.193561553955078,
    "entropy": 1.253965973854065,
    "total_loss": 112.67668585777282
  },
  {
    "episode": 40,
    "avg_reward_per_step": 8.995126701440173,
    "episode_length": 1327,
    "policy_loss": -152.0970687866211,
    "value_loss": 0.5040637254714966,
    "entropy": 1.2366392612457275,
    "total_loss": -152.08766076564788
  },
  {
    "episode": 41,
    "avg_reward_per_step": 4.435611193416628,
    "episode_length": 1749,
    "policy_loss": -74.64664459228516,
    "value_loss": 0.5011280179023743,
    "entropy": 1.237663447856903,
    "total_loss": -74.64058195352554
  },
  {
    "episode": 42,
    "avg_reward_per_step": -5.997003246983469,
    "episode_length": 3000,
    "policy_loss": 100.53564834594727,
    "value_loss": 2.144807457923889,
    "entropy": 1.2435834407806396,
    "total_loss": 102.1830224275589
  },
  {
    "episode": 43,
    "avg_reward_per_step": 14.140121456462765,
    "episode_length": 1068,
    "policy_loss": -238.23941802978516,
    "value_loss": 0.5084112584590912,
    "entropy": 1.253159523010254,
    "total_loss": -238.23227058053016
  },
  {
    "episode": 44,
    "avg_reward_per_step": 10.67388319856977,
    "episode_length": 1254,
    "policy_loss": -180.01993560791016,
    "value_loss": 0.505487710237503,
    "entropy": 1.2310872077941895,
    "total_loss": -180.00688278079033
  },
  {
    "episode": 45,
    "avg_reward_per_step": 17.390646682120853,
    "episode_length": 897,
    "policy_loss": -293.09344482421875,
    "value_loss": 0.5107505023479462,
    "entropy": 1.2462525963783264,
    "total_loss": -293.08119536042216
  },
  {
    "episode": 46,
    "avg_reward_per_step": 25.11542411501219,
    "episode_length": 655,
    "policy_loss": -423.5481872558594,
    "value_loss": 0.5166889131069183,
    "entropy": 1.2308626174926758,
    "total_loss": -423.5238433897495
  },
  {
    "episode": 47,
    "avg_reward_per_step": 86.19487381033646,
    "episode_length": 222,
    "policy_loss": -1456.9285278320312,
    "value_loss": 0.5752890110015869,
    "entropy": 1.2253034710884094,
    "total_loss": -1456.8433602094651
  },
  {
    "episode": 48,
    "avg_reward_per_step": 4.534276798998973,
    "episode_length": 2245,
    "policy_loss": -76.77400588989258,
    "value_loss": 0.5016818046569824,
    "entropy": 1.2356075644493103,
    "total_loss": -76.76656711101532
  },
  {
    "episode": 49,
    "avg_reward_per_step": 36.91188756116016,
    "episode_length": 481,
    "policy_loss": -623.4873962402344,
    "value_loss": 0.5272915661334991,
    "entropy": 1.1755695939064026,
    "total_loss": -623.4303325116634
  },
  {
    "episode": 50,
    "avg_reward_per_step": -6.092896361526664,
    "episode_length": 3000,
    "policy_loss": 102.03550338745117,
    "value_loss": 1.972818911075592,
    "entropy": 1.1902269124984741,
    "total_loss": 103.53223153352738
  },
  {
    "episode": 51,
    "avg_reward_per_step": 5.6780243356961595,
    "episode_length": 1611,
    "policy_loss": -95.84719467163086,
    "value_loss": 0.5018141865730286,
    "entropy": 1.137685775756836,
    "total_loss": -95.80045479536057
  },
  {
    "episode": 52,
    "avg_reward_per_step": 30.20565477749127,
    "episode_length": 555,
    "policy_loss": -509.80250549316406,
    "value_loss": 0.5206899046897888,
    "entropy": 1.1409330368041992,
    "total_loss": -509.73818880319595
  },
  {
    "episode": 53,
    "avg_reward_per_step": 7.595934739060272,
    "episode_length": 1659,
    "policy_loss": -128.49209594726562,
    "value_loss": 0.5036357343196869,
    "entropy": 1.1310966610908508,
    "total_loss": -128.44089887738227
  },
  {
    "episode": 54,
    "avg_reward_per_step": 12.86224239064912,
    "episode_length": 1009,
    "policy_loss": -217.8218002319336,
    "value_loss": 0.5064946711063385,
    "entropy": 1.1068724393844604,
    "total_loss": -217.75805453658103
  },
  {
    "episode": 55,
    "avg_reward_per_step": 8.715923094031728,
    "episode_length": 1182,
    "policy_loss": -147.7413330078125,
    "value_loss": 0.5032833218574524,
    "entropy": 1.1022599339485168,
    "total_loss": -147.67895365953444
  },
  {
    "episode": 56,
    "avg_reward_per_step": 1.489865049152117,
    "episode_length": 2200,
    "policy_loss": -25.90131187438965,
    "value_loss": 0.49997659027576447,
    "entropy": 1.0961602926254272,
    "total_loss": -25.839799401164054
  },
  {
    "episode": 57,
    "avg_reward_per_step": 2.2252265942965974,
    "episode_length": 2359,
    "policy_loss": -38.14683151245117,
    "value_loss": 0.5002712905406952,
    "entropy": 1.1042608618736267,
    "total_loss": -38.08826456665993
  },
  {
    "episode": 58,
    "avg_reward_per_step": 5.626911017812659,
    "episode_length": 1505,
    "policy_loss": -95.3519515991211,
    "value_loss": 0.5016394257545471,
    "entropy": 1.0719714164733887,
    "total_loss": -95.27910073995591
  },
  {
    "episode": 59,
    "avg_reward_per_step": 6.873160806440626,
    "episode_length": 1720,
    "policy_loss": -116.20257949829102,
    "value_loss": 0.5030379891395569,
    "entropy": 1.1025129556655884,
    "total_loss": -116.1405466914177
  },
  {
    "episode": 60,
    "avg_reward_per_step": 5.384495138091369,
    "episode_length": 1625,
    "policy_loss": -91.11664199829102,
    "value_loss": 0.5016356408596039,
    "entropy": 1.0530391931533813,
    "total_loss": -91.03622203469277
  },
  {
    "episode": 61,
    "avg_reward_per_step": 46.75311180878367,
    "episode_length": 377,
    "policy_loss": -790.518310546875,
    "value_loss": 0.5348221957683563,
    "entropy": 1.0543155670166016,
    "total_loss": -790.4052145779133
  },
  {
    "episode": 62,
    "avg_reward_per_step": 2.9745528527316267,
    "episode_length": 1967,
    "policy_loss": -50.40855407714844,
    "value_loss": 0.5004631578922272,
    "entropy": 1.037988543510437,
    "total_loss": -50.32328633666039
  },
  {
    "episode": 63,
    "avg_reward_per_step": 3.615103158643479,
    "episode_length": 1890,
    "policy_loss": -61.41986656188965,
    "value_loss": 0.5007603168487549,
    "entropy": 1.0328303575515747,
    "total_loss": -61.332238388061526
  },
  {
    "episode": 64,
    "avg_reward_per_step": 7.459654996180182,
    "episode_length": 1605,
    "policy_loss": -126.1165885925293,
    "value_loss": 0.5033795535564423,
    "entropy": 1.0629279017448425,
    "total_loss": -126.0383801996708
  },
  {
    "episode": 65,
    "avg_reward_per_step": 89.24677172358653,
    "episode_length": 218,
    "policy_loss": -1504.5390625,
    "value_loss": 0.5796565115451813,
    "entropy": 0.9992676079273224,
    "total_loss": -1504.3591130316258
  },
  {
    "episode": 66,
    "avg_reward_per_step": 39.809220706613225,
    "episode_length": 431,
    "policy_loss": -672.4356079101562,
    "value_loss": 0.5283517837524414,
    "entropy": 0.987921953201294,
    "total_loss": -672.3024249076843
  },
  {
    "episode": 67,
    "avg_reward_per_step": 174.19580455470802,
    "episode_length": 115,
    "policy_loss": -2927.0745849609375,
    "value_loss": 0.6916213929653168,
    "entropy": 0.9044467806816101,
    "total_loss": -2926.7447422802447
  },
  {
    "episode": 68,
    "avg_reward_per_step": 100.00248679695316,
    "episode_length": 189,
    "policy_loss": -1684.9413452148438,
    "value_loss": 0.588963121175766,
    "entropy": 0.9075057208538055,
    "total_loss": -1684.7153843820095
  },
  {
    "episode": 69,
    "avg_reward_per_step": -8.054637678226202,
    "episode_length": 3000,
    "policy_loss": 134.7627716064453,
    "value_loss": 2.3623602390289307,
    "entropy": 0.9665677547454834,
    "total_loss": 136.73850474357604
  },
  {
    "episode": 70,
    "avg_reward_per_step": -9.170608057956338,
    "episode_length": 3000,
    "policy_loss": 153.57628631591797,
    "value_loss": 2.8342835903167725,
    "entropy": 0.9264329373836517,
    "total_loss": 156.0399967312813
  },
  {
    "episode": 71,
    "avg_reward_per_step": -8.51921692494783,
    "episode_length": 3000,
    "policy_loss": 142.63381958007812,
    "value_loss": 2.2399919033050537,
    "entropy": 0.9509394466876984,
    "total_loss": 144.4934357047081
  },
  {
    "episode": 72,
    "avg_reward_per_step": -9.88674098554924,
    "episode_length": 3000,
    "policy_loss": 165.5538558959961,
    "value_loss": 3.733871102333069,
    "entropy": 0.9091208577156067,
    "total_loss": 168.9240786552429
  },
  {
    "episode": 73,
    "avg_reward_per_step": 7.1898271118668795,
    "episode_length": 1221,
    "policy_loss": -121.65035247802734,
    "value_loss": 0.5022023022174835,
    "entropy": 0.8758209943771362,
    "total_loss": -121.49847857356072
  },
  {
    "episode": 74,
    "avg_reward_per_step": 51.23021409742206,
    "episode_length": 348,
    "policy_loss": -865.2636108398438,
    "value_loss": 0.5390399694442749,
    "entropy": 0.8424745500087738,
    "total_loss": -865.061560690403
  },
  {
    "episode": 75,
    "avg_reward_per_step": 364.0751758035774,
    "episode_length": 55,
    "policy_loss": -5925.205078125,
    "value_loss": 1.1023838520050049,
    "entropy": 0.9475128352642059,
    "total_loss": -5924.481699407101
  },
  {
    "episode": 76,
    "avg_reward_per_step": -7.987116545853283,
    "episode_length": 3000,
    "policy_loss": 133.36158752441406,
    "value_loss": 2.0134893655776978,
    "entropy": 0.9969283640384674,
    "total_loss": 134.97630554437637
  },
  {
    "episode": 77,
    "avg_reward_per_step": 25.16446848872093,
    "episode_length": 605,
    "policy_loss": -425.6474151611328,
    "value_loss": 0.5154057741165161,
    "entropy": 0.969343900680542,
    "total_loss": -425.5197469472885
  },
  {
    "episode": 78,
    "avg_reward_per_step": -8.698937612298177,
    "episode_length": 3000,
    "policy_loss": 145.22067260742188,
    "value_loss": 2.285807251930237,
    "entropy": 1.01726496219635,
    "total_loss": 147.09957387447358
  },
  {
    "episode": 79,
    "avg_reward_per_step": 6.369277657647748,
    "episode_length": 1633,
    "policy_loss": -108.12228012084961,
    "value_loss": 0.5024504065513611,
    "entropy": 1.0899317860603333,
    "total_loss": -108.05580242872239
  },
  {
    "episode": 80,
    "avg_reward_per_step": 281.89444007660245,
    "episode_length": 71,
    "policy_loss": -4695.356201171875,
    "value_loss": 0.8943402469158173,
    "entropy": 1.088226318359375,
    "total_loss": -4694.897151452303
  },
  {
    "episode": 81,
    "avg_reward_per_step": 266.4742102776287,
    "episode_length": 75,
    "policy_loss": -4455.886962890625,
    "value_loss": 0.8594059944152832,
    "entropy": 1.0615097284317017,
    "total_loss": -4455.452160787582
  },
  {
    "episode": 82,
    "avg_reward_per_step": -8.128385991799417,
    "episode_length": 3000,
    "policy_loss": 135.80751037597656,
    "value_loss": 2.0935933589935303,
    "entropy": 1.0332587361335754,
    "total_loss": 137.48780024051666
  },
  {
    "episode": 83,
    "avg_reward_per_step": -9.567987507116936,
    "episode_length": 3000,
    "policy_loss": 159.77845764160156,
    "value_loss": 3.497860908508301,
    "entropy": 0.9134474992752075,
    "total_loss": 162.91093955039977
  },
  {
    "episode": 84,
    "avg_reward_per_step": 5.957954780571098,
    "episode_length": 1176,
    "policy_loss": -100.9131851196289,
    "value_loss": 0.501330703496933,
    "entropy": 0.900406002998352,
    "total_loss": -100.77201681733132
  },
  {
    "episode": 85,
    "avg_reward_per_step": -11.434123293630549,
    "episode_length": 3000,
    "policy_loss": 191.0015411376953,
    "value_loss": 4.479537010192871,
    "entropy": 0.8459482491016388,
    "total_loss": 195.14269884824753
  },
  {
    "episode": 86,
    "avg_reward_per_step": 0.7455948080576041,
    "episode_length": 1540,
    "policy_loss": -13.82301950454712,
    "value_loss": 0.4997071772813797,
    "entropy": 0.8182161152362823,
    "total_loss": -13.650598773360253
  },
  {
    "episode": 87,
    "avg_reward_per_step": -1.8630531449612227,
    "episode_length": 1857,
    "policy_loss": 29.987701416015625,
    "value_loss": 0.49996940791606903,
    "entropy": 0.8105191886425018,
    "total_loss": 30.163463148474694
  },
  {
    "episode": 88,
    "avg_reward_per_step": -2.445831704857622,
    "episode_length": 2298,
    "policy_loss": 39.5177001953125,
    "value_loss": 0.5003045201301575,
    "entropy": 0.8072766661643982,
    "total_loss": 39.6950940489769
  },
  {
    "episode": 89,
    "avg_reward_per_step": 187.8043535605124,
    "episode_length": 106,
    "policy_loss": -3168.07958984375,
    "value_loss": 0.7113072574138641,
    "entropy": 0.8096741735935211,
    "total_loss": -3167.6921522557736
  },
  {
    "episode": 90,
    "avg_reward_per_step": -11.901441210525135,
    "episode_length": 3000,
    "policy_loss": 198.69561004638672,
    "value_loss": 4.261204957962036,
    "entropy": 0.8146913051605225,
    "total_loss": 202.63093848228453
  },
  {
    "episode": 91,
    "avg_reward_per_step": 19.23626327364288,
    "episode_length": 667,
    "policy_loss": -326.85028076171875,
    "value_loss": 0.5096435248851776,
    "entropy": 0.7886021137237549,
    "total_loss": -326.65607808232306
  },
  {
    "episode": 92,
    "avg_reward_per_step": -12.672762799966284,
    "episode_length": 3000,
    "policy_loss": 211.560302734375,
    "value_loss": 4.63282036781311,
    "entropy": 0.7384666800498962,
    "total_loss": 215.89773643016815
  },
  {
    "episode": 93,
    "avg_reward_per_step": -11.441866173075915,
    "episode_length": 3000,
    "policy_loss": 190.69225311279297,
    "value_loss": 3.037997603416443,
    "entropy": 0.7365793287754059,
    "total_loss": 193.43561898469926
  },
  {
    "episode": 94,
    "avg_reward_per_step": 212.55430562438758,
    "episode_length": 94,
    "policy_loss": -3581.496337890625,
    "value_loss": 0.7540630102157593,
    "entropy": 0.7425724267959595,
    "total_loss": -3581.0393038511274
  },
  {
    "episode": 95,
    "avg_reward_per_step": -13.846578744385624,
    "episode_length": 3000,
    "policy_loss": 231.01602172851562,
    "value_loss": 6.2088611125946045,
    "entropy": 0.7612436711788177,
    "total_loss": 236.9203853726387
  },
  {
    "episode": 96,
    "avg_reward_per_step": -9.99032165836956,
    "episode_length": 3000,
    "policy_loss": 166.31853485107422,
    "value_loss": 2.3229262828826904,
    "entropy": 0.8512078821659088,
    "total_loss": 168.30097798109054
  },
  {
    "episode": 97,
    "avg_reward_per_step": 2.6197667685368287,
    "episode_length": 1523,
    "policy_loss": -46.50533866882324,
    "value_loss": 0.5001649856567383,
    "entropy": 0.8304885625839233,
    "total_loss": -46.33736910820007
  },
  {
    "episode": 98,
    "avg_reward_per_step": 286.0867264205369,
    "episode_length": 70,
    "policy_loss": -4829.127685546875,
    "value_loss": 0.9035460352897644,
    "entropy": 0.8978681564331055,
    "total_loss": -4828.583286774158
  },
  {
    "episode": 99,
    "avg_reward_per_step": 50.137778206806274,
    "episode_length": 350,
    "policy_loss": -852.69287109375,
    "value_loss": 0.5376134514808655,
    "entropy": 0.9125816226005554,
    "total_loss": -852.5202902913094
  },
  {
    "episode": 100,
    "avg_reward_per_step": 104.53696802111709,
    "episode_length": 184,
    "policy_loss": -1765.371337890625,
    "value_loss": 0.5958028137683868,
    "entropy": 1.0100763440132141,
    "total_loss": -1765.1795656144618
  },
  {
    "episode": 101,
    "avg_reward_per_step": 9.890673708312523,
    "episode_length": 1446,
    "policy_loss": -169.35895538330078,
    "value_loss": 0.505654513835907,
    "entropy": 1.1208195090293884,
    "total_loss": -169.30162867307664
  },
  {
    "episode": 102,
    "avg_reward_per_step": 126.443156033611,
    "episode_length": 154,
    "policy_loss": -2127.860595703125,
    "value_loss": 0.6219705045223236,
    "entropy": 1.084434688091278,
    "total_loss": -2127.672399073839
  },
  {
    "episode": 103,
    "avg_reward_per_step": 12.732792738960327,
    "episode_length": 1171,
    "policy_loss": -216.37925720214844,
    "value_loss": 0.5075809359550476,
    "entropy": 1.1191803812980652,
    "total_loss": -216.31934841871262
  },
  {
    "episode": 104,
    "avg_reward_per_step": 19.471670779452065,
    "episode_length": 885,
    "policy_loss": -329.40049743652344,
    "value_loss": 0.513708233833313,
    "entropy": 1.130862057209015,
    "total_loss": -329.33913402557374
  },
  {
    "episode": 105,
    "avg_reward_per_step": 38.075200372296344,
    "episode_length": 483,
    "policy_loss": -643.7283935546875,
    "value_loss": 0.5294976830482483,
    "entropy": 1.12969309091568,
    "total_loss": -643.6507731080055
  },
  {
    "episode": 106,
    "avg_reward_per_step": 141.76708681382686,
    "episode_length": 139,
    "policy_loss": -2391.6407470703125,
    "value_loss": 0.643701821565628,
    "entropy": 1.1314319968223572,
    "total_loss": -2391.4496180474757
  },
  {
    "episode": 107,
    "avg_reward_per_step": 90.43552186341022,
    "episode_length": 213,
    "policy_loss": -1530.20068359375,
    "value_loss": 0.5808156430721283,
    "entropy": 1.1349336504936218,
    "total_loss": -1530.0738414108753
  },
  {
    "episode": 108,
    "avg_reward_per_step": 26.76180041324332,
    "episode_length": 672,
    "policy_loss": -452.70269775390625,
    "value_loss": 0.5198864638805389,
    "entropy": 1.151462733745575,
    "total_loss": -452.64339638352396
  },
  {
    "episode": 109,
    "avg_reward_per_step": 22.04634404015553,
    "episode_length": 799,
    "policy_loss": -373.2681121826172,
    "value_loss": 0.5158949196338654,
    "entropy": 1.1511161923408508,
    "total_loss": -373.21266373991966
  },
  {
    "episode": 110,
    "avg_reward_per_step": 87.55410108139446,
    "episode_length": 224,
    "policy_loss": -1482.3429565429688,
    "value_loss": 0.5793120265007019,
    "entropy": 1.1756654381752014,
    "total_loss": -1482.2339106917382
  },
  {
    "episode": 111,
    "avg_reward_per_step": 47.447713073113306,
    "episode_length": 392,
    "policy_loss": -801.731201171875,
    "value_loss": 0.5377341508865356,
    "entropy": 1.1376665830612183,
    "total_loss": -801.648533654213
  },
  {
    "episode": 112,
    "avg_reward_per_step": 11.029406179291223,
    "episode_length": 1395,
    "policy_loss": -187.7223129272461,
    "value_loss": 0.5068383514881134,
    "entropy": 1.170083999633789,
    "total_loss": -187.6835081756115
  },
  {
    "episode": 113,
    "avg_reward_per_step": 14.129722663006257,
    "episode_length": 1137,
    "policy_loss": -239.76022338867188,
    "value_loss": 0.509175717830658,
    "entropy": 1.1686240434646606,
    "total_loss": -239.71849728822707
  },
  {
    "episode": 114,
    "avg_reward_per_step": 23.398772235804635,
    "episode_length": 753,
    "policy_loss": -396.403076171875,
    "value_loss": 0.5170134007930756,
    "entropy": 1.1668390035629272,
    "total_loss": -396.3527983725071
  },
  {
    "episode": 115,
    "avg_reward_per_step": 5.386821668802762,
    "episode_length": 2231,
    "policy_loss": -92.73579025268555,
    "value_loss": 0.5025557577610016,
    "entropy": 1.1790478825569153,
    "total_loss": -92.70485364794732
  },
  {
    "episode": 116,
    "avg_reward_per_step": 30.824877780514825,
    "episode_length": 588,
    "policy_loss": -521.6385192871094,
    "value_loss": 0.5232692956924438,
    "entropy": 1.1886368989944458,
    "total_loss": -521.5907047510148
  },
  {
    "episode": 117,
    "avg_reward_per_step": 43.18158091177064,
    "episode_length": 430,
    "policy_loss": -729.1180725097656,
    "value_loss": 0.5339750945568085,
    "entropy": 1.1619877219200134,
    "total_loss": -729.0488925039768
  },
  {
    "episode": 118,
    "avg_reward_per_step": 49.40908086563065,
    "episode_length": 383,
    "policy_loss": -834.4341125488281,
    "value_loss": 0.5402259528636932,
    "entropy": 1.1639075875282288,
    "total_loss": -834.3594496309757
  },
  {
    "episode": 119,
    "avg_reward_per_step": 85.61889169376407,
    "episode_length": 228,
    "policy_loss": -1449.17724609375,
    "value_loss": 0.5775038003921509,
    "entropy": 1.178166687488556,
    "total_loss": -1449.0710089683532
  },
  {
    "episode": 120,
    "avg_reward_per_step": 39.23262367737383,
    "episode_length": 479,
    "policy_loss": -664.0592956542969,
    "value_loss": 0.5312331020832062,
    "entropy": 1.1797348260879517,
    "total_loss": -663.9999564826488
  },
  {
    "episode": 121,
    "avg_reward_per_step": 64.58581808879869,
    "episode_length": 290,
    "policy_loss": -1090.3309936523438,
    "value_loss": 0.5531720519065857,
    "entropy": 1.1558537483215332,
    "total_loss": -1090.2401630997658
  },
  {
    "episode": 122,
    "avg_reward_per_step": 18.67870151974189,
    "episode_length": 852,
    "policy_loss": -316.75852966308594,
    "value_loss": 0.5119883418083191,
    "entropy": 1.1642140746116638,
    "total_loss": -316.71222695112226
  },
  {
    "episode": 123,
    "avg_reward_per_step": 27.066071560967696,
    "episode_length": 618,
    "policy_loss": -458.79998779296875,
    "value_loss": 0.5185497105121613,
    "entropy": 1.1445280313491821,
    "total_loss": -458.7392492949963
  },
  {
    "episode": 124,
    "avg_reward_per_step": 51.36138205976135,
    "episode_length": 355,
    "policy_loss": -867.747314453125,
    "value_loss": 0.5400010943412781,
    "entropy": 1.1398237943649292,
    "total_loss": -867.6632428765297
  },
  {
    "episode": 125,
    "avg_reward_per_step": 35.655636553969,
    "episode_length": 498,
    "policy_loss": -602.6968994140625,
    "value_loss": 0.5263868272304535,
    "entropy": 1.1375085711479187,
    "total_loss": -602.6255160152912
  },
  {
    "episode": 126,
    "avg_reward_per_step": 69.8181229685761,
    "episode_length": 270,
    "policy_loss": -1179.3880004882812,
    "value_loss": 0.5583613216876984,
    "entropy": 1.117694079875946,
    "total_loss": -1179.276716798544
  },
  {
    "episode": 127,
    "avg_reward_per_step": 16.616338938457286,
    "episode_length": 970,
    "policy_loss": -282.50193786621094,
    "value_loss": 0.5107893943786621,
    "entropy": 1.1042558550834656,
    "total_loss": -282.4328508138657
  },
  {
    "episode": 128,
    "avg_reward_per_step": 14.379781827810016,
    "episode_length": 1023,
    "policy_loss": -244.46709442138672,
    "value_loss": 0.5083944201469421,
    "entropy": 1.1065630316734314,
    "total_loss": -244.40132521390916
  },
  {
    "episode": 129,
    "avg_reward_per_step": 69.83354719996751,
    "episode_length": 271,
    "policy_loss": -1179.8148193359375,
    "value_loss": 0.558869868516922,
    "entropy": 1.0758253931999207,
    "total_loss": -1179.6862796247005
  },
  {
    "episode": 130,
    "avg_reward_per_step": 5.287046749046999,
    "episode_length": 1943,
    "policy_loss": -91.06713104248047,
    "value_loss": 0.5020653307437897,
    "entropy": 1.1001644134521484,
    "total_loss": -91.00513147711754
  },
  {
    "episode": 131,
    "avg_reward_per_step": 43.45485790891846,
    "episode_length": 429,
    "policy_loss": -736.5303039550781,
    "value_loss": 0.5347454845905304,
    "entropy": 1.1081514954566956,
    "total_loss": -736.4388190686702
  },
  {
    "episode": 132,
    "avg_reward_per_step": 98.08096444926399,
    "episode_length": 197,
    "policy_loss": -1656.800048828125,
    "value_loss": 0.5893726348876953,
    "entropy": 1.054705023765564,
    "total_loss": -1656.6325582027434
  },
  {
    "episode": 133,
    "avg_reward_per_step": 49.454602522778906,
    "episode_length": 387,
    "policy_loss": -834.6161193847656,
    "value_loss": 0.5406292378902435,
    "entropy": 1.0535452365875244,
    "total_loss": -834.4969082415104
  },
  {
    "episode": 134,
    "avg_reward_per_step": 29.904572523496896,
    "episode_length": 568,
    "policy_loss": -507.1532440185547,
    "value_loss": 0.5210233926773071,
    "entropy": 1.042211651802063,
    "total_loss": -507.0491052865982
  },
  {
    "episode": 135,
    "avg_reward_per_step": 14.939500418399168,
    "episode_length": 1046,
    "policy_loss": -253.61087036132812,
    "value_loss": 0.5093684196472168,
    "entropy": 1.0502901077270508,
    "total_loss": -253.52161798477172
  },
  {
    "episode": 136,
    "avg_reward_per_step": 89.96156946548528,
    "episode_length": 210,
    "policy_loss": -1518.6116333007812,
    "value_loss": 0.5786037147045135,
    "entropy": 1.0032448172569275,
    "total_loss": -1518.4343275129795
  },
  {
    "episode": 137,
    "avg_reward_per_step": 22.537328670172787,
    "episode_length": 721,
    "policy_loss": -383.13311767578125,
    "value_loss": 0.5148060321807861,
    "entropy": 1.0120741128921509,
    "total_loss": -383.0231412887573
  },
  {
    "episode": 138,
    "avg_reward_per_step": 29.865525341182725,
    "episode_length": 589,
    "policy_loss": -505.60211181640625,
    "value_loss": 0.5217108130455017,
    "entropy": 0.9785408973693848,
    "total_loss": -505.4718173623085
  },
  {
    "episode": 139,
    "avg_reward_per_step": 129.88042140381148,
    "episode_length": 150,
    "policy_loss": -2196.4649658203125,
    "value_loss": 0.6263304352760315,
    "entropy": 0.9874069690704346,
    "total_loss": -2196.2335981726646
  },
  {
    "episode": 140,
    "avg_reward_per_step": 37.04493064872084,
    "episode_length": 476,
    "policy_loss": -625.4579772949219,
    "value_loss": 0.5274232625961304,
    "entropy": 0.9711492955684662,
    "total_loss": -625.3190137505532
  },
  {
    "episode": 141,
    "avg_reward_per_step": 80.01173990416665,
    "episode_length": 240,
    "policy_loss": -1353.42333984375,
    "value_loss": 0.5704652667045593,
    "entropy": 0.9920139312744141,
    "total_loss": -1353.2496801495552
  },
  {
    "episode": 142,
    "avg_reward_per_step": 11.99037614479915,
    "episode_length": 1045,
    "policy_loss": -204.18887329101562,
    "value_loss": 0.5058611333370209,
    "entropy": 0.9415262341499329,
    "total_loss": -204.05962265133857
  },
  {
    "episode": 143,
    "avg_reward_per_step": 154.60288898707142,
    "episode_length": 126,
    "policy_loss": -2613.484130859375,
    "value_loss": 0.6582946181297302,
    "entropy": 0.9614827632904053,
    "total_loss": -2613.2104293465613
  },
  {
    "episode": 144,
    "avg_reward_per_step": 61.38099647475131,
    "episode_length": 306,
    "policy_loss": -1036.7322998046875,
    "value_loss": 0.5505227148532867,
    "entropy": 0.9598829448223114,
    "total_loss": -1036.5657302677632
  },
  {
    "episode": 145,
    "avg_reward_per_step": 177.96996008428238,
    "episode_length": 111,
    "policy_loss": -3010.567626953125,
    "value_loss": 0.6947373747825623,
    "entropy": 0.9326725900173187,
    "total_loss": -3010.2459586143495
  },
  {
    "episode": 146,
    "avg_reward_per_step": 8.407432240341764,
    "episode_length": 1407,
    "policy_loss": -142.9224090576172,
    "value_loss": 0.5038661062717438,
    "entropy": 0.8852022290229797,
    "total_loss": -142.77262384295463
  },
  {
    "episode": 147,
    "avg_reward_per_step": 17.222374796556323,
    "episode_length": 871,
    "policy_loss": -292.6809539794922,
    "value_loss": 0.5103324353694916,
    "entropy": 0.8609880805015564,
    "total_loss": -292.5150167763233
  },
  {
    "episode": 148,
    "avg_reward_per_step": 111.71836123754751,
    "episode_length": 172,
    "policy_loss": -1886.8634033203125,
    "value_loss": 0.6036593914031982,
    "entropy": 0.8474813997745514,
    "total_loss": -1886.5987364888192
  },
  {
    "episode": 149,
    "avg_reward_per_step": 76.17962487290363,
    "episode_length": 239,
    "policy_loss": -1286.7294311523438,
    "value_loss": 0.5625361204147339,
    "entropy": 0.8401263952255249,
    "total_loss": -1286.5029455900192
  },
  {
    "episode": 150,
    "avg_reward_per_step": 88.73061911106977,
    "episode_length": 220,
    "policy_loss": -1496.683837890625,
    "value_loss": 0.5800025761127472,
    "entropy": 0.8606564700603485,
    "total_loss": -1496.4480979025363
  },
  {
    "episode": 151,
    "avg_reward_per_step": 35.52633105717949,
    "episode_length": 492,
    "policy_loss": -600.3704223632812,
    "value_loss": 0.5257744789123535,
    "entropy": 0.828350841999054,
    "total_loss": -600.1759882211685
  },
  {
    "episode": 152,
    "avg_reward_per_step": 94.52356096611624,
    "episode_length": 207,
    "policy_loss": -1595.2747192382812,
    "value_loss": 0.5861477553844452,
    "entropy": 0.8651707172393799,
    "total_loss": -1595.0346397697926
  },
  {
    "episode": 153,
    "avg_reward_per_step": 79.53103429137994,
    "episode_length": 245,
    "policy_loss": -1343.4617309570312,
    "value_loss": 0.5702478289604187,
    "entropy": 0.8328869044780731,
    "total_loss": -1343.2246378898622
  },
  {
    "episode": 154,
    "avg_reward_per_step": 85.01163487118244,
    "episode_length": 224,
    "policy_loss": -1436.1505737304688,
    "value_loss": 0.573708713054657,
    "entropy": 0.8166288137435913,
    "total_loss": -1435.9035165429116
  },
  {
    "episode": 155,
    "avg_reward_per_step": 57.42035547584523,
    "episode_length": 330,
    "policy_loss": -971.6929931640625,
    "value_loss": 0.5474561750888824,
    "entropy": 0.8400743007659912,
    "total_loss": -971.4815667092801
  },
  {
    "episode": 156,
    "avg_reward_per_step": 37.47451950996539,
    "episode_length": 477,
    "policy_loss": -637.1414184570312,
    "value_loss": 0.5280625522136688,
    "entropy": 0.819361001253128,
    "total_loss": -636.9411003053189
  },
  {
    "episode": 157,
    "avg_reward_per_step": 38.22733732838332,
    "episode_length": 489,
    "policy_loss": -641.4484252929688,
    "value_loss": 0.5302397608757019,
    "entropy": 0.845443844795227,
    "total_loss": -641.2563630700112
  },
  {
    "episode": 158,
    "avg_reward_per_step": 18.966903024349918,
    "episode_length": 912,
    "policy_loss": -321.70997619628906,
    "value_loss": 0.5134457349777222,
    "entropy": 0.8631897866725922,
    "total_loss": -321.5418063759804
  },
  {
    "episode": 159,
    "avg_reward_per_step": 67.64947210273324,
    "episode_length": 284,
    "policy_loss": -1143.9701538085938,
    "value_loss": 0.5577245056629181,
    "entropy": 0.8536412715911865,
    "total_loss": -1143.7538858115672
  },
  {
    "episode": 160,
    "avg_reward_per_step": 132.50371706421606,
    "episode_length": 149,
    "policy_loss": -2240.8756103515625,
    "value_loss": 0.6324407160282135,
    "entropy": 0.8545827865600586,
    "total_loss": -2240.5850027501583
  },
  {
    "episode": 161,
    "avg_reward_per_step": 32.0170648965171,
    "episode_length": 579,
    "policy_loss": -542.1880187988281,
    "value_loss": 0.5248080790042877,
    "entropy": 0.8691754937171936,
    "total_loss": -542.0108809173107
  },
  {
    "episode": 162,
    "avg_reward_per_step": 11.104475727354027,
    "episode_length": 1426,
    "policy_loss": -188.87835693359375,
    "value_loss": 0.5070807635784149,
    "entropy": 0.8941284418106079,
    "total_loss": -188.72892754673958
  },
  {
    "episode": 163,
    "avg_reward_per_step": 52.45826271939478,
    "episode_length": 366,
    "policy_loss": -884.19970703125,
    "value_loss": 0.5435685217380524,
    "entropy": 0.9001144170761108,
    "total_loss": -884.0161842763424
  },
  {
    "episode": 164,
    "avg_reward_per_step": 24.21670254480169,
    "episode_length": 743,
    "policy_loss": -410.2305908203125,
    "value_loss": 0.5179161429405212,
    "entropy": 0.9064158797264099,
    "total_loss": -410.07524102926254
  },
  {
    "episode": 165,
    "avg_reward_per_step": 42.65434017775443,
    "episode_length": 442,
    "policy_loss": -724.4419250488281,
    "value_loss": 0.5343821942806244,
    "entropy": 0.9013161361217499,
    "total_loss": -724.2680693089962
  },
  {
    "episode": 166,
    "avg_reward_per_step": 42.51243905547971,
    "episode_length": 448,
    "policy_loss": -721.3572692871094,
    "value_loss": 0.5345572829246521,
    "entropy": 0.9279824197292328,
    "total_loss": -721.1939049720764
  },
  {
    "episode": 167,
    "avg_reward_per_step": 80.7964254654113,
    "episode_length": 244,
    "policy_loss": -1361.1015014648438,
    "value_loss": 0.572899341583252,
    "entropy": 0.928249716758728,
    "total_loss": -1360.899902009964
  },
  {
    "episode": 168,
    "avg_reward_per_step": 89.56312476176787,
    "episode_length": 219,
    "policy_loss": -1512.1385498046875,
    "value_loss": 0.5812754929065704,
    "entropy": 0.9166485965251923,
    "total_loss": -1511.923933750391
  },
  {
    "episode": 169,
    "avg_reward_per_step": 57.290268402933826,
    "episode_length": 330,
    "policy_loss": -967.9940795898438,
    "value_loss": 0.5471363067626953,
    "entropy": 0.9075634181499481,
    "total_loss": -967.809968650341
  },
  {
    "episode": 170,
    "avg_reward_per_step": 49.221030516558756,
    "episode_length": 379,
    "policy_loss": -830.8175659179688,
    "value_loss": 0.5394526720046997,
    "entropy": 0.9147269427776337,
    "total_loss": -830.6440040230751
  },
  {
    "episode": 171,
    "avg_reward_per_step": 71.39619788117264,
    "episode_length": 271,
    "policy_loss": -1207.8168334960938,
    "value_loss": 0.561741828918457,
    "entropy": 0.9115158021450043,
    "total_loss": -1207.6196979880333
  },
  {
    "episode": 172,
    "avg_reward_per_step": 42.03588924258377,
    "episode_length": 429,
    "policy_loss": -709.4151916503906,
    "value_loss": 0.5318995714187622,
    "entropy": 0.8781276643276215,
    "total_loss": -709.2345431447029
  },
  {
    "episode": 173,
    "avg_reward_per_step": 8.731015571928818,
    "episode_length": 1500,
    "policy_loss": -148.70928192138672,
    "value_loss": 0.5044440031051636,
    "entropy": 0.8815541565418243,
    "total_loss": -148.5574595808983
  },
  {
    "episode": 174,
    "avg_reward_per_step": 199.77685534079953,
    "episode_length": 99,
    "policy_loss": -3360.798583984375,
    "value_loss": 0.7296723127365112,
    "entropy": 0.882047027349472,
    "total_loss": -3360.4217304825784
  },
  {
    "episode": 175,
    "avg_reward_per_step": 61.442122926726356,
    "episode_length": 311,
    "policy_loss": -1038.4592895507812,
    "value_loss": 0.5517909824848175,
    "entropy": 0.9092917442321777,
    "total_loss": -1038.2712152659892
  },
  {
    "episode": 176,
    "avg_reward_per_step": 92.70127336209994,
    "episode_length": 207,
    "policy_loss": -1567.3665771484375,
    "value_loss": 0.5825114548206329,
    "entropy": 0.8720065057277679,
    "total_loss": -1567.1328682959079
  },
  {
    "episode": 177,
    "avg_reward_per_step": 172.75422845284402,
    "episode_length": 114,
    "policy_loss": -2913.1456298828125,
    "value_loss": 0.686247706413269,
    "entropy": 0.8647709786891937,
    "total_loss": -2912.805290567875
  },
  {
    "episode": 178,
    "avg_reward_per_step": 46.44191300739579,
    "episode_length": 407,
    "policy_loss": -788.014892578125,
    "value_loss": 0.5374785363674164,
    "entropy": 0.8751826584339142,
    "total_loss": -787.8274871051311
  },
  {
    "episode": 179,
    "avg_reward_per_step": 66.86726553582568,
    "episode_length": 290,
    "policy_loss": -1127.189208984375,
    "value_loss": 0.5574909746646881,
    "entropy": 0.8756220042705536,
    "total_loss": -1126.9819668114185
  },
  {
    "episode": 180,
    "avg_reward_per_step": 210.15695832617064,
    "episode_length": 95,
    "policy_loss": -3537.45947265625,
    "value_loss": 0.7505660057067871,
    "entropy": 0.883330374956131,
    "total_loss": -3537.062238800526
  },
  {
    "episode": 181,
    "avg_reward_per_step": 11.051094943471389,
    "episode_length": 1444,
    "policy_loss": -187.9071502685547,
    "value_loss": 0.5070793032646179,
    "entropy": 0.8821932375431061,
    "total_loss": -187.7529482603073
  },
  {
    "episode": 182,
    "avg_reward_per_step": 29.584712593004372,
    "episode_length": 623,
    "policy_loss": -501.35826110839844,
    "value_loss": 0.5226089358329773,
    "entropy": 0.8745956718921661,
    "total_loss": -501.1854904413223
  },
  {
    "episode": 183,
    "avg_reward_per_step": 90.64413846146033,
    "episode_length": 218,
    "policy_loss": -1531.0142822265625,
    "value_loss": 0.5833347737789154,
    "entropy": 0.8674692809581757,
    "total_loss": -1530.7779351651668
  },
  {
    "episode": 184,
    "avg_reward_per_step": 27.058698533982483,
    "episode_length": 683,
    "policy_loss": -457.8734893798828,
    "value_loss": 0.5206784009933472,
    "entropy": 0.8925979435443878,
    "total_loss": -457.7098501563072
  },
  {
    "episode": 185,
    "avg_reward_per_step": 103.7454853105093,
    "episode_length": 191,
    "policy_loss": -1749.2153930664062,
    "value_loss": 0.5982054173946381,
    "entropy": 0.8709371387958527,
    "total_loss": -1748.96556250453
  },
  {
    "episode": 186,
    "avg_reward_per_step": 91.47084001441759,
    "episode_length": 216,
    "policy_loss": -1543.0924682617188,
    "value_loss": 0.584181934595108,
    "entropy": 0.8891522884368896,
    "total_loss": -1542.8639472424984
  },
  {
    "episode": 187,
    "avg_reward_per_step": 127.39120189033346,
    "episode_length": 156,
    "policy_loss": -2148.61474609375,
    "value_loss": 0.6268263757228851,
    "entropy": 0.8944084048271179,
    "total_loss": -2148.345683079958
  },
  {
    "episode": 188,
    "avg_reward_per_step": 38.50127643760156,
    "episode_length": 494,
    "policy_loss": -650.4237365722656,
    "value_loss": 0.5309287309646606,
    "entropy": 0.9074682593345642,
    "total_loss": -650.2557951450348
  },
  {
    "episode": 189,
    "avg_reward_per_step": 52.64051987821004,
    "episode_length": 362,
    "policy_loss": -889.0186462402344,
    "value_loss": 0.543399840593338,
    "entropy": 0.9127776026725769,
    "total_loss": -888.84035744071
  },
  {
    "episode": 190,
    "avg_reward_per_step": 138.62085466502398,
    "episode_length": 143,
    "policy_loss": -2338.09228515625,
    "value_loss": 0.6403289139270782,
    "entropy": 0.9118536114692688,
    "total_loss": -2337.8166976869106
  },
  {
    "episode": 191,
    "avg_reward_per_step": 120.47379025753747,
    "episode_length": 165,
    "policy_loss": -2032.8760986328125,
    "value_loss": 0.6183659136295319,
    "entropy": 0.9047839343547821,
    "total_loss": -2032.619646292925
  },
  {
    "episode": 192,
    "avg_reward_per_step": 23.31805292438477,
    "episode_length": 789,
    "policy_loss": -394.4640197753906,
    "value_loss": 0.5177144110202789,
    "entropy": 0.8932142853736877,
    "total_loss": -394.30359107851984
  },
  {
    "episode": 193,
    "avg_reward_per_step": 34.43435045262375,
    "episode_length": 548,
    "policy_loss": -581.4794921875,
    "value_loss": 0.5271499156951904,
    "entropy": 0.8872349858283997,
    "total_loss": -581.3072362661362
  },
  {
    "episode": 194,
    "avg_reward_per_step": 48.46271503304011,
    "episode_length": 390,
    "policy_loss": -818.3352355957031,
    "value_loss": 0.5392731428146362,
    "entropy": 0.8875727951526642,
    "total_loss": -818.1509915709496
  },
  {
    "episode": 195,
    "avg_reward_per_step": 27.13517342139936,
    "episode_length": 661,
    "policy_loss": -458.95286560058594,
    "value_loss": 0.520068347454071,
    "entropy": 0.8865096867084503,
    "total_loss": -458.78740112781526
  },
  {
    "episode": 196,
    "avg_reward_per_step": 91.72218164970914,
    "episode_length": 213,
    "policy_loss": -1558.7586059570312,
    "value_loss": 0.5834809839725494,
    "entropy": 0.8741599917411804,
    "total_loss": -1558.5247889697553
  },
  {
    "episode": 197,
    "avg_reward_per_step": 37.71679884722539,
    "episode_length": 489,
    "policy_loss": -639.646728515625,
    "value_loss": 0.5291824340820312,
    "entropy": 0.8733026087284088,
    "total_loss": -639.4668671250344
  },
  {
    "episode": 198,
    "avg_reward_per_step": 99.32413550771783,
    "episode_length": 198,
    "policy_loss": -1670.0371704101562,
    "value_loss": 0.5922797620296478,
    "entropy": 0.8658646941184998,
    "total_loss": -1669.791236525774
  },
  {
    "episode": 199,
    "avg_reward_per_step": 39.190160408325546,
    "episode_length": 455,
    "policy_loss": -661.2447204589844,
    "value_loss": 0.5292975008487701,
    "entropy": 0.8456039726734161,
    "total_loss": -661.053664547205
  },
  {
    "episode": 200,
    "avg_reward_per_step": 219.3256191796324,
    "episode_length": 91,
    "policy_loss": -3691.5975341796875,
    "value_loss": 0.7665614485740662,
    "entropy": 0.8744303584098816,
    "total_loss": -3691.1807448744776
  },
  {
    "episode": 201,
    "avg_reward_per_step": 107.79609461956656,
    "episode_length": 182,
    "policy_loss": -1819.829833984375,
    "value_loss": 0.601464569568634,
    "entropy": 0.8486540615558624,
    "total_loss": -1819.5678310394287
  },
  {
    "episode": 202,
    "avg_reward_per_step": 42.351209821390675,
    "episode_length": 438,
    "policy_loss": -717.0023193359375,
    "value_loss": 0.5334750711917877,
    "entropy": 0.8259324431419373,
    "total_loss": -716.7992172420024
  },
  {
    "episode": 203,
    "avg_reward_per_step": 68.80485407954859,
    "episode_length": 278,
    "policy_loss": -1162.8211669921875,
    "value_loss": 0.5583584904670715,
    "entropy": 0.7961301207542419,
    "total_loss": -1162.581260550022
  },
  {
    "episode": 204,
    "avg_reward_per_step": 41.25169684324403,
    "episode_length": 426,
    "policy_loss": -695.6786804199219,
    "value_loss": 0.5303278863430023,
    "entropy": 0.7870707511901855,
    "total_loss": -695.4631808340549
  },
  {
    "episode": 205,
    "avg_reward_per_step": 49.652268157234566,
    "episode_length": 367,
    "policy_loss": -839.6798095703125,
    "value_loss": 0.5385199189186096,
    "entropy": 0.7537394464015961,
    "total_loss": -839.4427854299545
  },
  {
    "episode": 206,
    "avg_reward_per_step": 5.908697696863819,
    "episode_length": 1637,
    "policy_loss": -101.80337905883789,
    "value_loss": 0.5020687282085419,
    "entropy": 0.7337806224822998,
    "total_loss": -101.59482257962227
  },
  {
    "episode": 207,
    "avg_reward_per_step": 112.57092434808996,
    "episode_length": 173,
    "policy_loss": -1898.650146484375,
    "value_loss": 0.6067219376564026,
    "entropy": 0.7616520822048187,
    "total_loss": -1898.3480853796004
  },
  {
    "episode": 208,
    "avg_reward_per_step": 8.475782222076724,
    "episode_length": 1265,
    "policy_loss": -144.7023468017578,
    "value_loss": 0.5033459067344666,
    "entropy": 0.7101882696151733,
    "total_loss": -144.48307620286943
  },
  {
    "episode": 209,
    "avg_reward_per_step": 5.688139500161934,
    "episode_length": 1678,
    "policy_loss": -97.46293640136719,
    "value_loss": 0.5019514560699463,
    "entropy": 0.7034292817115784,
    "total_loss": -97.24235665798187
  },
  {
    "episode": 210,
    "avg_reward_per_step": 7.991351003728413,
    "episode_length": 1339,
    "policy_loss": -136.68218994140625,
    "value_loss": 0.5032124817371368,
    "entropy": 0.7091581523418427,
    "total_loss": -136.46264072060586
  },
  {
    "episode": 211,
    "avg_reward_per_step": 26.46036919785451,
    "episode_length": 576,
    "policy_loss": -447.1632080078125,
    "value_loss": 0.5161978900432587,
    "entropy": 0.6941632032394409,
    "total_loss": -446.924675399065
  },
  {
    "episode": 212,
    "avg_reward_per_step": -7.519939673581949,
    "episode_length": 3000,
    "policy_loss": 124.99341583251953,
    "value_loss": 1.8003749251365662,
    "entropy": 0.6859115362167358,
    "total_loss": 126.5194261431694
  },
  {
    "episode": 213,
    "avg_reward_per_step": -8.106592356301979,
    "episode_length": 3000,
    "policy_loss": 134.9338836669922,
    "value_loss": 1.947488784790039,
    "entropy": 0.6944116055965424,
    "total_loss": 136.6036078095436
  },
  {
    "episode": 214,
    "avg_reward_per_step": 14.926876332597033,
    "episode_length": 876,
    "policy_loss": -253.64031982421875,
    "value_loss": 0.5076405704021454,
    "entropy": 0.7029593586921692,
    "total_loss": -253.41386299729348
  },
  {
    "episode": 215,
    "avg_reward_per_step": 66.27515253466797,
    "episode_length": 275,
    "policy_loss": -1120.1610107421875,
    "value_loss": 0.5528963506221771,
    "entropy": 0.69573774933815,
    "total_loss": -1119.8864094913006
  },
  {
    "episode": 216,
    "avg_reward_per_step": 62.44955029765991,
    "episode_length": 283,
    "policy_loss": -1055.5964965820312,
    "value_loss": 0.5478025078773499,
    "entropy": 0.6934836208820343,
    "total_loss": -1055.3260875225067
  },
  {
    "episode": 217,
    "avg_reward_per_step": 1.5810535791903795,
    "episode_length": 1909,
    "policy_loss": -28.771526336669922,
    "value_loss": 0.4999520480632782,
    "entropy": 0.6985591351985931,
    "total_loss": -28.55099794268608
  },
  {
    "episode": 218,
    "avg_reward_per_step": 18.105781459158873,
    "episode_length": 792,
    "policy_loss": -307.1825256347656,
    "value_loss": 0.5103662610054016,
    "entropy": 0.7366116642951965,
    "total_loss": -306.9668040394783
  },
  {
    "episode": 219,
    "avg_reward_per_step": 1.586668074575872,
    "episode_length": 2052,
    "policy_loss": -29.062807083129883,
    "value_loss": 0.5000004470348358,
    "entropy": 0.7283549308776855,
    "total_loss": -28.85414860844612
  },
  {
    "episode": 220,
    "avg_reward_per_step": -6.66765625530039,
    "episode_length": 3000,
    "policy_loss": 110.20476531982422,
    "value_loss": 1.6446915864944458,
    "entropy": 0.7400186359882355,
    "total_loss": 111.55344945192337
  },
  {
    "episode": 221,
    "avg_reward_per_step": 16.211505226802323,
    "episode_length": 814,
    "policy_loss": -275.01853942871094,
    "value_loss": 0.508344292640686,
    "entropy": 0.7407677471637726,
    "total_loss": -274.80650223493575
  },
  {
    "episode": 222,
    "avg_reward_per_step": 78.03320180515178,
    "episode_length": 241,
    "policy_loss": -1317.8506469726562,
    "value_loss": 0.5656993687152863,
    "entropy": 0.7741910815238953,
    "total_loss": -1317.5946240365506
  },
  {
    "episode": 223,
    "avg_reward_per_step": 39.48021222674003,
    "episode_length": 419,
    "policy_loss": -668.5613403320312,
    "value_loss": 0.5271236002445221,
    "entropy": 0.765474796295166,
    "total_loss": -668.3404066503048
  },
  {
    "episode": 224,
    "avg_reward_per_step": 7.265580469118138,
    "episode_length": 1480,
    "policy_loss": -124.44796752929688,
    "value_loss": 0.5029698014259338,
    "entropy": 0.7810732424259186,
    "total_loss": -124.2574270248413
  },
  {
    "episode": 225,
    "avg_reward_per_step": 20.29368862246272,
    "episode_length": 787,
    "policy_loss": -343.84410095214844,
    "value_loss": 0.513161301612854,
    "entropy": 0.7842746078968048,
    "total_loss": -343.6446494936943
  },
  {
    "episode": 226,
    "avg_reward_per_step": 184.81281962493586,
    "episode_length": 107,
    "policy_loss": -3129.7579345703125,
    "value_loss": 0.7052569091320038,
    "entropy": 0.8034929037094116,
    "total_loss": -3129.374074822664
  },
  {
    "episode": 227,
    "avg_reward_per_step": 50.205352103939354,
    "episode_length": 353,
    "policy_loss": -847.1388549804688,
    "value_loss": 0.537854790687561,
    "entropy": 0.7576545178890228,
    "total_loss": -846.9040619969368
  },
  {
    "episode": 228,
    "avg_reward_per_step": 44.282180277359565,
    "episode_length": 394,
    "policy_loss": -746.3399658203125,
    "value_loss": 0.5324665606021881,
    "entropy": 0.7294756472110748,
    "total_loss": -746.0992895185948
  },
  {
    "episode": 229,
    "avg_reward_per_step": 86.44716146910024,
    "episode_length": 222,
    "policy_loss": -1460.6951904296875,
    "value_loss": 0.5761508047580719,
    "entropy": 0.7339028418064117,
    "total_loss": -1460.412600761652
  },
  {
    "episode": 230,
    "avg_reward_per_step": 14.837453150621473,
    "episode_length": 847,
    "policy_loss": -251.75454711914062,
    "value_loss": 0.5072580277919769,
    "entropy": 0.6997963786125183,
    "total_loss": -251.52720764279366
  },
  {
    "episode": 231,
    "avg_reward_per_step": 5.652492484076876,
    "episode_length": 1389,
    "policy_loss": -97.56317520141602,
    "value_loss": 0.5015561580657959,
    "entropy": 0.6809461712837219,
    "total_loss": -97.33399751186371
  },
  {
    "episode": 232,
    "avg_reward_per_step": -9.751441480699487,
    "episode_length": 3000,
    "policy_loss": 161.9245147705078,
    "value_loss": 3.071634888648987,
    "entropy": 0.6628321707248688,
    "total_loss": 164.73101679086685
  },
  {
    "episode": 233,
    "avg_reward_per_step": 17.751672517968483,
    "episode_length": 760,
    "policy_loss": -301.4721374511719,
    "value_loss": 0.509412556886673,
    "entropy": 0.6732523441314697,
    "total_loss": -301.2320258319378
  },
  {
    "episode": 234,
    "avg_reward_per_step": -9.69816523726556,
    "episode_length": 3000,
    "policy_loss": 160.89720153808594,
    "value_loss": 3.1558321714401245,
    "entropy": 0.657963216304779,
    "total_loss": 163.78984842300414
  },
  {
    "episode": 235,
    "avg_reward_per_step": 16.55100740152527,
    "episode_length": 774,
    "policy_loss": -281.5486297607422,
    "value_loss": 0.5082516372203827,
    "entropy": 0.6580075621604919,
    "total_loss": -281.303581148386
  },
  {
    "episode": 236,
    "avg_reward_per_step": 1.392272092324152,
    "episode_length": 1916,
    "policy_loss": -26.15289306640625,
    "value_loss": 0.4999234527349472,
    "entropy": 0.6582145392894745,
    "total_loss": -25.916255429387093
  },
  {
    "episode": 237,
    "avg_reward_per_step": -9.666746057981957,
    "episode_length": 3000,
    "policy_loss": 160.09749603271484,
    "value_loss": 2.9012022018432617,
    "entropy": 0.6468702554702759,
    "total_loss": 162.73995013236998
  },
  {
    "episode": 238,
    "avg_reward_per_step": 74.2305014549208,
    "episode_length": 255,
    "policy_loss": -1253.3231811523438,
    "value_loss": 0.5625788271427155,
    "entropy": 0.7166379392147064,
    "total_loss": -1253.0472575008869
  },
  {
    "episode": 239,
    "avg_reward_per_step": 15.34345451066621,
    "episode_length": 865,
    "policy_loss": -260.5447235107422,
    "value_loss": 0.5079410076141357,
    "entropy": 0.6539105176925659,
    "total_loss": -260.29834671020507
  },
  {
    "episode": 240,
    "avg_reward_per_step": 3.7561940134692953,
    "episode_length": 1533,
    "policy_loss": -66.06014633178711,
    "value_loss": 0.5006138384342194,
    "entropy": 0.6550013720989227,
    "total_loss": -65.82153304219246
  },
  {
    "episode": 241,
    "avg_reward_per_step": 14.88562236330723,
    "episode_length": 839,
    "policy_loss": -254.01173400878906,
    "value_loss": 0.507203996181488,
    "entropy": 0.633229672908783,
    "total_loss": -253.7578218817711
  },
  {
    "episode": 242,
    "avg_reward_per_step": 58.42688747343464,
    "episode_length": 309,
    "policy_loss": -988.8988647460938,
    "value_loss": 0.5455370247364044,
    "entropy": 0.636348694562912,
    "total_loss": -988.6078671991825
  },
  {
    "episode": 243,
    "avg_reward_per_step": -0.6827905038090876,
    "episode_length": 2329,
    "policy_loss": 8.14535903930664,
    "value_loss": 0.4997953921556473,
    "entropy": 0.6478399336338043,
    "total_loss": 8.386018458008767
  },
  {
    "episode": 244,
    "avg_reward_per_step": 10.160020280022957,
    "episode_length": 1100,
    "policy_loss": -174.12860107421875,
    "value_loss": 0.5043977797031403,
    "entropy": 0.6531510949134827,
    "total_loss": -173.885463732481
  },
  {
    "episode": 245,
    "avg_reward_per_step": -9.55618786471647,
    "episode_length": 3000,
    "policy_loss": 157.77735137939453,
    "value_loss": 3.055189609527588,
    "entropy": 0.6598427593708038,
    "total_loss": 160.5686038851738
  },
  {
    "episode": 246,
    "avg_reward_per_step": 37.30831603115757,
    "episode_length": 442,
    "policy_loss": -631.8526000976562,
    "value_loss": 0.5254844129085541,
    "entropy": 0.6857605278491974,
    "total_loss": -631.6014198958874
  },
  {
    "episode": 247,
    "avg_reward_per_step": 51.074594865001735,
    "episode_length": 353,
    "policy_loss": -863.9169311523438,
    "value_loss": 0.5392645597457886,
    "entropy": 0.6942920982837677,
    "total_loss": -863.6553834319114
  },
  {
    "episode": 248,
    "avg_reward_per_step": 53.16827687778077,
    "episode_length": 339,
    "policy_loss": -900.1610107421875,
    "value_loss": 0.5416362881660461,
    "entropy": 0.7013332843780518,
    "total_loss": -899.8999077677727
  },
  {
    "episode": 249,
    "avg_reward_per_step": 33.59351609238123,
    "episode_length": 474,
    "policy_loss": -569.9263000488281,
    "value_loss": 0.5219753980636597,
    "entropy": 0.676241397857666,
    "total_loss": -569.6748212099076
  },
  {
    "episode": 250,
    "avg_reward_per_step": 0.4084472749023137,
    "episode_length": 2279,
    "policy_loss": -9.963797569274902,
    "value_loss": 0.49982327222824097,
    "entropy": 0.6764398813247681,
    "total_loss": -9.734550249576568
  },
  {
    "episode": 251,
    "avg_reward_per_step": 21.149567334039265,
    "episode_length": 666,
    "policy_loss": -360.6949005126953,
    "value_loss": 0.5119024515151978,
    "entropy": 0.6729862987995148,
    "total_loss": -360.45219258069994
  },
  {
    "episode": 252,
    "avg_reward_per_step": 186.71938400246017,
    "episode_length": 107,
    "policy_loss": -3146.51025390625,
    "value_loss": 0.7109718024730682,
    "entropy": 0.7425825595855713,
    "total_loss": -3146.096315127611
  },
  {
    "episode": 253,
    "avg_reward_per_step": 2.0464836768816252,
    "episode_length": 1921,
    "policy_loss": -37.855857849121094,
    "value_loss": 0.5001480281352997,
    "entropy": 0.6537218987941742,
    "total_loss": -37.61719858050346
  },
  {
    "episode": 254,
    "avg_reward_per_step": -10.417195049130777,
    "episode_length": 3000,
    "policy_loss": 172.1122589111328,
    "value_loss": 2.930157423019409,
    "entropy": 0.622200071811676,
    "total_loss": 174.79353630542755
  },
  {
    "episode": 255,
    "avg_reward_per_step": 49.16341173974811,
    "episode_length": 355,
    "policy_loss": -834.0145568847656,
    "value_loss": 0.5369712710380554,
    "entropy": 0.6365807950496674,
    "total_loss": -833.7322179317474
  },
  {
    "episode": 256,
    "avg_reward_per_step": -10.943940196177383,
    "episode_length": 3000,
    "policy_loss": 180.70321655273438,
    "value_loss": 3.0507668256759644,
    "entropy": 0.6053786873817444,
    "total_loss": 183.51183190345765
  },
  {
    "episode": 257,
    "avg_reward_per_step": 3.5894484498044275,
    "episode_length": 1530,
    "policy_loss": -64.04788780212402,
    "value_loss": 0.5005742013454437,
    "entropy": 0.6300215423107147,
    "total_loss": -63.799322217702866
  },
  {
    "episode": 258,
    "avg_reward_per_step": -10.052696940334673,
    "episode_length": 3000,
    "policy_loss": 165.5662841796875,
    "value_loss": 3.1125229597091675,
    "entropy": 0.6194500923156738,
    "total_loss": 168.4310271024704
  },
  {
    "episode": 259,
    "avg_reward_per_step": -9.804307159249962,
    "episode_length": 3000,
    "policy_loss": 161.38487243652344,
    "value_loss": 2.7985833883285522,
    "entropy": 0.6298338770866394,
    "total_loss": 163.93152227401734
  },
  {
    "episode": 260,
    "avg_reward_per_step": -9.072143208005166,
    "episode_length": 3000,
    "policy_loss": 148.94920349121094,
    "value_loss": 2.878541588783264,
    "entropy": 0.6185029745101929,
    "total_loss": 151.58034389019014
  },
  {
    "episode": 261,
    "avg_reward_per_step": -10.088169469240485,
    "episode_length": 3000,
    "policy_loss": 165.82343292236328,
    "value_loss": 2.6385605335235596,
    "entropy": 0.6181318461894989,
    "total_loss": 168.21474071741105
  },
  {
    "episode": 262,
    "avg_reward_per_step": 54.513235645835735,
    "episode_length": 333,
    "policy_loss": -922.74462890625,
    "value_loss": 0.5432181656360626,
    "entropy": 0.6556940674781799,
    "total_loss": -922.4636883676052
  },
  {
    "episode": 263,
    "avg_reward_per_step": 76.27319791468355,
    "episode_length": 241,
    "policy_loss": -1294.6591796875,
    "value_loss": 0.5632221698760986,
    "entropy": 0.65446937084198,
    "total_loss": -1294.3577452659606
  },
  {
    "episode": 264,
    "avg_reward_per_step": 74.21076180923197,
    "episode_length": 247,
    "policy_loss": -1259.707763671875,
    "value_loss": 0.5605311095714569,
    "entropy": 0.6595306098461151,
    "total_loss": -1259.411044806242
  },
  {
    "episode": 265,
    "avg_reward_per_step": 12.403364022995746,
    "episode_length": 947,
    "policy_loss": -215.8305892944336,
    "value_loss": 0.5057365596294403,
    "entropy": 0.6610773205757141,
    "total_loss": -215.58928366303445
  },
  {
    "episode": 266,
    "avg_reward_per_step": 0.3795826603486361,
    "episode_length": 2461,
    "policy_loss": -10.789709568023682,
    "value_loss": 0.4998425394296646,
    "entropy": 0.6871345043182373,
    "total_loss": -10.564720830321312
  },
  {
    "episode": 267,
    "avg_reward_per_step": 11.364210806372084,
    "episode_length": 1035,
    "policy_loss": -196.4271240234375,
    "value_loss": 0.5053151249885559,
    "entropy": 0.7031558454036713,
    "total_loss": -196.2030712366104
  },
  {
    "episode": 268,
    "avg_reward_per_step": 116.11332612822167,
    "episode_length": 167,
    "policy_loss": -1966.82958984375,
    "value_loss": 0.6105959117412567,
    "entropy": 0.7609357535839081,
    "total_loss": -1966.5233682334424
  },
  {
    "episode": 269,
    "avg_reward_per_step": 94.7426150842197,
    "episode_length": 207,
    "policy_loss": -1611.576416015625,
    "value_loss": 0.5876319408416748,
    "entropy": 0.7714720964431763,
    "total_loss": -1611.2973729133605
  },
  {
    "episode": 270,
    "avg_reward_per_step": 53.98002338833083,
    "episode_length": 345,
    "policy_loss": -909.8771362304688,
    "value_loss": 0.5438684225082397,
    "entropy": 0.7860027849674225,
    "total_loss": -909.6476689219475
  },
  {
    "episode": 271,
    "avg_reward_per_step": 55.22782481038616,
    "episode_length": 345,
    "policy_loss": -934.7076721191406,
    "value_loss": 0.545890212059021,
    "entropy": 0.7811921834945679,
    "total_loss": -934.4742587804794
  },
  {
    "episode": 272,
    "avg_reward_per_step": 94.02173453918525,
    "episode_length": 207,
    "policy_loss": -1594.5263061523438,
    "value_loss": 0.5859749615192413,
    "entropy": 0.7570361495018005,
    "total_loss": -1594.2431456506251
  },
  {
    "episode": 273,
    "avg_reward_per_step": 146.4201184733186,
    "episode_length": 136,
    "policy_loss": -2476.3756103515625,
    "value_loss": 0.6520649790763855,
    "entropy": 0.7633437812328339,
    "total_loss": -2476.0288828849793
  },
  {
    "episode": 274,
    "avg_reward_per_step": 45.6523631012809,
    "episode_length": 417,
    "policy_loss": -775.5948181152344,
    "value_loss": 0.5374248325824738,
    "entropy": 0.7548830807209015,
    "total_loss": -775.3593465149403
  },
  {
    "episode": 275,
    "avg_reward_per_step": 150.90085074752943,
    "episode_length": 132,
    "policy_loss": -2550.8089599609375,
    "value_loss": 0.658306360244751,
    "entropy": 0.6927080750465393,
    "total_loss": -2550.427736830711
  },
  {
    "episode": 276,
    "avg_reward_per_step": 83.05833927392823,
    "episode_length": 239,
    "policy_loss": -1407.4232177734375,
    "value_loss": 0.5757765769958496,
    "entropy": 0.7284668982028961,
    "total_loss": -1407.1388279557227
  },
  {
    "episode": 277,
    "avg_reward_per_step": 40.96058476950148,
    "episode_length": 477,
    "policy_loss": -694.4981994628906,
    "value_loss": 0.5344480574131012,
    "entropy": 0.7008695602416992,
    "total_loss": -694.2440992295742
  },
  {
    "episode": 278,
    "avg_reward_per_step": 60.83013311847075,
    "episode_length": 321,
    "policy_loss": -1032.9723510742188,
    "value_loss": 0.552490234375,
    "entropy": 0.7264241278171539,
    "total_loss": -1032.7104304909706
  },
  {
    "episode": 279,
    "avg_reward_per_step": 21.307178044398423,
    "episode_length": 865,
    "policy_loss": -363.6142578125,
    "value_loss": 0.5164474844932556,
    "entropy": 0.7675940096378326,
    "total_loss": -363.40484793186187
  },
  {
    "episode": 280,
    "avg_reward_per_step": 26.10236297006915,
    "episode_length": 696,
    "policy_loss": -444.6481628417969,
    "value_loss": 0.5198526084423065,
    "entropy": 0.7797202467918396,
    "total_loss": -444.4401983320713
  },
  {
    "episode": 281,
    "avg_reward_per_step": 37.489661437469486,
    "episode_length": 502,
    "policy_loss": -637.9904174804688,
    "value_loss": 0.5300265550613403,
    "entropy": 0.8132213950157166,
    "total_loss": -637.7856794834137
  },
  {
    "episode": 282,
    "avg_reward_per_step": 78.15938296100104,
    "episode_length": 252,
    "policy_loss": -1333.8285522460938,
    "value_loss": 0.570278137922287,
    "entropy": 0.7782272696495056,
    "total_loss": -1333.5695650160312
  },
  {
    "episode": 283,
    "avg_reward_per_step": 16.077841490803657,
    "episode_length": 1028,
    "policy_loss": -274.76092529296875,
    "value_loss": 0.5109860599040985,
    "entropy": 0.8222722113132477,
    "total_loss": -274.5788481175899
  },
  {
    "episode": 284,
    "avg_reward_per_step": 25.972243415850215,
    "episode_length": 667,
    "policy_loss": -442.0157928466797,
    "value_loss": 0.5187301337718964,
    "entropy": 0.8348730802536011,
    "total_loss": -441.8310119450092
  },
  {
    "episode": 285,
    "avg_reward_per_step": 76.49129904183663,
    "episode_length": 255,
    "policy_loss": -1292.0816650390625,
    "value_loss": 0.568075954914093,
    "entropy": 0.8383554816246033,
    "total_loss": -1291.8489312767983
  },
  {
    "episode": 286,
    "avg_reward_per_step": 35.810285056143044,
    "episode_length": 500,
    "policy_loss": -608.718994140625,
    "value_loss": 0.5271342694759369,
    "entropy": 0.8202852010726929,
    "total_loss": -608.5199739515781
  },
  {
    "episode": 287,
    "avg_reward_per_step": 42.50204597322913,
    "episode_length": 435,
    "policy_loss": -722.5531921386719,
    "value_loss": 0.5334327518939972,
    "entropy": 0.8533858358860016,
    "total_loss": -722.3611137211323
  },
  {
    "episode": 288,
    "avg_reward_per_step": 126.3698754099461,
    "episode_length": 154,
    "policy_loss": -2180.1502685546875,
    "value_loss": 0.6237152814865112,
    "entropy": 0.865063488483429,
    "total_loss": -2179.8725786685945
  },
  {
    "episode": 289,
    "avg_reward_per_step": 2.5114450871918432,
    "episode_length": 2089,
    "policy_loss": -48.396385192871094,
    "value_loss": 0.5004425942897797,
    "entropy": 0.7942362725734711,
    "total_loss": -48.2136371076107
  },
  {
    "episode": 290,
    "avg_reward_per_step": 83.21018116342857,
    "episode_length": 228,
    "policy_loss": -1404.5675048828125,
    "value_loss": 0.5718381404876709,
    "entropy": 0.8324865102767944,
    "total_loss": -1404.3286613464356
  },
  {
    "episode": 291,
    "avg_reward_per_step": -0.6400012529271999,
    "episode_length": 2406,
    "policy_loss": 7.408615350723267,
    "value_loss": 0.4998215138912201,
    "entropy": 0.7341696918010712,
    "total_loss": 7.614768987894058
  },
  {
    "episode": 292,
    "avg_reward_per_step": 71.83239253782433,
    "episode_length": 259,
    "policy_loss": -1218.5758056640625,
    "value_loss": 0.5596307516098022,
    "entropy": 0.814155250787735,
    "total_loss": -1218.3418370127679
  },
  {
    "episode": 293,
    "avg_reward_per_step": -0.9378144270794738,
    "episode_length": 2198,
    "policy_loss": 11.178626537322998,
    "value_loss": 0.4998089224100113,
    "entropy": 0.6884865462779999,
    "total_loss": 11.40304084122181
  },
  {
    "episode": 294,
    "avg_reward_per_step": 193.25976244085274,
    "episode_length": 103,
    "policy_loss": -3267.6982421875,
    "value_loss": 0.72205451130867,
    "entropy": 0.8508002161979675,
    "total_loss": -3267.3165077626704
  },
  {
    "episode": 295,
    "avg_reward_per_step": 12.845401009131251,
    "episode_length": 947,
    "policy_loss": -220.8971710205078,
    "value_loss": 0.50627002120018,
    "entropy": 0.6852024793624878,
    "total_loss": -220.66498199105263
  },
  {
    "episode": 296,
    "avg_reward_per_step": 14.538018799464979,
    "episode_length": 789,
    "policy_loss": -250.43732452392578,
    "value_loss": 0.5065876841545105,
    "entropy": 0.5750555694103241,
    "total_loss": -250.1607590675354
  },
  {
    "episode": 297,
    "avg_reward_per_step": 0.09034104643521561,
    "episode_length": 1800,
    "policy_loss": -6.6333746910095215,
    "value_loss": 0.499765008687973,
    "entropy": 0.566466897726059,
    "total_loss": -6.360196441411972
  },
  {
    "episode": 298,
    "avg_reward_per_step": -12.801759883759539,
    "episode_length": 3000,
    "policy_loss": 210.67479705810547,
    "value_loss": 3.5178959369659424,
    "entropy": 0.5439599752426147,
    "total_loss": 213.97510900497437
  },
  {
    "episode": 299,
    "avg_reward_per_step": -12.725264652941437,
    "episode_length": 3000,
    "policy_loss": 209.12698364257812,
    "value_loss": 3.7688586711883545,
    "entropy": 0.5474540889263153,
    "total_loss": 212.67686067819596
  },
  {
    "episode": 300,
    "avg_reward_per_step": -13.646469310124411,
    "episode_length": 3000,
    "policy_loss": 224.39129638671875,
    "value_loss": 3.822638154029846,
    "entropy": 0.4842931479215622,
    "total_loss": 228.02021728157996
  }
]