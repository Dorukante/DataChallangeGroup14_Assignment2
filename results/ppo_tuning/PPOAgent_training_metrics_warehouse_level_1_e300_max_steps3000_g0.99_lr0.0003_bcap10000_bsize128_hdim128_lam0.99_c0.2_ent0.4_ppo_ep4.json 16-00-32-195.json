[
  {
    "episode": 1,
    "avg_reward_per_step": 16.94870686097302,
    "episode_length": 937,
    "policy_loss": -888.3250885009766,
    "value_loss": 0.5360643714666367,
    "entropy": 1.3833343088626862,
    "total_loss": -888.342357853055
  },
  {
    "episode": 2,
    "avg_reward_per_step": 4.2925003571880955,
    "episode_length": 2336,
    "policy_loss": -223.72870635986328,
    "value_loss": 0.5053589344024658,
    "entropy": 1.3724211156368256,
    "total_loss": -223.77231587171553
  },
  {
    "episode": 3,
    "avg_reward_per_step": 10.74573438383896,
    "episode_length": 1408,
    "policy_loss": -559.0918884277344,
    "value_loss": 0.5212956070899963,
    "entropy": 1.3508090674877167,
    "total_loss": -559.1109164476395
  },
  {
    "episode": 4,
    "avg_reward_per_step": 21.11951023793435,
    "episode_length": 815,
    "policy_loss": -1071.1474609375,
    "value_loss": 0.5502737164497375,
    "entropy": 1.3017803728580475,
    "total_loss": -1071.1178993701935
  },
  {
    "episode": 5,
    "avg_reward_per_step": 46.630143385187786,
    "episode_length": 390,
    "policy_loss": -2365.38720703125,
    "value_loss": 0.6373061090707779,
    "entropy": 1.2793273627758026,
    "total_loss": -2365.2616318672895
  },
  {
    "episode": 6,
    "avg_reward_per_step": 27.60395080248109,
    "episode_length": 634,
    "policy_loss": -1397.4454345703125,
    "value_loss": 0.5697078555822372,
    "entropy": 1.245443731546402,
    "total_loss": -1397.373904207349
  },
  {
    "episode": 7,
    "avg_reward_per_step": 138.8934582976999,
    "episode_length": 143,
    "policy_loss": -6674.7574462890625,
    "value_loss": 1.3003111779689789,
    "entropy": 1.2429592907428741,
    "total_loss": -6673.954318827391
  },
  {
    "episode": 8,
    "avg_reward_per_step": 41.526848208254606,
    "episode_length": 433,
    "policy_loss": -2112.0447387695312,
    "value_loss": 0.6179286688566208,
    "entropy": 1.2172976434230804,
    "total_loss": -2111.9137291580437
  },
  {
    "episode": 9,
    "avg_reward_per_step": 37.66399609533425,
    "episode_length": 485,
    "policy_loss": -1906.5162048339844,
    "value_loss": 0.6065921038389206,
    "entropy": 1.1652942597866058,
    "total_loss": -1906.3757304340602
  },
  {
    "episode": 10,
    "avg_reward_per_step": 34.26221412351065,
    "episode_length": 539,
    "policy_loss": -1740.0357971191406,
    "value_loss": 0.594153642654419,
    "entropy": 1.1330591142177582,
    "total_loss": -1739.8948671221733
  },
  {
    "episode": 11,
    "avg_reward_per_step": 58.23415546347639,
    "episode_length": 328,
    "policy_loss": -2958.5518798828125,
    "value_loss": 0.696270689368248,
    "entropy": 1.1413120329380035,
    "total_loss": -2958.3121340066195
  },
  {
    "episode": 12,
    "avg_reward_per_step": 34.58368780654424,
    "episode_length": 542,
    "policy_loss": -1742.8396606445312,
    "value_loss": 0.5989736765623093,
    "entropy": 1.141790896654129,
    "total_loss": -1742.6974033266306
  },
  {
    "episode": 13,
    "avg_reward_per_step": 65.0343953635042,
    "episode_length": 298,
    "policy_loss": -3286.0926513671875,
    "value_loss": 0.7307492196559906,
    "entropy": 1.1543478965759277,
    "total_loss": -3285.823641306162
  },
  {
    "episode": 14,
    "avg_reward_per_step": -2.9400047524870647,
    "episode_length": 3000,
    "policy_loss": 147.86244583129883,
    "value_loss": 2.9351720213890076,
    "entropy": 1.1099533438682556,
    "total_loss": 150.35363651514052
  },
  {
    "episode": 15,
    "avg_reward_per_step": 19.54768061950257,
    "episode_length": 918,
    "policy_loss": -989.8469390869141,
    "value_loss": 0.5476832985877991,
    "entropy": 1.1167387068271637,
    "total_loss": -989.7459512710572
  },
  {
    "episode": 16,
    "avg_reward_per_step": 16.29977974657771,
    "episode_length": 1116,
    "policy_loss": -821.1506958007812,
    "value_loss": 0.5396229475736618,
    "entropy": 1.0852051377296448,
    "total_loss": -821.0451549082994
  },
  {
    "episode": 17,
    "avg_reward_per_step": 9.172709193924305,
    "episode_length": 1752,
    "policy_loss": -461.83895111083984,
    "value_loss": 0.518804207444191,
    "entropy": 1.0649985074996948,
    "total_loss": -461.74614630639553
  },
  {
    "episode": 18,
    "avg_reward_per_step": 26.486321325918137,
    "episode_length": 705,
    "policy_loss": -1339.8027954101562,
    "value_loss": 0.5701611340045929,
    "entropy": 1.0783085227012634,
    "total_loss": -1339.6639576852322
  },
  {
    "episode": 19,
    "avg_reward_per_step": 84.38872740722998,
    "episode_length": 236,
    "policy_loss": -4242.4063720703125,
    "value_loss": 0.8472900390625,
    "entropy": 1.055124968290329,
    "total_loss": -4241.981132018566
  },
  {
    "episode": 20,
    "avg_reward_per_step": 33.59555992677337,
    "episode_length": 571,
    "policy_loss": -1693.1492309570312,
    "value_loss": 0.5953087657690048,
    "entropy": 1.1174698770046234,
    "total_loss": -1693.0009101420642
  },
  {
    "episode": 21,
    "avg_reward_per_step": 7.1407211278092975,
    "episode_length": 2087,
    "policy_loss": -361.15049743652344,
    "value_loss": 0.5135315507650375,
    "entropy": 1.1298664510250092,
    "total_loss": -361.0889124661684
  },
  {
    "episode": 22,
    "avg_reward_per_step": 18.330712351727325,
    "episode_length": 998,
    "policy_loss": -929.8354644775391,
    "value_loss": 0.5456103831529617,
    "entropy": 1.150246798992157,
    "total_loss": -929.749952813983
  },
  {
    "episode": 23,
    "avg_reward_per_step": 26.81876514781538,
    "episode_length": 681,
    "policy_loss": -1357.4154357910156,
    "value_loss": 0.5688979774713516,
    "entropy": 1.1974863111972809,
    "total_loss": -1357.325532338023
  },
  {
    "episode": 24,
    "avg_reward_per_step": 82.1661059680581,
    "episode_length": 239,
    "policy_loss": -4129.5570068359375,
    "value_loss": 0.8284853845834732,
    "entropy": 1.1718223989009857,
    "total_loss": -4129.197250410914
  },
  {
    "episode": 25,
    "avg_reward_per_step": 17.96110352889435,
    "episode_length": 1003,
    "policy_loss": -910.5488739013672,
    "value_loss": 0.5435317754745483,
    "entropy": 1.16021528840065,
    "total_loss": -910.4694282412529
  },
  {
    "episode": 26,
    "avg_reward_per_step": 48.06075809417572,
    "episode_length": 403,
    "policy_loss": -2421.3995361328125,
    "value_loss": 0.6509569436311722,
    "entropy": 1.1254818737506866,
    "total_loss": -2421.1987719386816
  },
  {
    "episode": 27,
    "avg_reward_per_step": 73.50449118829755,
    "episode_length": 269,
    "policy_loss": -3702.2904663085938,
    "value_loss": 0.7797408401966095,
    "entropy": 1.0851939022541046,
    "total_loss": -3701.944803029299
  },
  {
    "episode": 28,
    "avg_reward_per_step": 5.858283607304784,
    "episode_length": 2596,
    "policy_loss": -295.0093536376953,
    "value_loss": 0.5111838579177856,
    "entropy": 1.110013097524643,
    "total_loss": -294.9421750187874
  },
  {
    "episode": 29,
    "avg_reward_per_step": 144.2931221222085,
    "episode_length": 138,
    "policy_loss": -6893.1722412109375,
    "value_loss": 1.361526608467102,
    "entropy": 1.126840502023697,
    "total_loss": -6892.26145080328
  },
  {
    "episode": 30,
    "avg_reward_per_step": 37.03351550020696,
    "episode_length": 512,
    "policy_loss": -1880.9934692382812,
    "value_loss": 0.6068586260080338,
    "entropy": 1.188978672027588,
    "total_loss": -1880.8622020810842
  },
  {
    "episode": 31,
    "avg_reward_per_step": 8.416716186915314,
    "episode_length": 1698,
    "policy_loss": -424.33924865722656,
    "value_loss": 0.5152336955070496,
    "entropy": 1.2299122512340546,
    "total_loss": -424.3159798622131
  },
  {
    "episode": 32,
    "avg_reward_per_step": 10.369505683217065,
    "episode_length": 1440,
    "policy_loss": -524.7247314453125,
    "value_loss": 0.5198751538991928,
    "entropy": 1.2344274520874023,
    "total_loss": -524.6986272722482
  },
  {
    "episode": 33,
    "avg_reward_per_step": 75.92429859822012,
    "episode_length": 256,
    "policy_loss": -3827.7998046875,
    "value_loss": 0.7905725687742233,
    "entropy": 1.257583886384964,
    "total_loss": -3827.5122656732797
  },
  {
    "episode": 34,
    "avg_reward_per_step": 3.7246810306471345,
    "episode_length": 2280,
    "policy_loss": -189.380859375,
    "value_loss": 0.5038000494241714,
    "entropy": 1.2655438482761383,
    "total_loss": -189.38327686488628
  },
  {
    "episode": 35,
    "avg_reward_per_step": 39.30951707043632,
    "episode_length": 471,
    "policy_loss": -1989.7994689941406,
    "value_loss": 0.6111553311347961,
    "entropy": 1.2813768684864044,
    "total_loss": -1989.7008644104003
  },
  {
    "episode": 36,
    "avg_reward_per_step": 29.305288210601624,
    "episode_length": 616,
    "policy_loss": -1491.3021850585938,
    "value_loss": 0.5763773620128632,
    "entropy": 1.258011668920517,
    "total_loss": -1491.2290123641492
  },
  {
    "episode": 37,
    "avg_reward_per_step": 112.86794798254833,
    "episode_length": 176,
    "policy_loss": -5549.2498779296875,
    "value_loss": 1.058046281337738,
    "entropy": 1.245334655046463,
    "total_loss": -5548.689965510368
  },
  {
    "episode": 38,
    "avg_reward_per_step": 17.28394748777219,
    "episode_length": 968,
    "policy_loss": -876.8027954101562,
    "value_loss": 0.5388296842575073,
    "entropy": 1.2467142641544342,
    "total_loss": -876.7626514315605
  },
  {
    "episode": 39,
    "avg_reward_per_step": 55.437717754663744,
    "episode_length": 345,
    "policy_loss": -2798.6663818359375,
    "value_loss": 0.6825558543205261,
    "entropy": 1.2099971175193787,
    "total_loss": -2798.4678248286245
  },
  {
    "episode": 40,
    "avg_reward_per_step": 80.42778789552356,
    "episode_length": 243,
    "policy_loss": -4039.5952758789062,
    "value_loss": 0.8168477267026901,
    "entropy": 1.1929135918617249,
    "total_loss": -4039.255593588948
  },
  {
    "episode": 41,
    "avg_reward_per_step": 51.26329528066058,
    "episode_length": 379,
    "policy_loss": -2598.9113159179688,
    "value_loss": 0.6658366918563843,
    "entropy": 1.153255134820938,
    "total_loss": -2598.7067812800406
  },
  {
    "episode": 42,
    "avg_reward_per_step": 18.82419636406255,
    "episode_length": 929,
    "policy_loss": -953.4843597412109,
    "value_loss": 0.5446998327970505,
    "entropy": 1.1769587993621826,
    "total_loss": -953.4104434281587
  },
  {
    "episode": 43,
    "avg_reward_per_step": 4.149835077382657,
    "episode_length": 2844,
    "policy_loss": -210.07582092285156,
    "value_loss": 0.5060531944036484,
    "entropy": 1.187660813331604,
    "total_loss": -210.04483205378057
  },
  {
    "episode": 44,
    "avg_reward_per_step": 7.950340372640186,
    "episode_length": 1791,
    "policy_loss": -401.0429000854492,
    "value_loss": 0.5142178386449814,
    "entropy": 1.186309665441513,
    "total_loss": -401.0032061129808
  },
  {
    "episode": 45,
    "avg_reward_per_step": 145.86612103507173,
    "episode_length": 135,
    "policy_loss": -6999.4317626953125,
    "value_loss": 1.3618232905864716,
    "entropy": 1.1734870672225952,
    "total_loss": -6998.539334231615
  },
  {
    "episode": 46,
    "avg_reward_per_step": 9.750257919009256,
    "episode_length": 1314,
    "policy_loss": -496.55943298339844,
    "value_loss": 0.5162651538848877,
    "entropy": 1.1048900485038757,
    "total_loss": -496.4851238489151
  },
  {
    "episode": 47,
    "avg_reward_per_step": 6.991821829793757,
    "episode_length": 1378,
    "policy_loss": -361.41094970703125,
    "value_loss": 0.5086528211832047,
    "entropy": 1.0228218734264374,
    "total_loss": -361.3114256352186
  },
  {
    "episode": 48,
    "avg_reward_per_step": -8.197669776474036,
    "episode_length": 3000,
    "policy_loss": 407.42992401123047,
    "value_loss": 5.739480018615723,
    "entropy": 0.9661874622106552,
    "total_loss": 412.7829290449619
  },
  {
    "episode": 49,
    "avg_reward_per_step": 16.258200535910934,
    "episode_length": 826,
    "policy_loss": -831.6908569335938,
    "value_loss": 0.5298472046852112,
    "entropy": 0.9337586313486099,
    "total_loss": -831.534513181448
  },
  {
    "episode": 50,
    "avg_reward_per_step": 8.74649163695828,
    "episode_length": 1155,
    "policy_loss": -451.7987747192383,
    "value_loss": 0.5116298347711563,
    "entropy": 0.9355640411376953,
    "total_loss": -451.6613705009222
  },
  {
    "episode": 51,
    "avg_reward_per_step": 10.22171899399828,
    "episode_length": 1079,
    "policy_loss": -530.5183715820312,
    "value_loss": 0.5149582773447037,
    "entropy": 0.9422543346881866,
    "total_loss": -530.3803150385618
  },
  {
    "episode": 52,
    "avg_reward_per_step": 20.23396899804046,
    "episode_length": 766,
    "policy_loss": -1034.5820922851562,
    "value_loss": 0.5428382903337479,
    "entropy": 0.9632590562105179,
    "total_loss": -1034.4245576173066
  },
  {
    "episode": 53,
    "avg_reward_per_step": 1.8250625555033932,
    "episode_length": 1914,
    "policy_loss": -99.90922546386719,
    "value_loss": 0.500661626458168,
    "entropy": 0.976245790719986,
    "total_loss": -99.79906215369701
  },
  {
    "episode": 54,
    "avg_reward_per_step": 1.5780211377168682,
    "episode_length": 2142,
    "policy_loss": -83.04259300231934,
    "value_loss": 0.5004692077636719,
    "entropy": 0.9736860990524292,
    "total_loss": -82.93159823417663
  },
  {
    "episode": 55,
    "avg_reward_per_step": 9.728564702457117,
    "episode_length": 1142,
    "policy_loss": -498.70337677001953,
    "value_loss": 0.5138229727745056,
    "entropy": 0.9852849096059799,
    "total_loss": -498.58366776108744
  },
  {
    "episode": 56,
    "avg_reward_per_step": -8.810809042427117,
    "episode_length": 3000,
    "policy_loss": 437.9986877441406,
    "value_loss": 6.167136788368225,
    "entropy": 1.0056814849376678,
    "total_loss": 443.7635519385338
  },
  {
    "episode": 57,
    "avg_reward_per_step": 41.55656602633157,
    "episode_length": 408,
    "policy_loss": -2117.4526977539062,
    "value_loss": 0.6118284463882446,
    "entropy": 1.0126492977142334,
    "total_loss": -2117.245929026604
  },
  {
    "episode": 58,
    "avg_reward_per_step": 8.3801909066792,
    "episode_length": 1172,
    "policy_loss": -435.14058685302734,
    "value_loss": 0.510546550154686,
    "entropy": 1.0339028537273407,
    "total_loss": -435.0436014443636
  },
  {
    "episode": 59,
    "avg_reward_per_step": 36.458775518596966,
    "episode_length": 468,
    "policy_loss": -1869.1245422363281,
    "value_loss": 0.5938956439495087,
    "entropy": 1.0533053278923035,
    "total_loss": -1868.9519687235356
  },
  {
    "episode": 60,
    "avg_reward_per_step": 59.889657200095115,
    "episode_length": 316,
    "policy_loss": -3052.1774291992188,
    "value_loss": 0.7047159373760223,
    "entropy": 1.0550165176391602,
    "total_loss": -3051.8947198688984
  },
  {
    "episode": 61,
    "avg_reward_per_step": 23.323605666577542,
    "episode_length": 694,
    "policy_loss": -1199.9050598144531,
    "value_loss": 0.5522564351558685,
    "entropy": 1.1123386919498444,
    "total_loss": -1199.797738856077
  },
  {
    "episode": 62,
    "avg_reward_per_step": 106.3931220475164,
    "episode_length": 182,
    "policy_loss": -5275.9017333984375,
    "value_loss": 0.9933403134346008,
    "entropy": 1.1405357420444489,
    "total_loss": -5275.364607381821
  },
  {
    "episode": 63,
    "avg_reward_per_step": 37.62226669464236,
    "episode_length": 494,
    "policy_loss": -1899.8267822265625,
    "value_loss": 0.6082069426774979,
    "entropy": 1.1376289129257202,
    "total_loss": -1899.6736268490554
  },
  {
    "episode": 64,
    "avg_reward_per_step": 70.79331170874038,
    "episode_length": 271,
    "policy_loss": -3567.4540405273438,
    "value_loss": 0.7600999474525452,
    "entropy": 1.1586714684963226,
    "total_loss": -3567.1574091672896
  },
  {
    "episode": 65,
    "avg_reward_per_step": 61.55335124374701,
    "episode_length": 304,
    "policy_loss": -3124.9618530273438,
    "value_loss": 0.7074486315250397,
    "entropy": 1.1502510905265808,
    "total_loss": -3124.7145048320294
  },
  {
    "episode": 66,
    "avg_reward_per_step": 17.81422142209546,
    "episode_length": 930,
    "policy_loss": -905.7488555908203,
    "value_loss": 0.540558785200119,
    "entropy": 1.1727263629436493,
    "total_loss": -905.6773873507976
  },
  {
    "episode": 67,
    "avg_reward_per_step": 27.346903224217318,
    "episode_length": 631,
    "policy_loss": -1386.4373474121094,
    "value_loss": 0.5673597455024719,
    "entropy": 1.1377290487289429,
    "total_loss": -1386.3250792860986
  },
  {
    "episode": 68,
    "avg_reward_per_step": 9.092111751523982,
    "episode_length": 1536,
    "policy_loss": -464.21128845214844,
    "value_loss": 0.5166070312261581,
    "entropy": 1.1419378221035004,
    "total_loss": -464.1514565497637
  },
  {
    "episode": 69,
    "avg_reward_per_step": 63.952272677052356,
    "episode_length": 296,
    "policy_loss": -3243.2857666015625,
    "value_loss": 0.7198131680488586,
    "entropy": 1.1253301799297333,
    "total_loss": -3243.0160855054855
  },
  {
    "episode": 70,
    "avg_reward_per_step": 58.54888501198694,
    "episode_length": 329,
    "policy_loss": -2968.3954467773438,
    "value_loss": 0.7005293965339661,
    "entropy": 1.1326642632484436,
    "total_loss": -2968.147983086109
  },
  {
    "episode": 71,
    "avg_reward_per_step": 65.95092979955365,
    "episode_length": 286,
    "policy_loss": -3348.6347045898438,
    "value_loss": 0.7296533435583115,
    "entropy": 1.161485642194748,
    "total_loss": -3348.369645503163
  },
  {
    "episode": 72,
    "avg_reward_per_step": 38.68487702183547,
    "episode_length": 487,
    "policy_loss": -1969.1260375976562,
    "value_loss": 0.6113565266132355,
    "entropy": 1.0928109884262085,
    "total_loss": -1968.9518054664136
  },
  {
    "episode": 73,
    "avg_reward_per_step": 5.539998251895489,
    "episode_length": 1803,
    "policy_loss": -282.3809051513672,
    "value_loss": 0.5069549828767776,
    "entropy": 1.1191688776016235,
    "total_loss": -282.32161771953105
  },
  {
    "episode": 74,
    "avg_reward_per_step": -6.2315368551696935,
    "episode_length": 3000,
    "policy_loss": 310.76847076416016,
    "value_loss": 3.6149933338165283,
    "entropy": 1.080570638179779,
    "total_loss": 313.95123584270476
  },
  {
    "episode": 75,
    "avg_reward_per_step": 11.231597118668933,
    "episode_length": 1064,
    "policy_loss": -577.7572174072266,
    "value_loss": 0.5179167240858078,
    "entropy": 1.0722984671592712,
    "total_loss": -577.6682200700045
  },
  {
    "episode": 76,
    "avg_reward_per_step": 42.606001430081655,
    "episode_length": 407,
    "policy_loss": -2179.42431640625,
    "value_loss": 0.6162444651126862,
    "entropy": 1.0479735136032104,
    "total_loss": -2179.2272613465784
  },
  {
    "episode": 77,
    "avg_reward_per_step": 3.3672159134617683,
    "episode_length": 1988,
    "policy_loss": -178.4163818359375,
    "value_loss": 0.502777025103569,
    "entropy": 1.0707955062389374,
    "total_loss": -178.3419230133295
  },
  {
    "episode": 78,
    "avg_reward_per_step": 10.666411804021275,
    "episode_length": 1113,
    "policy_loss": -548.09130859375,
    "value_loss": 0.5166512429714203,
    "entropy": 1.0902960300445557,
    "total_loss": -548.0107757627964
  },
  {
    "episode": 79,
    "avg_reward_per_step": 154.33863519390997,
    "episode_length": 126,
    "policy_loss": -7244.2227783203125,
    "value_loss": 1.436798632144928,
    "entropy": 1.0663219392299652,
    "total_loss": -7243.212508463859
  },
  {
    "episode": 80,
    "avg_reward_per_step": 18.543629102852787,
    "episode_length": 851,
    "policy_loss": -947.9996490478516,
    "value_loss": 0.5402060300111771,
    "entropy": 1.0938734710216522,
    "total_loss": -947.8969924062491
  },
  {
    "episode": 81,
    "avg_reward_per_step": 95.06345794261453,
    "episode_length": 208,
    "policy_loss": -4751.5435791015625,
    "value_loss": 0.9152111113071442,
    "entropy": 1.0516020953655243,
    "total_loss": -4751.049008828401
  },
  {
    "episode": 82,
    "avg_reward_per_step": 66.42677588758525,
    "episode_length": 295,
    "policy_loss": -3367.7244873046875,
    "value_loss": 0.7399066835641861,
    "entropy": 1.032079815864563,
    "total_loss": -3367.3974125474692
  },
  {
    "episode": 83,
    "avg_reward_per_step": 20.79356438660072,
    "episode_length": 857,
    "policy_loss": -1061.2929992675781,
    "value_loss": 0.5512060075998306,
    "entropy": 0.9871627688407898,
    "total_loss": -1061.1366583675147
  },
  {
    "episode": 84,
    "avg_reward_per_step": 129.0929493528457,
    "episode_length": 154,
    "policy_loss": -6215.002685546875,
    "value_loss": 1.2053248286247253,
    "entropy": 0.9432622790336609,
    "total_loss": -6214.174665629864
  },
  {
    "episode": 85,
    "avg_reward_per_step": 17.382533958204146,
    "episode_length": 1055,
    "policy_loss": -883.9436645507812,
    "value_loss": 0.5433940142393112,
    "entropy": 0.8896566778421402,
    "total_loss": -883.7561332076788
  },
  {
    "episode": 86,
    "avg_reward_per_step": 8.815972830885695,
    "episode_length": 1826,
    "policy_loss": -447.0357360839844,
    "value_loss": 0.5183183401823044,
    "entropy": 0.8957209587097168,
    "total_loss": -446.875706127286
  },
  {
    "episode": 87,
    "avg_reward_per_step": 20.275058058627746,
    "episode_length": 912,
    "policy_loss": -1026.8088684082031,
    "value_loss": 0.5515543073415756,
    "entropy": 0.8605621308088303,
    "total_loss": -1026.6015389531851
  },
  {
    "episode": 88,
    "avg_reward_per_step": 30.374947641427493,
    "episode_length": 627,
    "policy_loss": -1534.2117614746094,
    "value_loss": 0.5843647420406342,
    "entropy": 0.8197851330041885,
    "total_loss": -1533.9553107857705
  },
  {
    "episode": 89,
    "avg_reward_per_step": -1.8382469142902222,
    "episode_length": 3000,
    "policy_loss": 90.0701675415039,
    "value_loss": 2.716168999671936,
    "entropy": 0.8033470660448074,
    "total_loss": 92.46499771475791
  },
  {
    "episode": 90,
    "avg_reward_per_step": 13.70863662767856,
    "episode_length": 1349,
    "policy_loss": -691.5323944091797,
    "value_loss": 0.5333872586488724,
    "entropy": 0.7629890739917755,
    "total_loss": -691.3042027801275
  },
  {
    "episode": 91,
    "avg_reward_per_step": 11.04785234625694,
    "episode_length": 1565,
    "policy_loss": -558.4161529541016,
    "value_loss": 0.5250726640224457,
    "entropy": 0.7774344235658646,
    "total_loss": -558.2020540595055
  },
  {
    "episode": 92,
    "avg_reward_per_step": 14.323121655111676,
    "episode_length": 1258,
    "policy_loss": -729.3271789550781,
    "value_loss": 0.5347593873739243,
    "entropy": 0.787102222442627,
    "total_loss": -729.1072604566813
  },
  {
    "episode": 93,
    "avg_reward_per_step": 14.392117288894994,
    "episode_length": 1260,
    "policy_loss": -730.1837921142578,
    "value_loss": 0.5348425805568695,
    "entropy": 0.817836806178093,
    "total_loss": -729.9760842561722
  },
  {
    "episode": 94,
    "avg_reward_per_step": 134.71773341134468,
    "episode_length": 148,
    "policy_loss": -6505.38525390625,
    "value_loss": 1.258969485759735,
    "entropy": 0.8853768855333328,
    "total_loss": -6504.480435174703
  },
  {
    "episode": 95,
    "avg_reward_per_step": 13.8379759725359,
    "episode_length": 1159,
    "policy_loss": -701.5542907714844,
    "value_loss": 0.5289986282587051,
    "entropy": 0.9158473312854767,
    "total_loss": -701.3916310757398
  },
  {
    "episode": 96,
    "avg_reward_per_step": 33.98427637883494,
    "episode_length": 539,
    "policy_loss": -1725.7242431640625,
    "value_loss": 0.5934476256370544,
    "entropy": 0.906138077378273,
    "total_loss": -1725.4932507693768
  },
  {
    "episode": 97,
    "avg_reward_per_step": 56.55112626086668,
    "episode_length": 341,
    "policy_loss": -2857.4194946289062,
    "value_loss": 0.6865531653165817,
    "entropy": 0.8995524048805237,
    "total_loss": -2857.092762425542
  },
  {
    "episode": 98,
    "avg_reward_per_step": 64.60000441668652,
    "episode_length": 295,
    "policy_loss": -3260.1353149414062,
    "value_loss": 0.7229331731796265,
    "entropy": 0.898883730173111,
    "total_loss": -3259.771935260296
  },
  {
    "episode": 99,
    "avg_reward_per_step": 24.913182564336452,
    "episode_length": 712,
    "policy_loss": -1262.4279479980469,
    "value_loss": 0.5617807805538177,
    "entropy": 0.8998769521713257,
    "total_loss": -1262.2261179983616
  },
  {
    "episode": 100,
    "avg_reward_per_step": 38.29706902754891,
    "episode_length": 477,
    "policy_loss": -1950.3067626953125,
    "value_loss": 0.605564758181572,
    "entropy": 0.9075164049863815,
    "total_loss": -1950.0642044991255
  },
  {
    "episode": 101,
    "avg_reward_per_step": 56.08090320596989,
    "episode_length": 338,
    "policy_loss": -2840.0949096679688,
    "value_loss": 0.6830113381147385,
    "entropy": 0.9036179780960083,
    "total_loss": -2839.7733455210923
  },
  {
    "episode": 102,
    "avg_reward_per_step": 47.07220236572075,
    "episode_length": 406,
    "policy_loss": -2379.8499145507812,
    "value_loss": 0.6463491767644882,
    "entropy": 0.9187869876623154,
    "total_loss": -2379.5710801690816
  },
  {
    "episode": 103,
    "avg_reward_per_step": 172.12998424915287,
    "episode_length": 115,
    "policy_loss": -7888.7391357421875,
    "value_loss": 1.6640031933784485,
    "entropy": 0.9277988076210022,
    "total_loss": -7887.446252071857
  },
  {
    "episode": 104,
    "avg_reward_per_step": 53.13309742714192,
    "episode_length": 363,
    "policy_loss": -2699.726318359375,
    "value_loss": 0.6742195934057236,
    "entropy": 0.9363459795713425,
    "total_loss": -2699.426637157798
  },
  {
    "episode": 105,
    "avg_reward_per_step": 58.465950689160195,
    "episode_length": 331,
    "policy_loss": -2948.9222412109375,
    "value_loss": 0.6976950764656067,
    "entropy": 0.9223088473081589,
    "total_loss": -2948.5934696733952
  },
  {
    "episode": 106,
    "avg_reward_per_step": 35.07456255471473,
    "episode_length": 527,
    "policy_loss": -1767.5782470703125,
    "value_loss": 0.5980319678783417,
    "entropy": 0.9582830369472504,
    "total_loss": -1767.363528317213
  },
  {
    "episode": 107,
    "avg_reward_per_step": 10.52557501917979,
    "episode_length": 1506,
    "policy_loss": -535.1356506347656,
    "value_loss": 0.5218534618616104,
    "entropy": 0.9569290280342102,
    "total_loss": -534.9965687841177
  },
  {
    "episode": 108,
    "avg_reward_per_step": 42.11213466118542,
    "episode_length": 454,
    "policy_loss": -2143.64111328125,
    "value_loss": 0.6258333921432495,
    "entropy": 0.9413919895887375,
    "total_loss": -2143.391836684942
  },
  {
    "episode": 109,
    "avg_reward_per_step": 135.23882525907837,
    "episode_length": 147,
    "policy_loss": -6508.302734375,
    "value_loss": 1.2655717730522156,
    "entropy": 0.9667474627494812,
    "total_loss": -6507.423861587047
  },
  {
    "episode": 110,
    "avg_reward_per_step": 60.38351213138707,
    "episode_length": 325,
    "policy_loss": -3067.7120971679688,
    "value_loss": 0.7095316499471664,
    "entropy": 0.9589550942182541,
    "total_loss": -3067.3861475557087
  },
  {
    "episode": 111,
    "avg_reward_per_step": 93.86327427524245,
    "episode_length": 210,
    "policy_loss": -4673.3348388671875,
    "value_loss": 0.9082706272602081,
    "entropy": 0.9797583371400833,
    "total_loss": -4672.818471574783
  },
  {
    "episode": 112,
    "avg_reward_per_step": 222.09527034981494,
    "episode_length": 90,
    "policy_loss": -9470.64990234375,
    "value_loss": 2.4128223061561584,
    "entropy": 0.957788273692131,
    "total_loss": -9468.62019534707
  },
  {
    "episode": 113,
    "avg_reward_per_step": 18.373266411739678,
    "episode_length": 980,
    "policy_loss": -928.4788665771484,
    "value_loss": 0.5449709743261337,
    "entropy": 0.9138848185539246,
    "total_loss": -928.2994495302439
  },
  {
    "episode": 114,
    "avg_reward_per_step": 51.39817036809255,
    "episode_length": 382,
    "policy_loss": -2606.208740234375,
    "value_loss": 0.6674273908138275,
    "entropy": 0.8233360797166824,
    "total_loss": -2605.870647275448
  },
  {
    "episode": 115,
    "avg_reward_per_step": 46.44742995936247,
    "episode_length": 416,
    "policy_loss": -2372.5797119140625,
    "value_loss": 0.6447011828422546,
    "entropy": 0.8700534254312515,
    "total_loss": -2372.2830321013926
  },
  {
    "episode": 116,
    "avg_reward_per_step": 108.93832242281222,
    "episode_length": 182,
    "policy_loss": -5365.09375,
    "value_loss": 1.0249283611774445,
    "entropy": 0.8149986416101456,
    "total_loss": -5364.394821095467
  },
  {
    "episode": 117,
    "avg_reward_per_step": 99.975947788134,
    "episode_length": 196,
    "policy_loss": -5016.392333984375,
    "value_loss": 0.951929047703743,
    "entropy": 0.8494001477956772,
    "total_loss": -5015.780164995789
  },
  {
    "episode": 118,
    "avg_reward_per_step": 97.45852933779166,
    "episode_length": 202,
    "policy_loss": -4826.545654296875,
    "value_loss": 0.934356078505516,
    "entropy": 0.9138126373291016,
    "total_loss": -4825.976823273301
  },
  {
    "episode": 119,
    "avg_reward_per_step": 128.35143494517382,
    "episode_length": 154,
    "policy_loss": -6203.0953369140625,
    "value_loss": 1.1947860717773438,
    "entropy": 0.9261004626750946,
    "total_loss": -6202.270991027355
  },
  {
    "episode": 120,
    "avg_reward_per_step": 26.152757222738177,
    "episode_length": 679,
    "policy_loss": -1328.336669921875,
    "value_loss": 0.5662829875946045,
    "entropy": 0.9538659006357193,
    "total_loss": -1328.1519332945347
  },
  {
    "episode": 121,
    "avg_reward_per_step": 69.71860970500154,
    "episode_length": 278,
    "policy_loss": -3514.9092407226562,
    "value_loss": 0.7567794173955917,
    "entropy": 0.9701227396726608,
    "total_loss": -3514.5405104011297
  },
  {
    "episode": 122,
    "avg_reward_per_step": 106.82185111852183,
    "episode_length": 183,
    "policy_loss": -5291.686279296875,
    "value_loss": 1.0018035471439362,
    "entropy": 0.9569956809282303,
    "total_loss": -5291.0672740221025
  },
  {
    "episode": 123,
    "avg_reward_per_step": 72.84172287870084,
    "episode_length": 268,
    "policy_loss": -3660.6639404296875,
    "value_loss": 0.7733814120292664,
    "entropy": 0.9477172046899796,
    "total_loss": -3660.269645899534
  },
  {
    "episode": 124,
    "avg_reward_per_step": 37.807868440609724,
    "episode_length": 482,
    "policy_loss": -1912.8312377929688,
    "value_loss": 0.6047945320606232,
    "entropy": 0.9293394386768341,
    "total_loss": -1912.598179036379
  },
  {
    "episode": 125,
    "avg_reward_per_step": 27.23092051728784,
    "episode_length": 637,
    "policy_loss": -1387.1249084472656,
    "value_loss": 0.5681620389223099,
    "entropy": 0.8950745314359665,
    "total_loss": -1386.9147762209177
  },
  {
    "episode": 126,
    "avg_reward_per_step": 74.58063452888423,
    "episode_length": 259,
    "policy_loss": -3764.4664306640625,
    "value_loss": 0.7827249765396118,
    "entropy": 0.8943219780921936,
    "total_loss": -3764.0414344787596
  },
  {
    "episode": 127,
    "avg_reward_per_step": 29.403807134062145,
    "episode_length": 603,
    "policy_loss": -1503.8733215332031,
    "value_loss": 0.5767092108726501,
    "entropy": 0.8686073422431946,
    "total_loss": -1503.6440552592278
  },
  {
    "episode": 128,
    "avg_reward_per_step": 67.0002146471706,
    "episode_length": 291,
    "policy_loss": -3368.3351440429688,
    "value_loss": 0.7411247491836548,
    "entropy": 0.8350886851549149,
    "total_loss": -3367.9280547678472
  },
  {
    "episode": 129,
    "avg_reward_per_step": 157.76570487568213,
    "episode_length": 126,
    "policy_loss": -7366.2017822265625,
    "value_loss": 1.5074892044067383,
    "entropy": 0.8193567395210266,
    "total_loss": -7365.022035717964
  },
  {
    "episode": 130,
    "avg_reward_per_step": 33.44074547226384,
    "episode_length": 534,
    "policy_loss": -1702.5838623046875,
    "value_loss": 0.5881602615118027,
    "entropy": 0.7785381525754929,
    "total_loss": -1702.3071173042058
  },
  {
    "episode": 131,
    "avg_reward_per_step": 42.25097862158495,
    "episode_length": 428,
    "policy_loss": -2155.0604858398438,
    "value_loss": 0.6207980513572693,
    "entropy": 0.7795036435127258,
    "total_loss": -2154.7514892458917
  },
  {
    "episode": 132,
    "avg_reward_per_step": 114.00172223320169,
    "episode_length": 173,
    "policy_loss": -5628.271728515625,
    "value_loss": 1.0628048181533813,
    "entropy": 0.7627511471509933,
    "total_loss": -5627.514024156332
  },
  {
    "episode": 133,
    "avg_reward_per_step": 218.41505830524287,
    "episode_length": 91,
    "policy_loss": -9286.510009765625,
    "value_loss": 2.329358220100403,
    "entropy": 0.746193066239357,
    "total_loss": -9284.47912877202
  },
  {
    "episode": 134,
    "avg_reward_per_step": 240.59775303380837,
    "episode_length": 83,
    "policy_loss": -9970.814697265625,
    "value_loss": 2.715084671974182,
    "entropy": 0.716448187828064,
    "total_loss": -9968.386191868782
  },
  {
    "episode": 135,
    "avg_reward_per_step": 75.47045644167895,
    "episode_length": 259,
    "policy_loss": -3781.15380859375,
    "value_loss": 0.7892012894153595,
    "entropy": 0.7221847921609879,
    "total_loss": -3780.653481221199
  },
  {
    "episode": 136,
    "avg_reward_per_step": 23.536011181893574,
    "episode_length": 675,
    "policy_loss": -1203.7117919921875,
    "value_loss": 0.5520930737257004,
    "entropy": 0.6438695043325424,
    "total_loss": -1203.4172467201947
  },
  {
    "episode": 137,
    "avg_reward_per_step": 38.81045108583677,
    "episode_length": 466,
    "policy_loss": -1978.0577392578125,
    "value_loss": 0.6075595021247864,
    "entropy": 0.6549094021320343,
    "total_loss": -1977.7121435165404
  },
  {
    "episode": 138,
    "avg_reward_per_step": 170.75628430856955,
    "episode_length": 117,
    "policy_loss": -7830.4832763671875,
    "value_loss": 1.66862952709198,
    "entropy": 0.6331781446933746,
    "total_loss": -7829.067918097973
  },
  {
    "episode": 139,
    "avg_reward_per_step": 5.5969986662391396,
    "episode_length": 1869,
    "policy_loss": -287.14447021484375,
    "value_loss": 0.5072781443595886,
    "entropy": 0.6170971393585205,
    "total_loss": -286.8840309262276
  },
  {
    "episode": 140,
    "avg_reward_per_step": 102.30780508096059,
    "episode_length": 192,
    "policy_loss": -5064.4564208984375,
    "value_loss": 0.973165437579155,
    "entropy": 0.5980091094970703,
    "total_loss": -5063.722459104657
  },
  {
    "episode": 141,
    "avg_reward_per_step": 19.74690269094122,
    "episode_length": 771,
    "policy_loss": -1007.9498596191406,
    "value_loss": 0.5409507304430008,
    "entropy": 0.5622919052839279,
    "total_loss": -1007.6338256508112
  },
  {
    "episode": 142,
    "avg_reward_per_step": 151.01179764280886,
    "episode_length": 132,
    "policy_loss": -7108.0780029296875,
    "value_loss": 1.4322715401649475,
    "entropy": 0.5859099477529526,
    "total_loss": -7106.880095368624
  },
  {
    "episode": 143,
    "avg_reward_per_step": 30.14593203847891,
    "episode_length": 558,
    "policy_loss": -1555.4537353515625,
    "value_loss": 0.5745847225189209,
    "entropy": 0.5892770439386368,
    "total_loss": -1555.114861446619
  },
  {
    "episode": 144,
    "avg_reward_per_step": 89.98124711575076,
    "episode_length": 215,
    "policy_loss": -4500.4749755859375,
    "value_loss": 0.8710286170244217,
    "entropy": 0.5637732446193695,
    "total_loss": -4499.829456266761
  },
  {
    "episode": 145,
    "avg_reward_per_step": 67.86657845197445,
    "episode_length": 286,
    "policy_loss": -3429.5979614257812,
    "value_loss": 0.7452109009027481,
    "entropy": 0.5722086727619171,
    "total_loss": -3429.0816339939834
  },
  {
    "episode": 146,
    "avg_reward_per_step": 107.659228462693,
    "episode_length": 184,
    "policy_loss": -5309.624267578125,
    "value_loss": 1.0154292285442352,
    "entropy": 0.5518435686826706,
    "total_loss": -5308.829575777054
  },
  {
    "episode": 147,
    "avg_reward_per_step": 117.8394028286766,
    "episode_length": 169,
    "policy_loss": -5783.62353515625,
    "value_loss": 1.101532757282257,
    "entropy": 0.5372872799634933,
    "total_loss": -5782.736917310953
  },
  {
    "episode": 148,
    "avg_reward_per_step": 98.0040609497763,
    "episode_length": 199,
    "policy_loss": -4896.2030029296875,
    "value_loss": 0.9340701401233673,
    "entropy": 0.5634830296039581,
    "total_loss": -4895.494326001406
  },
  {
    "episode": 149,
    "avg_reward_per_step": 80.70442969757445,
    "episode_length": 246,
    "policy_loss": -4058.4197998046875,
    "value_loss": 0.8252944350242615,
    "entropy": 0.4555335119366646,
    "total_loss": -4057.776718774438
  },
  {
    "episode": 150,
    "avg_reward_per_step": 153.7291579783822,
    "episode_length": 130,
    "policy_loss": -7188.3924560546875,
    "value_loss": 1.4654090702533722,
    "entropy": 0.49933797121047974,
    "total_loss": -7187.126782172918
  },
  {
    "episode": 151,
    "avg_reward_per_step": -1.9487841434918152,
    "episode_length": 3000,
    "policy_loss": 95.7265853881836,
    "value_loss": 1.3511877954006195,
    "entropy": 0.506462424993515,
    "total_loss": 96.87518821358681
  },
  {
    "episode": 152,
    "avg_reward_per_step": 17.177197487196526,
    "episode_length": 1082,
    "policy_loss": -867.0833587646484,
    "value_loss": 0.5430780053138733,
    "entropy": 0.4741472750902176,
    "total_loss": -866.7299396693707
  },
  {
    "episode": 153,
    "avg_reward_per_step": 48.84840524503418,
    "episode_length": 405,
    "policy_loss": -2474.417724609375,
    "value_loss": 0.6579234600067139,
    "entropy": 0.4539084732532501,
    "total_loss": -2473.9413645386694
  },
  {
    "episode": 154,
    "avg_reward_per_step": 36.1795918972279,
    "episode_length": 525,
    "policy_loss": -1823.9478454589844,
    "value_loss": 0.6034785211086273,
    "entropy": 0.5401851683855057,
    "total_loss": -1823.56044100523
  },
  {
    "episode": 155,
    "avg_reward_per_step": 98.72085445916667,
    "episode_length": 202,
    "policy_loss": -4941.7181396484375,
    "value_loss": 0.947562962770462,
    "entropy": 0.5132950246334076,
    "total_loss": -4940.975894695521
  },
  {
    "episode": 156,
    "avg_reward_per_step": 13.799940364566291,
    "episode_length": 1123,
    "policy_loss": -703.7427368164062,
    "value_loss": 0.5281669199466705,
    "entropy": 0.6004954129457474,
    "total_loss": -703.4547680616379
  },
  {
    "episode": 157,
    "avg_reward_per_step": 178.1228606236179,
    "episode_length": 112,
    "policy_loss": -8105.374755859375,
    "value_loss": 1.7619178891181946,
    "entropy": 0.5390576124191284,
    "total_loss": -8103.828461015224
  },
  {
    "episode": 158,
    "avg_reward_per_step": 118.77718225900136,
    "episode_length": 167,
    "policy_loss": -5803.0413818359375,
    "value_loss": 1.1094609498977661,
    "entropy": 0.5333141386508942,
    "total_loss": -5802.1452465415005
  },
  {
    "episode": 159,
    "avg_reward_per_step": 115.51093713794191,
    "episode_length": 172,
    "policy_loss": -5680.160400390625,
    "value_loss": 1.0804259479045868,
    "entropy": 0.5232356488704681,
    "total_loss": -5679.289268702269
  },
  {
    "episode": 160,
    "avg_reward_per_step": 94.34300246617147,
    "episode_length": 210,
    "policy_loss": -4697.66064453125,
    "value_loss": 0.9113857001066208,
    "entropy": 0.4726593866944313,
    "total_loss": -4696.938322585821
  },
  {
    "episode": 161,
    "avg_reward_per_step": 62.12948863718512,
    "episode_length": 296,
    "policy_loss": -3159.1205444335938,
    "value_loss": 0.705469936132431,
    "entropy": 0.4816545099020004,
    "total_loss": -3158.607736301422
  },
  {
    "episode": 162,
    "avg_reward_per_step": 199.62890067800626,
    "episode_length": 100,
    "policy_loss": -8778.4873046875,
    "value_loss": 2.0489695072174072,
    "entropy": 0.47682172805070877,
    "total_loss": -8776.629063871504
  },
  {
    "episode": 163,
    "avg_reward_per_step": 57.572983632415074,
    "episode_length": 313,
    "policy_loss": -2956.9324951171875,
    "value_loss": 0.676963210105896,
    "entropy": 0.4770684167742729,
    "total_loss": -2956.446359273791
  },
  {
    "episode": 164,
    "avg_reward_per_step": 161.81006198634995,
    "episode_length": 123,
    "policy_loss": -7506.3216552734375,
    "value_loss": 1.5557932555675507,
    "entropy": 0.4960531145334244,
    "total_loss": -7504.964283263684
  },
  {
    "episode": 165,
    "avg_reward_per_step": 209.4326288086455,
    "episode_length": 95,
    "policy_loss": -9069.048583984375,
    "value_loss": 2.1908047199249268,
    "entropy": 0.5347591042518616,
    "total_loss": -9067.071682906151
  },
  {
    "episode": 166,
    "avg_reward_per_step": 184.94075634866627,
    "episode_length": 108,
    "policy_loss": -8275.491455078125,
    "value_loss": 1.8555525839328766,
    "entropy": 0.49240046739578247,
    "total_loss": -8273.83286268115
  },
  {
    "episode": 167,
    "avg_reward_per_step": 55.95937481134026,
    "episode_length": 341,
    "policy_loss": -2828.072265625,
    "value_loss": 0.6816226243972778,
    "entropy": 0.5688912123441696,
    "total_loss": -2827.6181994855406
  },
  {
    "episode": 168,
    "avg_reward_per_step": 117.53998030581306,
    "episode_length": 169,
    "policy_loss": -5753.63330078125,
    "value_loss": 1.1007335484027863,
    "entropy": 0.5059363842010498,
    "total_loss": -5752.734941786528
  },
  {
    "episode": 169,
    "avg_reward_per_step": 164.028325051029,
    "episode_length": 122,
    "policy_loss": -7562.86669921875,
    "value_loss": 1.5829675197601318,
    "entropy": 0.5528195202350616,
    "total_loss": -7561.504859507084
  },
  {
    "episode": 170,
    "avg_reward_per_step": 39.38526705941303,
    "episode_length": 450,
    "policy_loss": -2007.9878540039062,
    "value_loss": 0.6059724986553192,
    "entropy": 0.5737454295158386,
    "total_loss": -2007.6113796770574
  },
  {
    "episode": 171,
    "avg_reward_per_step": 27.732122474944674,
    "episode_length": 624,
    "policy_loss": -1399.4786987304688,
    "value_loss": 0.5680148899555206,
    "entropy": 0.5659013241529465,
    "total_loss": -1399.1370443701744
  },
  {
    "episode": 172,
    "avg_reward_per_step": 27.44551847111919,
    "episode_length": 560,
    "policy_loss": -1410.7469787597656,
    "value_loss": 0.5599090456962585,
    "entropy": 0.5547261536121368,
    "total_loss": -1410.4089601755143
  },
  {
    "episode": 173,
    "avg_reward_per_step": 119.91252154748949,
    "episode_length": 166,
    "policy_loss": -5855.033203125,
    "value_loss": 1.1208849251270294,
    "entropy": 0.4652232751250267,
    "total_loss": -5854.098407509923
  },
  {
    "episode": 174,
    "avg_reward_per_step": 47.21531303825887,
    "episode_length": 373,
    "policy_loss": -2412.6624755859375,
    "value_loss": 0.6338991075754166,
    "entropy": 0.535125270485878,
    "total_loss": -2412.2426265865565
  },
  {
    "episode": 175,
    "avg_reward_per_step": 76.53362893218,
    "episode_length": 244,
    "policy_loss": -3855.8021240234375,
    "value_loss": 0.7771956026554108,
    "entropy": 0.48808471858501434,
    "total_loss": -3855.220162308216
  },
  {
    "episode": 176,
    "avg_reward_per_step": 77.28918773808545,
    "episode_length": 257,
    "policy_loss": -3889.9730834960938,
    "value_loss": 0.8014022707939148,
    "entropy": 0.4013206660747528,
    "total_loss": -3889.33220949173
  },
  {
    "episode": 177,
    "avg_reward_per_step": 108.64291583569565,
    "episode_length": 181,
    "policy_loss": -5360.8072509765625,
    "value_loss": 1.019787847995758,
    "entropy": 0.5226099342107773,
    "total_loss": -5359.996507102251
  },
  {
    "episode": 178,
    "avg_reward_per_step": 19.35139920096935,
    "episode_length": 714,
    "policy_loss": -975.4340667724609,
    "value_loss": 0.5352084785699844,
    "entropy": 0.43491101264953613,
    "total_loss": -975.0728226989507
  },
  {
    "episode": 179,
    "avg_reward_per_step": 77.8280821021861,
    "episode_length": 254,
    "policy_loss": -3910.498779296875,
    "value_loss": 0.8034197986125946,
    "entropy": 0.34908589720726013,
    "total_loss": -3909.8349938571455
  },
  {
    "episode": 180,
    "avg_reward_per_step": 54.318142463989,
    "episode_length": 336,
    "policy_loss": -2763.0399780273438,
    "value_loss": 0.6644814312458038,
    "entropy": 0.4052494019269943,
    "total_loss": -2762.5375963568686
  },
  {
    "episode": 181,
    "avg_reward_per_step": 67.15860075442532,
    "episode_length": 276,
    "policy_loss": -3390.8613891601562,
    "value_loss": 0.726156547665596,
    "entropy": 0.4607802852988243,
    "total_loss": -3390.3195447266103
  },
  {
    "episode": 182,
    "avg_reward_per_step": -2.004772940988138,
    "episode_length": 2409,
    "policy_loss": 96.68759155273438,
    "value_loss": 0.500838115811348,
    "entropy": 0.3958457186818123,
    "total_loss": 97.03009138107299
  },
  {
    "episode": 183,
    "avg_reward_per_step": 165.99136466899287,
    "episode_length": 120,
    "policy_loss": -7671.8822021484375,
    "value_loss": 1.606618732213974,
    "entropy": 0.534122884273529,
    "total_loss": -7670.489232569933
  },
  {
    "episode": 184,
    "avg_reward_per_step": 21.350295346157502,
    "episode_length": 675,
    "policy_loss": -1102.890625,
    "value_loss": 0.5413371175527573,
    "entropy": 0.414710596203804,
    "total_loss": -1102.5151721209288
  },
  {
    "episode": 185,
    "avg_reward_per_step": 119.2782983250084,
    "episode_length": 167,
    "policy_loss": -5838.7509765625,
    "value_loss": 1.1173239350318909,
    "entropy": 0.4600994437932968,
    "total_loss": -5837.817692404986
  },
  {
    "episode": 186,
    "avg_reward_per_step": 149.7754706914588,
    "episode_length": 133,
    "policy_loss": -7116.2802734375,
    "value_loss": 1.4160066545009613,
    "entropy": 0.49507519602775574,
    "total_loss": -7115.06229686141
  },
  {
    "episode": 187,
    "avg_reward_per_step": 33.48080252503046,
    "episode_length": 541,
    "policy_loss": -1700.8087463378906,
    "value_loss": 0.5891354829072952,
    "entropy": 0.4701130613684654,
    "total_loss": -1700.4076560795306
  },
  {
    "episode": 188,
    "avg_reward_per_step": 165.10410283922874,
    "episode_length": 121,
    "policy_loss": -7661.70068359375,
    "value_loss": 1.59490168094635,
    "entropy": 0.48424016684293747,
    "total_loss": -7660.299477979541
  },
  {
    "episode": 189,
    "avg_reward_per_step": 207.98042400501618,
    "episode_length": 96,
    "policy_loss": -9031.38623046875,
    "value_loss": 2.1788495779037476,
    "entropy": 0.4957105740904808,
    "total_loss": -9029.405665120483
  },
  {
    "episode": 190,
    "avg_reward_per_step": 164.8476008294503,
    "episode_length": 121,
    "policy_loss": -7672.5693359375,
    "value_loss": 1.5886718034744263,
    "entropy": 0.44120410084724426,
    "total_loss": -7671.157145774365
  },
  {
    "episode": 191,
    "avg_reward_per_step": 114.92208926625524,
    "episode_length": 173,
    "policy_loss": -5627.52294921875,
    "value_loss": 1.0749232470989227,
    "entropy": 0.41319746524095535,
    "total_loss": -5626.6133049577475
  },
  {
    "episode": 192,
    "avg_reward_per_step": 18.866699226017282,
    "episode_length": 892,
    "policy_loss": -964.1937103271484,
    "value_loss": 0.5436452478170395,
    "entropy": 0.35377324372529984,
    "total_loss": -963.7915743768215
  },
  {
    "episode": 193,
    "avg_reward_per_step": 100.16192996990621,
    "episode_length": 198,
    "policy_loss": -4974.254638671875,
    "value_loss": 0.9546706080436707,
    "entropy": 0.44007136672735214,
    "total_loss": -4973.475996610522
  },
  {
    "episode": 194,
    "avg_reward_per_step": 103.2797675103556,
    "episode_length": 192,
    "policy_loss": -5133.70458984375,
    "value_loss": 0.9785137176513672,
    "entropy": 0.4657285138964653,
    "total_loss": -5132.912367531657
  },
  {
    "episode": 195,
    "avg_reward_per_step": 108.40699646845913,
    "episode_length": 181,
    "policy_loss": -5375.663818359375,
    "value_loss": 1.014145404100418,
    "entropy": 0.469400554895401,
    "total_loss": -5374.837433177233
  },
  {
    "episode": 196,
    "avg_reward_per_step": 75.0205605617027,
    "episode_length": 262,
    "policy_loss": -3775.934814453125,
    "value_loss": 0.7862877696752548,
    "entropy": 0.4742981716990471,
    "total_loss": -3775.3382459521295
  },
  {
    "episode": 197,
    "avg_reward_per_step": 215.03874542690403,
    "episode_length": 93,
    "policy_loss": -9261.65185546875,
    "value_loss": 2.296858251094818,
    "entropy": 0.5453648567199707,
    "total_loss": -9259.573143160344
  },
  {
    "episode": 198,
    "avg_reward_per_step": 81.78243750074591,
    "episode_length": 231,
    "policy_loss": -4119.5791015625,
    "value_loss": 0.8112994432449341,
    "entropy": 0.5595432221889496,
    "total_loss": -4118.991619408131
  },
  {
    "episode": 199,
    "avg_reward_per_step": 246.78711668258572,
    "episode_length": 81,
    "policy_loss": -10050.692138671875,
    "value_loss": 2.8218265771865845,
    "entropy": 0.6373472511768341,
    "total_loss": -10048.12525099516
  },
  {
    "episode": 200,
    "avg_reward_per_step": 131.24670616394377,
    "episode_length": 151,
    "policy_loss": -6309.377197265625,
    "value_loss": 1.221305251121521,
    "entropy": 0.6118034422397614,
    "total_loss": -6308.400613391399
  },
  {
    "episode": 201,
    "avg_reward_per_step": 54.4390191765622,
    "episode_length": 331,
    "policy_loss": -2786.2897338867188,
    "value_loss": 0.6661979258060455,
    "entropy": 0.5913217812776566,
    "total_loss": -2785.860064673424
  },
  {
    "episode": 202,
    "avg_reward_per_step": 147.5999843851837,
    "episode_length": 135,
    "policy_loss": -6961.7435302734375,
    "value_loss": 1.3985860645771027,
    "entropy": 0.5918705463409424,
    "total_loss": -6960.581692427397
  },
  {
    "episode": 203,
    "avg_reward_per_step": 38.199810527669264,
    "episode_length": 474,
    "policy_loss": -1951.1110534667969,
    "value_loss": 0.6061634123325348,
    "entropy": 0.6296429187059402,
    "total_loss": -1950.7567472219466
  },
  {
    "episode": 204,
    "avg_reward_per_step": 214.76116447104607,
    "episode_length": 93,
    "policy_loss": -9307.40771484375,
    "value_loss": 2.2816927433013916,
    "entropy": 0.6309710443019867,
    "total_loss": -9305.37841051817
  },
  {
    "episode": 205,
    "avg_reward_per_step": 96.68855066874498,
    "episode_length": 200,
    "policy_loss": -4812.1702880859375,
    "value_loss": 0.9158297777175903,
    "entropy": 0.6408851593732834,
    "total_loss": -4811.510812371969
  },
  {
    "episode": 206,
    "avg_reward_per_step": 240.72730222375515,
    "episode_length": 83,
    "policy_loss": -9922.307373046875,
    "value_loss": 2.7163073420524597,
    "entropy": 0.6298989653587341,
    "total_loss": -9919.843025290966
  },
  {
    "episode": 207,
    "avg_reward_per_step": 49.10656799881815,
    "episode_length": 367,
    "policy_loss": -2510.1064453125,
    "value_loss": 0.6449270695447922,
    "entropy": 0.5909948199987411,
    "total_loss": -2509.6979161709546
  },
  {
    "episode": 208,
    "avg_reward_per_step": -3.6676506432528506,
    "episode_length": 2953,
    "policy_loss": 182.71381378173828,
    "value_loss": 0.5043801516294479,
    "entropy": 0.5081561729311943,
    "total_loss": 183.01493146419526
  },
  {
    "episode": 209,
    "avg_reward_per_step": 14.498498568121255,
    "episode_length": 788,
    "policy_loss": -746.6111907958984,
    "value_loss": 0.5214496403932571,
    "entropy": 0.5008586049079895,
    "total_loss": -746.2900845974684
  },
  {
    "episode": 210,
    "avg_reward_per_step": 190.47612971674656,
    "episode_length": 104,
    "policy_loss": -8490.3017578125,
    "value_loss": 1.907654196023941,
    "entropy": 0.5827849805355072,
    "total_loss": -8488.62721760869
  },
  {
    "episode": 211,
    "avg_reward_per_step": 63.666748303772586,
    "episode_length": 281,
    "policy_loss": -3257.4364013671875,
    "value_loss": 0.7021434903144836,
    "entropy": 0.577832892537117,
    "total_loss": -3256.965391033888
  },
  {
    "episode": 212,
    "avg_reward_per_step": 13.753074213143469,
    "episode_length": 800,
    "policy_loss": -710.7050628662109,
    "value_loss": 0.5194366127252579,
    "entropy": 0.5019881576299667,
    "total_loss": -710.3864215165377
  },
  {
    "episode": 213,
    "avg_reward_per_step": 3.3220397414280054,
    "episode_length": 1374,
    "policy_loss": -171.9063377380371,
    "value_loss": 0.5015009194612503,
    "entropy": 0.4922805204987526,
    "total_loss": -171.60174902677537
  },
  {
    "episode": 214,
    "avg_reward_per_step": 147.0035494209421,
    "episode_length": 135,
    "policy_loss": -6976.390625,
    "value_loss": 1.380625456571579,
    "entropy": 0.58203125,
    "total_loss": -6975.242812043429
  },
  {
    "episode": 215,
    "avg_reward_per_step": 44.51177982134768,
    "episode_length": 396,
    "policy_loss": -2260.70166015625,
    "value_loss": 0.623546376824379,
    "entropy": 0.5550862550735474,
    "total_loss": -2260.300148281455
  },
  {
    "episode": 216,
    "avg_reward_per_step": 39.0626064392604,
    "episode_length": 418,
    "policy_loss": -1992.7605285644531,
    "value_loss": 0.5964979827404022,
    "entropy": 0.5000534504652023,
    "total_loss": -1992.364051961899
  },
  {
    "episode": 217,
    "avg_reward_per_step": 66.47438695186908,
    "episode_length": 274,
    "policy_loss": -3377.4415283203125,
    "value_loss": 0.7200217396020889,
    "entropy": 0.5467329025268555,
    "total_loss": -3376.9401997417212
  },
  {
    "episode": 218,
    "avg_reward_per_step": -2.378579723836306,
    "episode_length": 2393,
    "policy_loss": 118.01666641235352,
    "value_loss": 0.5013127475976944,
    "entropy": 0.4949360564351082,
    "total_loss": 118.32000473737716
  },
  {
    "episode": 219,
    "avg_reward_per_step": 26.566295148456344,
    "episode_length": 568,
    "policy_loss": -1373.5029602050781,
    "value_loss": 0.5555475503206253,
    "entropy": 0.5180789232254028,
    "total_loss": -1373.1546442240476
  },
  {
    "episode": 220,
    "avg_reward_per_step": 235.487581961995,
    "episode_length": 85,
    "policy_loss": -9765.2041015625,
    "value_loss": 2.6292829513549805,
    "entropy": 0.6481949836015701,
    "total_loss": -9762.834096604585
  },
  {
    "episode": 221,
    "avg_reward_per_step": 173.66115332757806,
    "episode_length": 115,
    "policy_loss": -7906.5732421875,
    "value_loss": 1.7030323147773743,
    "entropy": 0.6208663582801819,
    "total_loss": -7905.118556416035
  },
  {
    "episode": 222,
    "avg_reward_per_step": 91.98437436282053,
    "episode_length": 216,
    "policy_loss": -4616.5518798828125,
    "value_loss": 0.8984057903289795,
    "entropy": 0.5601018220186234,
    "total_loss": -4615.877514821291
  },
  {
    "episode": 223,
    "avg_reward_per_step": 57.75449190358933,
    "episode_length": 323,
    "policy_loss": -2956.1577758789062,
    "value_loss": 0.6859136372804642,
    "entropy": 0.5406034737825394,
    "total_loss": -2955.688103631139
  },
  {
    "episode": 224,
    "avg_reward_per_step": 104.62019489744466,
    "episode_length": 190,
    "policy_loss": -5183.05908203125,
    "value_loss": 0.9905395954847336,
    "entropy": 0.5786189883947372,
    "total_loss": -5182.299990031123
  },
  {
    "episode": 225,
    "avg_reward_per_step": 34.85316288406635,
    "episode_length": 542,
    "policy_loss": -1755.7831726074219,
    "value_loss": 0.597086563706398,
    "entropy": 0.5123489499092102,
    "total_loss": -1755.391025623679
  },
  {
    "episode": 226,
    "avg_reward_per_step": 16.945604615275688,
    "episode_length": 978,
    "policy_loss": -854.008544921875,
    "value_loss": 0.5369279086589813,
    "entropy": 0.5081686079502106,
    "total_loss": -853.6748844563961
  },
  {
    "episode": 227,
    "avg_reward_per_step": 170.65637096801797,
    "episode_length": 117,
    "policy_loss": -7863.7708740234375,
    "value_loss": 1.6696887016296387,
    "entropy": 0.48525363206863403,
    "total_loss": -7862.295286774635
  },
  {
    "episode": 228,
    "avg_reward_per_step": 62.812691077721354,
    "episode_length": 303,
    "policy_loss": -3160.46923828125,
    "value_loss": 0.7130739241838455,
    "entropy": 0.5180308073759079,
    "total_loss": -3159.9633766800166
  },
  {
    "episode": 229,
    "avg_reward_per_step": 6.827723598884387,
    "episode_length": 2087,
    "policy_loss": -340.5550308227539,
    "value_loss": 0.5119838565587997,
    "entropy": 0.4921191334724426,
    "total_loss": -340.2398946195841
  },
  {
    "episode": 230,
    "avg_reward_per_step": 19.92560043339588,
    "episode_length": 850,
    "policy_loss": -1003.9120635986328,
    "value_loss": 0.5454844087362289,
    "entropy": 0.5227490216493607,
    "total_loss": -1003.5756787985563
  },
  {
    "episode": 231,
    "avg_reward_per_step": 81.90298022073041,
    "episode_length": 243,
    "policy_loss": -4144.120178222656,
    "value_loss": 0.832045778632164,
    "entropy": 0.45373526215553284,
    "total_loss": -4143.4696265488865
  },
  {
    "episode": 232,
    "avg_reward_per_step": 35.257227763577276,
    "episode_length": 542,
    "policy_loss": -1774.5356140136719,
    "value_loss": 0.600400298833847,
    "entropy": 0.47667860239744186,
    "total_loss": -1774.125885155797
  },
  {
    "episode": 233,
    "avg_reward_per_step": 80.25066831935148,
    "episode_length": 248,
    "policy_loss": -4022.541259765625,
    "value_loss": 0.8214997500181198,
    "entropy": 0.4600430577993393,
    "total_loss": -4021.9037772387264
  },
  {
    "episode": 234,
    "avg_reward_per_step": 98.05341085496548,
    "episode_length": 203,
    "policy_loss": -4849.4161376953125,
    "value_loss": 0.9408080726861954,
    "entropy": 0.42398666590452194,
    "total_loss": -4848.6449242889885
  },
  {
    "episode": 235,
    "avg_reward_per_step": 35.63283950634862,
    "episode_length": 507,
    "policy_loss": -1799.5657348632812,
    "value_loss": 0.595238670706749,
    "entropy": 0.493195615708828,
    "total_loss": -1799.167774438858
  },
  {
    "episode": 236,
    "avg_reward_per_step": 102.69326818005463,
    "episode_length": 194,
    "policy_loss": -5071.232177734375,
    "value_loss": 0.9765027761459351,
    "entropy": 0.4280150234699249,
    "total_loss": -5070.426880967617
  },
  {
    "episode": 237,
    "avg_reward_per_step": 23.084551545519407,
    "episode_length": 699,
    "policy_loss": -1164.5437316894531,
    "value_loss": 0.5508870631456375,
    "entropy": 0.46228010207414627,
    "total_loss": -1164.1777566671371
  },
  {
    "episode": 238,
    "avg_reward_per_step": 27.682814266327657,
    "episode_length": 568,
    "policy_loss": -1406.031494140625,
    "value_loss": 0.5605581253767014,
    "entropy": 0.47363395243883133,
    "total_loss": -1405.660389596224
  },
  {
    "episode": 239,
    "avg_reward_per_step": 40.259437017750116,
    "episode_length": 432,
    "policy_loss": -2033.958740234375,
    "value_loss": 0.6051701307296753,
    "entropy": 0.46827056258916855,
    "total_loss": -2033.540878328681
  },
  {
    "episode": 240,
    "avg_reward_per_step": 93.41394268072946,
    "episode_length": 213,
    "policy_loss": -4664.89697265625,
    "value_loss": 0.9074404984712601,
    "entropy": 0.4375746548175812,
    "total_loss": -4664.164562019706
  },
  {
    "episode": 241,
    "avg_reward_per_step": 40.419674453622115,
    "episode_length": 431,
    "policy_loss": -2038.0362243652344,
    "value_loss": 0.6056796908378601,
    "entropy": 0.4295443147420883,
    "total_loss": -2037.6023624002933
  },
  {
    "episode": 242,
    "avg_reward_per_step": 96.49145016291043,
    "episode_length": 206,
    "policy_loss": -4820.4542236328125,
    "value_loss": 0.9281554818153381,
    "entropy": 0.39409489929676056,
    "total_loss": -4819.683706110716
  },
  {
    "episode": 243,
    "avg_reward_per_step": 49.02261839668474,
    "episode_length": 380,
    "policy_loss": -2468.857666015625,
    "value_loss": 0.6466483324766159,
    "entropy": 0.33902657777071,
    "total_loss": -2468.3466283142566
  },
  {
    "episode": 244,
    "avg_reward_per_step": 52.88335371412904,
    "episode_length": 376,
    "policy_loss": -2662.7960815429688,
    "value_loss": 0.674751341342926,
    "entropy": 0.29398859292268753,
    "total_loss": -2662.238925638795
  },
  {
    "episode": 245,
    "avg_reward_per_step": 197.98614664438804,
    "episode_length": 101,
    "policy_loss": -8721.494873046875,
    "value_loss": 2.0305612683296204,
    "entropy": 0.4364912360906601,
    "total_loss": -8719.638908272982
  },
  {
    "episode": 246,
    "avg_reward_per_step": 27.05794330943927,
    "episode_length": 595,
    "policy_loss": -1358.040283203125,
    "value_loss": 0.5591543763875961,
    "entropy": 0.35552606731653214,
    "total_loss": -1357.623339253664
  },
  {
    "episode": 247,
    "avg_reward_per_step": 102.69502976435557,
    "episode_length": 194,
    "policy_loss": -5066.4215087890625,
    "value_loss": 0.9746096581220627,
    "entropy": 0.37537918984889984,
    "total_loss": -5065.59705080688
  },
  {
    "episode": 248,
    "avg_reward_per_step": 66.19510626836095,
    "episode_length": 300,
    "policy_loss": -3324.56591796875,
    "value_loss": 0.7390945851802826,
    "entropy": 0.3656039237976074,
    "total_loss": -3323.973064953089
  },
  {
    "episode": 249,
    "avg_reward_per_step": 136.96245550887085,
    "episode_length": 146,
    "policy_loss": -6554.25830078125,
    "value_loss": 1.2803505659103394,
    "entropy": 0.3358188793063164,
    "total_loss": -6553.112277767063
  },
  {
    "episode": 250,
    "avg_reward_per_step": 28.733331446710793,
    "episode_length": 550,
    "policy_loss": -1449.01708984375,
    "value_loss": 0.5622159242630005,
    "entropy": 0.34366267919540405,
    "total_loss": -1448.5923389911652
  },
  {
    "episode": 251,
    "avg_reward_per_step": 128.90125311256253,
    "episode_length": 155,
    "policy_loss": -6257.101318359375,
    "value_loss": 1.2019596993923187,
    "entropy": 0.3424174264073372,
    "total_loss": -6256.036325630545
  },
  {
    "episode": 252,
    "avg_reward_per_step": 25.76890297629144,
    "episode_length": 589,
    "policy_loss": -1320.9977416992188,
    "value_loss": 0.5541129559278488,
    "entropy": 0.36033795773983,
    "total_loss": -1320.5877639263867
  },
  {
    "episode": 253,
    "avg_reward_per_step": 119.81233146314295,
    "episode_length": 167,
    "policy_loss": -5833.11279296875,
    "value_loss": 1.1169785261154175,
    "entropy": 0.2815691903233528,
    "total_loss": -5832.108442118764
  },
  {
    "episode": 254,
    "avg_reward_per_step": 116.45201398711713,
    "episode_length": 172,
    "policy_loss": -5689.847900390625,
    "value_loss": 1.0891517996788025,
    "entropy": 0.29164915531873703,
    "total_loss": -5688.875408253074
  },
  {
    "episode": 255,
    "avg_reward_per_step": 52.16060619738024,
    "episode_length": 331,
    "policy_loss": -2651.5181274414062,
    "value_loss": 0.6454062014818192,
    "entropy": 0.3768801614642143,
    "total_loss": -2651.02347330451
  },
  {
    "episode": 256,
    "avg_reward_per_step": 38.150319862376456,
    "episode_length": 427,
    "policy_loss": -1928.2491149902344,
    "value_loss": 0.59018574655056,
    "entropy": 0.32374395430088043,
    "total_loss": -1927.7884268254043
  },
  {
    "episode": 257,
    "avg_reward_per_step": 42.54011452660585,
    "episode_length": 404,
    "policy_loss": -2157.5311279296875,
    "value_loss": 0.6110651344060898,
    "entropy": 0.35721278190612793,
    "total_loss": -2157.062947908044
  },
  {
    "episode": 258,
    "avg_reward_per_step": 163.81535819293174,
    "episode_length": 122,
    "policy_loss": -7622.0081787109375,
    "value_loss": 1.5739411413669586,
    "entropy": 0.35421375930309296,
    "total_loss": -7620.575923073292
  },
  {
    "episode": 259,
    "avg_reward_per_step": 30.902173749269707,
    "episode_length": 576,
    "policy_loss": -1551.3134460449219,
    "value_loss": 0.577375516295433,
    "entropy": 0.3259848728775978,
    "total_loss": -1550.8664644777775
  },
  {
    "episode": 260,
    "avg_reward_per_step": 30.198466958121358,
    "episode_length": 531,
    "policy_loss": -1538.64306640625,
    "value_loss": 0.5686501711606979,
    "entropy": 0.3910711631178856,
    "total_loss": -1538.2308447003365
  },
  {
    "episode": 261,
    "avg_reward_per_step": 33.29398963281282,
    "episode_length": 469,
    "policy_loss": -1701.4521789550781,
    "value_loss": 0.5745329558849335,
    "entropy": 0.33392393589019775,
    "total_loss": -1701.0112155735492
  },
  {
    "episode": 262,
    "avg_reward_per_step": 70.00119288331527,
    "episode_length": 284,
    "policy_loss": -3505.1637573242188,
    "value_loss": 0.7593431770801544,
    "entropy": 0.2174026258289814,
    "total_loss": -3504.49137519747
  },
  {
    "episode": 263,
    "avg_reward_per_step": 30.02476169420518,
    "episode_length": 556,
    "policy_loss": -1511.1847534179688,
    "value_loss": 0.5693624764680862,
    "entropy": 0.3526312783360481,
    "total_loss": -1510.7564434528351
  },
  {
    "episode": 264,
    "avg_reward_per_step": 145.34588207414612,
    "episode_length": 138,
    "policy_loss": -6891.4056396484375,
    "value_loss": 1.369588315486908,
    "entropy": 0.3056136816740036,
    "total_loss": -6890.15829680562
  },
  {
    "episode": 265,
    "avg_reward_per_step": 18.75442035759017,
    "episode_length": 787,
    "policy_loss": -935.0871429443359,
    "value_loss": 0.5358553528785706,
    "entropy": 0.3642675578594208,
    "total_loss": -934.6969946146012
  },
  {
    "episode": 266,
    "avg_reward_per_step": 138.11142912912047,
    "episode_length": 144,
    "policy_loss": -6590.7095947265625,
    "value_loss": 1.2903323769569397,
    "entropy": 0.30759839713573456,
    "total_loss": -6589.5423017084595
  },
  {
    "episode": 267,
    "avg_reward_per_step": 110.77360609606288,
    "episode_length": 180,
    "policy_loss": -5433.6634521484375,
    "value_loss": 1.0404407978057861,
    "entropy": 0.26190681010484695,
    "total_loss": -5432.727774074674
  },
  {
    "episode": 268,
    "avg_reward_per_step": 34.27312853999467,
    "episode_length": 491,
    "policy_loss": -1734.48193359375,
    "value_loss": 0.5828114300966263,
    "entropy": 0.31777580827474594,
    "total_loss": -1734.0262324869632
  },
  {
    "episode": 269,
    "avg_reward_per_step": 137.68578516211963,
    "episode_length": 145,
    "policy_loss": -6551.7293701171875,
    "value_loss": 1.2835457623004913,
    "entropy": 0.3007369190454483,
    "total_loss": -6550.566119122505
  },
  {
    "episode": 270,
    "avg_reward_per_step": 85.38028269574063,
    "episode_length": 232,
    "policy_loss": -4257.230712890625,
    "value_loss": 0.8489819169044495,
    "entropy": 0.26491979509592056,
    "total_loss": -4256.487698891759
  },
  {
    "episode": 271,
    "avg_reward_per_step": 51.670991443875224,
    "episode_length": 358,
    "policy_loss": -2587.5628051757812,
    "value_loss": 0.6549130827188492,
    "entropy": 0.3021888807415962,
    "total_loss": -2587.028767645359
  },
  {
    "episode": 272,
    "avg_reward_per_step": 142.6624509232343,
    "episode_length": 140,
    "policy_loss": -6748.638427734375,
    "value_loss": 1.338543713092804,
    "entropy": 0.29224296659231186,
    "total_loss": -6747.4167812079195
  },
  {
    "episode": 273,
    "avg_reward_per_step": 39.34600555038173,
    "episode_length": 421,
    "policy_loss": -2001.7532653808594,
    "value_loss": 0.5970236361026764,
    "entropy": 0.3074549660086632,
    "total_loss": -2001.27922373116
  },
  {
    "episode": 274,
    "avg_reward_per_step": 17.958143319332468,
    "episode_length": 692,
    "policy_loss": -912.5673370361328,
    "value_loss": 0.5284572541713715,
    "entropy": 0.3084445148706436,
    "total_loss": -912.1622575879097
  },
  {
    "episode": 275,
    "avg_reward_per_step": 47.68778516605451,
    "episode_length": 372,
    "policy_loss": -2414.90478515625,
    "value_loss": 0.633276104927063,
    "entropy": 0.32681746780872345,
    "total_loss": -2414.4022360384465
  },
  {
    "episode": 276,
    "avg_reward_per_step": 114.7257909742282,
    "episode_length": 173,
    "policy_loss": -5613.8197021484375,
    "value_loss": 1.0692524313926697,
    "entropy": 0.27970004826784134,
    "total_loss": -5612.862329736352
  },
  {
    "episode": 277,
    "avg_reward_per_step": 101.76907924743308,
    "episode_length": 195,
    "policy_loss": -5009.706787109375,
    "value_loss": 0.9641046077013016,
    "entropy": 0.2588338926434517,
    "total_loss": -5008.846216058731
  },
  {
    "episode": 278,
    "avg_reward_per_step": 33.983022322463675,
    "episode_length": 477,
    "policy_loss": -1709.8443908691406,
    "value_loss": 0.5774884223937988,
    "entropy": 0.3384440019726753,
    "total_loss": -1709.402280047536
  },
  {
    "episode": 279,
    "avg_reward_per_step": 43.37937548784303,
    "episode_length": 373,
    "policy_loss": -2214.0676879882812,
    "value_loss": 0.6071260869503021,
    "entropy": 0.30232907831668854,
    "total_loss": -2213.5814935326575
  },
  {
    "episode": 280,
    "avg_reward_per_step": 181.81333947865926,
    "episode_length": 110,
    "policy_loss": -8189.0355224609375,
    "value_loss": 1.7975319623947144,
    "entropy": 0.315711110830307,
    "total_loss": -8187.3642749428745
  },
  {
    "episode": 281,
    "avg_reward_per_step": 39.98743821171901,
    "episode_length": 495,
    "policy_loss": -1997.8395080566406,
    "value_loss": 0.6189375817775726,
    "entropy": 0.13266518712043762,
    "total_loss": -1997.2736365497112
  },
  {
    "episode": 282,
    "avg_reward_per_step": 17.95292033431899,
    "episode_length": 715,
    "policy_loss": -898.5993194580078,
    "value_loss": 0.5281849652528763,
    "entropy": 0.2682268097996712,
    "total_loss": -898.1784252166748
  },
  {
    "episode": 283,
    "avg_reward_per_step": 18.066115118024843,
    "episode_length": 731,
    "policy_loss": -904.8509826660156,
    "value_loss": 0.5297493934631348,
    "entropy": 0.2711821123957634,
    "total_loss": -904.4297061175108
  },
  {
    "episode": 284,
    "avg_reward_per_step": 105.89144098270839,
    "episode_length": 188,
    "policy_loss": -5224.5201416015625,
    "value_loss": 0.9975530654191971,
    "entropy": 0.21398387849330902,
    "total_loss": -5223.608182087541
  },
  {
    "episode": 285,
    "avg_reward_per_step": 263.3303034884512,
    "episode_length": 76,
    "policy_loss": -10459.958251953125,
    "value_loss": 3.1325334310531616,
    "entropy": 0.3370482251048088,
    "total_loss": -10456.960537812114
  },
  {
    "episode": 286,
    "avg_reward_per_step": 186.9877525353976,
    "episode_length": 107,
    "policy_loss": -8314.264892578125,
    "value_loss": 1.874050498008728,
    "entropy": 0.24443621188402176,
    "total_loss": -8312.48861656487
  },
  {
    "episode": 287,
    "avg_reward_per_step": 33.14867598957599,
    "episode_length": 514,
    "policy_loss": -1666.9757995605469,
    "value_loss": 0.5799529254436493,
    "entropy": 0.23685651645064354,
    "total_loss": -1666.4905892416834
  },
  {
    "episode": 288,
    "avg_reward_per_step": 111.34520052580388,
    "episode_length": 179,
    "policy_loss": -5442.32958984375,
    "value_loss": 1.0408748388290405,
    "entropy": 0.22439076378941536,
    "total_loss": -5441.378471310437
  },
  {
    "episode": 289,
    "avg_reward_per_step": 212.90456728455717,
    "episode_length": 94,
    "policy_loss": -9143.29296875,
    "value_loss": 2.249107241630554,
    "entropy": 0.2845587432384491,
    "total_loss": -9141.157685005664
  },
  {
    "episode": 290,
    "avg_reward_per_step": 109.03682936676574,
    "episode_length": 183,
    "policy_loss": -5338.1893310546875,
    "value_loss": 1.0237473249435425,
    "entropy": 0.18446754291653633,
    "total_loss": -5337.239370746911
  },
  {
    "episode": 291,
    "avg_reward_per_step": 224.85272023312854,
    "episode_length": 89,
    "policy_loss": -9477.367431640625,
    "value_loss": 2.447387933731079,
    "entropy": 0.281105674803257,
    "total_loss": -9475.032485976815
  },
  {
    "episode": 292,
    "avg_reward_per_step": 23.29605100673021,
    "episode_length": 553,
    "policy_loss": -1179.3302307128906,
    "value_loss": 0.5391045212745667,
    "entropy": 0.20660119876265526,
    "total_loss": -1178.873766671121
  },
  {
    "episode": 293,
    "avg_reward_per_step": 186.79789253155695,
    "episode_length": 107,
    "policy_loss": -8308.93896484375,
    "value_loss": 1.8679095208644867,
    "entropy": 0.21983083337545395,
    "total_loss": -8307.158987656236
  },
  {
    "episode": 294,
    "avg_reward_per_step": 270.28949211186625,
    "episode_length": 74,
    "policy_loss": -10570.66796875,
    "value_loss": 3.255881190299988,
    "entropy": 0.27756737917661667,
    "total_loss": -10567.52311451137
  },
  {
    "episode": 295,
    "avg_reward_per_step": 192.3254083219435,
    "episode_length": 104,
    "policy_loss": -8505.5966796875,
    "value_loss": 1.9430599212646484,
    "entropy": 0.19825899600982666,
    "total_loss": -8503.73292336464
  },
  {
    "episode": 296,
    "avg_reward_per_step": 192.58182580141641,
    "episode_length": 104,
    "policy_loss": -8459.75,
    "value_loss": 1.9508832693099976,
    "entropy": 0.21363640949130058,
    "total_loss": -8457.884571294486
  },
  {
    "episode": 297,
    "avg_reward_per_step": 170.60822860597457,
    "episode_length": 117,
    "policy_loss": -7765.3245849609375,
    "value_loss": 1.652973473072052,
    "entropy": 0.23450633883476257,
    "total_loss": -7763.765414023399
  },
  {
    "episode": 298,
    "avg_reward_per_step": 133.98121078789566,
    "episode_length": 149,
    "policy_loss": -6405.781494140625,
    "value_loss": 1.2440996170043945,
    "entropy": 0.16622761636972427,
    "total_loss": -6404.603885570168
  },
  {
    "episode": 299,
    "avg_reward_per_step": 16.156890162189598,
    "episode_length": 711,
    "policy_loss": -797.4190673828125,
    "value_loss": 0.5218909382820129,
    "entropy": 0.205902848392725,
    "total_loss": -796.9795375838876
  },
  {
    "episode": 300,
    "avg_reward_per_step": 194.7651539855382,
    "episode_length": 103,
    "policy_loss": -8538.548095703125,
    "value_loss": 1.9819273054599762,
    "entropy": 0.15545666217803955,
    "total_loss": -8536.628351062536
  }
]