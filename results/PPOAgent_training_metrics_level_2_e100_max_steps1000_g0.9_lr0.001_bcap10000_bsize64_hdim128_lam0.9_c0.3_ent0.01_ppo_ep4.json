[
  {
    "episode": 1,
    "avg_reward_per_step": -0.5072448011971925,
    "episode_length": 1000,
    "policy_loss": -0.006674173075706058,
    "value_loss": 17.51584482192993,
    "entropy": 1.3483639657497406,
    "total_loss": 8.737764598231763
  },
  {
    "episode": 2,
    "avg_reward_per_step": -0.5573779990038549,
    "episode_length": 1000,
    "policy_loss": -0.007943612182511828,
    "value_loss": 9.519428968429565,
    "entropy": 1.3225174844264984,
    "total_loss": 4.738545697188006
  },
  {
    "episode": 3,
    "avg_reward_per_step": -0.42280555661239616,
    "episode_length": 1000,
    "policy_loss": -0.00522069142479431,
    "value_loss": 12.30707859992981,
    "entropy": 1.2841288447380066,
    "total_loss": 6.135477320092731
  },
  {
    "episode": 4,
    "avg_reward_per_step": -0.5008481891268537,
    "episode_length": 1000,
    "policy_loss": -0.003362073931842957,
    "value_loss": 7.171213984489441,
    "entropy": 1.2362812459468842,
    "total_loss": 3.5698821058534085
  },
  {
    "episode": 5,
    "avg_reward_per_step": -0.13576865583773526,
    "episode_length": 646,
    "policy_loss": -0.005657993302818909,
    "value_loss": 63.135769844055176,
    "entropy": 1.1911919713020325,
    "total_loss": 31.550315009011747
  },
  {
    "episode": 6,
    "avg_reward_per_step": -0.4835699525806926,
    "episode_length": 1000,
    "policy_loss": -0.002972676427569265,
    "value_loss": 8.63595175743103,
    "entropy": 1.1194047629833221,
    "total_loss": 4.303809154658112
  },
  {
    "episode": 7,
    "avg_reward_per_step": 0.08860160273511795,
    "episode_length": 407,
    "policy_loss": -0.005441266834691039,
    "value_loss": 99.90812873840332,
    "entropy": 1.0482647120952606,
    "total_loss": 49.938140455246014
  },
  {
    "episode": 8,
    "avg_reward_per_step": 0.9149899815750294,
    "episode_length": 165,
    "policy_loss": -0.010690996306948364,
    "value_loss": 265.6785659790039,
    "entropy": 0.9433829337358475,
    "total_loss": 132.81915816385765
  },
  {
    "episode": 9,
    "avg_reward_per_step": 1.1776243501874406,
    "episode_length": 146,
    "policy_loss": -0.012895248032953166,
    "value_loss": 263.3629837036133,
    "entropy": 0.8052511215209961,
    "total_loss": 131.6605440925585
  },
  {
    "episode": 10,
    "avg_reward_per_step": -0.3026819707989765,
    "episode_length": 849,
    "policy_loss": 0.00011466837288809373,
    "value_loss": 53.43740272521973,
    "entropy": 0.8302663564682007,
    "total_loss": 26.71051336741807
  },
  {
    "episode": 11,
    "avg_reward_per_step": -0.4866309327753472,
    "episode_length": 1000,
    "policy_loss": -0.011686043525114265,
    "value_loss": 14.349643468856812,
    "entropy": 0.8102401196956635,
    "total_loss": 7.155033289706335
  },
  {
    "episode": 12,
    "avg_reward_per_step": -0.29660832775315726,
    "episode_length": 964,
    "policy_loss": -0.011069066866003452,
    "value_loss": 45.95123291015625,
    "entropy": 0.7922712564468384,
    "total_loss": 22.956624675647653
  },
  {
    "episode": 13,
    "avg_reward_per_step": -0.1231485789903394,
    "episode_length": 586,
    "policy_loss": -0.0034741880954243243,
    "value_loss": 71.35062217712402,
    "entropy": 0.7815125584602356,
    "total_loss": 35.66402177488199
  },
  {
    "episode": 14,
    "avg_reward_per_step": 0.6458437681889654,
    "episode_length": 218,
    "policy_loss": 0.0018494227626617565,
    "value_loss": 166.38124084472656,
    "entropy": 0.7744073271751404,
    "total_loss": 83.18472577185419
  },
  {
    "episode": 15,
    "avg_reward_per_step": 1.4834839397992614,
    "episode_length": 120,
    "policy_loss": -0.005262576753739312,
    "value_loss": 333.47217559814453,
    "entropy": 0.7479762136936188,
    "total_loss": 166.72334546018158
  },
  {
    "episode": 16,
    "avg_reward_per_step": 0.4004726719950125,
    "episode_length": 258,
    "policy_loss": -0.00105788331694745,
    "value_loss": 149.57686614990234,
    "entropy": 0.7709556370973587,
    "total_loss": 74.77966563526326
  },
  {
    "episode": 17,
    "avg_reward_per_step": 0.00584766775761675,
    "episode_length": 461,
    "policy_loss": -0.006017707509732073,
    "value_loss": 82.71298408508301,
    "entropy": 0.7800260782241821,
    "total_loss": 41.34267407424953
  },
  {
    "episode": 18,
    "avg_reward_per_step": 0.12145802894533644,
    "episode_length": 383,
    "policy_loss": -0.00047238454416520526,
    "value_loss": 101.36407852172852,
    "entropy": 0.7463105469942093,
    "total_loss": 50.674103770850145
  },
  {
    "episode": 19,
    "avg_reward_per_step": -0.14858756845754728,
    "episode_length": 669,
    "policy_loss": -0.0018034972890745848,
    "value_loss": 57.19203281402588,
    "entropy": 0.73992820084095,
    "total_loss": 28.586813627715454
  },
  {
    "episode": 20,
    "avg_reward_per_step": -0.38593030466408507,
    "episode_length": 1000,
    "policy_loss": -0.0008540750782703999,
    "value_loss": 11.361182689666748,
    "entropy": 0.7146856486797333,
    "total_loss": 5.672590413268306
  },
  {
    "episode": 21,
    "avg_reward_per_step": -0.43947000456429236,
    "episode_length": 1000,
    "policy_loss": 0.0013935923159587027,
    "value_loss": 5.700100421905518,
    "entropy": 0.6732839792966843,
    "total_loss": 2.844710963475751
  },
  {
    "episode": 22,
    "avg_reward_per_step": -0.4367289553105314,
    "episode_length": 1000,
    "policy_loss": -0.0036240869341417348,
    "value_loss": 4.18343710899353,
    "entropy": 0.5900034755468369,
    "total_loss": 2.082194432807155
  },
  {
    "episode": 23,
    "avg_reward_per_step": -0.4382339106602881,
    "episode_length": 1000,
    "policy_loss": 0.0014802091664170014,
    "value_loss": 3.977200210094452,
    "entropy": 0.4882025197148323,
    "total_loss": 1.9851982890164945
  },
  {
    "episode": 24,
    "avg_reward_per_step": -0.4347385637489893,
    "episode_length": 1000,
    "policy_loss": -0.0025577557042706645,
    "value_loss": 3.100829005241394,
    "entropy": 0.44148770719766617,
    "total_loss": 1.5434418698444496
  },
  {
    "episode": 25,
    "avg_reward_per_step": -0.4357877195215073,
    "episode_length": 1000,
    "policy_loss": -0.0013792328250130659,
    "value_loss": 3.0102373361587524,
    "entropy": 0.4276188760995865,
    "total_loss": 1.4994632464933673
  },
  {
    "episode": 26,
    "avg_reward_per_step": -0.43593367137247974,
    "episode_length": 1000,
    "policy_loss": -8.883571332263251e-05,
    "value_loss": 3.036077618598938,
    "entropy": 0.42269671708345413,
    "total_loss": 1.5137230064153118
  },
  {
    "episode": 27,
    "avg_reward_per_step": -0.43041341411764067,
    "episode_length": 1000,
    "policy_loss": -0.003336990434676501,
    "value_loss": 3.1409929990768433,
    "entropy": 0.45053187012672424,
    "total_loss": 1.562654190402478
  },
  {
    "episode": 28,
    "avg_reward_per_step": 1.0537703306454573,
    "episode_length": 159,
    "policy_loss": -0.0031307621371388095,
    "value_loss": 240.2422981262207,
    "entropy": 0.42546868324279785,
    "total_loss": 120.1137636141408
  },
  {
    "episode": 29,
    "avg_reward_per_step": 1.79904812805796,
    "episode_length": 105,
    "policy_loss": -0.0009202995436634609,
    "value_loss": 358.8918228149414,
    "entropy": 0.47508396953344345,
    "total_loss": 179.44024026823172
  },
  {
    "episode": 30,
    "avg_reward_per_step": 1.6876197537068565,
    "episode_length": 110,
    "policy_loss": 0.006474551820958185,
    "value_loss": 314.4246139526367,
    "entropy": 0.5225314348936081,
    "total_loss": 157.21355621379038
  },
  {
    "episode": 31,
    "avg_reward_per_step": 0.3131518501954821,
    "episode_length": 292,
    "policy_loss": 0.001877758620077219,
    "value_loss": 120.26856803894043,
    "entropy": 0.5934187322854996,
    "total_loss": 60.13022759076743
  },
  {
    "episode": 32,
    "avg_reward_per_step": 2.7167470997706338,
    "episode_length": 74,
    "policy_loss": 0.004556893157093178,
    "value_loss": 478.52339935302734,
    "entropy": 0.5585978776216507,
    "total_loss": 239.26067059089453
  },
  {
    "episode": 33,
    "avg_reward_per_step": -0.42689118694538813,
    "episode_length": 1000,
    "policy_loss": -0.010365610093810318,
    "value_loss": 38.2068567276001,
    "entropy": 0.6766659915447235,
    "total_loss": 19.086296093790793
  },
  {
    "episode": 34,
    "avg_reward_per_step": 0.5472483297749796,
    "episode_length": 229,
    "policy_loss": -0.00853030795869969,
    "value_loss": 153.18474578857422,
    "entropy": 0.6191961914300919,
    "total_loss": 76.57765062441412
  },
  {
    "episode": 35,
    "avg_reward_per_step": 1.2083309204593466,
    "episode_length": 141,
    "policy_loss": -0.0006664737862231984,
    "value_loss": 244.78200912475586,
    "entropy": 0.6011418700218201,
    "total_loss": 122.3843266698915
  },
  {
    "episode": 36,
    "avg_reward_per_step": 1.0691153517208463,
    "episode_length": 155,
    "policy_loss": -0.0028529469130349483,
    "value_loss": 197.2262954711914,
    "entropy": 0.5398956090211868,
    "total_loss": 98.60489583259245
  },
  {
    "episode": 37,
    "avg_reward_per_step": 1.698430175074468,
    "episode_length": 109,
    "policy_loss": 0.0001465589345546192,
    "value_loss": 299.5271224975586,
    "entropy": 0.47526778280735016,
    "total_loss": 149.75895512988578
  },
  {
    "episode": 38,
    "avg_reward_per_step": 1.1404353718086884,
    "episode_length": 146,
    "policy_loss": -0.0016566179780457269,
    "value_loss": 222.94557571411133,
    "entropy": 0.4516724497079849,
    "total_loss": 111.46661451458054
  },
  {
    "episode": 39,
    "avg_reward_per_step": 2.6682313169330465,
    "episode_length": 77,
    "policy_loss": 0.005125005588891174,
    "value_loss": 415.810302734375,
    "entropy": 0.4471074640750885,
    "total_loss": 207.90580529813565
  },
  {
    "episode": 40,
    "avg_reward_per_step": 0.32700528043942106,
    "episode_length": 298,
    "policy_loss": -0.0032871932450732055,
    "value_loss": 110.33493041992188,
    "entropy": 0.48381219804286957,
    "total_loss": 55.15933989473544
  },
  {
    "episode": 41,
    "avg_reward_per_step": 0.741159285742017,
    "episode_length": 191,
    "policy_loss": -0.007897216834600762,
    "value_loss": 162.31462860107422,
    "entropy": 0.42633359879255295,
    "total_loss": 81.14515374771457
  },
  {
    "episode": 42,
    "avg_reward_per_step": 0.4438440582208076,
    "episode_length": 260,
    "policy_loss": -0.0017940704786899575,
    "value_loss": 118.16177368164062,
    "entropy": 0.428282730281353,
    "total_loss": 59.07480994303881
  },
  {
    "episode": 43,
    "avg_reward_per_step": 1.0791159068308829,
    "episode_length": 153,
    "policy_loss": 0.0006640230298264882,
    "value_loss": 181.48093795776367,
    "entropy": 0.3952799513936043,
    "total_loss": 90.73718020239772
  },
  {
    "episode": 44,
    "avg_reward_per_step": -0.0363419839136231,
    "episode_length": 507,
    "policy_loss": 0.00632616204069103,
    "value_loss": 68.68895149230957,
    "entropy": 0.3615020513534546,
    "total_loss": 34.34718688768194
  },
  {
    "episode": 45,
    "avg_reward_per_step": -0.17645100228162705,
    "episode_length": 727,
    "policy_loss": 0.001604186443027844,
    "value_loss": 49.440300941467285,
    "entropy": 0.31607798486948013,
    "total_loss": 24.718593877327976
  },
  {
    "episode": 46,
    "avg_reward_per_step": -0.4407190094300119,
    "episode_length": 1000,
    "policy_loss": 0.000339157031616244,
    "value_loss": 8.0850248336792,
    "entropy": 0.2928345203399658,
    "total_loss": 4.039923228667816
  },
  {
    "episode": 47,
    "avg_reward_per_step": -0.43343677207460163,
    "episode_length": 1000,
    "policy_loss": 0.0017010197525377801,
    "value_loss": 5.956396818161011,
    "entropy": 0.2706511616706848,
    "total_loss": 2.9771929172163367
  },
  {
    "episode": 48,
    "avg_reward_per_step": -0.43939023804107913,
    "episode_length": 1000,
    "policy_loss": 0.0002598181999053928,
    "value_loss": 4.461376070976257,
    "entropy": 0.28677690774202347,
    "total_loss": 2.228080084610614
  },
  {
    "episode": 49,
    "avg_reward_per_step": -0.4319345965014975,
    "episode_length": 1000,
    "policy_loss": -0.002000088893808538,
    "value_loss": 3.902644991874695,
    "entropy": 0.31491027772426605,
    "total_loss": 1.9461733042662963
  },
  {
    "episode": 50,
    "avg_reward_per_step": -0.4380806395783551,
    "episode_length": 1000,
    "policy_loss": -0.0013044196841074385,
    "value_loss": 3.1364211440086365,
    "entropy": 0.36217401176691055,
    "total_loss": 1.5632844122025418
  },
  {
    "episode": 51,
    "avg_reward_per_step": -0.4304701202616253,
    "episode_length": 1000,
    "policy_loss": -0.0021570705738850338,
    "value_loss": 3.342371106147766,
    "entropy": 0.4261687844991684,
    "total_loss": 1.6647667946550064
  },
  {
    "episode": 52,
    "avg_reward_per_step": -0.4334161002594689,
    "episode_length": 1000,
    "policy_loss": -0.002055721747223238,
    "value_loss": 3.2255601286888123,
    "entropy": 0.44630127400159836,
    "total_loss": 1.6062613298571669
  },
  {
    "episode": 53,
    "avg_reward_per_step": 0.01595255890645186,
    "episode_length": 477,
    "policy_loss": -0.008253618510805083,
    "value_loss": 69.26020050048828,
    "entropy": 0.47983089089393616,
    "total_loss": 34.617048322824395
  },
  {
    "episode": 54,
    "avg_reward_per_step": 0.27925849353236937,
    "episode_length": 307,
    "policy_loss": -0.00197877492494003,
    "value_loss": 105.93973159790039,
    "entropy": 0.5244757831096649,
    "total_loss": 52.96264226619416
  },
  {
    "episode": 55,
    "avg_reward_per_step": 1.3598198021872072,
    "episode_length": 129,
    "policy_loss": -0.002382083727378692,
    "value_loss": 242.61880493164062,
    "entropy": 0.4013547897338867,
    "total_loss": 121.30300683419559
  },
  {
    "episode": 56,
    "avg_reward_per_step": 0.4990177651005274,
    "episode_length": 234,
    "policy_loss": -0.0013948133734946744,
    "value_loss": 146.62638092041016,
    "entropy": 0.5420421957969666,
    "total_loss": 73.30637522487362
  },
  {
    "episode": 57,
    "avg_reward_per_step": 1.77565058944928,
    "episode_length": 105,
    "policy_loss": 0.015275946698550591,
    "value_loss": 294.7228698730469,
    "entropy": 0.4512920677661896,
    "total_loss": 147.37219796254433
  },
  {
    "episode": 58,
    "avg_reward_per_step": -0.102722048310585,
    "episode_length": 534,
    "policy_loss": 0.0033689403776968607,
    "value_loss": 83.52859497070312,
    "entropy": 0.6345197558403015,
    "total_loss": 41.76132122817086
  },
  {
    "episode": 59,
    "avg_reward_per_step": -0.22043249126744174,
    "episode_length": 740,
    "policy_loss": -0.002707604204958969,
    "value_loss": 58.38994026184082,
    "entropy": 0.6785241216421127,
    "total_loss": 29.185477285499033
  },
  {
    "episode": 60,
    "avg_reward_per_step": 0.3733454454006609,
    "episode_length": 265,
    "policy_loss": -0.0011102921400825139,
    "value_loss": 124.10363388061523,
    "entropy": 0.6818303465843201,
    "total_loss": 62.04388834470169
  },
  {
    "episode": 61,
    "avg_reward_per_step": -0.197212623772998,
    "episode_length": 695,
    "policy_loss": 0.0018986936951543576,
    "value_loss": 62.16877269744873,
    "entropy": 0.7258985340595245,
    "total_loss": 31.079026057078924
  },
  {
    "episode": 62,
    "avg_reward_per_step": 2.2107092513556776,
    "episode_length": 89,
    "policy_loss": 0.026417249928783137,
    "value_loss": 349.28472900390625,
    "entropy": 0.5271498709917068,
    "total_loss": 174.66351025317198
  },
  {
    "episode": 63,
    "avg_reward_per_step": 0.046733256873666584,
    "episode_length": 414,
    "policy_loss": -0.0006062033000471811,
    "value_loss": 88.48464393615723,
    "entropy": 0.5856266468763351,
    "total_loss": 44.23585949830981
  },
  {
    "episode": 64,
    "avg_reward_per_step": 0.8150613951721476,
    "episode_length": 182,
    "policy_loss": -0.010148816145854278,
    "value_loss": 150.86551666259766,
    "entropy": 0.4771462753415108,
    "total_loss": 75.41783805239956
  },
  {
    "episode": 65,
    "avg_reward_per_step": 0.04625355825866194,
    "episode_length": 424,
    "policy_loss": -0.011716888984665275,
    "value_loss": 110.10299301147461,
    "entropy": 0.5155960693955421,
    "total_loss": 55.034623656058685
  },
  {
    "episode": 66,
    "avg_reward_per_step": 1.445784312402873,
    "episode_length": 123,
    "policy_loss": -0.001406607935980908,
    "value_loss": 225.37334442138672,
    "entropy": 0.4140793904662132,
    "total_loss": 112.68112480885272
  },
  {
    "episode": 67,
    "avg_reward_per_step": 0.9606040648163475,
    "episode_length": 168,
    "policy_loss": 0.0018110789810417138,
    "value_loss": 174.00364303588867,
    "entropy": 0.43728604167699814,
    "total_loss": 86.9992597365086
  },
  {
    "episode": 68,
    "avg_reward_per_step": 1.3519358227113583,
    "episode_length": 133,
    "policy_loss": 0.0014860835972354547,
    "value_loss": 190.39081573486328,
    "entropy": 0.44688543677330017,
    "total_loss": 95.19242509666114
  },
  {
    "episode": 69,
    "avg_reward_per_step": 2.0501277308479873,
    "episode_length": 94,
    "policy_loss": -0.0009454245582480869,
    "value_loss": 278.9907760620117,
    "entropy": 0.35980506986379623,
    "total_loss": 139.490844555749
  },
  {
    "episode": 70,
    "avg_reward_per_step": 1.0849017429391532,
    "episode_length": 153,
    "policy_loss": -0.004892109176889675,
    "value_loss": 177.5470314025879,
    "entropy": 0.4094887301325798,
    "total_loss": 88.76452870481573
  },
  {
    "episode": 71,
    "avg_reward_per_step": 1.3412686393568716,
    "episode_length": 131,
    "policy_loss": -0.014171018304288907,
    "value_loss": 203.22789001464844,
    "entropy": 0.3861681669950485,
    "total_loss": 101.59591230734998
  },
  {
    "episode": 72,
    "avg_reward_per_step": 0.9668288673831654,
    "episode_length": 163,
    "policy_loss": -0.0003243121639240343,
    "value_loss": 172.57863235473633,
    "entropy": 0.40352367609739304,
    "total_loss": 86.28495662844327
  },
  {
    "episode": 73,
    "avg_reward_per_step": 1.8333566431033974,
    "episode_length": 103,
    "policy_loss": -0.005780709451923438,
    "value_loss": 244.94869995117188,
    "entropy": 0.4149731621146202,
    "total_loss": 122.46441953451287
  },
  {
    "episode": 74,
    "avg_reward_per_step": 0.45999049079033005,
    "episode_length": 242,
    "policy_loss": -0.0027833149647187305,
    "value_loss": 136.60431289672852,
    "entropy": 0.5032974258065224,
    "total_loss": 68.29434015914147
  },
  {
    "episode": 75,
    "avg_reward_per_step": 0.8149203886317617,
    "episode_length": 182,
    "policy_loss": -0.0014180040244744507,
    "value_loss": 147.31900787353516,
    "entropy": 0.4648805260658264,
    "total_loss": 73.65343712748245
  },
  {
    "episode": 76,
    "avg_reward_per_step": 0.4002997281568954,
    "episode_length": 258,
    "policy_loss": -0.00034559385643628815,
    "value_loss": 132.82859420776367,
    "entropy": 0.5349709242582321,
    "total_loss": 66.40860180078282
  },
  {
    "episode": 77,
    "avg_reward_per_step": -0.2031252202669184,
    "episode_length": 751,
    "policy_loss": -0.0009620120256634834,
    "value_loss": 62.4768009185791,
    "entropy": 0.6233672201633453,
    "total_loss": 31.231204775062253
  },
  {
    "episode": 78,
    "avg_reward_per_step": 1.7618909992524574,
    "episode_length": 107,
    "policy_loss": -0.0009924893330826023,
    "value_loss": 260.5816955566406,
    "entropy": 0.4449607953429222,
    "total_loss": 130.2854056810338
  },
  {
    "episode": 79,
    "avg_reward_per_step": -0.1285192803419471,
    "episode_length": 610,
    "policy_loss": 0.0012343819416318347,
    "value_loss": 67.98492431640625,
    "entropy": 0.5293965339660645,
    "total_loss": 33.98840257480509
  },
  {
    "episode": 80,
    "avg_reward_per_step": -0.0028130679520840134,
    "episode_length": 470,
    "policy_loss": -0.008504352972723783,
    "value_loss": 73.72401237487793,
    "entropy": 0.4712122976779938,
    "total_loss": 36.84878971148947
  },
  {
    "episode": 81,
    "avg_reward_per_step": 0.4214471809012319,
    "episode_length": 251,
    "policy_loss": -0.0009117464933696695,
    "value_loss": 117.93529319763184,
    "entropy": 0.44015754014253616,
    "total_loss": 58.96233327692112
  },
  {
    "episode": 82,
    "avg_reward_per_step": -0.4500594465943897,
    "episode_length": 1000,
    "policy_loss": 0.005981835109182043,
    "value_loss": 11.766072988510132,
    "entropy": 0.4545254409313202,
    "total_loss": 5.8844730749549345
  },
  {
    "episode": 83,
    "avg_reward_per_step": -0.44767668005952665,
    "episode_length": 1000,
    "policy_loss": 0.004084650664124556,
    "value_loss": 4.996121644973755,
    "entropy": 0.43429672718048096,
    "total_loss": 2.4978025058791973
  },
  {
    "episode": 84,
    "avg_reward_per_step": 1.5536467898143125,
    "episode_length": 122,
    "policy_loss": -0.004985794129201082,
    "value_loss": 213.59678268432617,
    "entropy": 0.3366710841655731,
    "total_loss": 106.79003883719223
  },
  {
    "episode": 85,
    "avg_reward_per_step": 0.38768017981100056,
    "episode_length": 269,
    "policy_loss": 0.00416737891578714,
    "value_loss": 114.65250205993652,
    "entropy": 0.4765288531780243,
    "total_loss": 57.32565312035227
  },
  {
    "episode": 86,
    "avg_reward_per_step": 0.7116618346431436,
    "episode_length": 199,
    "policy_loss": 0.0027809286572421654,
    "value_loss": 141.8598518371582,
    "entropy": 0.476024366915226,
    "total_loss": 70.9279466035672
  },
  {
    "episode": 87,
    "avg_reward_per_step": -0.37947362840950466,
    "episode_length": 1000,
    "policy_loss": -0.0012667153817602639,
    "value_loss": 13.61769151687622,
    "entropy": 0.5319882333278656,
    "total_loss": 6.802259160723072
  },
  {
    "episode": 88,
    "avg_reward_per_step": -0.375501001434208,
    "episode_length": 1000,
    "policy_loss": 0.0002008134164789288,
    "value_loss": 10.77344799041748,
    "entropy": 0.5424396842718124,
    "total_loss": 5.3815004117825005
  },
  {
    "episode": 89,
    "avg_reward_per_step": -0.1712128800116841,
    "episode_length": 715,
    "policy_loss": -0.0007358900818528191,
    "value_loss": 39.33476257324219,
    "entropy": 0.5579363852739334,
    "total_loss": 19.661066032686502
  },
  {
    "episode": 90,
    "avg_reward_per_step": -0.45333499990521575,
    "episode_length": 1000,
    "policy_loss": -5.2346347425569206e-05,
    "value_loss": 6.733944654464722,
    "entropy": 0.5950510203838348,
    "total_loss": 3.360969470681097
  },
  {
    "episode": 91,
    "avg_reward_per_step": 1.3466035532625396,
    "episode_length": 136,
    "policy_loss": 0.0020851177498972806,
    "value_loss": 190.1411247253418,
    "entropy": 0.41011811047792435,
    "total_loss": 95.06854629931603
  },
  {
    "episode": 92,
    "avg_reward_per_step": 1.093711437279841,
    "episode_length": 154,
    "policy_loss": 0.008709058002266401,
    "value_loss": 180.96304321289062,
    "entropy": 0.5222787857055664,
    "total_loss": 90.48500787659053
  },
  {
    "episode": 93,
    "avg_reward_per_step": 1.5902410617188072,
    "episode_length": 115,
    "policy_loss": -0.0012230704360578493,
    "value_loss": 232.77540969848633,
    "entropy": 0.5089754015207291,
    "total_loss": 116.38139202479191
  },
  {
    "episode": 94,
    "avg_reward_per_step": 0.7384469782497582,
    "episode_length": 191,
    "policy_loss": -0.0023139000566144707,
    "value_loss": 151.0438346862793,
    "entropy": 0.4892703890800476,
    "total_loss": 75.51471073919222
  },
  {
    "episode": 95,
    "avg_reward_per_step": 0.7368521232776499,
    "episode_length": 194,
    "policy_loss": 0.006778913254239932,
    "value_loss": 128.24409675598145,
    "entropy": 0.43632760643959045,
    "total_loss": 64.12446401518056
  },
  {
    "episode": 96,
    "avg_reward_per_step": 1.8522320747447523,
    "episode_length": 102,
    "policy_loss": -0.0033282512107257745,
    "value_loss": 241.7326545715332,
    "entropy": 0.3684939444065094,
    "total_loss": 120.8593140951118
  },
  {
    "episode": 97,
    "avg_reward_per_step": 0.8396661898087463,
    "episode_length": 180,
    "policy_loss": 0.002507546466464783,
    "value_loss": 148.54898834228516,
    "entropy": 0.3551067039370537,
    "total_loss": 74.27345065056967
  },
  {
    "episode": 98,
    "avg_reward_per_step": -0.36724231364039206,
    "episode_length": 1000,
    "policy_loss": 0.010641501051373847,
    "value_loss": 9.793064832687378,
    "entropy": 0.3514595702290535,
    "total_loss": 4.903659321692773
  },
  {
    "episode": 99,
    "avg_reward_per_step": 0.88593331636534,
    "episode_length": 174,
    "policy_loss": -0.0007844157565459753,
    "value_loss": 138.8260841369629,
    "entropy": 0.31602731347084045,
    "total_loss": 69.4090973795902
  },
  {
    "episode": 100,
    "avg_reward_per_step": 0.6935128546336311,
    "episode_length": 204,
    "policy_loss": -0.003874274133933042,
    "value_loss": 118.37318992614746,
    "entropy": 0.3487158417701721,
    "total_loss": 59.1792335305221
  }
]