[
  {
    "episode": 1,
    "avg_reward_per_step": -3.48192496435664,
    "episode_length": 3000,
    "policy_loss": 35.28420543670654,
    "value_loss": 1.778724730014801,
    "entropy": 1.3788884580135345,
    "total_loss": 36.51137478351593
  },
  {
    "episode": 2,
    "avg_reward_per_step": -2.484288693303823,
    "episode_length": 3000,
    "policy_loss": 25.18651294708252,
    "value_loss": 1.5017831325531006,
    "entropy": 1.371579885482788,
    "total_loss": 26.139664125442504
  },
  {
    "episode": 3,
    "avg_reward_per_step": 15.686182855181208,
    "episode_length": 1139,
    "policy_loss": -165.89789199829102,
    "value_loss": 0.5065330862998962,
    "entropy": 1.3672721683979034,
    "total_loss": -165.93826777935027
  },
  {
    "episode": 4,
    "avg_reward_per_step": -3.2584974811906515,
    "episode_length": 3000,
    "policy_loss": 33.212127685546875,
    "value_loss": 1.5378122329711914,
    "entropy": 1.3800198137760162,
    "total_loss": 34.19793199300766
  },
  {
    "episode": 5,
    "avg_reward_per_step": -3.2901288190084337,
    "episode_length": 3000,
    "policy_loss": 33.31174945831299,
    "value_loss": 1.518867701292038,
    "entropy": 1.3811110258102417,
    "total_loss": 34.27817274928093
  },
  {
    "episode": 6,
    "avg_reward_per_step": 21.08802972357696,
    "episode_length": 849,
    "policy_loss": -218.9613037109375,
    "value_loss": 0.5088455975055695,
    "entropy": 1.3800910711288452,
    "total_loss": -219.00449454188347
  },
  {
    "episode": 7,
    "avg_reward_per_step": 105.63747636465156,
    "episode_length": 187,
    "policy_loss": -1120.5890808105469,
    "value_loss": 0.553913876414299,
    "entropy": 1.373718798160553,
    "total_loss": -1120.5846544533968
  },
  {
    "episode": 8,
    "avg_reward_per_step": -3.3784293201189097,
    "episode_length": 3000,
    "policy_loss": 34.04127025604248,
    "value_loss": 1.384625256061554,
    "entropy": 1.3608855307102203,
    "total_loss": 34.88154129981994
  },
  {
    "episode": 9,
    "avg_reward_per_step": 69.37250531947713,
    "episode_length": 281,
    "policy_loss": -723.4357452392578,
    "value_loss": 0.5337042957544327,
    "entropy": 1.3375995457172394,
    "total_loss": -723.4370807617903
  },
  {
    "episode": 10,
    "avg_reward_per_step": 25.602740209053245,
    "episode_length": 716,
    "policy_loss": -273.67047119140625,
    "value_loss": 0.5111165046691895,
    "entropy": 1.30371955037117,
    "total_loss": -273.68084250688554
  },
  {
    "episode": 11,
    "avg_reward_per_step": 17.47775600960916,
    "episode_length": 1015,
    "policy_loss": -183.23661041259766,
    "value_loss": 0.5072785913944244,
    "entropy": 1.2555410265922546,
    "total_loss": -183.23154823184012
  },
  {
    "episode": 12,
    "avg_reward_per_step": -1.6074113116815087,
    "episode_length": 3000,
    "policy_loss": 15.497619152069092,
    "value_loss": 1.0208821892738342,
    "entropy": 1.1729525923728943,
    "total_loss": 16.049320304393767
  },
  {
    "episode": 13,
    "avg_reward_per_step": -1.3493515424233335,
    "episode_length": 3000,
    "policy_loss": 12.738144159317017,
    "value_loss": 0.8844883441925049,
    "entropy": 1.1334844529628754,
    "total_loss": 13.169238722324371
  },
  {
    "episode": 14,
    "avg_reward_per_step": -1.5801255713026907,
    "episode_length": 3000,
    "policy_loss": 14.96058440208435,
    "value_loss": 1.0770575106143951,
    "entropy": 1.0814483761787415,
    "total_loss": 15.60506256222725
  },
  {
    "episode": 15,
    "avg_reward_per_step": -1.267512518164307,
    "episode_length": 3000,
    "policy_loss": 11.553797245025635,
    "value_loss": 1.1187634766101837,
    "entropy": 1.03176611661911,
    "total_loss": 12.259854274988175
  },
  {
    "episode": 16,
    "avg_reward_per_step": -1.350286404362648,
    "episode_length": 3000,
    "policy_loss": 12.179442167282104,
    "value_loss": 0.9537883996963501,
    "entropy": 1.0462429225444794,
    "total_loss": 12.714733397960662
  },
  {
    "episode": 17,
    "avg_reward_per_step": -1.1397982339469637,
    "episode_length": 3000,
    "policy_loss": 9.821544647216797,
    "value_loss": 0.984869971871376,
    "entropy": 0.9803951680660248,
    "total_loss": 10.414256551861763
  },
  {
    "episode": 18,
    "avg_reward_per_step": -1.1836176016158317,
    "episode_length": 3000,
    "policy_loss": 9.946842193603516,
    "value_loss": 0.8802324086427689,
    "entropy": 1.0175601541996002,
    "total_loss": 10.420050540566445
  },
  {
    "episode": 19,
    "avg_reward_per_step": 6.227004681298544,
    "episode_length": 2679,
    "policy_loss": -66.6978988647461,
    "value_loss": 0.5025904625654221,
    "entropy": 0.9864078462123871,
    "total_loss": -66.58987154066563
  },
  {
    "episode": 20,
    "avg_reward_per_step": -1.3344314769237733,
    "episode_length": 3000,
    "policy_loss": 10.937776803970337,
    "value_loss": 0.8615700602531433,
    "entropy": 0.9890734553337097,
    "total_loss": 11.403717482089997
  },
  {
    "episode": 21,
    "avg_reward_per_step": -1.1189647774614948,
    "episode_length": 3000,
    "policy_loss": 8.500342607498169,
    "value_loss": 0.8616824895143509,
    "entropy": 0.9855621755123138,
    "total_loss": 8.967800226807594
  },
  {
    "episode": 22,
    "avg_reward_per_step": -0.9717729540518614,
    "episode_length": 3000,
    "policy_loss": 6.717498421669006,
    "value_loss": 0.7854050993919373,
    "entropy": 0.9920791834592819,
    "total_loss": 7.106071847677231
  },
  {
    "episode": 23,
    "avg_reward_per_step": -1.2201145703348846,
    "episode_length": 3000,
    "policy_loss": 8.905917644500732,
    "value_loss": 0.8668143302202225,
    "entropy": 0.9981694966554642,
    "total_loss": 9.37346417605877
  },
  {
    "episode": 24,
    "avg_reward_per_step": -1.3904802703883998,
    "episode_length": 3000,
    "policy_loss": 10.243522644042969,
    "value_loss": 0.772631511092186,
    "entropy": 1.0088148713111877,
    "total_loss": 10.61262820661068
  },
  {
    "episode": 25,
    "avg_reward_per_step": -1.246621083233703,
    "episode_length": 3000,
    "policy_loss": 8.44202995300293,
    "value_loss": 0.7199148684740067,
    "entropy": 1.0025422871112823,
    "total_loss": 8.760927906632423
  },
  {
    "episode": 26,
    "avg_reward_per_step": -1.1610291494108669,
    "episode_length": 3000,
    "policy_loss": 7.37244987487793,
    "value_loss": 0.7516233772039413,
    "entropy": 0.9888710826635361,
    "total_loss": 7.728524819016457
  },
  {
    "episode": 27,
    "avg_reward_per_step": 14.41874647245453,
    "episode_length": 1292,
    "policy_loss": -153.72673797607422,
    "value_loss": 0.5067623555660248,
    "entropy": 1.0204923152923584,
    "total_loss": -153.62817254662514
  },
  {
    "episode": 28,
    "avg_reward_per_step": -1.01863228673867,
    "episode_length": 3000,
    "policy_loss": 5.252403259277344,
    "value_loss": 0.6606499552726746,
    "entropy": 1.0101463794708252,
    "total_loss": 5.508994662761689
  },
  {
    "episode": 29,
    "avg_reward_per_step": -1.3553914249498105,
    "episode_length": 3000,
    "policy_loss": 8.35048770904541,
    "value_loss": 0.688586637377739,
    "entropy": 1.0614606738090515,
    "total_loss": 8.614490076899529
  },
  {
    "episode": 30,
    "avg_reward_per_step": -1.2535504773952926,
    "episode_length": 3000,
    "policy_loss": 6.897438168525696,
    "value_loss": 0.6411860883235931,
    "entropy": 1.0688367784023285,
    "total_loss": 7.111089545488357
  },
  {
    "episode": 31,
    "avg_reward_per_step": -1.218569045077984,
    "episode_length": 3000,
    "policy_loss": 6.332083582878113,
    "value_loss": 0.6604999154806137,
    "entropy": 1.0308604538440704,
    "total_loss": 6.580239316821098
  },
  {
    "episode": 32,
    "avg_reward_per_step": -1.2606510906744335,
    "episode_length": 3000,
    "policy_loss": 6.396416664123535,
    "value_loss": 0.6119986325502396,
    "entropy": 1.072711169719696,
    "total_loss": 6.5793308287858965
  },
  {
    "episode": 33,
    "avg_reward_per_step": 11.7220627436372,
    "episode_length": 1541,
    "policy_loss": -127.68559837341309,
    "value_loss": 0.5055650472640991,
    "entropy": 1.1046614944934845,
    "total_loss": -127.62189792394638
  },
  {
    "episode": 34,
    "avg_reward_per_step": -1.3618866827266871,
    "episode_length": 3000,
    "policy_loss": 6.735495924949646,
    "value_loss": 0.663814127445221,
    "entropy": 1.0579535067081451,
    "total_loss": 6.976128649711609
  },
  {
    "episode": 35,
    "avg_reward_per_step": 19.34333304532733,
    "episode_length": 964,
    "policy_loss": -208.71602630615234,
    "value_loss": 0.5091537237167358,
    "entropy": 1.1188175082206726,
    "total_loss": -208.65439958572387
  },
  {
    "episode": 36,
    "avg_reward_per_step": -1.3412365846280074,
    "episode_length": 3000,
    "policy_loss": 6.046983599662781,
    "value_loss": 0.5954700857400894,
    "entropy": 1.120876669883728,
    "total_loss": 6.194103017449379
  },
  {
    "episode": 37,
    "avg_reward_per_step": 30.83751891569013,
    "episode_length": 609,
    "policy_loss": -331.9011688232422,
    "value_loss": 0.5144713371992111,
    "entropy": 1.1908135116100311,
    "total_loss": -331.863022890687
  },
  {
    "episode": 38,
    "avg_reward_per_step": 25.437339590785033,
    "episode_length": 738,
    "policy_loss": -278.3252487182617,
    "value_loss": 0.5120662450790405,
    "entropy": 1.1886605620384216,
    "total_loss": -278.28864669799805
  },
  {
    "episode": 39,
    "avg_reward_per_step": 61.24598562705708,
    "episode_length": 319,
    "policy_loss": -652.0764617919922,
    "value_loss": 0.5302503108978271,
    "entropy": 1.2381851077079773,
    "total_loss": -652.0414855241776
  },
  {
    "episode": 40,
    "avg_reward_per_step": 11.559626859480955,
    "episode_length": 1238,
    "policy_loss": -126.00140762329102,
    "value_loss": 0.5042740106582642,
    "entropy": 1.210431545972824,
    "total_loss": -125.98130623102188
  },
  {
    "episode": 41,
    "avg_reward_per_step": 20.64898659304221,
    "episode_length": 886,
    "policy_loss": -221.87150955200195,
    "value_loss": 0.5096503794193268,
    "entropy": 1.2483553886413574,
    "total_loss": -221.86120132803916
  },
  {
    "episode": 42,
    "avg_reward_per_step": 47.248200762267246,
    "episode_length": 402,
    "policy_loss": -499.7547607421875,
    "value_loss": 0.5224488079547882,
    "entropy": 1.1713623106479645,
    "total_loss": -499.7008568584919
  },
  {
    "episode": 43,
    "avg_reward_per_step": 70.49214456281265,
    "episode_length": 263,
    "policy_loss": -749.1969757080078,
    "value_loss": 0.5328974723815918,
    "entropy": 1.0994613766670227,
    "total_loss": -749.103862786293
  },
  {
    "episode": 44,
    "avg_reward_per_step": 101.21615281770696,
    "episode_length": 191,
    "policy_loss": -1068.6582946777344,
    "value_loss": 0.550832524895668,
    "entropy": 1.0302915424108505,
    "total_loss": -1068.519578769803
  },
  {
    "episode": 45,
    "avg_reward_per_step": 7.638730106793145,
    "episode_length": 1165,
    "policy_loss": -88.20161819458008,
    "value_loss": 0.5016732662916183,
    "entropy": 0.8369871079921722,
    "total_loss": -88.03473977148533
  },
  {
    "episode": 46,
    "avg_reward_per_step": 1.346163300184991,
    "episode_length": 1543,
    "policy_loss": -22.33065891265869,
    "value_loss": 0.49991466104984283,
    "entropy": 0.7564437240362167,
    "total_loss": -22.133321741223334
  },
  {
    "episode": 47,
    "avg_reward_per_step": -11.734474520697132,
    "episode_length": 3000,
    "policy_loss": 111.85003089904785,
    "value_loss": 2.6745648980140686,
    "entropy": 0.722057119011879,
    "total_loss": 114.23577294945717
  },
  {
    "episode": 48,
    "avg_reward_per_step": -12.6724930657702,
    "episode_length": 3000,
    "policy_loss": 121.27856063842773,
    "value_loss": 3.195944130420685,
    "entropy": 0.67792908847332,
    "total_loss": 124.2033331334591
  },
  {
    "episode": 49,
    "avg_reward_per_step": -11.994875531178494,
    "episode_length": 3000,
    "policy_loss": 113.96906089782715,
    "value_loss": 2.4349727034568787,
    "entropy": 0.694696381688118,
    "total_loss": 116.12615504860878
  },
  {
    "episode": 50,
    "avg_reward_per_step": -4.007382044556965,
    "episode_length": 2458,
    "policy_loss": 31.48898935317993,
    "value_loss": 0.5004099160432816,
    "entropy": 0.6609459072351456,
    "total_loss": 31.725020906329156
  },
  {
    "episode": 51,
    "avg_reward_per_step": -11.849385538135076,
    "episode_length": 3000,
    "policy_loss": 111.7154712677002,
    "value_loss": 2.4791809916496277,
    "entropy": 0.7006836384534836,
    "total_loss": 113.91437880396843
  },
  {
    "episode": 52,
    "avg_reward_per_step": -2.0963386284655146,
    "episode_length": 2645,
    "policy_loss": 11.323514223098755,
    "value_loss": 0.49998708069324493,
    "entropy": 0.7130952179431915,
    "total_loss": 11.538263216614723
  },
  {
    "episode": 53,
    "avg_reward_per_step": -10.702335474213024,
    "episode_length": 3000,
    "policy_loss": 99.38449478149414,
    "value_loss": 2.322766363620758,
    "entropy": 0.7343119233846664,
    "total_loss": 101.41353637576103
  },
  {
    "episode": 54,
    "avg_reward_per_step": 8.141690933815465,
    "episode_length": 1201,
    "policy_loss": -98.15134239196777,
    "value_loss": 0.502164751291275,
    "entropy": 0.820237785577774,
    "total_loss": -97.9772727549076
  },
  {
    "episode": 55,
    "avg_reward_per_step": -2.611689708387396,
    "episode_length": 2381,
    "policy_loss": 12.999335765838623,
    "value_loss": 0.49997301399707794,
    "entropy": 0.7217475771903992,
    "total_loss": 13.210609748959541
  },
  {
    "episode": 56,
    "avg_reward_per_step": 28.974033008364074,
    "episode_length": 625,
    "policy_loss": -312.58888244628906,
    "value_loss": 0.5134684443473816,
    "entropy": 0.9308972358703613,
    "total_loss": -312.44777289628985
  },
  {
    "episode": 57,
    "avg_reward_per_step": 72.03616329596888,
    "episode_length": 259,
    "policy_loss": -761.0251159667969,
    "value_loss": 0.5343091934919357,
    "entropy": 0.8298828452825546,
    "total_loss": -760.822759911418
  },
  {
    "episode": 58,
    "avg_reward_per_step": 58.199920468714915,
    "episode_length": 329,
    "policy_loss": -618.4625701904297,
    "value_loss": 0.5283676236867905,
    "entropy": 0.9003319293260574,
    "total_loss": -618.2943353384733
  },
  {
    "episode": 59,
    "avg_reward_per_step": 17.379082300284516,
    "episode_length": 998,
    "policy_loss": -190.1632423400879,
    "value_loss": 0.5080757737159729,
    "entropy": 0.8466572016477585,
    "total_loss": -189.99382944703103
  },
  {
    "episode": 60,
    "avg_reward_per_step": 10.483526511104289,
    "episode_length": 1654,
    "policy_loss": -117.5672664642334,
    "value_loss": 0.5053222179412842,
    "entropy": 0.7994847148656845,
    "total_loss": -117.38173813223838
  },
  {
    "episode": 61,
    "avg_reward_per_step": 29.019290713124313,
    "episode_length": 640,
    "policy_loss": -311.92908477783203,
    "value_loss": 0.5139600038528442,
    "entropy": 0.7779485285282135,
    "total_loss": -311.72630418539046
  },
  {
    "episode": 62,
    "avg_reward_per_step": 13.783501218033132,
    "episode_length": 1321,
    "policy_loss": -153.4657325744629,
    "value_loss": 0.5069986134767532,
    "entropy": 0.7293163686990738,
    "total_loss": -153.25046050846578
  },
  {
    "episode": 63,
    "avg_reward_per_step": 9.649566950576649,
    "episode_length": 1858,
    "policy_loss": -110.98532676696777,
    "value_loss": 0.5052024573087692,
    "entropy": 0.6948057562112808,
    "total_loss": -110.75804661214352
  },
  {
    "episode": 64,
    "avg_reward_per_step": -1.5173852542610509,
    "episode_length": 3000,
    "policy_loss": 4.174487471580505,
    "value_loss": 0.5120710283517838,
    "entropy": 0.6767026036977768,
    "total_loss": 4.415877458453179
  },
  {
    "episode": 65,
    "avg_reward_per_step": -1.3417396672825548,
    "episode_length": 3000,
    "policy_loss": 2.306132435798645,
    "value_loss": 0.49121150374412537,
    "entropy": 0.6167922019958496,
    "total_loss": 2.5506270587444306
  },
  {
    "episode": 66,
    "avg_reward_per_step": -1.0470668984163978,
    "episode_length": 3000,
    "policy_loss": -0.7359392195940018,
    "value_loss": 0.4761577472090721,
    "entropy": 0.5866827070713043,
    "total_loss": -0.4944545552134514
  },
  {
    "episode": 67,
    "avg_reward_per_step": -0.9333632981008991,
    "episode_length": 3000,
    "policy_loss": -1.8322829008102417,
    "value_loss": 0.4966581463813782,
    "entropy": 0.5646142512559891,
    "total_loss": -1.5614704549312592
  },
  {
    "episode": 68,
    "avg_reward_per_step": -0.8627098561474087,
    "episode_length": 3000,
    "policy_loss": -2.4027141332626343,
    "value_loss": 0.5149856805801392,
    "entropy": 0.5530629903078079,
    "total_loss": -2.108953648805618
  },
  {
    "episode": 69,
    "avg_reward_per_step": -0.8475110823636027,
    "episode_length": 3000,
    "policy_loss": -2.334533214569092,
    "value_loss": 0.498053215444088,
    "entropy": 0.5453244298696518,
    "total_loss": -2.0546097710728644
  },
  {
    "episode": 70,
    "avg_reward_per_step": -0.8092407921540087,
    "episode_length": 3000,
    "policy_loss": -2.1460118293762207,
    "value_loss": 0.5029220804572105,
    "entropy": 0.5027765929698944,
    "total_loss": -1.844200386106968
  },
  {
    "episode": 71,
    "avg_reward_per_step": -0.7981967387798352,
    "episode_length": 3000,
    "policy_loss": -1.6677095592021942,
    "value_loss": 0.5011224821209908,
    "entropy": 0.47717443853616714,
    "total_loss": -1.3574568524956703
  },
  {
    "episode": 72,
    "avg_reward_per_step": -1.0572015840515336,
    "episode_length": 3000,
    "policy_loss": 0.4442307651042938,
    "value_loss": 0.4773075133562088,
    "entropy": 0.5743893086910248,
    "total_loss": 0.6917825549840927
  },
  {
    "episode": 73,
    "avg_reward_per_step": -0.7728310240269463,
    "episode_length": 3000,
    "policy_loss": -1.3114366233348846,
    "value_loss": 0.48256807029247284,
    "entropy": 0.49056289345026016,
    "total_loss": -1.025093710422516
  },
  {
    "episode": 74,
    "avg_reward_per_step": -0.7662237423376567,
    "episode_length": 3000,
    "policy_loss": -0.6666251868009567,
    "value_loss": 0.4783225357532501,
    "entropy": 0.45475707948207855,
    "total_loss": -0.370205482840538
  },
  {
    "episode": 75,
    "avg_reward_per_step": 6.0078508659464545,
    "episode_length": 2918,
    "policy_loss": -70.91305541992188,
    "value_loss": 0.5035132318735123,
    "entropy": 0.552237868309021,
    "total_loss": -70.63043733537197
  },
  {
    "episode": 76,
    "avg_reward_per_step": 8.631371575292688,
    "episode_length": 2124,
    "policy_loss": -97.70488357543945,
    "value_loss": 0.5047844797372818,
    "entropy": 0.5255573391914368,
    "total_loss": -97.41032203137874
  },
  {
    "episode": 77,
    "avg_reward_per_step": 7.41296483274821,
    "episode_length": 2360,
    "policy_loss": -88.62626075744629,
    "value_loss": 0.5040081292390823,
    "entropy": 0.5898519903421402,
    "total_loss": -88.35819342434407
  },
  {
    "episode": 78,
    "avg_reward_per_step": -1.098481197754763,
    "episode_length": 3000,
    "policy_loss": 2.6909088492393494,
    "value_loss": 0.5138984173536301,
    "entropy": 0.6171570718288422,
    "total_loss": 2.9579444378614426
  },
  {
    "episode": 79,
    "avg_reward_per_step": 5.684928137120934,
    "episode_length": 2960,
    "policy_loss": -67.66767120361328,
    "value_loss": 0.5033173114061356,
    "entropy": 0.6421633511781693,
    "total_loss": -67.42121923267841
  },
  {
    "episode": 80,
    "avg_reward_per_step": 17.960980780843382,
    "episode_length": 1043,
    "policy_loss": -192.84368515014648,
    "value_loss": 0.509001761674881,
    "entropy": 0.6956332921981812,
    "total_loss": -192.61293670535088
  },
  {
    "episode": 81,
    "avg_reward_per_step": 18.31355170137779,
    "episode_length": 1013,
    "policy_loss": -197.50554275512695,
    "value_loss": 0.509017139673233,
    "entropy": 0.7199420481920242,
    "total_loss": -197.28450243473054
  },
  {
    "episode": 82,
    "avg_reward_per_step": 16.65760900130835,
    "episode_length": 1076,
    "policy_loss": -180.94294357299805,
    "value_loss": 0.5080450624227524,
    "entropy": 0.7337775975465775,
    "total_loss": -180.72840954959392
  },
  {
    "episode": 83,
    "avg_reward_per_step": 11.488608307061174,
    "episode_length": 1553,
    "policy_loss": -129.00372505187988,
    "value_loss": 0.5057624727487564,
    "entropy": 0.7502339035272598,
    "total_loss": -128.79805614054203
  },
  {
    "episode": 84,
    "avg_reward_per_step": 41.61261182044928,
    "episode_length": 464,
    "policy_loss": -448.17972564697266,
    "value_loss": 0.5204606354236603,
    "entropy": 0.7874680310487747,
    "total_loss": -447.9742522239685
  },
  {
    "episode": 85,
    "avg_reward_per_step": 85.06465212684024,
    "episode_length": 226,
    "policy_loss": -906.2330169677734,
    "value_loss": 0.5421888530254364,
    "entropy": 0.7858667820692062,
    "total_loss": -906.0051748275757
  },
  {
    "episode": 86,
    "avg_reward_per_step": 79.87713450037893,
    "episode_length": 233,
    "policy_loss": -869.4005126953125,
    "value_loss": 0.5378820598125458,
    "entropy": 0.7322044521570206,
    "total_loss": -869.1555124163627
  },
  {
    "episode": 87,
    "avg_reward_per_step": 1.8936343778562128,
    "episode_length": 1819,
    "policy_loss": -27.19924259185791,
    "value_loss": 0.5001650154590607,
    "entropy": 0.6332617998123169,
    "total_loss": -26.952382296323776
  },
  {
    "episode": 88,
    "avg_reward_per_step": -12.695408025894135,
    "episode_length": 3000,
    "policy_loss": 120.39800834655762,
    "value_loss": 2.8254305124282837,
    "entropy": 0.47085122019052505,
    "total_loss": 123.0350983709097
  },
  {
    "episode": 89,
    "avg_reward_per_step": -13.640604511151778,
    "episode_length": 3000,
    "policy_loss": 129.85795974731445,
    "value_loss": 3.079792618751526,
    "entropy": 0.4070751965045929,
    "total_loss": 132.77492228746414
  },
  {
    "episode": 90,
    "avg_reward_per_step": -14.941022717113214,
    "episode_length": 3000,
    "policy_loss": 142.6571388244629,
    "value_loss": 3.3076826333999634,
    "entropy": 0.3718115910887718,
    "total_loss": 145.81609682142735
  },
  {
    "episode": 91,
    "avg_reward_per_step": -13.450011896481277,
    "episode_length": 3000,
    "policy_loss": 126.89613151550293,
    "value_loss": 2.53147155046463,
    "entropy": 0.3991258442401886,
    "total_loss": 129.2679527282715
  },
  {
    "episode": 92,
    "avg_reward_per_step": -13.989471159870266,
    "episode_length": 3000,
    "policy_loss": 131.71924591064453,
    "value_loss": 3.3903521299362183,
    "entropy": 0.37445343285799026,
    "total_loss": 134.95981666743756
  },
  {
    "episode": 93,
    "avg_reward_per_step": -14.725390486451964,
    "episode_length": 3000,
    "policy_loss": 138.45313262939453,
    "value_loss": 3.280445098876953,
    "entropy": 0.3623461201786995,
    "total_loss": 141.5886392802
  },
  {
    "episode": 94,
    "avg_reward_per_step": -14.319023906337568,
    "episode_length": 3000,
    "policy_loss": 133.5456314086914,
    "value_loss": 3.285832643508911,
    "entropy": 0.3878927454352379,
    "total_loss": 136.67630695402622
  },
  {
    "episode": 95,
    "avg_reward_per_step": -14.707379786045749,
    "episode_length": 3000,
    "policy_loss": 136.34437942504883,
    "value_loss": 3.111944556236267,
    "entropy": 0.3150932192802429,
    "total_loss": 139.330286693573
  },
  {
    "episode": 96,
    "avg_reward_per_step": -14.622431300154803,
    "episode_length": 3000,
    "policy_loss": 134.4998435974121,
    "value_loss": 2.944565236568451,
    "entropy": 0.3223603293299675,
    "total_loss": 137.31546470224856
  },
  {
    "episode": 97,
    "avg_reward_per_step": -13.586972836406945,
    "episode_length": 3000,
    "policy_loss": 123.38631248474121,
    "value_loss": 2.6501671075820923,
    "entropy": 0.4229210913181305,
    "total_loss": 125.86731115579605
  },
  {
    "episode": 98,
    "avg_reward_per_step": -4.704120346926016,
    "episode_length": 2146,
    "policy_loss": 30.714811325073242,
    "value_loss": 0.5002968609333038,
    "entropy": 0.3887224346399307,
    "total_loss": 31.059619212150572
  },
  {
    "episode": 99,
    "avg_reward_per_step": -0.13956806733012186,
    "episode_length": 1757,
    "policy_loss": -16.67924928665161,
    "value_loss": 0.4999503046274185,
    "entropy": 0.433404766023159,
    "total_loss": -16.352660888433455
  },
  {
    "episode": 100,
    "avg_reward_per_step": 22.53908501747892,
    "episode_length": 570,
    "policy_loss": -254.36816787719727,
    "value_loss": 0.5075562000274658,
    "entropy": 0.3923640623688698,
    "total_loss": -254.01755730211735
  },
  {
    "episode": 101,
    "avg_reward_per_step": 0.43971668271608505,
    "episode_length": 1633,
    "policy_loss": -24.092177867889404,
    "value_loss": 0.4999890998005867,
    "entropy": 0.5118314474821091,
    "total_loss": -23.79692134708166
  },
  {
    "episode": 102,
    "avg_reward_per_step": 11.213740034388836,
    "episode_length": 1023,
    "policy_loss": -134.33002471923828,
    "value_loss": 0.5040204375982285,
    "entropy": 0.6758187115192413,
    "total_loss": -134.09633176624774
  },
  {
    "episode": 103,
    "avg_reward_per_step": 13.504736160836336,
    "episode_length": 840,
    "policy_loss": -158.2711067199707,
    "value_loss": 0.5043181031942368,
    "entropy": 0.6166496872901917,
    "total_loss": -158.01344849169254
  },
  {
    "episode": 104,
    "avg_reward_per_step": 57.09723784973518,
    "episode_length": 306,
    "policy_loss": -611.2915802001953,
    "value_loss": 0.5257346332073212,
    "entropy": 0.6235663890838623,
    "total_loss": -611.0152721226216
  },
  {
    "episode": 105,
    "avg_reward_per_step": 18.34208761106937,
    "episode_length": 979,
    "policy_loss": -204.77573013305664,
    "value_loss": 0.5097298622131348,
    "entropy": 0.7566606253385544,
    "total_loss": -204.56866452097893
  },
  {
    "episode": 106,
    "avg_reward_per_step": 61.9192273941347,
    "episode_length": 302,
    "policy_loss": -658.3638000488281,
    "value_loss": 0.5301474779844284,
    "entropy": 0.6581168621778488,
    "total_loss": -658.0968993157148
  },
  {
    "episode": 107,
    "avg_reward_per_step": 33.47377109758808,
    "episode_length": 487,
    "policy_loss": -366.18336486816406,
    "value_loss": 0.5143741071224213,
    "entropy": 0.6409218907356262,
    "total_loss": -365.9253595173359
  },
  {
    "episode": 108,
    "avg_reward_per_step": 126.359354529595,
    "episode_length": 158,
    "policy_loss": -1324.2481994628906,
    "value_loss": 0.5690620243549347,
    "entropy": 0.6527945697307587,
    "total_loss": -1323.940255266428
  },
  {
    "episode": 109,
    "avg_reward_per_step": 81.20564973174116,
    "episode_length": 235,
    "policy_loss": -858.9404754638672,
    "value_loss": 0.5409409552812576,
    "entropy": 0.7266860157251358,
    "total_loss": -858.6902089148759
  },
  {
    "episode": 110,
    "avg_reward_per_step": -9.167472721513164,
    "episode_length": 3000,
    "policy_loss": 75.06514358520508,
    "value_loss": 1.2731956839561462,
    "entropy": 0.5760138928890228,
    "total_loss": 76.10793371200562
  },
  {
    "episode": 111,
    "avg_reward_per_step": -9.387379367119685,
    "episode_length": 3000,
    "policy_loss": 77.26119995117188,
    "value_loss": 1.4236771762371063,
    "entropy": 0.5995108634233475,
    "total_loss": 78.44507278203965
  },
  {
    "episode": 112,
    "avg_reward_per_step": 72.39273152439917,
    "episode_length": 264,
    "policy_loss": -772.4140472412109,
    "value_loss": 0.5367504060268402,
    "entropy": 0.6818585693836212,
    "total_loss": -772.1500402629375
  },
  {
    "episode": 113,
    "avg_reward_per_step": -8.47863578862154,
    "episode_length": 3000,
    "policy_loss": 68.06520652770996,
    "value_loss": 1.2163249850273132,
    "entropy": 0.629417285323143,
    "total_loss": 69.02976459860801
  },
  {
    "episode": 114,
    "avg_reward_per_step": 253.69253227542214,
    "episode_length": 79,
    "policy_loss": -2658.3907470703125,
    "value_loss": 0.6591521352529526,
    "entropy": 0.7216663807630539,
    "total_loss": -2658.0202614873647
  },
  {
    "episode": 115,
    "avg_reward_per_step": -9.763567553081764,
    "episode_length": 3000,
    "policy_loss": 79.60321426391602,
    "value_loss": 1.4232004284858704,
    "entropy": 0.6214190274477005,
    "total_loss": 80.7778470814228
  },
  {
    "episode": 116,
    "avg_reward_per_step": 66.72882284329633,
    "episode_length": 265,
    "policy_loss": -720.9589080810547,
    "value_loss": 0.5306375026702881,
    "entropy": 0.6770384758710861,
    "total_loss": -720.6990859687328
  },
  {
    "episode": 117,
    "avg_reward_per_step": 131.74069830067182,
    "episode_length": 148,
    "policy_loss": -1386.2965393066406,
    "value_loss": 0.5707054883241653,
    "entropy": 0.6783022433519363,
    "total_loss": -1385.9971547156572
  },
  {
    "episode": 118,
    "avg_reward_per_step": 84.27765534771096,
    "episode_length": 223,
    "policy_loss": -897.9830627441406,
    "value_loss": 0.5420088469982147,
    "entropy": 0.5897839814424515,
    "total_loss": -897.6769674897193
  },
  {
    "episode": 119,
    "avg_reward_per_step": -9.938377552047918,
    "episode_length": 3000,
    "policy_loss": 80.80106735229492,
    "value_loss": 1.3939786851406097,
    "entropy": 0.5236312225461006,
    "total_loss": 81.98559354841709
  },
  {
    "episode": 120,
    "avg_reward_per_step": 42.7998830841906,
    "episode_length": 376,
    "policy_loss": -463.9618606567383,
    "value_loss": 0.5180713683366776,
    "entropy": 0.36227254569530487,
    "total_loss": -463.5886983066797
  },
  {
    "episode": 121,
    "avg_reward_per_step": -11.897310116899742,
    "episode_length": 3000,
    "policy_loss": 99.66218948364258,
    "value_loss": 1.5073038339614868,
    "entropy": 0.45289016515016556,
    "total_loss": 100.988337251544
  },
  {
    "episode": 122,
    "avg_reward_per_step": -12.151466407363417,
    "episode_length": 3000,
    "policy_loss": 101.52524185180664,
    "value_loss": 1.5070668756961823,
    "entropy": 0.4284013584256172,
    "total_loss": 102.86094818413258
  },
  {
    "episode": 123,
    "avg_reward_per_step": 274.8748468408678,
    "episode_length": 73,
    "policy_loss": -2892.6273803710938,
    "value_loss": 0.6777002364397049,
    "entropy": 0.47804808616638184,
    "total_loss": -2892.1408993691207
  },
  {
    "episode": 124,
    "avg_reward_per_step": 13.77728805610418,
    "episode_length": 862,
    "policy_loss": -167.3648223876953,
    "value_loss": 0.5052399337291718,
    "entropy": 0.37358901649713516,
    "total_loss": -167.00901806056498
  },
  {
    "episode": 125,
    "avg_reward_per_step": 17.67578735425972,
    "episode_length": 911,
    "policy_loss": -206.4437141418457,
    "value_loss": 0.5089884102344513,
    "entropy": 0.39087188243865967,
    "total_loss": -206.09107448458673
  },
  {
    "episode": 126,
    "avg_reward_per_step": -10.419544732453177,
    "episode_length": 3000,
    "policy_loss": 81.93867301940918,
    "value_loss": 1.2422086894512177,
    "entropy": 0.47724224627017975,
    "total_loss": 82.98998481035233
  },
  {
    "episode": 127,
    "avg_reward_per_step": 45.52369974526484,
    "episode_length": 383,
    "policy_loss": -496.1563949584961,
    "value_loss": 0.5214645564556122,
    "entropy": 0.4200119823217392,
    "total_loss": -495.80293519496917
  },
  {
    "episode": 128,
    "avg_reward_per_step": 144.8656777816437,
    "episode_length": 138,
    "policy_loss": -1530.9573974609375,
    "value_loss": 0.5812417566776276,
    "entropy": 0.4194141924381256,
    "total_loss": -1530.5439213812351
  },
  {
    "episode": 129,
    "avg_reward_per_step": -10.722584897558137,
    "episode_length": 3000,
    "policy_loss": 84.8303337097168,
    "value_loss": 1.176528662443161,
    "entropy": 0.37910815328359604,
    "total_loss": 85.85521911084652
  },
  {
    "episode": 130,
    "avg_reward_per_step": -11.651777361629058,
    "episode_length": 3000,
    "policy_loss": 93.6972827911377,
    "value_loss": 1.2748010158538818,
    "entropy": 0.40796876698732376,
    "total_loss": 94.80889630019665
  },
  {
    "episode": 131,
    "avg_reward_per_step": 102.55178446496498,
    "episode_length": 194,
    "policy_loss": -1081.7589111328125,
    "value_loss": 0.555671364068985,
    "entropy": 0.39001545310020447,
    "total_loss": -1081.3592459499837
  },
  {
    "episode": 132,
    "avg_reward_per_step": -10.486624598905827,
    "episode_length": 3000,
    "policy_loss": 80.95119094848633,
    "value_loss": 1.0537661015987396,
    "entropy": 0.3883492201566696,
    "total_loss": 81.8496173620224
  },
  {
    "episode": 133,
    "avg_reward_per_step": -12.407209608123674,
    "episode_length": 3000,
    "policy_loss": 99.48702812194824,
    "value_loss": 1.4230186343193054,
    "entropy": 0.35114312916994095,
    "total_loss": 100.76958950459957
  },
  {
    "episode": 134,
    "avg_reward_per_step": 241.53725098011427,
    "episode_length": 83,
    "policy_loss": -2524.873046875,
    "value_loss": 0.65072862803936,
    "entropy": 0.33253537863492966,
    "total_loss": -2524.3553323984147
  },
  {
    "episode": 135,
    "avg_reward_per_step": -11.207217376014853,
    "episode_length": 3000,
    "policy_loss": 87.61461448669434,
    "value_loss": 1.208641916513443,
    "entropy": 0.35245227068662643,
    "total_loss": 88.68227549493312
  },
  {
    "episode": 136,
    "avg_reward_per_step": 5.56364273639531,
    "episode_length": 1401,
    "policy_loss": -86.28607177734375,
    "value_loss": 0.5021863132715225,
    "entropy": 0.18777959048748016,
    "total_loss": -85.85899730026722
  },
  {
    "episode": 137,
    "avg_reward_per_step": -13.57059247106854,
    "episode_length": 3000,
    "policy_loss": 110.1402816772461,
    "value_loss": 1.2854291498661041,
    "entropy": 0.2645071819424629,
    "total_loss": 111.3199079543352
  },
  {
    "episode": 138,
    "avg_reward_per_step": -11.207897596400386,
    "episode_length": 3000,
    "policy_loss": 86.07170486450195,
    "value_loss": 0.889159232378006,
    "entropy": 0.25707055628299713,
    "total_loss": 86.85803587436676
  },
  {
    "episode": 139,
    "avg_reward_per_step": 52.56744350638166,
    "episode_length": 377,
    "policy_loss": -573.6168060302734,
    "value_loss": 0.5287552028894424,
    "entropy": 0.10973358526825905,
    "total_loss": -573.1319442614913
  },
  {
    "episode": 140,
    "avg_reward_per_step": 45.65427108727266,
    "episode_length": 427,
    "policy_loss": -498.8531265258789,
    "value_loss": 0.5253545045852661,
    "entropy": 0.26441264897584915,
    "total_loss": -498.433537080884
  },
  {
    "episode": 141,
    "avg_reward_per_step": 92.06500647418179,
    "episode_length": 215,
    "policy_loss": -980.2021179199219,
    "value_loss": 0.5501505732536316,
    "entropy": 0.2951803058385849,
    "total_loss": -979.7700394690037
  },
  {
    "episode": 142,
    "avg_reward_per_step": 95.4957983460339,
    "episode_length": 209,
    "policy_loss": -1010.2524719238281,
    "value_loss": 0.5526723116636276,
    "entropy": 0.278814859688282,
    "total_loss": -1009.8113255560398
  },
  {
    "episode": 143,
    "avg_reward_per_step": 145.7091158767206,
    "episode_length": 137,
    "policy_loss": -1534.3902893066406,
    "value_loss": 0.5825402289628983,
    "entropy": 0.30259575694799423,
    "total_loss": -1533.928787380457
  },
  {
    "episode": 144,
    "avg_reward_per_step": -14.935149405885964,
    "episode_length": 3000,
    "policy_loss": 120.77109146118164,
    "value_loss": 1.8801255226135254,
    "entropy": 0.19409049302339554,
    "total_loss": 122.57358078658581
  },
  {
    "episode": 145,
    "avg_reward_per_step": 100.02781740160763,
    "episode_length": 199,
    "policy_loss": -1061.2367858886719,
    "value_loss": 0.555087074637413,
    "entropy": 0.29842445254325867,
    "total_loss": -1060.8010685950517
  },
  {
    "episode": 146,
    "avg_reward_per_step": 224.8085232919332,
    "episode_length": 89,
    "policy_loss": -2344.0006103515625,
    "value_loss": 0.6380226016044617,
    "entropy": 0.3230515718460083,
    "total_loss": -2343.4918083786965
  },
  {
    "episode": 147,
    "avg_reward_per_step": 214.96300232047565,
    "episode_length": 93,
    "policy_loss": -2261.2339477539062,
    "value_loss": 0.6304801106452942,
    "entropy": 0.2589677833020687,
    "total_loss": -2260.707054756582
  },
  {
    "episode": 148,
    "avg_reward_per_step": 161.29039313592688,
    "episode_length": 124,
    "policy_loss": -1689.7281494140625,
    "value_loss": 0.59286268055439,
    "entropy": 0.31733355671167374,
    "total_loss": -1689.2622201561928
  },
  {
    "episode": 149,
    "avg_reward_per_step": 238.37978292109545,
    "episode_length": 84,
    "policy_loss": -2512.8617553710938,
    "value_loss": 0.6487236768007278,
    "entropy": 0.3372771516442299,
    "total_loss": -2512.347942554951
  },
  {
    "episode": 150,
    "avg_reward_per_step": 132.10501720070855,
    "episode_length": 151,
    "policy_loss": -1378.5422668457031,
    "value_loss": 0.5743223577737808,
    "entropy": 0.2613750249147415,
    "total_loss": -1378.0724944978951
  },
  {
    "episode": 151,
    "avg_reward_per_step": 62.17167788802811,
    "episode_length": 318,
    "policy_loss": -669.5072784423828,
    "value_loss": 0.5342907309532166,
    "entropy": 0.27191708981990814,
    "total_loss": -669.0817545473576
  },
  {
    "episode": 152,
    "avg_reward_per_step": 33.565644363898464,
    "episode_length": 580,
    "policy_loss": -376.6316146850586,
    "value_loss": 0.5195783227682114,
    "entropy": 0.2595786228775978,
    "total_loss": -376.2158678114414
  },
  {
    "episode": 153,
    "avg_reward_per_step": 121.03876177418846,
    "episode_length": 165,
    "policy_loss": -1274.9490356445312,
    "value_loss": 0.5676888823509216,
    "entropy": 0.2558397874236107,
    "total_loss": -1274.4836826771498
  },
  {
    "episode": 154,
    "avg_reward_per_step": -16.078194928815016,
    "episode_length": 3000,
    "policy_loss": 130.6944694519043,
    "value_loss": 2.2322861552238464,
    "entropy": 0.21204275265336037,
    "total_loss": 132.8419385060668
  },
  {
    "episode": 155,
    "avg_reward_per_step": 260.5582541488759,
    "episode_length": 77,
    "policy_loss": -2721.153564453125,
    "value_loss": 0.6671421676874161,
    "entropy": 0.23875851929187775,
    "total_loss": -2720.5819256931545
  },
  {
    "episode": 156,
    "avg_reward_per_step": 257.0137547445294,
    "episode_length": 78,
    "policy_loss": -2684.188720703125,
    "value_loss": 0.6640445739030838,
    "entropy": 0.23934471234679222,
    "total_loss": -2683.620414014161
  },
  {
    "episode": 157,
    "avg_reward_per_step": 81.26618566578117,
    "episode_length": 244,
    "policy_loss": -867.0724945068359,
    "value_loss": 0.5445674657821655,
    "entropy": 0.26688623428344727,
    "total_loss": -866.6346815347672
  },
  {
    "episode": 158,
    "avg_reward_per_step": 121.51220082505009,
    "episode_length": 164,
    "policy_loss": -1283.4577331542969,
    "value_loss": 0.5679942071437836,
    "entropy": 0.21380138769745827,
    "total_loss": -1282.9752595022321
  },
  {
    "episode": 159,
    "avg_reward_per_step": 259.875680964504,
    "episode_length": 77,
    "policy_loss": -2711.5684814453125,
    "value_loss": 0.66612109541893,
    "entropy": 0.22271905839443207,
    "total_loss": -2710.9914479732515
  },
  {
    "episode": 160,
    "avg_reward_per_step": 120.6412588569833,
    "episode_length": 165,
    "policy_loss": -1272.1751403808594,
    "value_loss": 0.5673546493053436,
    "entropy": 0.22800682485103607,
    "total_loss": -1271.6989884614945
  },
  {
    "episode": 161,
    "avg_reward_per_step": 260.87575317984204,
    "episode_length": 77,
    "policy_loss": -2736.374267578125,
    "value_loss": 0.6678190380334854,
    "entropy": 0.1944393776357174,
    "total_loss": -2735.7842242911456
  },
  {
    "episode": 162,
    "avg_reward_per_step": 260.68141276101005,
    "episode_length": 77,
    "policy_loss": -2724.8294677734375,
    "value_loss": 0.6674594432115555,
    "entropy": 0.15359506011009216,
    "total_loss": -2724.22344635427
  },
  {
    "episode": 163,
    "avg_reward_per_step": 68.43092651620049,
    "episode_length": 291,
    "policy_loss": -733.0582122802734,
    "value_loss": 0.5380664765834808,
    "entropy": 0.17383655905723572,
    "total_loss": -732.5896804273128
  },
  {
    "episode": 164,
    "avg_reward_per_step": 29.717647237821417,
    "episode_length": 522,
    "policy_loss": -342.0409622192383,
    "value_loss": 0.5134379863739014,
    "entropy": 0.15573050826787949,
    "total_loss": -341.58981643617153
  },
  {
    "episode": 165,
    "avg_reward_per_step": 27.439705815044167,
    "episode_length": 590,
    "policy_loss": -317.3297576904297,
    "value_loss": 0.5133035778999329,
    "entropy": 0.16731613129377365,
    "total_loss": -316.8833805650473
  },
  {
    "episode": 166,
    "avg_reward_per_step": 282.493255765264,
    "episode_length": 71,
    "policy_loss": -2975.5280151367188,
    "value_loss": 0.6858671456575394,
    "entropy": 0.1706726998090744,
    "total_loss": -2974.9104170709847
  },
  {
    "episode": 167,
    "avg_reward_per_step": 27.376814454808486,
    "episode_length": 533,
    "policy_loss": -321.75611114501953,
    "value_loss": 0.5117104649543762,
    "entropy": 0.20991137251257896,
    "total_loss": -321.3283652290702
  },
  {
    "episode": 168,
    "avg_reward_per_step": 63.20591291623583,
    "episode_length": 295,
    "policy_loss": -687.0641174316406,
    "value_loss": 0.5323171466588974,
    "entropy": 0.2880851477384567,
    "total_loss": -686.6470343440772
  },
  {
    "episode": 169,
    "avg_reward_per_step": 152.92170327084128,
    "episode_length": 131,
    "policy_loss": -1614.2607116699219,
    "value_loss": 0.587746188044548,
    "entropy": 0.1243901364505291,
    "total_loss": -1613.7227215364576
  },
  {
    "episode": 170,
    "avg_reward_per_step": 271.3419945575822,
    "episode_length": 74,
    "policy_loss": -2833.97509765625,
    "value_loss": 0.6765001863241196,
    "entropy": 0.08876802772283554,
    "total_loss": -2833.334104681015
  },
  {
    "episode": 171,
    "avg_reward_per_step": 267.5592083221182,
    "episode_length": 75,
    "policy_loss": -2799.6954345703125,
    "value_loss": 0.673049807548523,
    "entropy": 0.16131296753883362,
    "total_loss": -2799.0869099497795
  },
  {
    "episode": 172,
    "avg_reward_per_step": 271.20516168871234,
    "episode_length": 74,
    "policy_loss": -2843.3527221679688,
    "value_loss": 0.6763258874416351,
    "entropy": 0.11495278589427471,
    "total_loss": -2842.722377394885
  },
  {
    "episode": 173,
    "avg_reward_per_step": -4.832715806459124,
    "episode_length": 3000,
    "policy_loss": 18.819573402404785,
    "value_loss": 0.4904327467083931,
    "entropy": 0.1947634220123291,
    "total_loss": 19.232100780308247
  },
  {
    "episode": 174,
    "avg_reward_per_step": 282.2360453457721,
    "episode_length": 71,
    "policy_loss": -2959.558349609375,
    "value_loss": 0.6852746307849884,
    "entropy": 0.1734686866402626,
    "total_loss": -2958.942462453246
  },
  {
    "episode": 175,
    "avg_reward_per_step": 157.72466146323842,
    "episode_length": 127,
    "policy_loss": -1651.1348876953125,
    "value_loss": 0.590772956609726,
    "entropy": 0.12522908300161362,
    "total_loss": -1650.5942063719035
  },
  {
    "episode": 176,
    "avg_reward_per_step": 286.29026405820576,
    "episode_length": 70,
    "policy_loss": -2981.307861328125,
    "value_loss": 0.6887614876031876,
    "entropy": 0.15482979267835617,
    "total_loss": -2980.6810317575932
  },
  {
    "episode": 177,
    "avg_reward_per_step": 22.438608725672832,
    "episode_length": 794,
    "policy_loss": -260.32118225097656,
    "value_loss": 0.5129178166389465,
    "entropy": 0.1983247920870781,
    "total_loss": -259.8875943511724
  },
  {
    "episode": 178,
    "avg_reward_per_step": 271.2855416233587,
    "episode_length": 74,
    "policy_loss": -2857.9915771484375,
    "value_loss": 0.67601577937603,
    "entropy": 0.15730037912726402,
    "total_loss": -2857.3784815207123
  },
  {
    "episode": 179,
    "avg_reward_per_step": 25.423443464565583,
    "episode_length": 763,
    "policy_loss": -288.8911437988281,
    "value_loss": 0.5156116932630539,
    "entropy": 0.12343994528055191,
    "total_loss": -288.4249080836773
  },
  {
    "episode": 180,
    "avg_reward_per_step": 282.7141941359969,
    "episode_length": 71,
    "policy_loss": -2967.2872314453125,
    "value_loss": 0.6857507079839706,
    "entropy": 0.1470605581998825,
    "total_loss": -2966.6603049606083
  },
  {
    "episode": 181,
    "avg_reward_per_step": 107.80615373215785,
    "episode_length": 185,
    "policy_loss": -1136.3123168945312,
    "value_loss": 0.5598283857107162,
    "entropy": 0.12883281335234642,
    "total_loss": -1135.8040216341615
  },
  {
    "episode": 182,
    "avg_reward_per_step": 271.2604344880858,
    "episode_length": 74,
    "policy_loss": -2839.1024780273438,
    "value_loss": 0.6760685443878174,
    "entropy": 0.13900867104530334,
    "total_loss": -2838.482012951374
  },
  {
    "episode": 183,
    "avg_reward_per_step": 267.30412557389394,
    "episode_length": 75,
    "policy_loss": -2832.6228637695312,
    "value_loss": 0.6725367456674576,
    "entropy": 0.11349519900977612,
    "total_loss": -2831.9957251034675
  },
  {
    "episode": 184,
    "avg_reward_per_step": 274.9714799416631,
    "episode_length": 73,
    "policy_loss": -2865.063720703125,
    "value_loss": 0.6790634989738464,
    "entropy": 0.09879602119326591,
    "total_loss": -2864.4241756126285
  },
  {
    "episode": 185,
    "avg_reward_per_step": 267.0665666473925,
    "episode_length": 75,
    "policy_loss": -2810.6417846679688,
    "value_loss": 0.6719710677862167,
    "entropy": 0.0887794978916645,
    "total_loss": -2810.005325399339
  },
  {
    "episode": 186,
    "avg_reward_per_step": 278.63853255450476,
    "episode_length": 72,
    "policy_loss": -2952.3347778320312,
    "value_loss": 0.6821947246789932,
    "entropy": 0.14715313166379929,
    "total_loss": -2951.7114443600176
  },
  {
    "episode": 187,
    "avg_reward_per_step": 56.874201114908374,
    "episode_length": 310,
    "policy_loss": -609.1283416748047,
    "value_loss": 0.5270757377147675,
    "entropy": 0.19733429700136185,
    "total_loss": -608.6801996558904
  },
  {
    "episode": 188,
    "avg_reward_per_step": 154.19038749543122,
    "episode_length": 130,
    "policy_loss": -1620.7178039550781,
    "value_loss": 0.5884639322757721,
    "entropy": 0.09807828813791275,
    "total_loss": -1620.1685713380575
  },
  {
    "episode": 189,
    "avg_reward_per_step": 66.32834158012646,
    "episode_length": 299,
    "policy_loss": -712.4433135986328,
    "value_loss": 0.536323294043541,
    "entropy": 0.08796242624521255,
    "total_loss": -711.9421752750874
  },
  {
    "episode": 190,
    "avg_reward_per_step": 110.27302886170204,
    "episode_length": 181,
    "policy_loss": -1165.753173828125,
    "value_loss": 0.5610676854848862,
    "entropy": 0.08940814808011055,
    "total_loss": -1165.227869401872
  },
  {
    "episode": 191,
    "avg_reward_per_step": 84.30169528080074,
    "episode_length": 232,
    "policy_loss": -901.1376647949219,
    "value_loss": 0.5449398905038834,
    "entropy": 0.23860353603959084,
    "total_loss": -900.6881663188339
  },
  {
    "episode": 192,
    "avg_reward_per_step": 116.76943105355907,
    "episode_length": 169,
    "policy_loss": -1254.9560241699219,
    "value_loss": 0.5634703934192657,
    "entropy": 0.23355483636260033,
    "total_loss": -1254.4859757110476
  },
  {
    "episode": 193,
    "avg_reward_per_step": 290.67039333548075,
    "episode_length": 69,
    "policy_loss": -3013.0529174804688,
    "value_loss": 0.6926126778125763,
    "entropy": 0.060456995852291584,
    "total_loss": -3012.384487600997
  },
  {
    "episode": 194,
    "avg_reward_per_step": 282.9468368568261,
    "episode_length": 71,
    "policy_loss": -2935.6585083007812,
    "value_loss": 0.6860955357551575,
    "entropy": 0.06663739122450352,
    "total_loss": -2934.999067721516
  },
  {
    "episode": 195,
    "avg_reward_per_step": 133.22593332721465,
    "episode_length": 149,
    "policy_loss": -1410.1219787597656,
    "value_loss": 0.573601245880127,
    "entropy": 0.20346363633871078,
    "total_loss": -1409.629762968421
  },
  {
    "episode": 196,
    "avg_reward_per_step": 274.9867211139525,
    "episode_length": 73,
    "policy_loss": -2854.764404296875,
    "value_loss": 0.6790729761123657,
    "entropy": 0.06338785868138075,
    "total_loss": -2854.110686464235
  },
  {
    "episode": 197,
    "avg_reward_per_step": 283.04586034133155,
    "episode_length": 71,
    "policy_loss": -2935.8530883789062,
    "value_loss": 0.6862605065107346,
    "entropy": 0.07761016674339771,
    "total_loss": -2935.1978719390927
  },
  {
    "episode": 198,
    "avg_reward_per_step": 282.82377455105257,
    "episode_length": 71,
    "policy_loss": -2931.9005126953125,
    "value_loss": 0.6859841495752335,
    "entropy": 0.0477020563557744,
    "total_loss": -2931.2336093682798
  },
  {
    "episode": 199,
    "avg_reward_per_step": 148.82907600490216,
    "episode_length": 132,
    "policy_loss": -1562.9617004394531,
    "value_loss": 0.582396999001503,
    "entropy": 0.156497273594141,
    "total_loss": -1562.4419023498892
  },
  {
    "episode": 200,
    "avg_reward_per_step": 150.4821601397062,
    "episode_length": 132,
    "policy_loss": -1573.3338012695312,
    "value_loss": 0.5840832591056824,
    "entropy": 0.14263932034373283,
    "total_loss": -1572.8067737385632
  },
  {
    "episode": 201,
    "avg_reward_per_step": 155.64706974055633,
    "episode_length": 127,
    "policy_loss": -1627.8122863769531,
    "value_loss": 0.5872627645730972,
    "entropy": 0.1409962922334671,
    "total_loss": -1627.2814221292733
  },
  {
    "episode": 202,
    "avg_reward_per_step": 283.04586034133155,
    "episode_length": 71,
    "policy_loss": -2931.3928833007812,
    "value_loss": 0.686202883720398,
    "entropy": 0.060835737735033035,
    "total_loss": -2930.731014712155
  },
  {
    "episode": 203,
    "avg_reward_per_step": 45.61164459145092,
    "episode_length": 427,
    "policy_loss": -500.29664611816406,
    "value_loss": 0.5248042345046997,
    "entropy": 0.11306892707943916,
    "total_loss": -499.81706945449116
  },
  {
    "episode": 204,
    "avg_reward_per_step": 283.145408995811,
    "episode_length": 71,
    "policy_loss": -2930.898681640625,
    "value_loss": 0.686334952712059,
    "entropy": 0.060957551933825016,
    "total_loss": -2930.2367297086867
  },
  {
    "episode": 205,
    "avg_reward_per_step": 286.9381730301938,
    "episode_length": 70,
    "policy_loss": -2975.416015625,
    "value_loss": 0.6894528418779373,
    "entropy": 0.08161486312747002,
    "total_loss": -2974.759208728373
  },
  {
    "episode": 206,
    "avg_reward_per_step": 295.11050345302385,
    "episode_length": 68,
    "policy_loss": -3055.2244262695312,
    "value_loss": 0.6965708136558533,
    "entropy": 0.046676307916641235,
    "total_loss": -3054.546525979042
  },
  {
    "episode": 207,
    "avg_reward_per_step": 290.43061505197375,
    "episode_length": 69,
    "policy_loss": -3009.6730346679688,
    "value_loss": 0.692080020904541,
    "entropy": 0.06481230910867453,
    "total_loss": -3009.0068795707075
  },
  {
    "episode": 208,
    "avg_reward_per_step": 286.769731684288,
    "episode_length": 70,
    "policy_loss": -2967.6273193359375,
    "value_loss": 0.6890694499015808,
    "entropy": 0.0530310170724988,
    "total_loss": -2966.959462292865
  },
  {
    "episode": 209,
    "avg_reward_per_step": 283.13038844640414,
    "episode_length": 71,
    "policy_loss": -2931.0387573242188,
    "value_loss": 0.6861853152513504,
    "entropy": 0.04855951387435198,
    "total_loss": -2930.371995814517
  },
  {
    "episode": 210,
    "avg_reward_per_step": 270.95908743148084,
    "episode_length": 74,
    "policy_loss": -2807.9025268554688,
    "value_loss": 0.6750427633523941,
    "entropy": 0.05224821995943785,
    "total_loss": -2807.2483833801
  },
  {
    "episode": 211,
    "avg_reward_per_step": 152.2557456939515,
    "episode_length": 130,
    "policy_loss": -1593.5185241699219,
    "value_loss": 0.5849687308073044,
    "entropy": 0.11810422874987125,
    "total_loss": -1592.9807971306145
  },
  {
    "episode": 212,
    "avg_reward_per_step": 126.56541127847346,
    "episode_length": 152,
    "policy_loss": -1325.6369934082031,
    "value_loss": 0.566817581653595,
    "entropy": 0.1468910351395607,
    "total_loss": -1325.1289322406053
  },
  {
    "episode": 213,
    "avg_reward_per_step": 164.2501165561198,
    "episode_length": 121,
    "policy_loss": -1717.4815063476562,
    "value_loss": 0.5929618030786514,
    "entropy": 0.1369245983660221,
    "total_loss": -1716.943314383924
  },
  {
    "episode": 214,
    "avg_reward_per_step": 283.04586034133155,
    "episode_length": 71,
    "policy_loss": -2928.7342529296875,
    "value_loss": 0.6858756989240646,
    "entropy": 0.046066674403846264,
    "total_loss": -2928.066803900525
  },
  {
    "episode": 215,
    "avg_reward_per_step": 283.04586034133155,
    "episode_length": 71,
    "policy_loss": -2928.4786987304688,
    "value_loss": 0.685846820473671,
    "entropy": 0.047063170932233334,
    "total_loss": -2927.811677178368
  },
  {
    "episode": 216,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2930.168212890625,
    "value_loss": 0.6860799193382263,
    "entropy": 0.04722369462251663,
    "total_loss": -2929.5010224491357
  },
  {
    "episode": 217,
    "avg_reward_per_step": 286.769731684288,
    "episode_length": 70,
    "policy_loss": -2965.8137817382812,
    "value_loss": 0.6887775659561157,
    "entropy": 0.04672364331781864,
    "total_loss": -2965.1436936296523
  },
  {
    "episode": 218,
    "avg_reward_per_step": 283.0772462101199,
    "episode_length": 71,
    "policy_loss": -2927.9954833984375,
    "value_loss": 0.6858046799898148,
    "entropy": 0.04786630067974329,
    "total_loss": -2927.3288252387197
  },
  {
    "episode": 219,
    "avg_reward_per_step": 191.48021295400864,
    "episode_length": 104,
    "policy_loss": -2009.9456481933594,
    "value_loss": 0.6122382879257202,
    "entropy": 0.1304340772330761,
    "total_loss": -2009.385583536327
  },
  {
    "episode": 220,
    "avg_reward_per_step": 283.0205235141456,
    "episode_length": 71,
    "policy_loss": -2926.81396484375,
    "value_loss": 0.6855674833059311,
    "entropy": 0.04123314656317234,
    "total_loss": -2926.1448906190694
  },
  {
    "episode": 221,
    "avg_reward_per_step": 283.04586034133155,
    "episode_length": 71,
    "policy_loss": -2926.1609497070312,
    "value_loss": 0.6855183094739914,
    "entropy": 0.047476950101554394,
    "total_loss": -2925.4944221775977
  },
  {
    "episode": 222,
    "avg_reward_per_step": 283.145408995811,
    "episode_length": 71,
    "policy_loss": -2927.2192993164062,
    "value_loss": 0.6855831444263458,
    "entropy": 0.04247354529798031,
    "total_loss": -2926.550705590099
  },
  {
    "episode": 223,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2926.909423828125,
    "value_loss": 0.6856313496828079,
    "entropy": 0.032525768503546715,
    "total_loss": -2926.236802785844
  },
  {
    "episode": 224,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2926.7550048828125,
    "value_loss": 0.6855790466070175,
    "entropy": 0.031177384313195944,
    "total_loss": -2926.081896789931
  },
  {
    "episode": 225,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2926.5032958984375,
    "value_loss": 0.6855318695306778,
    "entropy": 0.02898932108655572,
    "total_loss": -2925.8293597573415
  },
  {
    "episode": 226,
    "avg_reward_per_step": 283.145408995811,
    "episode_length": 71,
    "policy_loss": -2925.7969360351562,
    "value_loss": 0.685373842716217,
    "entropy": 0.03676981385797262,
    "total_loss": -2925.126270117983
  },
  {
    "episode": 227,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2925.6043090820312,
    "value_loss": 0.6854386925697327,
    "entropy": 0.025276809465140104,
    "total_loss": -2924.9289811132476
  },
  {
    "episode": 228,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2925.5699462890625,
    "value_loss": 0.6853923946619034,
    "entropy": 0.02465627947822213,
    "total_loss": -2924.894416406192
  },
  {
    "episode": 229,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2925.271484375,
    "value_loss": 0.6853485852479935,
    "entropy": 0.024123672861605883,
    "total_loss": -2924.5957852588967
  },
  {
    "episode": 230,
    "avg_reward_per_step": 287.0774828932059,
    "episode_length": 70,
    "policy_loss": -2965.50244140625,
    "value_loss": 0.6885738372802734,
    "entropy": 0.03941511083394289,
    "total_loss": -2964.8296336133035
  },
  {
    "episode": 231,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2924.4605102539062,
    "value_loss": 0.6852637976408005,
    "entropy": 0.026447813026607037,
    "total_loss": -2923.7858255814763
  },
  {
    "episode": 232,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2924.206787109375,
    "value_loss": 0.6852191686630249,
    "entropy": 0.02567926235496998,
    "total_loss": -2923.531839645654
  },
  {
    "episode": 233,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2923.9044189453125,
    "value_loss": 0.685172438621521,
    "entropy": 0.023112202994525433,
    "total_loss": -2923.228491387889
  },
  {
    "episode": 234,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2923.5711669921875,
    "value_loss": 0.6851239800453186,
    "entropy": 0.020121692679822445,
    "total_loss": -2922.8940916892143
  },
  {
    "episode": 235,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2923.2308959960938,
    "value_loss": 0.6850743591785431,
    "entropy": 0.017596862744539976,
    "total_loss": -2922.552860382013
  },
  {
    "episode": 236,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2922.8948974609375,
    "value_loss": 0.6850241869688034,
    "entropy": 0.015797217143699527,
    "total_loss": -2922.2161921608263
  },
  {
    "episode": 237,
    "avg_reward_per_step": 119.03482375914712,
    "episode_length": 167,
    "policy_loss": -1242.4794311523438,
    "value_loss": 0.5647566318511963,
    "entropy": 0.07374367490410805,
    "total_loss": -1241.9441719904542
  },
  {
    "episode": 238,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2922.2206420898438,
    "value_loss": 0.684923455119133,
    "entropy": 0.015059442725032568,
    "total_loss": -2921.5417424118145
  },
  {
    "episode": 239,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2921.8317260742188,
    "value_loss": 0.6848697513341904,
    "entropy": 0.0141175608150661,
    "total_loss": -2921.1525033472108
  },
  {
    "episode": 240,
    "avg_reward_per_step": 283.145408995811,
    "episode_length": 71,
    "policy_loss": -2921.5877075195312,
    "value_loss": 0.6846970170736313,
    "entropy": 0.025053671561181545,
    "total_loss": -2920.913031971082
  },
  {
    "episode": 241,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2921.1031494140625,
    "value_loss": 0.6847646236419678,
    "entropy": 0.013126651756465435,
    "total_loss": -2920.423635451123
  },
  {
    "episode": 242,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2920.7894897460938,
    "value_loss": 0.6847133636474609,
    "entropy": 0.013683590106666088,
    "total_loss": -2920.110249818489
  },
  {
    "episode": 243,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2920.4680786132812,
    "value_loss": 0.6846615672111511,
    "entropy": 0.014065317111089826,
    "total_loss": -2919.7890431729147
  },
  {
    "episode": 244,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2920.1304931640625,
    "value_loss": 0.684609055519104,
    "entropy": 0.014284467324614525,
    "total_loss": -2919.4515978954732
  },
  {
    "episode": 245,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2919.7783203125,
    "value_loss": 0.6845555901527405,
    "entropy": 0.014365025097504258,
    "total_loss": -2919.099510732386
  },
  {
    "episode": 246,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2919.4152221679688,
    "value_loss": 0.6845008730888367,
    "entropy": 0.014304784592241049,
    "total_loss": -2918.736443208717
  },
  {
    "episode": 247,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2919.0462036132812,
    "value_loss": 0.6844451874494553,
    "entropy": 0.01408670749515295,
    "total_loss": -2918.3673931088297
  },
  {
    "episode": 248,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2918.67138671875,
    "value_loss": 0.6843883246183395,
    "entropy": 0.013726836536079645,
    "total_loss": -2917.992489128746
  },
  {
    "episode": 249,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2918.291015625,
    "value_loss": 0.684330478310585,
    "entropy": 0.013267446076497436,
    "total_loss": -2917.61199212512
  },
  {
    "episode": 250,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2917.9055786132812,
    "value_loss": 0.6842718124389648,
    "entropy": 0.012765694409608841,
    "total_loss": -2917.226413078606
  },
  {
    "episode": 251,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2917.5153198242188,
    "value_loss": 0.6842122822999954,
    "entropy": 0.01227525225840509,
    "total_loss": -2916.8360176428223
  },
  {
    "episode": 252,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2917.1217041015625,
    "value_loss": 0.684152364730835,
    "entropy": 0.011813336284831166,
    "total_loss": -2916.4422770713454
  },
  {
    "episode": 253,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3040.8292846679688,
    "value_loss": 0.6946685016155243,
    "entropy": 0.018534664530307055,
    "total_loss": -3040.142030032165
  },
  {
    "episode": 254,
    "avg_reward_per_step": 283.145408995811,
    "episode_length": 71,
    "policy_loss": -2916.4436645507812,
    "value_loss": 0.6839049607515335,
    "entropy": 0.018414787016808987,
    "total_loss": -2915.7671255048363
  },
  {
    "episode": 255,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2915.8795776367188,
    "value_loss": 0.6839640438556671,
    "entropy": 0.011855173856019974,
    "total_loss": -2915.2003556624054
  },
  {
    "episode": 256,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2915.4716796875,
    "value_loss": 0.6838988363742828,
    "entropy": 0.011808202369138598,
    "total_loss": -2914.792504132073
  },
  {
    "episode": 257,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2915.0794067382812,
    "value_loss": 0.6838350296020508,
    "entropy": 0.011855752905830741,
    "total_loss": -2914.4003140098416
  },
  {
    "episode": 258,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2914.682861328125,
    "value_loss": 0.6837718039751053,
    "entropy": 0.011854003183543682,
    "total_loss": -2914.0038311254234
  },
  {
    "episode": 259,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2914.2730102539062,
    "value_loss": 0.6837088167667389,
    "entropy": 0.011853164993226528,
    "total_loss": -2913.594042703137
  },
  {
    "episode": 260,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2913.8521728515625,
    "value_loss": 0.6836455017328262,
    "entropy": 0.01190721313469112,
    "total_loss": -2913.1732902350836
  },
  {
    "episode": 261,
    "avg_reward_per_step": 282.74852105317893,
    "episode_length": 71,
    "policy_loss": -2911.7078247070312,
    "value_loss": 0.6828746795654297,
    "entropy": 0.02894058497622609,
    "total_loss": -2911.0365262614564
  },
  {
    "episode": 262,
    "avg_reward_per_step": 86.22158610337918,
    "episode_length": 229,
    "policy_loss": -899.1585693359375,
    "value_loss": 0.5447129011154175,
    "entropy": 0.0901745893061161,
    "total_loss": -898.6499262705445
  },
  {
    "episode": 263,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2912.5170288085938,
    "value_loss": 0.6834255158901215,
    "entropy": 0.012126746820285916,
    "total_loss": -2911.838453991432
  },
  {
    "episode": 264,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2912.0765991210938,
    "value_loss": 0.6833546757698059,
    "entropy": 0.011577842058613896,
    "total_loss": -2911.397875582147
  },
  {
    "episode": 265,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2911.6043701171875,
    "value_loss": 0.6832865476608276,
    "entropy": 0.010567930527031422,
    "total_loss": -2910.9253107417376
  },
  {
    "episode": 266,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2911.12548828125,
    "value_loss": 0.6832191050052643,
    "entropy": 0.009851281996816397,
    "total_loss": -2910.4462096890434
  },
  {
    "episode": 267,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2910.6611938476562,
    "value_loss": 0.6831512153148651,
    "entropy": 0.009577443823218346,
    "total_loss": -2909.9818736098705
  },
  {
    "episode": 268,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2910.2039184570312,
    "value_loss": 0.683082327246666,
    "entropy": 0.009591483045369387,
    "total_loss": -2909.524672723003
  },
  {
    "episode": 269,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2909.7474365234375,
    "value_loss": 0.6830122768878937,
    "entropy": 0.009701189119368792,
    "total_loss": -2909.0683047221974
  },
  {
    "episode": 270,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2909.28662109375,
    "value_loss": 0.6829409003257751,
    "entropy": 0.009779842337593436,
    "total_loss": -2908.607592130359
  },
  {
    "episode": 271,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2908.8197631835938,
    "value_loss": 0.682868480682373,
    "entropy": 0.009777743835002184,
    "total_loss": -2908.1408058004454
  },
  {
    "episode": 272,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2908.34765625,
    "value_loss": 0.6827950775623322,
    "entropy": 0.009693705709651113,
    "total_loss": -2907.6687386547214
  },
  {
    "episode": 273,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2907.8701171875,
    "value_loss": 0.6827210187911987,
    "entropy": 0.009546336950734258,
    "total_loss": -2907.191214703489
  },
  {
    "episode": 274,
    "avg_reward_per_step": 286.769731684288,
    "episode_length": 70,
    "policy_loss": -2943.8778076171875,
    "value_loss": 0.6853745728731155,
    "entropy": 0.017146712634712458,
    "total_loss": -2943.1992917293683
  },
  {
    "episode": 275,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2906.912353515625,
    "value_loss": 0.6825762689113617,
    "entropy": 0.010982184205204248,
    "total_loss": -2906.234170120396
  },
  {
    "episode": 276,
    "avg_reward_per_step": 286.769731684288,
    "episode_length": 70,
    "policy_loss": -2942.96875,
    "value_loss": 0.6852304637432098,
    "entropy": 0.01847268920391798,
    "total_loss": -2942.2909086119384
  },
  {
    "episode": 277,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2905.9747314453125,
    "value_loss": 0.6824297904968262,
    "entropy": 0.014786244370043278,
    "total_loss": -2905.298216152564
  },
  {
    "episode": 278,
    "avg_reward_per_step": 286.769731684288,
    "episode_length": 70,
    "policy_loss": -2942.001220703125,
    "value_loss": 0.685082197189331,
    "entropy": 0.021162553690373898,
    "total_loss": -2941.324603527412
  },
  {
    "episode": 279,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3029.025634765625,
    "value_loss": 0.6928417980670929,
    "entropy": 0.015832743607461452,
    "total_loss": -3028.339126065001
  },
  {
    "episode": 280,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2904.51708984375,
    "value_loss": 0.6822051107883453,
    "entropy": 0.023791294544935226,
    "total_loss": -2903.84440125078
  },
  {
    "episode": 281,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3027.9807739257812,
    "value_loss": 0.6926859021186829,
    "entropy": 0.0174262598156929,
    "total_loss": -3027.295058527589
  },
  {
    "episode": 282,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2903.5350952148438,
    "value_loss": 0.6820475906133652,
    "entropy": 0.026448187418282032,
    "total_loss": -2902.8636268991977
  },
  {
    "episode": 283,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2903.142822265625,
    "value_loss": 0.681963637471199,
    "entropy": 0.025846567936241627,
    "total_loss": -2902.471197255328
  },
  {
    "episode": 284,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2902.6102294921875,
    "value_loss": 0.6818768531084061,
    "entropy": 0.023013700265437365,
    "total_loss": -2901.9375581191853
  },
  {
    "episode": 285,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3025.6713256835938,
    "value_loss": 0.6923476904630661,
    "entropy": 0.015659800730645657,
    "total_loss": -3024.985241913423
  },
  {
    "episode": 286,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2901.3740844726562,
    "value_loss": 0.6817081272602081,
    "entropy": 0.01902621705085039,
    "total_loss": -2900.6999868322164
  },
  {
    "episode": 287,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3024.7029418945312,
    "value_loss": 0.6921803504228592,
    "entropy": 0.01563317538239062,
    "total_loss": -3024.0170148142615
  },
  {
    "episode": 288,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2900.2630615234375,
    "value_loss": 0.6815444529056549,
    "entropy": 0.020903310272842646,
    "total_loss": -2899.589878394641
  },
  {
    "episode": 289,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3023.6641845703125,
    "value_loss": 0.6920153200626373,
    "entropy": 0.016667854972183704,
    "total_loss": -3022.978836392239
  },
  {
    "episode": 290,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2899.200439453125,
    "value_loss": 0.6813805252313614,
    "entropy": 0.023800059221684933,
    "total_loss": -2898.5285789515824
  },
  {
    "episode": 291,
    "avg_reward_per_step": 286.769731684288,
    "episode_length": 70,
    "policy_loss": -2935.1029663085938,
    "value_loss": 0.6840232163667679,
    "entropy": 0.026238447055220604,
    "total_loss": -2934.4294384710493
  },
  {
    "episode": 292,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3022.0054931640625,
    "value_loss": 0.69176284968853,
    "entropy": 0.016928683500736952,
    "total_loss": -3021.3205017877744
  },
  {
    "episode": 293,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2897.6019287109375,
    "value_loss": 0.6811272501945496,
    "entropy": 0.025550752878189087,
    "total_loss": -2896.931021761894
  },
  {
    "episode": 294,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3020.8577270507812,
    "value_loss": 0.6915888637304306,
    "entropy": 0.01674789935350418,
    "total_loss": -3020.172837346792
  },
  {
    "episode": 295,
    "avg_reward_per_step": 282.74852105317893,
    "episode_length": 71,
    "policy_loss": -2893.9622802734375,
    "value_loss": 0.680245891213417,
    "entropy": 0.027982727624475956,
    "total_loss": -2893.293227473274
  },
  {
    "episode": 296,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3019.23828125,
    "value_loss": 0.6913646757602692,
    "entropy": 0.016683696769177914,
    "total_loss": -3018.5535900529476
  },
  {
    "episode": 297,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2894.9902954101562,
    "value_loss": 0.6807054877281189,
    "entropy": 0.01413009874522686,
    "total_loss": -2894.3152419619264
  },
  {
    "episode": 298,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2894.3018798828125,
    "value_loss": 0.6806042641401291,
    "entropy": 0.0125278914347291,
    "total_loss": -2893.626286775246
  },
  {
    "episode": 299,
    "avg_reward_per_step": 283.19217921373695,
    "episode_length": 71,
    "policy_loss": -2893.6504516601562,
    "value_loss": 0.6805079877376556,
    "entropy": 0.011613933136686683,
    "total_loss": -2892.974589245673
  },
  {
    "episode": 300,
    "avg_reward_per_step": 295.3698467224208,
    "episode_length": 68,
    "policy_loss": -3016.8795166015625,
    "value_loss": 0.6909743696451187,
    "entropy": 0.019017632119357586,
    "total_loss": -3016.196149284765
  }
]