[
  {
    "episode": 1,
    "avg_reward_per_step": 12.0632204431955,
    "episode_length": 1249,
    "policy_loss": -206.24854278564453,
    "value_loss": 0.507144570350647,
    "entropy": 1.3691886365413666,
    "total_loss": -206.28907366991044
  },
  {
    "episode": 2,
    "avg_reward_per_step": 39.69039147187729,
    "episode_length": 459,
    "policy_loss": -680.6797027587891,
    "value_loss": 0.5303193032741547,
    "entropy": 1.3422599732875824,
    "total_loss": -680.68628744483
  },
  {
    "episode": 3,
    "avg_reward_per_step": 63.42955645919509,
    "episode_length": 304,
    "policy_loss": -1078.4728393554688,
    "value_loss": 0.5537005811929703,
    "entropy": 1.2877421379089355,
    "total_loss": -1078.4342356294394
  },
  {
    "episode": 4,
    "avg_reward_per_step": 245.49902897201838,
    "episode_length": 81,
    "policy_loss": -4139.4091796875,
    "value_loss": 0.8162560164928436,
    "entropy": 1.263938844203949,
    "total_loss": -4139.098499208689
  },
  {
    "episode": 5,
    "avg_reward_per_step": 2.8559985286955363,
    "episode_length": 2254,
    "policy_loss": -47.87614059448242,
    "value_loss": 0.5005150735378265,
    "entropy": 1.29468435049057,
    "total_loss": -47.893499261140825
  },
  {
    "episode": 6,
    "avg_reward_per_step": 2.4845003113962965,
    "episode_length": 2785,
    "policy_loss": -42.22689628601074,
    "value_loss": 0.5004949122667313,
    "entropy": 1.3153835535049438,
    "total_loss": -42.25255479514599
  },
  {
    "episode": 7,
    "avg_reward_per_step": 13.79640315648701,
    "episode_length": 1050,
    "policy_loss": -232.55406188964844,
    "value_loss": 0.5077666789293289,
    "entropy": 1.2921917140483856,
    "total_loss": -232.56317189633847
  },
  {
    "episode": 8,
    "avg_reward_per_step": 8.267634654314756,
    "episode_length": 1351,
    "policy_loss": -139.16211318969727,
    "value_loss": 0.503397211432457,
    "entropy": 1.279429018497467,
    "total_loss": -139.1704875856638
  },
  {
    "episode": 9,
    "avg_reward_per_step": 8.52715048766126,
    "episode_length": 1630,
    "policy_loss": -143.74180221557617,
    "value_loss": 0.5045168399810791,
    "entropy": 1.310372769832611,
    "total_loss": -143.76143448352815
  },
  {
    "episode": 10,
    "avg_reward_per_step": 5.894755424323379,
    "episode_length": 1760,
    "policy_loss": -99.33312225341797,
    "value_loss": 0.5021734684705734,
    "entropy": 1.2715935409069061,
    "total_loss": -99.33958620131015
  },
  {
    "episode": 11,
    "avg_reward_per_step": 11.934954190832736,
    "episode_length": 1129,
    "policy_loss": -201.84025955200195,
    "value_loss": 0.5061526298522949,
    "entropy": 1.2701435387134552,
    "total_loss": -201.84216433763504
  },
  {
    "episode": 12,
    "avg_reward_per_step": 66.85000544452978,
    "episode_length": 276,
    "policy_loss": -1132.0959777832031,
    "value_loss": 0.5542330592870712,
    "entropy": 1.2627074420452118,
    "total_loss": -1132.0468277007342
  },
  {
    "episode": 13,
    "avg_reward_per_step": 4.812431889737736,
    "episode_length": 1943,
    "policy_loss": -81.65591621398926,
    "value_loss": 0.5015333890914917,
    "entropy": 1.2926446497440338,
    "total_loss": -81.67144068479539
  },
  {
    "episode": 14,
    "avg_reward_per_step": 22.920449412707576,
    "episode_length": 729,
    "policy_loss": -387.71521759033203,
    "value_loss": 0.5154198110103607,
    "entropy": 1.2880162298679352,
    "total_loss": -387.71500427126887
  },
  {
    "episode": 15,
    "avg_reward_per_step": 18.755024342932906,
    "episode_length": 936,
    "policy_loss": -314.84154510498047,
    "value_loss": 0.5132232308387756,
    "entropy": 1.3094711303710938,
    "total_loss": -314.85211032629013
  },
  {
    "episode": 16,
    "avg_reward_per_step": 15.469727528111285,
    "episode_length": 1053,
    "policy_loss": -262.4282684326172,
    "value_loss": 0.5099858492612839,
    "entropy": 1.2807470560073853,
    "total_loss": -262.43058140575886
  },
  {
    "episode": 17,
    "avg_reward_per_step": 46.195400951982855,
    "episode_length": 401,
    "policy_loss": -779.8546905517578,
    "value_loss": 0.5362699329853058,
    "entropy": 1.250312864780426,
    "total_loss": -779.8185457646847
  },
  {
    "episode": 18,
    "avg_reward_per_step": 8.444670225477,
    "episode_length": 1643,
    "policy_loss": -141.67247009277344,
    "value_loss": 0.5044132471084595,
    "entropy": 1.2963373959064484,
    "total_loss": -141.68659180402756
  },
  {
    "episode": 19,
    "avg_reward_per_step": 24.07298120738211,
    "episode_length": 719,
    "policy_loss": -407.4235534667969,
    "value_loss": 0.516732856631279,
    "entropy": 1.2760308384895325,
    "total_loss": -407.4172329455614
  },
  {
    "episode": 20,
    "avg_reward_per_step": 34.56058911389259,
    "episode_length": 493,
    "policy_loss": -591.5948181152344,
    "value_loss": 0.5239928811788559,
    "entropy": 1.2498048841953278,
    "total_loss": -591.5707471877337
  },
  {
    "episode": 21,
    "avg_reward_per_step": 45.19905131599128,
    "episode_length": 411,
    "policy_loss": -757.7962646484375,
    "value_loss": 0.5353860557079315,
    "entropy": 1.207455962896347,
    "total_loss": -757.7438609778881
  },
  {
    "episode": 22,
    "avg_reward_per_step": 15.910101616832145,
    "episode_length": 879,
    "policy_loss": -267.39747619628906,
    "value_loss": 0.5085591524839401,
    "entropy": 1.1661239564418793,
    "total_loss": -267.35536662638185
  },
  {
    "episode": 23,
    "avg_reward_per_step": 55.45683861269611,
    "episode_length": 345,
    "policy_loss": -939.1620330810547,
    "value_loss": 0.5455397516489029,
    "entropy": 1.2452405989170074,
    "total_loss": -939.1145895689726
  },
  {
    "episode": 24,
    "avg_reward_per_step": 2.289491804485363,
    "episode_length": 2178,
    "policy_loss": -37.79776954650879,
    "value_loss": 0.5001189857721329,
    "entropy": 1.1811383068561554,
    "total_loss": -37.77010588347912
  },
  {
    "episode": 25,
    "avg_reward_per_step": 8.984846178969933,
    "episode_length": 1460,
    "policy_loss": -151.31703567504883,
    "value_loss": 0.5043771117925644,
    "entropy": 1.208443820476532,
    "total_loss": -151.29603609144687
  },
  {
    "episode": 26,
    "avg_reward_per_step": 39.38910976992402,
    "episode_length": 444,
    "policy_loss": -671.0300598144531,
    "value_loss": 0.528589740395546,
    "entropy": 1.2066459953784943,
    "total_loss": -670.984128472209
  },
  {
    "episode": 27,
    "avg_reward_per_step": 8.511744614816978,
    "episode_length": 1605,
    "policy_loss": -141.74992752075195,
    "value_loss": 0.504289522767067,
    "entropy": 1.2494599223136902,
    "total_loss": -141.74542196691036
  },
  {
    "episode": 28,
    "avg_reward_per_step": 56.41012358752391,
    "episode_length": 336,
    "policy_loss": -956.5599365234375,
    "value_loss": 0.5461971461772919,
    "entropy": 1.2614775896072388,
    "total_loss": -956.5183304131031
  },
  {
    "episode": 29,
    "avg_reward_per_step": 21.79838399743604,
    "episode_length": 775,
    "policy_loss": -367.50797271728516,
    "value_loss": 0.5146177560091019,
    "entropy": 1.2473265528678894,
    "total_loss": -367.4922855824232
  },
  {
    "episode": 30,
    "avg_reward_per_step": 79.73973390230657,
    "episode_length": 245,
    "policy_loss": -1369.2650451660156,
    "value_loss": 0.5705853849649429,
    "entropy": 1.2645684480667114,
    "total_loss": -1369.2002871602774
  },
  {
    "episode": 31,
    "avg_reward_per_step": 23.101181042431566,
    "episode_length": 717,
    "policy_loss": -389.1584014892578,
    "value_loss": 0.5152534991502762,
    "entropy": 1.1437794268131256,
    "total_loss": -389.1006597608328
  },
  {
    "episode": 32,
    "avg_reward_per_step": 39.786902676650655,
    "episode_length": 433,
    "policy_loss": -671.3588409423828,
    "value_loss": 0.5282749384641647,
    "entropy": 1.0829500555992126,
    "total_loss": -671.2637460261583
  },
  {
    "episode": 33,
    "avg_reward_per_step": 23.20518593995845,
    "episode_length": 637,
    "policy_loss": -389.66854095458984,
    "value_loss": 0.5134840905666351,
    "entropy": 1.0079454481601715,
    "total_loss": -389.55823504328725
  },
  {
    "episode": 34,
    "avg_reward_per_step": 10.534991490684886,
    "episode_length": 1101,
    "policy_loss": -177.5501365661621,
    "value_loss": 0.5043489634990692,
    "entropy": 1.0335678458213806,
    "total_loss": -177.4592147409916
  },
  {
    "episode": 35,
    "avg_reward_per_step": 9.646772088826143,
    "episode_length": 1149,
    "policy_loss": -161.42253875732422,
    "value_loss": 0.5038043856620789,
    "entropy": 1.0376912653446198,
    "total_loss": -161.33381087779998
  },
  {
    "episode": 36,
    "avg_reward_per_step": 25.664417200428613,
    "episode_length": 607,
    "policy_loss": -434.01878356933594,
    "value_loss": 0.5159425288438797,
    "entropy": 1.0701391100883484,
    "total_loss": -433.9308966845274
  },
  {
    "episode": 37,
    "avg_reward_per_step": 33.294468619971234,
    "episode_length": 524,
    "policy_loss": -561.2898101806641,
    "value_loss": 0.5236255526542664,
    "entropy": 1.14217209815979,
    "total_loss": -561.2230534672738
  },
  {
    "episode": 38,
    "avg_reward_per_step": 113.747120168894,
    "episode_length": 169,
    "policy_loss": -1917.1812744140625,
    "value_loss": 0.6051962077617645,
    "entropy": 1.1336210668087006,
    "total_loss": -1917.0295266330243
  },
  {
    "episode": 39,
    "avg_reward_per_step": 28.25635316621251,
    "episode_length": 606,
    "policy_loss": -476.7193069458008,
    "value_loss": 0.5194351226091385,
    "entropy": 1.172977089881897,
    "total_loss": -476.6690626591444
  },
  {
    "episode": 40,
    "avg_reward_per_step": 39.454913373906166,
    "episode_length": 467,
    "policy_loss": -665.2718200683594,
    "value_loss": 0.5300498306751251,
    "entropy": 1.2183316946029663,
    "total_loss": -665.2291029155255
  },
  {
    "episode": 41,
    "avg_reward_per_step": 52.52444291594396,
    "episode_length": 356,
    "policy_loss": -883.0629730224609,
    "value_loss": 0.541700005531311,
    "entropy": 1.2168993651866913,
    "total_loss": -883.0080327630043
  },
  {
    "episode": 42,
    "avg_reward_per_step": 26.846951802971862,
    "episode_length": 627,
    "policy_loss": -452.0904006958008,
    "value_loss": 0.5181277841329575,
    "entropy": 1.1967114210128784,
    "total_loss": -452.05095748007295
  },
  {
    "episode": 43,
    "avg_reward_per_step": 2.279643348890982,
    "episode_length": 2556,
    "policy_loss": -35.68100070953369,
    "value_loss": 0.5001731961965561,
    "entropy": 1.1698185503482819,
    "total_loss": -35.64875493347645
  },
  {
    "episode": 44,
    "avg_reward_per_step": 23.39727848999459,
    "episode_length": 695,
    "policy_loss": -393.67044830322266,
    "value_loss": 0.5149578899145126,
    "entropy": 1.1428917348384857,
    "total_loss": -393.61264710724356
  },
  {
    "episode": 45,
    "avg_reward_per_step": 13.98758506039131,
    "episode_length": 1037,
    "policy_loss": -232.85673141479492,
    "value_loss": 0.507556140422821,
    "entropy": 1.1461796462535858,
    "total_loss": -232.80764713287354
  },
  {
    "episode": 46,
    "avg_reward_per_step": 40.43590391471738,
    "episode_length": 426,
    "policy_loss": -687.8301086425781,
    "value_loss": 0.5286609828472137,
    "entropy": 1.0792510509490967,
    "total_loss": -687.7331480801106
  },
  {
    "episode": 47,
    "avg_reward_per_step": 9.130111075109907,
    "episode_length": 1169,
    "policy_loss": -153.85940551757812,
    "value_loss": 0.5032802224159241,
    "entropy": 0.9738779813051224,
    "total_loss": -153.74567648768425
  },
  {
    "episode": 48,
    "avg_reward_per_step": 102.5466532627065,
    "episode_length": 184,
    "policy_loss": -1745.56787109375,
    "value_loss": 0.5908303558826447,
    "entropy": 0.9204228222370148,
    "total_loss": -1745.3452098667622
  },
  {
    "episode": 49,
    "avg_reward_per_step": 6.593605309941623,
    "episode_length": 1347,
    "policy_loss": -110.98971748352051,
    "value_loss": 0.5017872601747513,
    "entropy": 0.9901962727308273,
    "total_loss": -110.88400873243809
  },
  {
    "episode": 50,
    "avg_reward_per_step": 10.31610137179818,
    "episode_length": 1069,
    "policy_loss": -171.05592346191406,
    "value_loss": 0.5039623379707336,
    "entropy": 0.9990822821855545,
    "total_loss": -170.95159403681754
  },
  {
    "episode": 51,
    "avg_reward_per_step": 28.80191411171015,
    "episode_length": 577,
    "policy_loss": -482.73219299316406,
    "value_loss": 0.5189874023199081,
    "entropy": 1.0120644569396973,
    "total_loss": -482.61803137362006
  },
  {
    "episode": 52,
    "avg_reward_per_step": 40.636514284430305,
    "episode_length": 447,
    "policy_loss": -686.5184326171875,
    "value_loss": 0.5305831581354141,
    "entropy": 1.0513619780540466,
    "total_loss": -686.4083942502737
  },
  {
    "episode": 53,
    "avg_reward_per_step": 79.10169803628489,
    "episode_length": 245,
    "policy_loss": -1350.0304565429688,
    "value_loss": 0.5689256191253662,
    "entropy": 1.1056936383247375,
    "total_loss": -1349.9038083791734
  },
  {
    "episode": 54,
    "avg_reward_per_step": 138.84302590627303,
    "episode_length": 143,
    "policy_loss": -2346.1593017578125,
    "value_loss": 0.6397159993648529,
    "entropy": 1.1282707750797272,
    "total_loss": -2345.9708940684795
  },
  {
    "episode": 55,
    "avg_reward_per_step": 75.83038248345594,
    "episode_length": 259,
    "policy_loss": -1283.5535583496094,
    "value_loss": 0.5665139555931091,
    "entropy": 1.0489074885845184,
    "total_loss": -1283.40660738945
  },
  {
    "episode": 56,
    "avg_reward_per_step": 51.39100332917688,
    "episode_length": 378,
    "policy_loss": -877.0153045654297,
    "value_loss": 0.5421726256608963,
    "entropy": 1.0451184213161469,
    "total_loss": -876.8911793082952
  },
  {
    "episode": 57,
    "avg_reward_per_step": 25.58386163306442,
    "episode_length": 710,
    "policy_loss": -430.3394088745117,
    "value_loss": 0.5183277726173401,
    "entropy": 0.9939113706350327,
    "total_loss": -430.2186456501484
  },
  {
    "episode": 58,
    "avg_reward_per_step": 30.960137582434164,
    "episode_length": 619,
    "policy_loss": -512.9610900878906,
    "value_loss": 0.5238252729177475,
    "entropy": 0.94278384745121,
    "total_loss": -512.8143783539533
  },
  {
    "episode": 59,
    "avg_reward_per_step": 61.29164138358524,
    "episode_length": 321,
    "policy_loss": -1053.9068603515625,
    "value_loss": 0.5519751012325287,
    "entropy": 0.9316253513097763,
    "total_loss": -1053.727535390854
  },
  {
    "episode": 60,
    "avg_reward_per_step": 44.01349629328968,
    "episode_length": 436,
    "policy_loss": -730.8809204101562,
    "value_loss": 0.5349343121051788,
    "entropy": 0.9143194109201431,
    "total_loss": -730.7117138624192
  },
  {
    "episode": 61,
    "avg_reward_per_step": 75.8949430288444,
    "episode_length": 257,
    "policy_loss": -1291.4229736328125,
    "value_loss": 0.5654521584510803,
    "entropy": 0.8815433382987976,
    "total_loss": -1291.210138809681
  },
  {
    "episode": 62,
    "avg_reward_per_step": 47.542430906014445,
    "episode_length": 395,
    "policy_loss": -808.2612609863281,
    "value_loss": 0.5369917452335358,
    "entropy": 0.845915213227272,
    "total_loss": -808.0626353263855
  },
  {
    "episode": 63,
    "avg_reward_per_step": -8.900996870483356,
    "episode_length": 3000,
    "policy_loss": 156.78798294067383,
    "value_loss": 2.7838255763053894,
    "entropy": 0.7131209820508957,
    "total_loss": 159.28656012415885
  },
  {
    "episode": 64,
    "avg_reward_per_step": 1.555880303585733,
    "episode_length": 1853,
    "policy_loss": -21.924846649169922,
    "value_loss": 0.4996906742453575,
    "entropy": 0.6566897034645081,
    "total_loss": -21.687831856310368
  },
  {
    "episode": 65,
    "avg_reward_per_step": -11.767127424408354,
    "episode_length": 3000,
    "policy_loss": 203.50708770751953,
    "value_loss": 3.436812102794647,
    "entropy": 0.5704444646835327,
    "total_loss": 206.71572202444077
  },
  {
    "episode": 66,
    "avg_reward_per_step": -11.956548730918996,
    "episode_length": 3000,
    "policy_loss": 205.96636581420898,
    "value_loss": 3.5582107305526733,
    "entropy": 0.5367327481508255,
    "total_loss": 209.30988344550133
  },
  {
    "episode": 67,
    "avg_reward_per_step": 100.75459695006454,
    "episode_length": 182,
    "policy_loss": -1692.2256469726562,
    "value_loss": 0.5859909653663635,
    "entropy": 0.5320886522531509,
    "total_loss": -1691.8524914681911
  },
  {
    "episode": 68,
    "avg_reward_per_step": -11.723585360674944,
    "episode_length": 3000,
    "policy_loss": 201.06091690063477,
    "value_loss": 3.178542196750641,
    "entropy": 0.506096176803112,
    "total_loss": 204.03702062666417
  },
  {
    "episode": 69,
    "avg_reward_per_step": -13.414517717841605,
    "episode_length": 3000,
    "policy_loss": 229.40435791015625,
    "value_loss": 3.786789655685425,
    "entropy": 0.44805576652288437,
    "total_loss": 233.01192525923253
  },
  {
    "episode": 70,
    "avg_reward_per_step": -12.646682976251467,
    "episode_length": 3000,
    "policy_loss": 215.8531379699707,
    "value_loss": 3.8009868264198303,
    "entropy": 0.4494181349873543,
    "total_loss": 219.47435754239558
  },
  {
    "episode": 71,
    "avg_reward_per_step": -1.1841239142557642,
    "episode_length": 1769,
    "policy_loss": 23.02975606918335,
    "value_loss": 0.49980246275663376,
    "entropy": 0.40684638172388077,
    "total_loss": 23.36681997925043
  },
  {
    "episode": 72,
    "avg_reward_per_step": -12.892188174946169,
    "episode_length": 3000,
    "policy_loss": 219.19856643676758,
    "value_loss": 3.47502064704895,
    "entropy": 0.4278242141008377,
    "total_loss": 222.5024573981762
  },
  {
    "episode": 73,
    "avg_reward_per_step": -14.188061220495912,
    "episode_length": 3000,
    "policy_loss": 240.5485954284668,
    "value_loss": 3.4195024967193604,
    "entropy": 0.40558475255966187,
    "total_loss": 243.8058640241623
  },
  {
    "episode": 74,
    "avg_reward_per_step": -12.089684492459202,
    "episode_length": 3000,
    "policy_loss": 204.9187889099121,
    "value_loss": 2.8613325357437134,
    "entropy": 0.46036485582590103,
    "total_loss": 207.59597550332546
  },
  {
    "episode": 75,
    "avg_reward_per_step": -12.475039549175483,
    "episode_length": 3000,
    "policy_loss": 211.30364227294922,
    "value_loss": 3.1989506483078003,
    "entropy": 0.45064834505319595,
    "total_loss": 214.32233358323575
  },
  {
    "episode": 76,
    "avg_reward_per_step": -11.61066008799417,
    "episode_length": 3000,
    "policy_loss": 196.32665252685547,
    "value_loss": 3.5881459712982178,
    "entropy": 0.46535053104162216,
    "total_loss": 199.72865828573703
  },
  {
    "episode": 77,
    "avg_reward_per_step": 4.155366421383105,
    "episode_length": 1149,
    "policy_loss": -70.2076244354248,
    "value_loss": 0.5002750009298325,
    "entropy": 0.4627342149615288,
    "total_loss": -69.89244312047958
  },
  {
    "episode": 78,
    "avg_reward_per_step": -4.762034406024492,
    "episode_length": 2733,
    "policy_loss": 80.33810234069824,
    "value_loss": 0.5021892189979553,
    "entropy": 0.48303595185279846,
    "total_loss": 80.64707717895507
  },
  {
    "episode": 79,
    "avg_reward_per_step": -12.085296933224534,
    "episode_length": 3000,
    "policy_loss": 203.29242706298828,
    "value_loss": 3.41184401512146,
    "entropy": 0.5049956068396568,
    "total_loss": 206.50227283537387
  },
  {
    "episode": 80,
    "avg_reward_per_step": -11.881122205134401,
    "episode_length": 3000,
    "policy_loss": 199.56333923339844,
    "value_loss": 3.1398202776908875,
    "entropy": 0.5309774875640869,
    "total_loss": 202.4907685160637
  },
  {
    "episode": 81,
    "avg_reward_per_step": -11.447960014204916,
    "episode_length": 3000,
    "policy_loss": 191.97451400756836,
    "value_loss": 3.0088513493537903,
    "entropy": 0.5380112677812576,
    "total_loss": 194.76816084980965
  },
  {
    "episode": 82,
    "avg_reward_per_step": -10.964256214213133,
    "episode_length": 3000,
    "policy_loss": 183.7115020751953,
    "value_loss": 3.1389010548591614,
    "entropy": 0.5659651458263397,
    "total_loss": 186.62401707172393
  },
  {
    "episode": 83,
    "avg_reward_per_step": -11.626142934884745,
    "episode_length": 3000,
    "policy_loss": 194.50982284545898,
    "value_loss": 3.2308924794197083,
    "entropy": 0.5417322814464569,
    "total_loss": 197.5240224123001
  },
  {
    "episode": 84,
    "avg_reward_per_step": -11.306232656229415,
    "episode_length": 3000,
    "policy_loss": 188.71259689331055,
    "value_loss": 3.003633439540863,
    "entropy": 0.5768357217311859,
    "total_loss": 191.48549604415894
  },
  {
    "episode": 85,
    "avg_reward_per_step": -10.628977810887474,
    "episode_length": 3000,
    "policy_loss": 176.80351638793945,
    "value_loss": 2.8819212913513184,
    "entropy": 0.5893194675445557,
    "total_loss": 179.44970989227295
  },
  {
    "episode": 86,
    "avg_reward_per_step": -11.091623502776498,
    "episode_length": 3000,
    "policy_loss": 184.44068145751953,
    "value_loss": 2.9043067693710327,
    "entropy": 0.5781543403863907,
    "total_loss": 187.113726490736
  },
  {
    "episode": 87,
    "avg_reward_per_step": 2.8370648611733733,
    "episode_length": 1400,
    "policy_loss": -51.2112340927124,
    "value_loss": 0.5000476688146591,
    "entropy": 0.5990488678216934,
    "total_loss": -50.95080597102642
  },
  {
    "episode": 88,
    "avg_reward_per_step": 27.63003171000875,
    "episode_length": 567,
    "policy_loss": -468.41353607177734,
    "value_loss": 0.5173918604850769,
    "entropy": 0.6293186992406845,
    "total_loss": -468.14787169098855
  },
  {
    "episode": 89,
    "avg_reward_per_step": 2.4913326547595296,
    "episode_length": 1810,
    "policy_loss": -45.37178707122803,
    "value_loss": 0.5001527965068817,
    "entropy": 0.6484611481428146,
    "total_loss": -45.13101873397827
  },
  {
    "episode": 90,
    "avg_reward_per_step": -11.252287207899688,
    "episode_length": 3000,
    "policy_loss": 186.1578598022461,
    "value_loss": 2.8843958377838135,
    "entropy": 0.607213944196701,
    "total_loss": 188.79937006235122
  },
  {
    "episode": 91,
    "avg_reward_per_step": -10.82209058377871,
    "episode_length": 3000,
    "policy_loss": 178.60431289672852,
    "value_loss": 3.01406991481781,
    "entropy": 0.6281262338161469,
    "total_loss": 181.36713231801986
  },
  {
    "episode": 92,
    "avg_reward_per_step": -10.485348405883489,
    "episode_length": 3000,
    "policy_loss": 172.57770156860352,
    "value_loss": 2.867267429828644,
    "entropy": 0.6223808228969574,
    "total_loss": 175.19601666927338
  },
  {
    "episode": 93,
    "avg_reward_per_step": -10.329628301439929,
    "episode_length": 3000,
    "policy_loss": 169.84197235107422,
    "value_loss": 2.4881860613822937,
    "entropy": 0.6239507645368576,
    "total_loss": 172.08057810664178
  },
  {
    "episode": 94,
    "avg_reward_per_step": 0.03256623667152226,
    "episode_length": 1968,
    "policy_loss": -5.246417164802551,
    "value_loss": 0.4997229352593422,
    "entropy": 0.6347795277833939,
    "total_loss": -5.000606040656566
  },
  {
    "episode": 95,
    "avg_reward_per_step": -10.045339540164777,
    "episode_length": 3000,
    "policy_loss": 164.35011291503906,
    "value_loss": 2.6770588755607605,
    "entropy": 0.6479016095399857,
    "total_loss": 166.76801114678383
  },
  {
    "episode": 96,
    "avg_reward_per_step": -10.508690081843007,
    "episode_length": 3000,
    "policy_loss": 171.8789176940918,
    "value_loss": 2.5833663940429688,
    "entropy": 0.6501521915197372,
    "total_loss": 174.20222321152687
  },
  {
    "episode": 97,
    "avg_reward_per_step": 8.85139957285662,
    "episode_length": 1108,
    "policy_loss": -155.0545883178711,
    "value_loss": 0.5033989101648331,
    "entropy": 0.6688186526298523,
    "total_loss": -154.8187168687582
  },
  {
    "episode": 98,
    "avg_reward_per_step": -9.441830305117447,
    "episode_length": 3000,
    "policy_loss": 153.1024284362793,
    "value_loss": 2.686169445514679,
    "entropy": 0.7055022567510605,
    "total_loss": 155.50639697909355
  },
  {
    "episode": 99,
    "avg_reward_per_step": 127.14495850586782,
    "episode_length": 155,
    "policy_loss": -2177.9475708007812,
    "value_loss": 0.6260700672864914,
    "entropy": 0.7934911996126175,
    "total_loss": -2177.63889721334
  },
  {
    "episode": 100,
    "avg_reward_per_step": 10.73853494113249,
    "episode_length": 1109,
    "policy_loss": -187.03826904296875,
    "value_loss": 0.505090981721878,
    "entropy": 0.7158483266830444,
    "total_loss": -186.8195173919201
  },
  {
    "episode": 101,
    "avg_reward_per_step": 19.197570829281325,
    "episode_length": 748,
    "policy_loss": -332.2873992919922,
    "value_loss": 0.5112013965845108,
    "entropy": 0.7046442031860352,
    "total_loss": -332.0580555766821
  },
  {
    "episode": 102,
    "avg_reward_per_step": 6.3577477767635004,
    "episode_length": 1433,
    "policy_loss": -115.79839134216309,
    "value_loss": 0.5022384971380234,
    "entropy": 0.7251654267311096,
    "total_loss": -115.5862190157175
  },
  {
    "episode": 103,
    "avg_reward_per_step": 10.513093383897028,
    "episode_length": 1256,
    "policy_loss": -184.84762573242188,
    "value_loss": 0.5056892186403275,
    "entropy": 0.7559874504804611,
    "total_loss": -184.64433149397374
  },
  {
    "episode": 104,
    "avg_reward_per_step": 229.6799007558656,
    "episode_length": 87,
    "policy_loss": -3923.094482421875,
    "value_loss": 0.7856693863868713,
    "entropy": 0.7785397171974182,
    "total_loss": -3922.620228922367
  },
  {
    "episode": 105,
    "avg_reward_per_step": 5.931882506464291,
    "episode_length": 1494,
    "policy_loss": -101.84107971191406,
    "value_loss": 0.5020410269498825,
    "entropy": 0.6185335367918015,
    "total_loss": -101.5864520996809
  },
  {
    "episode": 106,
    "avg_reward_per_step": -9.241388038120862,
    "episode_length": 3000,
    "policy_loss": 149.2376251220703,
    "value_loss": 2.0251020193099976,
    "entropy": 0.5490693151950836,
    "total_loss": 151.04309941530227
  },
  {
    "episode": 107,
    "avg_reward_per_step": -11.368537060011143,
    "episode_length": 3000,
    "policy_loss": 184.93391036987305,
    "value_loss": 1.933343917131424,
    "entropy": 0.49372193217277527,
    "total_loss": 186.66976551413535
  },
  {
    "episode": 108,
    "avg_reward_per_step": -10.355538374439242,
    "episode_length": 3000,
    "policy_loss": 167.29063415527344,
    "value_loss": 1.997446745634079,
    "entropy": 0.4874223992228508,
    "total_loss": 169.09311194121838
  },
  {
    "episode": 109,
    "avg_reward_per_step": -11.497932202107377,
    "episode_length": 3000,
    "policy_loss": 186.35821533203125,
    "value_loss": 2.215802848339081,
    "entropy": 0.4443918913602829,
    "total_loss": 188.39626142382622
  },
  {
    "episode": 110,
    "avg_reward_per_step": 18.447027426501148,
    "episode_length": 790,
    "policy_loss": -324.7960968017578,
    "value_loss": 0.5110804736614227,
    "entropy": 0.552473783493042,
    "total_loss": -324.5060058414936
  },
  {
    "episode": 111,
    "avg_reward_per_step": -10.250506493588581,
    "episode_length": 3000,
    "policy_loss": 164.6683464050293,
    "value_loss": 1.92525053024292,
    "entropy": 0.5234231054782867,
    "total_loss": 166.3842276930809
  },
  {
    "episode": 112,
    "avg_reward_per_step": -9.755168922323897,
    "episode_length": 3000,
    "policy_loss": 156.2134017944336,
    "value_loss": 1.807365357875824,
    "entropy": 0.5677366852760315,
    "total_loss": 157.793672478199
  },
  {
    "episode": 113,
    "avg_reward_per_step": 47.11506334627576,
    "episode_length": 381,
    "policy_loss": -807.0590362548828,
    "value_loss": 0.5365638732910156,
    "entropy": 0.690694585442543,
    "total_loss": -806.7987502157688
  },
  {
    "episode": 114,
    "avg_reward_per_step": 3.2707420643022713,
    "episode_length": 1982,
    "policy_loss": -63.254414558410645,
    "value_loss": 0.5008566677570343,
    "entropy": 0.6607123613357544,
    "total_loss": -63.01784283518791
  },
  {
    "episode": 115,
    "avg_reward_per_step": 55.53150743696904,
    "episode_length": 337,
    "policy_loss": -948.0809020996094,
    "value_loss": 0.5456830710172653,
    "entropy": 0.7108396291732788,
    "total_loss": -947.8195548802614
  },
  {
    "episode": 116,
    "avg_reward_per_step": 4.0301455247259845,
    "episode_length": 1935,
    "policy_loss": -76.63381767272949,
    "value_loss": 0.5012828558683395,
    "entropy": 0.6633842438459396,
    "total_loss": -76.39788851439953
  },
  {
    "episode": 117,
    "avg_reward_per_step": 3.408981348685188,
    "episode_length": 2100,
    "policy_loss": -66.2373104095459,
    "value_loss": 0.5009991377592087,
    "entropy": 0.6519052684307098,
    "total_loss": -65.99707337915898
  },
  {
    "episode": 118,
    "avg_reward_per_step": 71.34154907396002,
    "episode_length": 273,
    "policy_loss": -1219.5484619140625,
    "value_loss": 0.5629664808511734,
    "entropy": 0.7109068185091019,
    "total_loss": -1219.269858160615
  },
  {
    "episode": 119,
    "avg_reward_per_step": 24.5835880988309,
    "episode_length": 677,
    "policy_loss": -427.9101333618164,
    "value_loss": 0.5172152072191238,
    "entropy": 0.7167879790067673,
    "total_loss": -427.6796333462
  },
  {
    "episode": 120,
    "avg_reward_per_step": 106.15167720292553,
    "episode_length": 186,
    "policy_loss": -1807.0073547363281,
    "value_loss": 0.6011110246181488,
    "entropy": 0.7377214282751083,
    "total_loss": -1806.70133228302
  },
  {
    "episode": 121,
    "avg_reward_per_step": 70.87710526462574,
    "episode_length": 276,
    "policy_loss": -1214.1375427246094,
    "value_loss": 0.5628273040056229,
    "entropy": 0.7134220004081726,
    "total_loss": -1213.860084220767
  },
  {
    "episode": 122,
    "avg_reward_per_step": 103.24369325218767,
    "episode_length": 190,
    "policy_loss": -1760.3213500976562,
    "value_loss": 0.5973026156425476,
    "entropy": 0.673404186964035,
    "total_loss": -1759.9934091567993
  },
  {
    "episode": 123,
    "avg_reward_per_step": -6.123476241839469,
    "episode_length": 3000,
    "policy_loss": 94.98800086975098,
    "value_loss": 1.4656412601470947,
    "entropy": 0.6045072674751282,
    "total_loss": 96.21183922290803
  },
  {
    "episode": 124,
    "avg_reward_per_step": -7.2823484353425725,
    "episode_length": 3000,
    "policy_loss": 113.99782752990723,
    "value_loss": 1.4713842868804932,
    "entropy": 0.5655834674835205,
    "total_loss": 115.2429784297943
  },
  {
    "episode": 125,
    "avg_reward_per_step": 35.413117954132,
    "episode_length": 487,
    "policy_loss": -608.8853302001953,
    "value_loss": 0.5261005759239197,
    "entropy": 0.5750909000635147,
    "total_loss": -608.5892659842968
  },
  {
    "episode": 126,
    "avg_reward_per_step": 20.267094531002463,
    "episode_length": 772,
    "policy_loss": -351.5598907470703,
    "value_loss": 0.5133721083402634,
    "entropy": 0.5706211775541306,
    "total_loss": -351.2747671097517
  },
  {
    "episode": 127,
    "avg_reward_per_step": 49.945707457655104,
    "episode_length": 376,
    "policy_loss": -858.8027038574219,
    "value_loss": 0.5408612191677094,
    "entropy": 0.6098795682191849,
    "total_loss": -858.5057944655418
  },
  {
    "episode": 128,
    "avg_reward_per_step": 87.37912711545593,
    "episode_length": 222,
    "policy_loss": -1487.8997497558594,
    "value_loss": 0.5792220234870911,
    "entropy": 0.5840106457471848,
    "total_loss": -1487.554131990671
  },
  {
    "episode": 129,
    "avg_reward_per_step": 37.68782101512701,
    "episode_length": 475,
    "policy_loss": -648.9637451171875,
    "value_loss": 0.529009222984314,
    "entropy": 0.5891885161399841,
    "total_loss": -648.6704113006592
  },
  {
    "episode": 130,
    "avg_reward_per_step": 235.0144798842899,
    "episode_length": 85,
    "policy_loss": -4081.2467041015625,
    "value_loss": 0.7965297996997833,
    "entropy": 0.61373470723629,
    "total_loss": -4080.6956681847573
  },
  {
    "episode": 131,
    "avg_reward_per_step": -13.789735220800067,
    "episode_length": 3000,
    "policy_loss": 223.88006591796875,
    "value_loss": 2.7493714690208435,
    "entropy": 0.31163764744997025,
    "total_loss": 226.5047823280096
  },
  {
    "episode": 132,
    "avg_reward_per_step": 27.397655724468226,
    "episode_length": 534,
    "policy_loss": -470.56748962402344,
    "value_loss": 0.5167763978242874,
    "entropy": 0.28931504487991333,
    "total_loss": -470.1664392441511
  },
  {
    "episode": 133,
    "avg_reward_per_step": -13.714904536848112,
    "episode_length": 3000,
    "policy_loss": 220.98323440551758,
    "value_loss": 2.425899863243103,
    "entropy": 0.3015253096818924,
    "total_loss": 223.28852414488793
  },
  {
    "episode": 134,
    "avg_reward_per_step": 1.976036636892262,
    "episode_length": 1525,
    "policy_loss": -45.07552623748779,
    "value_loss": 0.5000097900629044,
    "entropy": 0.4718848094344139,
    "total_loss": -44.764270371198656
  },
  {
    "episode": 135,
    "avg_reward_per_step": 199.85673355907974,
    "episode_length": 100,
    "policy_loss": -3393.9192504882812,
    "value_loss": 0.7335575371980667,
    "entropy": 0.5861108303070068,
    "total_loss": -3393.420137283206
  },
  {
    "episode": 136,
    "avg_reward_per_step": -11.653363082047035,
    "episode_length": 3000,
    "policy_loss": 186.02471160888672,
    "value_loss": 2.115234851837158,
    "entropy": 0.370284765958786,
    "total_loss": 187.99183255434036
  },
  {
    "episode": 137,
    "avg_reward_per_step": -13.156051732815378,
    "episode_length": 3000,
    "policy_loss": 211.0771598815918,
    "value_loss": 2.1730716228485107,
    "entropy": 0.35961562395095825,
    "total_loss": 213.10638525485993
  },
  {
    "episode": 138,
    "avg_reward_per_step": -13.028769979731491,
    "episode_length": 3000,
    "policy_loss": 208.68915939331055,
    "value_loss": 2.4471396803855896,
    "entropy": 0.34068413823843,
    "total_loss": 211.00002541840075
  },
  {
    "episode": 139,
    "avg_reward_per_step": -13.371912864128543,
    "episode_length": 3000,
    "policy_loss": 213.98469161987305,
    "value_loss": 2.550345003604889,
    "entropy": 0.33971141278743744,
    "total_loss": 216.39915205836297
  },
  {
    "episode": 140,
    "avg_reward_per_step": -12.877196248640418,
    "episode_length": 3000,
    "policy_loss": 205.3885612487793,
    "value_loss": 2.373161196708679,
    "entropy": 0.3307170569896698,
    "total_loss": 207.6294356226921
  },
  {
    "episode": 141,
    "avg_reward_per_step": -13.377590104869048,
    "episode_length": 3000,
    "policy_loss": 213.40665817260742,
    "value_loss": 2.186410665512085,
    "entropy": 0.3426824286580086,
    "total_loss": 215.4559958666563
  },
  {
    "episode": 142,
    "avg_reward_per_step": 49.12518230309686,
    "episode_length": 356,
    "policy_loss": -842.9026641845703,
    "value_loss": 0.5376148372888565,
    "entropy": 0.41603388637304306,
    "total_loss": -842.5314629018307
  },
  {
    "episode": 143,
    "avg_reward_per_step": -12.382095592359889,
    "episode_length": 3000,
    "policy_loss": 195.7291488647461,
    "value_loss": 2.3160024881362915,
    "entropy": 0.36890213191509247,
    "total_loss": 197.89759050011634
  },
  {
    "episode": 144,
    "avg_reward_per_step": -12.292009448485341,
    "episode_length": 3000,
    "policy_loss": 194.05490112304688,
    "value_loss": 2.200482487678528,
    "entropy": 0.3711233288049698,
    "total_loss": 196.10693427920341
  },
  {
    "episode": 145,
    "avg_reward_per_step": -12.069681078977425,
    "episode_length": 3000,
    "policy_loss": 190.00987243652344,
    "value_loss": 1.9549668729305267,
    "entropy": 0.3706432059407234,
    "total_loss": 191.8165820270777
  },
  {
    "episode": 146,
    "avg_reward_per_step": 51.234636421643614,
    "episode_length": 365,
    "policy_loss": -879.8446502685547,
    "value_loss": 0.542620062828064,
    "entropy": 0.5807868540287018,
    "total_loss": -879.5343449473381
  },
  {
    "episode": 147,
    "avg_reward_per_step": -11.759398763928482,
    "episode_length": 3000,
    "policy_loss": 184.0222930908203,
    "value_loss": 2.014989733695984,
    "entropy": 0.4139402061700821,
    "total_loss": 185.87170674204827
  },
  {
    "episode": 148,
    "avg_reward_per_step": 100.28190476842502,
    "episode_length": 193,
    "policy_loss": -1720.2181701660156,
    "value_loss": 0.5934576839208603,
    "entropy": 0.5721063017845154,
    "total_loss": -1719.8535550028087
  },
  {
    "episode": 149,
    "avg_reward_per_step": 89.75589933471937,
    "episode_length": 209,
    "policy_loss": -1539.5925903320312,
    "value_loss": 0.5793503969907761,
    "entropy": 0.5424977540969849,
    "total_loss": -1539.2302390366792
  },
  {
    "episode": 150,
    "avg_reward_per_step": 16.869942878727755,
    "episode_length": 728,
    "policy_loss": -300.01512145996094,
    "value_loss": 0.5088264048099518,
    "entropy": 0.4261091351509094,
    "total_loss": -299.67673870921135
  },
  {
    "episode": 151,
    "avg_reward_per_step": -11.781039177157355,
    "episode_length": 3000,
    "policy_loss": 183.7737274169922,
    "value_loss": 2.21981018781662,
    "entropy": 0.34976107627153397,
    "total_loss": 185.8536331743002
  },
  {
    "episode": 152,
    "avg_reward_per_step": -12.589689924753072,
    "episode_length": 3000,
    "policy_loss": 197.01058197021484,
    "value_loss": 2.1357357501983643,
    "entropy": 0.36110953986644745,
    "total_loss": 199.00187390446663
  },
  {
    "episode": 153,
    "avg_reward_per_step": -5.121906769289563,
    "episode_length": 2680,
    "policy_loss": 70.60617065429688,
    "value_loss": 0.501528188586235,
    "entropy": 0.3266477957367897,
    "total_loss": 70.9770397245884
  },
  {
    "episode": 154,
    "avg_reward_per_step": -12.315869080834291,
    "episode_length": 3000,
    "policy_loss": 191.84139251708984,
    "value_loss": 2.200375556945801,
    "entropy": 0.32728666812181473,
    "total_loss": 193.9108534067869
  },
  {
    "episode": 155,
    "avg_reward_per_step": -13.813417518498003,
    "episode_length": 3000,
    "policy_loss": 216.57045364379883,
    "value_loss": 2.4960774183273315,
    "entropy": 0.30333341658115387,
    "total_loss": 218.9451976954937
  },
  {
    "episode": 156,
    "avg_reward_per_step": 43.14557636710611,
    "episode_length": 426,
    "policy_loss": -744.9862518310547,
    "value_loss": 0.5351781994104385,
    "entropy": 0.4353831112384796,
    "total_loss": -744.6252268761397
  },
  {
    "episode": 157,
    "avg_reward_per_step": -12.586637499391557,
    "episode_length": 3000,
    "policy_loss": 195.37400436401367,
    "value_loss": 2.199715256690979,
    "entropy": 0.36552732437849045,
    "total_loss": 197.42750869095326
  },
  {
    "episode": 158,
    "avg_reward_per_step": -11.515851522185432,
    "episode_length": 3000,
    "policy_loss": 177.0994987487793,
    "value_loss": 1.7791059911251068,
    "entropy": 0.3870998024940491,
    "total_loss": 178.72376481890677
  },
  {
    "episode": 159,
    "avg_reward_per_step": 224.03517775288307,
    "episode_length": 89,
    "policy_loss": -3826.0765380859375,
    "value_loss": 0.7766484767198563,
    "entropy": 0.544080525636673,
    "total_loss": -3825.517521819472
  },
  {
    "episode": 160,
    "avg_reward_per_step": -13.641210697657769,
    "episode_length": 3000,
    "policy_loss": 211.95625686645508,
    "value_loss": 2.195999324321747,
    "entropy": 0.30491726100444794,
    "total_loss": 214.03028928637505
  },
  {
    "episode": 161,
    "avg_reward_per_step": -12.820334945207446,
    "episode_length": 3000,
    "policy_loss": 197.91749954223633,
    "value_loss": 2.1233999133110046,
    "entropy": 0.25371864065527916,
    "total_loss": 199.93941199928523
  },
  {
    "episode": 162,
    "avg_reward_per_step": 66.08544431467875,
    "episode_length": 299,
    "policy_loss": -1137.0281677246094,
    "value_loss": 0.5599651485681534,
    "entropy": 0.28994348645210266,
    "total_loss": -1136.584179970622
  },
  {
    "episode": 163,
    "avg_reward_per_step": -13.210029253524985,
    "episode_length": 3000,
    "policy_loss": 204.18988800048828,
    "value_loss": 2.1489136815071106,
    "entropy": 0.20651639252901077,
    "total_loss": 206.25619512498378
  },
  {
    "episode": 164,
    "avg_reward_per_step": -15.134725233157518,
    "episode_length": 3000,
    "policy_loss": 236.33920669555664,
    "value_loss": 2.4965975284576416,
    "entropy": 0.1777903512120247,
    "total_loss": 238.76468808352948
  },
  {
    "episode": 165,
    "avg_reward_per_step": -15.555751477992448,
    "episode_length": 3000,
    "policy_loss": 243.08597946166992,
    "value_loss": 2.3660115003585815,
    "entropy": 0.11831166595220566,
    "total_loss": 245.40466629564762
  },
  {
    "episode": 166,
    "avg_reward_per_step": -14.227869264165317,
    "episode_length": 3000,
    "policy_loss": 220.09919357299805,
    "value_loss": 2.3250571489334106,
    "entropy": 0.16406499221920967,
    "total_loss": 222.35862472504377
  },
  {
    "episode": 167,
    "avg_reward_per_step": -14.225193757360453,
    "episode_length": 3000,
    "policy_loss": 219.6963233947754,
    "value_loss": 2.469889283180237,
    "entropy": 0.11255536042153835,
    "total_loss": 222.121190533787
  },
  {
    "episode": 168,
    "avg_reward_per_step": 79.6519291066766,
    "episode_length": 249,
    "policy_loss": -1373.411865234375,
    "value_loss": 0.5735777318477631,
    "entropy": 0.22196269780397415,
    "total_loss": -1372.9270725816489
  },
  {
    "episode": 169,
    "avg_reward_per_step": -14.116883892178443,
    "episode_length": 3000,
    "policy_loss": 216.90151596069336,
    "value_loss": 2.152606725692749,
    "entropy": 0.1611689254641533,
    "total_loss": 218.98965511620045
  },
  {
    "episode": 170,
    "avg_reward_per_step": 103.13454772591265,
    "episode_length": 189,
    "policy_loss": -1769.3582763671875,
    "value_loss": 0.5972498059272766,
    "entropy": 0.47309284657239914,
    "total_loss": -1768.950263699889
  },
  {
    "episode": 171,
    "avg_reward_per_step": -14.593966055768792,
    "episode_length": 3000,
    "policy_loss": 224.23136520385742,
    "value_loss": 2.034755229949951,
    "entropy": 0.15426979586482048,
    "total_loss": 226.20441251546146
  },
  {
    "episode": 172,
    "avg_reward_per_step": 13.212898575852096,
    "episode_length": 1171,
    "policy_loss": -247.4453582763672,
    "value_loss": 0.5098321586847305,
    "entropy": 0.09899056702852249,
    "total_loss": -246.97512234449385
  },
  {
    "episode": 173,
    "avg_reward_per_step": 221.9993635296128,
    "episode_length": 90,
    "policy_loss": -3773.7863159179688,
    "value_loss": 0.7741387486457825,
    "entropy": 0.33609624952077866,
    "total_loss": -3773.1466156691313
  },
  {
    "episode": 174,
    "avg_reward_per_step": 250.0284361565469,
    "episode_length": 80,
    "policy_loss": -4239.6707763671875,
    "value_loss": 0.8285831809043884,
    "entropy": 0.3820212110877037,
    "total_loss": -4238.995001670718
  },
  {
    "episode": 175,
    "avg_reward_per_step": 119.1457587501395,
    "episode_length": 167,
    "policy_loss": -2039.7620544433594,
    "value_loss": 0.619073823094368,
    "entropy": 0.21428105607628822,
    "total_loss": -2039.2286930426956
  },
  {
    "episode": 176,
    "avg_reward_per_step": 1.028801937464837,
    "episode_length": 1513,
    "policy_loss": -40.79812145233154,
    "value_loss": 0.5001376569271088,
    "entropy": 0.08251834101974964,
    "total_loss": -40.33099113181233
  },
  {
    "episode": 177,
    "avg_reward_per_step": 68.93671343395127,
    "episode_length": 280,
    "policy_loss": -1191.1979675292969,
    "value_loss": 0.5612203627824783,
    "entropy": 0.40298572182655334,
    "total_loss": -1190.797941455245
  },
  {
    "episode": 178,
    "avg_reward_per_step": 7.01290409516584,
    "episode_length": 1607,
    "policy_loss": -142.93229293823242,
    "value_loss": 0.5043220669031143,
    "entropy": 0.144398495554924,
    "total_loss": -142.48573026955128
  },
  {
    "episode": 179,
    "avg_reward_per_step": 6.531980608339656,
    "episode_length": 2000,
    "policy_loss": -132.38344955444336,
    "value_loss": 0.5049055069684982,
    "entropy": 0.14489204809069633,
    "total_loss": -131.93650086671113
  },
  {
    "episode": 180,
    "avg_reward_per_step": 54.14174788357569,
    "episode_length": 360,
    "policy_loss": -942.3457336425781,
    "value_loss": 0.5479569286108017,
    "entropy": 0.28582803159952164,
    "total_loss": -941.9121079266072
  },
  {
    "episode": 181,
    "avg_reward_per_step": 277.3993407155638,
    "episode_length": 72,
    "policy_loss": -4674.6385498046875,
    "value_loss": 0.8861215710639954,
    "entropy": 0.26470863074064255,
    "total_loss": -4673.85831168592
  },
  {
    "episode": 182,
    "avg_reward_per_step": 78.89848640185728,
    "episode_length": 250,
    "policy_loss": -1356.4463500976562,
    "value_loss": 0.5728349834680557,
    "entropy": 0.30435868352651596,
    "total_loss": -1355.9952585875988
  },
  {
    "episode": 183,
    "avg_reward_per_step": 6.917085654113363,
    "episode_length": 1706,
    "policy_loss": -138.99536514282227,
    "value_loss": 0.5046833902597427,
    "entropy": 0.11461441032588482,
    "total_loss": -138.53652751669287
  },
  {
    "episode": 184,
    "avg_reward_per_step": 7.0653773361695755,
    "episode_length": 1943,
    "policy_loss": -145.13685989379883,
    "value_loss": 0.505179226398468,
    "entropy": 0.0889474730938673,
    "total_loss": -144.6672596566379
  },
  {
    "episode": 185,
    "avg_reward_per_step": 63.98010397601992,
    "episode_length": 307,
    "policy_loss": -1104.7796325683594,
    "value_loss": 0.557439386844635,
    "entropy": 0.30023283511400223,
    "total_loss": -1104.3422863155604
  },
  {
    "episode": 186,
    "avg_reward_per_step": 281.22895790103763,
    "episode_length": 71,
    "policy_loss": -4728.275634765625,
    "value_loss": 0.8951749354600906,
    "entropy": 0.22562022507190704,
    "total_loss": -4727.4707079201935
  },
  {
    "episode": 187,
    "avg_reward_per_step": 281.2165093983099,
    "episode_length": 71,
    "policy_loss": -4731.052978515625,
    "value_loss": 0.8951534628868103,
    "entropy": 0.23268864303827286,
    "total_loss": -4730.250900509954
  },
  {
    "episode": 188,
    "avg_reward_per_step": 6.35920249677885,
    "episode_length": 2080,
    "policy_loss": -129.38288497924805,
    "value_loss": 0.5050512701272964,
    "entropy": 0.0829058289527893,
    "total_loss": -128.91099604070186
  },
  {
    "episode": 189,
    "avg_reward_per_step": 145.9923472743919,
    "episode_length": 136,
    "policy_loss": -2502.7329711914062,
    "value_loss": 0.652768537402153,
    "entropy": 0.21211222931742668,
    "total_loss": -2502.165047545731
  },
  {
    "episode": 190,
    "avg_reward_per_step": 256.1564708342447,
    "episode_length": 78,
    "policy_loss": -4324.8798828125,
    "value_loss": 0.8406234085559845,
    "entropy": 0.17931728810071945,
    "total_loss": -4324.110986319184
  },
  {
    "episode": 191,
    "avg_reward_per_step": 99.22650410837655,
    "episode_length": 198,
    "policy_loss": -1699.8423767089844,
    "value_loss": 0.5939397811889648,
    "entropy": 0.22990033775568008,
    "total_loss": -1699.3403970628976
  },
  {
    "episode": 192,
    "avg_reward_per_step": 71.02625590875749,
    "episode_length": 277,
    "policy_loss": -1224.0073852539062,
    "value_loss": 0.5647227317094803,
    "entropy": 0.22136220335960388,
    "total_loss": -1223.5312074035405
  },
  {
    "episode": 193,
    "avg_reward_per_step": 96.21430461458071,
    "episode_length": 206,
    "policy_loss": -1653.8966674804688,
    "value_loss": 0.5915945470333099,
    "entropy": 0.2335876077413559,
    "total_loss": -1653.398507976532
  },
  {
    "episode": 194,
    "avg_reward_per_step": 246.40738922700626,
    "episode_length": 81,
    "policy_loss": -4168.1451416015625,
    "value_loss": 0.8206557780504227,
    "entropy": 0.1798364259302616,
    "total_loss": -4167.396420393884
  },
  {
    "episode": 195,
    "avg_reward_per_step": 150.85172163750642,
    "episode_length": 132,
    "policy_loss": -2573.019775390625,
    "value_loss": 0.6598540842533112,
    "entropy": 0.2004310004413128,
    "total_loss": -2572.4400937065484
  },
  {
    "episode": 196,
    "avg_reward_per_step": 253.5065770526049,
    "episode_length": 79,
    "policy_loss": -4424.099365234375,
    "value_loss": 0.8364223539829254,
    "entropy": 0.21606186404824257,
    "total_loss": -4423.349367626011
  },
  {
    "episode": 197,
    "avg_reward_per_step": -0.4943079750266946,
    "episode_length": 3000,
    "policy_loss": -12.135230779647827,
    "value_loss": 2.8908956050872803,
    "entropy": 0.007001148769631982,
    "total_loss": -9.2471356340684
  },
  {
    "episode": 198,
    "avg_reward_per_step": -0.5151020889478988,
    "episode_length": 3000,
    "policy_loss": -11.303356647491455,
    "value_loss": 4.655184864997864,
    "entropy": 0.0073170289397239685,
    "total_loss": -6.651098594069481
  },
  {
    "episode": 199,
    "avg_reward_per_step": 151.06381349185858,
    "episode_length": 132,
    "policy_loss": -2574.5453491210938,
    "value_loss": 0.6599224805831909,
    "entropy": 0.18717975541949272,
    "total_loss": -2573.960298542678
  },
  {
    "episode": 200,
    "avg_reward_per_step": 277.6137394938924,
    "episode_length": 72,
    "policy_loss": -4665.258544921875,
    "value_loss": 0.8865533322095871,
    "entropy": 0.15502922609448433,
    "total_loss": -4664.434003280103
  },
  {
    "episode": 201,
    "avg_reward_per_step": 84.50688448508384,
    "episode_length": 234,
    "policy_loss": -1448.0126953125,
    "value_loss": 0.5783126950263977,
    "entropy": 0.18967445567250252,
    "total_loss": -1447.5102523997425
  },
  {
    "episode": 202,
    "avg_reward_per_step": 298.24293401681905,
    "episode_length": 67,
    "policy_loss": -4992.2640380859375,
    "value_loss": 0.9332260936498642,
    "entropy": 0.14289391040802002,
    "total_loss": -4991.387969556451
  },
  {
    "episode": 203,
    "avg_reward_per_step": 277.6025530036618,
    "episode_length": 72,
    "policy_loss": -4674.381591796875,
    "value_loss": 0.8858759552240372,
    "entropy": 0.14155905693769455,
    "total_loss": -4673.552339464426
  },
  {
    "episode": 204,
    "avg_reward_per_step": 16.585497101010258,
    "episode_length": 1173,
    "policy_loss": -299.1259765625,
    "value_loss": 0.5148745626211166,
    "entropy": 0.013393186265602708,
    "total_loss": -298.61645927438514
  },
  {
    "episode": 205,
    "avg_reward_per_step": -0.5675838363795085,
    "episode_length": 3000,
    "policy_loss": -8.924135446548462,
    "value_loss": 1.337060809135437,
    "entropy": 0.011817914433777332,
    "total_loss": -7.591801803186536
  },
  {
    "episode": 206,
    "avg_reward_per_step": 6.833708984274324,
    "episode_length": 2741,
    "policy_loss": -133.78866958618164,
    "value_loss": 0.5068991482257843,
    "entropy": 0.009587833657860756,
    "total_loss": -133.285605571419
  },
  {
    "episode": 207,
    "avg_reward_per_step": 40.029989860039905,
    "episode_length": 494,
    "policy_loss": -695.3415985107422,
    "value_loss": 0.5351965725421906,
    "entropy": 0.024414293002337217,
    "total_loss": -694.8161676554009
  },
  {
    "episode": 208,
    "avg_reward_per_step": 21.100086395247033,
    "episode_length": 927,
    "policy_loss": -374.86231994628906,
    "value_loss": 0.518555074930191,
    "entropy": 0.03687582537531853,
    "total_loss": -374.358515201509
  },
  {
    "episode": 209,
    "avg_reward_per_step": -0.5385630378682521,
    "episode_length": 3000,
    "policy_loss": -8.26479983329773,
    "value_loss": 1.0033864825963974,
    "entropy": 0.0064585336949676275,
    "total_loss": -7.2639967641793195
  },
  {
    "episode": 210,
    "avg_reward_per_step": 30.02738323514367,
    "episode_length": 656,
    "policy_loss": -525.6024169921875,
    "value_loss": 0.5262431353330612,
    "entropy": 0.023659856524318457,
    "total_loss": -525.0856377994642
  },
  {
    "episode": 211,
    "avg_reward_per_step": 218.00905542139773,
    "episode_length": 92,
    "policy_loss": -3697.0040283203125,
    "value_loss": 0.7681753188371658,
    "entropy": 0.10280076041817665,
    "total_loss": -3696.2769733056425
  },
  {
    "episode": 212,
    "avg_reward_per_step": -0.5292079771278858,
    "episode_length": 3000,
    "policy_loss": -7.683651566505432,
    "value_loss": 0.8473911136388779,
    "entropy": 0.01150685572065413,
    "total_loss": -6.840863195154816
  },
  {
    "episode": 213,
    "avg_reward_per_step": -3.885015579326767,
    "episode_length": 3000,
    "policy_loss": 49.0405797958374,
    "value_loss": 0.7158030867576599,
    "entropy": 0.02720832033082843,
    "total_loss": 49.74549955446273
  },
  {
    "episode": 214,
    "avg_reward_per_step": 290.40904295773623,
    "episode_length": 69,
    "policy_loss": -4882.29931640625,
    "value_loss": 0.9157234132289886,
    "entropy": 0.0817408636212349,
    "total_loss": -4881.416289338469
  },
  {
    "episode": 215,
    "avg_reward_per_step": 274.78150058928964,
    "episode_length": 73,
    "policy_loss": -4612.7130126953125,
    "value_loss": 0.8809603005647659,
    "entropy": 0.13923485577106476,
    "total_loss": -4611.887746337056
  },
  {
    "episode": 216,
    "avg_reward_per_step": 282.5359091433417,
    "episode_length": 71,
    "policy_loss": -4738.4075927734375,
    "value_loss": 0.8980861902236938,
    "entropy": 0.12479504197835922,
    "total_loss": -4737.5594246000055
  },
  {
    "episode": 217,
    "avg_reward_per_step": 175.97956272399523,
    "episode_length": 114,
    "policy_loss": -2999.577880859375,
    "value_loss": 0.6966254115104675,
    "entropy": 0.10401391237974167,
    "total_loss": -2998.9228610128166
  },
  {
    "episode": 218,
    "avg_reward_per_step": 282.44036989723134,
    "episode_length": 71,
    "policy_loss": -4750.1854248046875,
    "value_loss": 0.8979171067476273,
    "entropy": 0.08316756784915924,
    "total_loss": -4749.32077472508
  },
  {
    "episode": 219,
    "avg_reward_per_step": 282.7140655600939,
    "episode_length": 71,
    "policy_loss": -4762.4168701171875,
    "value_loss": 0.8988568633794785,
    "entropy": 0.1296998057514429,
    "total_loss": -4761.569893176109
  },
  {
    "episode": 220,
    "avg_reward_per_step": 282.24370264959964,
    "episode_length": 71,
    "policy_loss": -4755.662353515625,
    "value_loss": 0.8973682224750519,
    "entropy": 0.07079275138676167,
    "total_loss": -4754.793302393705
  },
  {
    "episode": 221,
    "avg_reward_per_step": 290.6336956546215,
    "episode_length": 69,
    "policy_loss": -4874.212158203125,
    "value_loss": 0.9164868146181107,
    "entropy": 0.0742098968476057,
    "total_loss": -4873.325355347246
  },
  {
    "episode": 222,
    "avg_reward_per_step": 287.1491054924844,
    "episode_length": 70,
    "policy_loss": -4850.51611328125,
    "value_loss": 0.9093628078699112,
    "entropy": 0.10771301575005054,
    "total_loss": -4849.64983567968
  },
  {
    "episode": 223,
    "avg_reward_per_step": 275.0946446830648,
    "episode_length": 73,
    "policy_loss": -4643.9359130859375,
    "value_loss": 0.8823982626199722,
    "entropy": 0.0856508370488882,
    "total_loss": -4643.087775158137
  },
  {
    "episode": 224,
    "avg_reward_per_step": 282.5979361877028,
    "episode_length": 71,
    "policy_loss": -4744.0545654296875,
    "value_loss": 0.8981738388538361,
    "entropy": 0.04201441444456577,
    "total_loss": -4743.173197356611
  },
  {
    "episode": 225,
    "avg_reward_per_step": 291.32005659184847,
    "episode_length": 69,
    "policy_loss": -4874.6842041015625,
    "value_loss": 0.918662503361702,
    "entropy": 0.06435338966548443,
    "total_loss": -4873.791282954067
  },
  {
    "episode": 226,
    "avg_reward_per_step": 295.57468064388553,
    "episode_length": 68,
    "policy_loss": -4946.590576171875,
    "value_loss": 0.9284282773733139,
    "entropy": 0.06083015166223049,
    "total_loss": -4945.686479955167
  },
  {
    "episode": 227,
    "avg_reward_per_step": 286.6455937783981,
    "episode_length": 70,
    "policy_loss": -4822.5888671875,
    "value_loss": 0.9072228074073792,
    "entropy": 0.041722734458744526,
    "total_loss": -4821.698333473876
  },
  {
    "episode": 228,
    "avg_reward_per_step": 299.7700303647022,
    "episode_length": 67,
    "policy_loss": -5013.0711669921875,
    "value_loss": 0.9380971193313599,
    "entropy": 0.0582906398922205,
    "total_loss": -5012.156386128813
  },
  {
    "episode": 229,
    "avg_reward_per_step": 299.586636061665,
    "episode_length": 67,
    "policy_loss": -4994.69140625,
    "value_loss": 0.9374035745859146,
    "entropy": 0.06280759442597628,
    "total_loss": -4993.779125713185
  },
  {
    "episode": 230,
    "avg_reward_per_step": 178.5694723163153,
    "episode_length": 112,
    "policy_loss": -3046.4155883789062,
    "value_loss": 0.7002358138561249,
    "entropy": 0.08099539950489998,
    "total_loss": -3045.7477507248523
  },
  {
    "episode": 231,
    "avg_reward_per_step": 295.21986701787773,
    "episode_length": 68,
    "policy_loss": -4941.551025390625,
    "value_loss": 0.9275785088539124,
    "entropy": 0.07644827663898468,
    "total_loss": -4940.6540261924265
  },
  {
    "episode": 232,
    "avg_reward_per_step": 299.0835929128019,
    "episode_length": 67,
    "policy_loss": -4998.4794921875,
    "value_loss": 0.9357023984193802,
    "entropy": 0.060577092692255974,
    "total_loss": -4997.568020626158
  },
  {
    "episode": 233,
    "avg_reward_per_step": 299.6662785714273,
    "episode_length": 67,
    "policy_loss": -5015.9681396484375,
    "value_loss": 0.9376240223646164,
    "entropy": 0.04135065246373415,
    "total_loss": -5015.047055887058
  },
  {
    "episode": 234,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5135.250732421875,
    "value_loss": 0.9572403430938721,
    "entropy": 0.054974027909338474,
    "total_loss": -5134.315481689945
  },
  {
    "episode": 235,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5136.7562255859375,
    "value_loss": 0.9573096334934235,
    "entropy": 0.046935947611927986,
    "total_loss": -5135.817690331489
  },
  {
    "episode": 236,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5131.9254150390625,
    "value_loss": 0.9572928547859192,
    "entropy": 0.03187196096405387,
    "total_loss": -5130.980870968662
  },
  {
    "episode": 237,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5128.4647216796875,
    "value_loss": 0.9572634547948837,
    "entropy": 0.026064835023134947,
    "total_loss": -5127.517884158902
  },
  {
    "episode": 238,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5128.4996337890625,
    "value_loss": 0.9572507590055466,
    "entropy": 0.021474497858434916,
    "total_loss": -5127.5509728292
  },
  {
    "episode": 239,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5127.9271240234375,
    "value_loss": 0.9572460055351257,
    "entropy": 0.017078140750527382,
    "total_loss": -5126.976709274202
  },
  {
    "episode": 240,
    "avg_reward_per_step": 299.0835929128019,
    "episode_length": 67,
    "policy_loss": -4995.2255859375,
    "value_loss": 0.9355786442756653,
    "entropy": 0.025402978993952274,
    "total_loss": -4994.300168484822
  },
  {
    "episode": 241,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5126.2081298828125,
    "value_loss": 0.9572405219078064,
    "entropy": 0.01688575278967619,
    "total_loss": -5125.25764366202
  },
  {
    "episode": 242,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5126.8660888671875,
    "value_loss": 0.9572449177503586,
    "entropy": 0.018474965821951628,
    "total_loss": -5125.916233935766
  },
  {
    "episode": 243,
    "avg_reward_per_step": 299.2192809932884,
    "episode_length": 67,
    "policy_loss": -4999.376220703125,
    "value_loss": 0.9358338266611099,
    "entropy": 0.022175644990056753,
    "total_loss": -4998.44925713446
  },
  {
    "episode": 244,
    "avg_reward_per_step": 170.57926790026693,
    "episode_length": 117,
    "policy_loss": -2912.1683959960938,
    "value_loss": 0.6874612271785736,
    "entropy": 0.04405232332646847,
    "total_loss": -2911.4985556982456
  },
  {
    "episode": 245,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5127.31103515625,
    "value_loss": 0.957221731543541,
    "entropy": 0.01942459959536791,
    "total_loss": -5126.361583264545
  },
  {
    "episode": 246,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5127.9622802734375,
    "value_loss": 0.9572116136550903,
    "entropy": 0.023377292323857546,
    "total_loss": -5127.014419576712
  },
  {
    "episode": 247,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5128.101318359375,
    "value_loss": 0.9572417736053467,
    "entropy": 0.016480296617373824,
    "total_loss": -5127.150668704417
  },
  {
    "episode": 248,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5127.1390380859375,
    "value_loss": 0.9572321474552155,
    "entropy": 0.01226469874382019,
    "total_loss": -5126.18671181798
  },
  {
    "episode": 249,
    "avg_reward_per_step": 308.210339190303,
    "episode_length": 65,
    "policy_loss": -5126.8834228515625,
    "value_loss": 0.9572166949510574,
    "entropy": 0.010635838378220797,
    "total_loss": -5125.930460491963
  },
  {
    "episode": 250,
    "avg_reward_per_step": 299.5731473511406,
    "episode_length": 67,
    "policy_loss": -4999.7835693359375,
    "value_loss": 0.9372103661298752,
    "entropy": 0.026899775955826044,
    "total_loss": -4998.85711888019
  },
  {
    "episode": 251,
    "avg_reward_per_step": 295.2091017728969,
    "episode_length": 68,
    "policy_loss": -4929.212646484375,
    "value_loss": 0.9267982989549637,
    "entropy": 0.04022475425153971,
    "total_loss": -4928.301938087121
  },
  {
    "episode": 252,
    "avg_reward_per_step": 290.45908878640773,
    "episode_length": 69,
    "policy_loss": -4848.8714599609375,
    "value_loss": 0.9154174774885178,
    "entropy": 0.043156808242201805,
    "total_loss": -4847.973305206746
  },
  {
    "episode": 253,
    "avg_reward_per_step": 295.1141517774004,
    "episode_length": 68,
    "policy_loss": -4930.0943603515625,
    "value_loss": 0.9265378415584564,
    "entropy": 0.030177374836057425,
    "total_loss": -4929.179893459938
  },
  {
    "episode": 254,
    "avg_reward_per_step": 295.1141517774004,
    "episode_length": 68,
    "policy_loss": -4925.3199462890625,
    "value_loss": 0.9265564829111099,
    "entropy": 0.025267571210861206,
    "total_loss": -4924.403496834636
  },
  {
    "episode": 255,
    "avg_reward_per_step": 295.1141517774004,
    "episode_length": 68,
    "policy_loss": -4923.302978515625,
    "value_loss": 0.9265934228897095,
    "entropy": 0.0186093975789845,
    "total_loss": -4922.383828851767
  },
  {
    "episode": 256,
    "avg_reward_per_step": 286.2975933834414,
    "episode_length": 70,
    "policy_loss": -4789.6807861328125,
    "value_loss": 0.9061023890972137,
    "entropy": 0.019958969671279192,
    "total_loss": -4788.782667331584
  },
  {
    "episode": 257,
    "avg_reward_per_step": 295.1141517774004,
    "episode_length": 68,
    "policy_loss": -4922.9130859375,
    "value_loss": 0.9266608357429504,
    "entropy": 0.015940757701173425,
    "total_loss": -4921.992801404837
  },
  {
    "episode": 258,
    "avg_reward_per_step": 175.3499888355501,
    "episode_length": 114,
    "policy_loss": -2991.9811401367188,
    "value_loss": 0.6949973851442337,
    "entropy": 0.03312735306099057,
    "total_loss": -2991.2993936927987
  },
  {
    "episode": 259,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4923.3372802734375,
    "value_loss": 0.9266358911991119,
    "entropy": 0.03234012704342604,
    "total_loss": -4922.423580433056
  },
  {
    "episode": 260,
    "avg_reward_per_step": 294.71806264039196,
    "episode_length": 68,
    "policy_loss": -4911.5784912109375,
    "value_loss": 0.9251623451709747,
    "entropy": 0.046636191196739674,
    "total_loss": -4910.671983342245
  },
  {
    "episode": 261,
    "avg_reward_per_step": 278.3320582274535,
    "episode_length": 72,
    "policy_loss": -4665.1441650390625,
    "value_loss": 0.8883655220270157,
    "entropy": 0.043351031839847565,
    "total_loss": -4664.273139929772
  },
  {
    "episode": 262,
    "avg_reward_per_step": -20.348862552548784,
    "episode_length": 3000,
    "policy_loss": 326.4785919189453,
    "value_loss": 12.94428539276123,
    "entropy": 0.023354387376457453,
    "total_loss": 339.41353555675596
  },
  {
    "episode": 263,
    "avg_reward_per_step": 294.6968296662827,
    "episode_length": 68,
    "policy_loss": -4920.8885498046875,
    "value_loss": 0.9254928678274155,
    "entropy": 0.029269093181937933,
    "total_loss": -4919.974764574133
  },
  {
    "episode": 264,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4924.40185546875,
    "value_loss": 0.9268375933170319,
    "entropy": 0.03414026368409395,
    "total_loss": -4923.488673980906
  },
  {
    "episode": 265,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.322265625,
    "value_loss": 0.9268345385789871,
    "entropy": 0.03231731755658984,
    "total_loss": -4924.408358013444
  },
  {
    "episode": 266,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.697509765625,
    "value_loss": 0.9268338531255722,
    "entropy": 0.028325462248176336,
    "total_loss": -4924.782006097399
  },
  {
    "episode": 267,
    "avg_reward_per_step": 172.31590728062346,
    "episode_length": 116,
    "policy_loss": -2928.3256225585938,
    "value_loss": 0.6905945837497711,
    "entropy": 0.04757426865398884,
    "total_loss": -2927.6540576823054
  },
  {
    "episode": 268,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4924.36376953125,
    "value_loss": 0.9268456250429153,
    "entropy": 0.023043021094053984,
    "total_loss": -4923.446141114645
  },
  {
    "episode": 269,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.771728515625,
    "value_loss": 0.9268267452716827,
    "entropy": 0.022316185291856527,
    "total_loss": -4924.85382824447
  },
  {
    "episode": 270,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.1474609375,
    "value_loss": 0.9268460273742676,
    "entropy": 0.02175143640488386,
    "total_loss": -4924.2293154846875
  },
  {
    "episode": 271,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.58203125,
    "value_loss": 0.9268570691347122,
    "entropy": 0.0185495144687593,
    "total_loss": -4924.662593986653
  },
  {
    "episode": 272,
    "avg_reward_per_step": 172.31590728062346,
    "episode_length": 116,
    "policy_loss": -2925.6539306640625,
    "value_loss": 0.6905959993600845,
    "entropy": 0.03820342477411032,
    "total_loss": -2924.978616034612
  },
  {
    "episode": 273,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4926.3231201171875,
    "value_loss": 0.9268263131380081,
    "entropy": 0.015975940506905317,
    "total_loss": -4925.402684180252
  },
  {
    "episode": 274,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4924.9774169921875,
    "value_loss": 0.9268297404050827,
    "entropy": 0.015004749642685056,
    "total_loss": -4924.05658915164
  },
  {
    "episode": 275,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.366943359375,
    "value_loss": 0.9268556535243988,
    "entropy": 0.015277673257514834,
    "total_loss": -4924.446198775154
  },
  {
    "episode": 276,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.3485107421875,
    "value_loss": 0.9268599152565002,
    "entropy": 0.011858321027830243,
    "total_loss": -4924.426394155342
  },
  {
    "episode": 277,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.1845703125,
    "value_loss": 0.926847517490387,
    "entropy": 0.010425302432850003,
    "total_loss": -4924.261892915983
  },
  {
    "episode": 278,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.401123046875,
    "value_loss": 0.9268409311771393,
    "entropy": 0.009505076333880424,
    "total_loss": -4924.478084146232
  },
  {
    "episode": 279,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.197998046875,
    "value_loss": 0.9268438518047333,
    "entropy": 0.009124586125835776,
    "total_loss": -4924.274804029521
  },
  {
    "episode": 280,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.154541015625,
    "value_loss": 0.9268485456705093,
    "entropy": 0.008883530972525477,
    "total_loss": -4924.2312458823435
  },
  {
    "episode": 281,
    "avg_reward_per_step": 295.1822522722322,
    "episode_length": 68,
    "policy_loss": -4925.1732177734375,
    "value_loss": 0.9268502593040466,
    "entropy": 0.00807482737582177,
    "total_loss": -4924.249597445084
  },
  {
    "episode": 282,
    "avg_reward_per_step": 281.9130014393772,
    "episode_length": 71,
    "policy_loss": -4720.361572265625,
    "value_loss": 0.8961816281080246,
    "entropy": 0.01309181354008615,
    "total_loss": -4719.470627362933
  },
  {
    "episode": 283,
    "avg_reward_per_step": 286.2975933834414,
    "episode_length": 70,
    "policy_loss": -4790.83642578125,
    "value_loss": 0.9063546061515808,
    "entropy": 0.01420791749842465,
    "total_loss": -4789.935754342097
  },
  {
    "episode": 284,
    "avg_reward_per_step": 286.2975933834414,
    "episode_length": 70,
    "policy_loss": -4783.8531494140625,
    "value_loss": 0.9062774181365967,
    "entropy": 0.021868645679205656,
    "total_loss": -4782.955619454197
  },
  {
    "episode": 285,
    "avg_reward_per_step": 295.1141517774004,
    "episode_length": 68,
    "policy_loss": -4926.4207763671875,
    "value_loss": 0.9267401248216629,
    "entropy": 0.02976736705750227,
    "total_loss": -4925.505943189189
  },
  {
    "episode": 286,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4997.4912109375,
    "value_loss": 0.9376781284809113,
    "entropy": 0.02666282234713435,
    "total_loss": -4996.564197937958
  },
  {
    "episode": 287,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4996.0623779296875,
    "value_loss": 0.9376499205827713,
    "entropy": 0.015528454910963774,
    "total_loss": -4995.130939391069
  },
  {
    "episode": 288,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.247802734375,
    "value_loss": 0.9376376867294312,
    "entropy": 0.012188320280984044,
    "total_loss": -4993.315040375758
  },
  {
    "episode": 289,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.5853271484375,
    "value_loss": 0.9376330524682999,
    "entropy": 0.010678920894861221,
    "total_loss": -4993.651965664327
  },
  {
    "episode": 290,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.5023193359375,
    "value_loss": 0.9376399666070938,
    "entropy": 0.008253937936387956,
    "total_loss": -4993.567980944505
  },
  {
    "episode": 291,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.29443359375,
    "value_loss": 0.9376494139432907,
    "entropy": 0.006896998616866767,
    "total_loss": -4993.359542979253
  },
  {
    "episode": 292,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.2569580078125,
    "value_loss": 0.9376547634601593,
    "entropy": 0.006268586148507893,
    "total_loss": -4993.321810678812
  },
  {
    "episode": 293,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.2506103515625,
    "value_loss": 0.9376568049192429,
    "entropy": 0.005643279990181327,
    "total_loss": -4993.315210858639
  },
  {
    "episode": 294,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.2318115234375,
    "value_loss": 0.9376569092273712,
    "entropy": 0.0049925948260352015,
    "total_loss": -4993.296151652141
  },
  {
    "episode": 295,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.2032470703125,
    "value_loss": 0.9376554936170578,
    "entropy": 0.004463563323952258,
    "total_loss": -4993.267377002025
  },
  {
    "episode": 296,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.1793212890625,
    "value_loss": 0.9376534521579742,
    "entropy": 0.004094913951121271,
    "total_loss": -4993.243305802485
  },
  {
    "episode": 297,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.1607666015625,
    "value_loss": 0.9376514703035355,
    "entropy": 0.0038386996602639556,
    "total_loss": -4993.224650611123
  },
  {
    "episode": 298,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.1412353515625,
    "value_loss": 0.9376491904258728,
    "entropy": 0.0036482991999946535,
    "total_loss": -4993.205045480817
  },
  {
    "episode": 299,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.1248779296875,
    "value_loss": 0.9376480728387833,
    "entropy": 0.003495930228382349,
    "total_loss": -4993.18862822894
  },
  {
    "episode": 300,
    "avg_reward_per_step": 299.62339778905147,
    "episode_length": 67,
    "policy_loss": -4994.10498046875,
    "value_loss": 0.9376465678215027,
    "entropy": 0.0033700696076266468,
    "total_loss": -4993.168681928772
  }
]