[
  {
    "episode": 1,
    "avg_reward_per_step": 18.460945787507455,
    "episode_length": 1002,
    "policy_loss": -315.8436050415039,
    "value_loss": 0.5138503015041351,
    "entropy": 1.368623673915863,
    "total_loss": -315.39818592369556
  },
  {
    "episode": 2,
    "avg_reward_per_step": 71.86001800250057,
    "episode_length": 273,
    "policy_loss": -1228.2368774414062,
    "value_loss": 0.5630273967981339,
    "entropy": 1.3630200326442719,
    "total_loss": -1227.7420010462404
  },
  {
    "episode": 3,
    "avg_reward_per_step": -1.7169857919062161,
    "episode_length": 3000,
    "policy_loss": 28.939167976379395,
    "value_loss": 1.0957806408405304,
    "entropy": 1.3462415933609009,
    "total_loss": 29.96763653755188
  },
  {
    "episode": 4,
    "avg_reward_per_step": 8.758316389484177,
    "episode_length": 1931,
    "policy_loss": -149.57110214233398,
    "value_loss": 0.5058265030384064,
    "entropy": 1.3304912745952606,
    "total_loss": -149.13180020302534
  },
  {
    "episode": 5,
    "avg_reward_per_step": 30.293250206633903,
    "episode_length": 631,
    "policy_loss": -511.88220977783203,
    "value_loss": 0.5239968150854111,
    "entropy": 1.3168500363826752,
    "total_loss": -511.42405546456575
  },
  {
    "episode": 6,
    "avg_reward_per_step": 8.265133187271262,
    "episode_length": 2025,
    "policy_loss": -139.66426467895508,
    "value_loss": 0.5054347068071365,
    "entropy": 1.2920385301113129,
    "total_loss": -139.2234318986535
  },
  {
    "episode": 7,
    "avg_reward_per_step": 11.392660815427059,
    "episode_length": 1548,
    "policy_loss": -191.48982620239258,
    "value_loss": 0.5079742670059204,
    "entropy": 1.2821055352687836,
    "total_loss": -191.04595721215009
  },
  {
    "episode": 8,
    "avg_reward_per_step": 18.143642666180245,
    "episode_length": 1012,
    "policy_loss": -306.07483673095703,
    "value_loss": 0.5134695172309875,
    "entropy": 1.2724055349826813,
    "total_loss": -305.6249874904752
  },
  {
    "episode": 9,
    "avg_reward_per_step": 26.468764765302264,
    "episode_length": 717,
    "policy_loss": -447.9262161254883,
    "value_loss": 0.5205080807209015,
    "entropy": 1.2656369507312775,
    "total_loss": -447.46898989230397
  },
  {
    "episode": 10,
    "avg_reward_per_step": 10.141718037468417,
    "episode_length": 1699,
    "policy_loss": -173.57519149780273,
    "value_loss": 0.5068725049495697,
    "entropy": 1.2534357905387878,
    "total_loss": -173.1309907823801
  },
  {
    "episode": 11,
    "avg_reward_per_step": 8.42636122512692,
    "episode_length": 1989,
    "policy_loss": -142.5332260131836,
    "value_loss": 0.5055051445960999,
    "entropy": 1.2082792520523071,
    "total_loss": -142.0881348311901
  },
  {
    "episode": 12,
    "avg_reward_per_step": 29.94949268761907,
    "episode_length": 641,
    "policy_loss": -506.6514129638672,
    "value_loss": 0.523638054728508,
    "entropy": 1.1592342853546143,
    "total_loss": -506.1857366234064
  },
  {
    "episode": 13,
    "avg_reward_per_step": 41.55392303551685,
    "episode_length": 466,
    "policy_loss": -709.3189392089844,
    "value_loss": 0.5336967557668686,
    "entropy": 1.0708555281162262,
    "total_loss": -708.8387852296233
  },
  {
    "episode": 14,
    "avg_reward_per_step": 30.08501714286169,
    "episode_length": 636,
    "policy_loss": -510.4992446899414,
    "value_loss": 0.5237051993608475,
    "entropy": 1.1054752171039581,
    "total_loss": -510.03081325143575
  },
  {
    "episode": 15,
    "avg_reward_per_step": 24.227267394357124,
    "episode_length": 781,
    "policy_loss": -407.02823638916016,
    "value_loss": 0.5185554027557373,
    "entropy": 1.0423067808151245,
    "total_loss": -406.5617963254452
  },
  {
    "episode": 16,
    "avg_reward_per_step": 10.363508860627071,
    "episode_length": 1678,
    "policy_loss": -174.48635482788086,
    "value_loss": 0.5070832818746567,
    "entropy": 1.0762200355529785,
    "total_loss": -174.03308254778386
  },
  {
    "episode": 17,
    "avg_reward_per_step": 10.872312804077803,
    "episode_length": 1609,
    "policy_loss": -183.30821990966797,
    "value_loss": 0.5074979811906815,
    "entropy": 1.0549694299697876,
    "total_loss": -182.85347039997578
  },
  {
    "episode": 18,
    "avg_reward_per_step": 54.64244040152717,
    "episode_length": 359,
    "policy_loss": -923.783203125,
    "value_loss": 0.5460951775312424,
    "entropy": 1.0408512651920319,
    "total_loss": -923.2891505107284
  },
  {
    "episode": 19,
    "avg_reward_per_step": 31.666086843613943,
    "episode_length": 612,
    "policy_loss": -537.2236328125,
    "value_loss": 0.5251731425523758,
    "entropy": 1.057912439107895,
    "total_loss": -536.751355291903
  },
  {
    "episode": 20,
    "avg_reward_per_step": 9.756944046769386,
    "episode_length": 1801,
    "policy_loss": -163.63066864013672,
    "value_loss": 0.5067579299211502,
    "entropy": 0.9947751015424728,
    "total_loss": -163.1736494652927
  },
  {
    "episode": 21,
    "avg_reward_per_step": 13.56134635718988,
    "episode_length": 1345,
    "policy_loss": -227.37487030029297,
    "value_loss": 0.509830966591835,
    "entropy": 0.9258795827627182,
    "total_loss": -226.91133331283928
  },
  {
    "episode": 22,
    "avg_reward_per_step": 71.78739688757545,
    "episode_length": 279,
    "policy_loss": -1215.0342102050781,
    "value_loss": 0.5635848492383957,
    "entropy": 0.9254079759120941,
    "total_loss": -1214.5168957546352
  },
  {
    "episode": 23,
    "avg_reward_per_step": 96.17011740362554,
    "episode_length": 208,
    "policy_loss": -1631.9393310546875,
    "value_loss": 0.589231088757515,
    "entropy": 0.9231596291065216,
    "total_loss": -1631.3962579473853
  },
  {
    "episode": 24,
    "avg_reward_per_step": 49.167923438388975,
    "episode_length": 402,
    "policy_loss": -827.5163726806641,
    "value_loss": 0.5412285476922989,
    "entropy": 0.8461903631687164,
    "total_loss": -827.0174536511302
  },
  {
    "episode": 25,
    "avg_reward_per_step": 22.14777081844386,
    "episode_length": 871,
    "policy_loss": -372.1011276245117,
    "value_loss": 0.517230674624443,
    "entropy": 0.746904045343399,
    "total_loss": -371.6212421521544
  },
  {
    "episode": 26,
    "avg_reward_per_step": -1.0119911942740107,
    "episode_length": 3000,
    "policy_loss": 17.1977219581604,
    "value_loss": 0.5418051183223724,
    "entropy": 0.7168323695659637,
    "total_loss": 17.703685458004475
  },
  {
    "episode": 27,
    "avg_reward_per_step": 7.549571679092924,
    "episode_length": 2405,
    "policy_loss": -126.37417030334473,
    "value_loss": 0.5053461194038391,
    "entropy": 0.6638144254684448,
    "total_loss": -125.90201490521432
  },
  {
    "episode": 28,
    "avg_reward_per_step": 20.732085452703178,
    "episode_length": 920,
    "policy_loss": -348.8240737915039,
    "value_loss": 0.5158908665180206,
    "entropy": 0.6900285184383392,
    "total_loss": -348.3426843509078
  },
  {
    "episode": 29,
    "avg_reward_per_step": -0.7491438559790534,
    "episode_length": 3000,
    "policy_loss": 12.656705856323242,
    "value_loss": 0.5210567265748978,
    "entropy": 0.6618458330631256,
    "total_loss": 13.144670291244983
  },
  {
    "episode": 30,
    "avg_reward_per_step": 51.04378445619924,
    "episode_length": 387,
    "policy_loss": -865.63134765625,
    "value_loss": 0.5427042841911316,
    "entropy": 0.7317737638950348,
    "total_loss": -865.1252320602537
  },
  {
    "episode": 31,
    "avg_reward_per_step": 97.9312084432825,
    "episode_length": 206,
    "policy_loss": -1654.9251403808594,
    "value_loss": 0.5919816344976425,
    "entropy": 0.7597916424274445,
    "total_loss": -1654.371148328483
  },
  {
    "episode": 32,
    "avg_reward_per_step": 59.104940316559826,
    "episode_length": 339,
    "policy_loss": -1000.4368133544922,
    "value_loss": 0.5514039248228073,
    "entropy": 0.7919758707284927,
    "total_loss": -999.9250082232059
  },
  {
    "episode": 33,
    "avg_reward_per_step": 46.808051874937725,
    "episode_length": 422,
    "policy_loss": -790.9543914794922,
    "value_loss": 0.5390753597021103,
    "entropy": 0.8308949917554855,
    "total_loss": -790.4568608693778
  },
  {
    "episode": 34,
    "avg_reward_per_step": 23.58120646263811,
    "episode_length": 817,
    "policy_loss": -396.8191452026367,
    "value_loss": 0.5184366255998611,
    "entropy": 0.8867647796869278,
    "total_loss": -396.3450468160212
  },
  {
    "episode": 35,
    "avg_reward_per_step": 57.303515843193054,
    "episode_length": 345,
    "policy_loss": -970.6029205322266,
    "value_loss": 0.5489181131124496,
    "entropy": 0.8532285690307617,
    "total_loss": -970.0966638475657
  },
  {
    "episode": 36,
    "avg_reward_per_step": 39.65304558863731,
    "episode_length": 494,
    "policy_loss": -671.3657073974609,
    "value_loss": 0.532439574599266,
    "entropy": 0.8172992914915085,
    "total_loss": -670.8741327874362
  },
  {
    "episode": 37,
    "avg_reward_per_step": 37.48385574594919,
    "episode_length": 526,
    "policy_loss": -631.9407043457031,
    "value_loss": 0.5307145714759827,
    "entropy": 0.7339345812797546,
    "total_loss": -631.4466865032912
  },
  {
    "episode": 38,
    "avg_reward_per_step": 129.86503131622055,
    "episode_length": 155,
    "policy_loss": -2211.1627807617188,
    "value_loss": 0.6302369087934494,
    "entropy": 0.7939056307077408,
    "total_loss": -2210.5722391344607
  },
  {
    "episode": 39,
    "avg_reward_per_step": 45.66937370767051,
    "episode_length": 432,
    "policy_loss": -768.4794769287109,
    "value_loss": 0.5379572063684464,
    "entropy": 0.7537218481302261,
    "total_loss": -767.979205814749
  },
  {
    "episode": 40,
    "avg_reward_per_step": 118.67093924029972,
    "episode_length": 170,
    "policy_loss": -2039.2762756347656,
    "value_loss": 0.6165321320295334,
    "entropy": 0.7339688688516617,
    "total_loss": -2038.6964419461788
  },
  {
    "episode": 41,
    "avg_reward_per_step": 116.61481292946567,
    "episode_length": 172,
    "policy_loss": -1969.9251098632812,
    "value_loss": 0.6127868890762329,
    "entropy": 0.715755045413971,
    "total_loss": -1969.3481107264756
  },
  {
    "episode": 42,
    "avg_reward_per_step": 91.36515562846553,
    "episode_length": 221,
    "policy_loss": -1543.1399230957031,
    "value_loss": 0.5845889896154404,
    "entropy": 0.6208598464727402,
    "total_loss": -1542.5863770984113
  },
  {
    "episode": 43,
    "avg_reward_per_step": 54.78475226729478,
    "episode_length": 364,
    "policy_loss": -928.9860076904297,
    "value_loss": 0.5470360964536667,
    "entropy": 0.6125423759222031,
    "total_loss": -928.4695987127722
  },
  {
    "episode": 44,
    "avg_reward_per_step": 100.8339438205594,
    "episode_length": 200,
    "policy_loss": -1699.9120483398438,
    "value_loss": 0.5952772498130798,
    "entropy": 0.5633107274770737,
    "total_loss": -1699.3449366264044
  },
  {
    "episode": 45,
    "avg_reward_per_step": 85.98028742763665,
    "episode_length": 232,
    "policy_loss": -1450.5632934570312,
    "value_loss": 0.5779615938663483,
    "entropy": 0.6857167184352875,
    "total_loss": -1450.0196176990867
  },
  {
    "episode": 46,
    "avg_reward_per_step": 120.15197399066574,
    "episode_length": 167,
    "policy_loss": -2044.504638671875,
    "value_loss": 0.6170695126056671,
    "entropy": 0.651682123541832,
    "total_loss": -2043.9201532654465
  },
  {
    "episode": 47,
    "avg_reward_per_step": 41.177375580687766,
    "episode_length": 481,
    "policy_loss": -701.3536529541016,
    "value_loss": 0.5342087149620056,
    "entropy": 0.6832200437784195,
    "total_loss": -700.8536052413285
  },
  {
    "episode": 48,
    "avg_reward_per_step": 80.53372187413716,
    "episode_length": 249,
    "policy_loss": -1358.2719421386719,
    "value_loss": 0.5728204399347305,
    "entropy": 0.7165799140930176,
    "total_loss": -1357.7349506944417
  },
  {
    "episode": 49,
    "avg_reward_per_step": 121.28080048628827,
    "episode_length": 166,
    "policy_loss": -2061.8915100097656,
    "value_loss": 0.6186832636594772,
    "entropy": 0.7124860733747482,
    "total_loss": -2061.3084510497747
  },
  {
    "episode": 50,
    "avg_reward_per_step": 63.78766507215259,
    "episode_length": 312,
    "policy_loss": -1077.7077941894531,
    "value_loss": 0.5553305149078369,
    "entropy": 0.7129964530467987,
    "total_loss": -1077.1881134971977
  },
  {
    "episode": 51,
    "avg_reward_per_step": 60.51361823802677,
    "episode_length": 328,
    "policy_loss": -1021.0103302001953,
    "value_loss": 0.5521257817745209,
    "entropy": 0.6542586386203766,
    "total_loss": -1020.4909173503518
  },
  {
    "episode": 52,
    "avg_reward_per_step": 35.009013120446504,
    "episode_length": 562,
    "policy_loss": -596.6202239990234,
    "value_loss": 0.5285967588424683,
    "entropy": 0.6042829304933548,
    "total_loss": -596.1218413867057
  },
  {
    "episode": 53,
    "avg_reward_per_step": 104.34670110561892,
    "episode_length": 193,
    "policy_loss": -1762.8475646972656,
    "value_loss": 0.5988544523715973,
    "entropy": 0.5759880989789963,
    "total_loss": -1762.277509649843
  },
  {
    "episode": 54,
    "avg_reward_per_step": 107.31222246343621,
    "episode_length": 187,
    "policy_loss": -1808.4672546386719,
    "value_loss": 0.6020471751689911,
    "entropy": 0.5558136105537415,
    "total_loss": -1807.8929981440306
  },
  {
    "episode": 55,
    "avg_reward_per_step": 114.91470750429097,
    "episode_length": 175,
    "policy_loss": -1943.2601318359375,
    "value_loss": 0.6112660616636276,
    "entropy": 0.5986272096633911,
    "total_loss": -1942.6787971347571
  },
  {
    "episode": 56,
    "avg_reward_per_step": 62.38373800722892,
    "episode_length": 317,
    "policy_loss": -1053.8808898925781,
    "value_loss": 0.5539120733737946,
    "entropy": 0.6302202641963959,
    "total_loss": -1053.3584888324142
  },
  {
    "episode": 57,
    "avg_reward_per_step": 77.41443708186294,
    "episode_length": 259,
    "policy_loss": -1303.5029602050781,
    "value_loss": 0.5693954080343246,
    "entropy": 0.6042266637086868,
    "total_loss": -1302.9637761302292
  },
  {
    "episode": 58,
    "avg_reward_per_step": 67.26955454591888,
    "episode_length": 297,
    "policy_loss": -1140.5005187988281,
    "value_loss": 0.5589734464883804,
    "entropy": 0.601379007101059,
    "total_loss": -1139.971614302695
  },
  {
    "episode": 59,
    "avg_reward_per_step": 73.43108889952454,
    "episode_length": 272,
    "policy_loss": -1250.9639892578125,
    "value_loss": 0.5650841146707535,
    "entropy": 0.5699002891778946,
    "total_loss": -1250.4274001576007
  },
  {
    "episode": 60,
    "avg_reward_per_step": 100.43267551018559,
    "episode_length": 201,
    "policy_loss": -1694.6012878417969,
    "value_loss": 0.5949917286634445,
    "entropy": 0.5303928852081299,
    "total_loss": -1694.0328157573938
  },
  {
    "episode": 61,
    "avg_reward_per_step": 86.8641779842471,
    "episode_length": 233,
    "policy_loss": -1467.05419921875,
    "value_loss": 0.5802642107009888,
    "entropy": 0.4877771809697151,
    "total_loss": -1466.4983238670975
  },
  {
    "episode": 62,
    "avg_reward_per_step": 80.60329341577004,
    "episode_length": 249,
    "policy_loss": -1364.604248046875,
    "value_loss": 0.5728996694087982,
    "entropy": 0.43664853274822235,
    "total_loss": -1364.0531808041037
  },
  {
    "episode": 63,
    "avg_reward_per_step": 66.94481814284906,
    "episode_length": 302,
    "policy_loss": -1127.8048095703125,
    "value_loss": 0.5595495104789734,
    "entropy": 0.37876560539007187,
    "total_loss": -1127.2641983401031
  },
  {
    "episode": 64,
    "avg_reward_per_step": 33.50933804275961,
    "episode_length": 599,
    "policy_loss": -568.9688262939453,
    "value_loss": 0.527845561504364,
    "entropy": 0.3674359992146492,
    "total_loss": -568.4593525324017
  },
  {
    "episode": 65,
    "avg_reward_per_step": 74.88913880711159,
    "episode_length": 269,
    "policy_loss": -1274.7130737304688,
    "value_loss": 0.5672415196895599,
    "entropy": 0.39304909110069275,
    "total_loss": -1274.1654846653341
  },
  {
    "episode": 66,
    "avg_reward_per_step": 89.52086134489288,
    "episode_length": 225,
    "policy_loss": -1518.3182067871094,
    "value_loss": 0.5826627165079117,
    "entropy": 0.431285597383976,
    "total_loss": -1517.7571083504706
  },
  {
    "episode": 67,
    "avg_reward_per_step": 90.26102243964888,
    "episode_length": 223,
    "policy_loss": -1527.5238342285156,
    "value_loss": 0.5834736078977585,
    "entropy": 0.4108978733420372,
    "total_loss": -1526.960905514285
  },
  {
    "episode": 68,
    "avg_reward_per_step": 59.461778900059606,
    "episode_length": 338,
    "policy_loss": -1008.4203338623047,
    "value_loss": 0.5517855584621429,
    "entropy": 0.3493908941745758,
    "total_loss": -1007.8860178485513
  },
  {
    "episode": 69,
    "avg_reward_per_step": 77.66035329889421,
    "episode_length": 260,
    "policy_loss": -1313.4239501953125,
    "value_loss": 0.5706852525472641,
    "entropy": 0.4013984650373459,
    "total_loss": -1312.873334866017
  },
  {
    "episode": 70,
    "avg_reward_per_step": 85.77045788792738,
    "episode_length": 235,
    "policy_loss": -1453.9598388671875,
    "value_loss": 0.5787671655416489,
    "entropy": 0.3793177306652069,
    "total_loss": -1453.4000375881792
  },
  {
    "episode": 71,
    "avg_reward_per_step": 66.20919744029288,
    "episode_length": 304,
    "policy_loss": -1127.6140441894531,
    "value_loss": 0.5584699362516403,
    "entropy": 0.3513350114226341,
    "total_loss": -1127.0731410037727
  },
  {
    "episode": 72,
    "avg_reward_per_step": 80.70312811953337,
    "episode_length": 250,
    "policy_loss": -1356.4592895507812,
    "value_loss": 0.5733814090490341,
    "entropy": 0.35832179337739944,
    "total_loss": -1355.9038242314011
  },
  {
    "episode": 73,
    "avg_reward_per_step": 72.8061000514718,
    "episode_length": 277,
    "policy_loss": -1233.4895324707031,
    "value_loss": 0.5653609335422516,
    "entropy": 0.3622622638940811,
    "total_loss": -1232.9422846503555
  },
  {
    "episode": 74,
    "avg_reward_per_step": 92.33145637611831,
    "episode_length": 217,
    "policy_loss": -1586.9034118652344,
    "value_loss": 0.585186630487442,
    "entropy": 0.37972860038280487,
    "total_loss": -1586.337211664766
  },
  {
    "episode": 75,
    "avg_reward_per_step": 94.09191893298029,
    "episode_length": 214,
    "policy_loss": -1623.0238647460938,
    "value_loss": 0.587601825594902,
    "entropy": 0.3835623934864998,
    "total_loss": -1622.4554410401731
  },
  {
    "episode": 76,
    "avg_reward_per_step": 75.32519330077774,
    "episode_length": 268,
    "policy_loss": -1263.1971130371094,
    "value_loss": 0.5678668767213821,
    "entropy": 0.3726242035627365,
    "total_loss": -1262.6478773705662
  },
  {
    "episode": 77,
    "avg_reward_per_step": 94.82720075769032,
    "episode_length": 212,
    "policy_loss": -1600.1134948730469,
    "value_loss": 0.5882879048585892,
    "entropy": 0.4121812805533409,
    "total_loss": -1599.545816032216
  },
  {
    "episode": 78,
    "avg_reward_per_step": 100.83023616921278,
    "episode_length": 201,
    "policy_loss": -1705.9945983886719,
    "value_loss": 0.5961397439241409,
    "entropy": 0.42287128418684006,
    "total_loss": -1705.419602208957
  },
  {
    "episode": 79,
    "avg_reward_per_step": 59.22174060560564,
    "episode_length": 340,
    "policy_loss": -1000.8230895996094,
    "value_loss": 0.551571398973465,
    "entropy": 0.3115244209766388,
    "total_loss": -1000.2870944216847
  },
  {
    "episode": 80,
    "avg_reward_per_step": 31.026070360859165,
    "episode_length": 643,
    "policy_loss": -528.8887329101562,
    "value_loss": 0.5254921317100525,
    "entropy": 0.2664821222424507,
    "total_loss": -528.3765648845583
  },
  {
    "episode": 81,
    "avg_reward_per_step": 60.25922904118868,
    "episode_length": 334,
    "policy_loss": -1022.6537933349609,
    "value_loss": 0.5524670481681824,
    "entropy": 0.26239394396543503,
    "total_loss": -1022.114445983991
  },
  {
    "episode": 82,
    "avg_reward_per_step": 39.910415921791845,
    "episode_length": 501,
    "policy_loss": -668.4249420166016,
    "value_loss": 0.5333635807037354,
    "entropy": 0.21199000254273415,
    "total_loss": -667.9021779360249
  },
  {
    "episode": 83,
    "avg_reward_per_step": 53.23455264334045,
    "episode_length": 378,
    "policy_loss": -900.0395355224609,
    "value_loss": 0.5458444803953171,
    "entropy": 0.2343761995434761,
    "total_loss": -899.5054098520428
  },
  {
    "episode": 84,
    "avg_reward_per_step": 64.8178767350322,
    "episode_length": 311,
    "policy_loss": -1098.0794677734375,
    "value_loss": 0.557137593626976,
    "entropy": 0.26077552884817123,
    "total_loss": -1097.535368956253
  },
  {
    "episode": 85,
    "avg_reward_per_step": 94.95278512709835,
    "episode_length": 212,
    "policy_loss": -1611.1849975585938,
    "value_loss": 0.5884704887866974,
    "entropy": 0.32238365709781647,
    "total_loss": -1610.612646252662
  },
  {
    "episode": 86,
    "avg_reward_per_step": 68.58143738073844,
    "episode_length": 294,
    "policy_loss": -1164.9928894042969,
    "value_loss": 0.5609139204025269,
    "entropy": 0.28399474173784256,
    "total_loss": -1164.4461752209813
  },
  {
    "episode": 87,
    "avg_reward_per_step": 93.69468609961271,
    "episode_length": 215,
    "policy_loss": -1585.5438537597656,
    "value_loss": 0.587032675743103,
    "entropy": 0.27536360174417496,
    "total_loss": -1584.9705892641098
  },
  {
    "episode": 88,
    "avg_reward_per_step": 73.64144361764062,
    "episode_length": 273,
    "policy_loss": -1238.9880065917969,
    "value_loss": 0.5657562017440796,
    "entropy": 0.30176374316215515,
    "total_loss": -1238.437338577211
  },
  {
    "episode": 89,
    "avg_reward_per_step": 108.40272011452129,
    "episode_length": 186,
    "policy_loss": -1846.0102844238281,
    "value_loss": 0.6037863194942474,
    "entropy": 0.375778503715992,
    "total_loss": -1845.4252870295197
  },
  {
    "episode": 90,
    "avg_reward_per_step": 79.88354846014317,
    "episode_length": 252,
    "policy_loss": -1345.9167175292969,
    "value_loss": 0.5722794681787491,
    "entropy": 0.2890964597463608,
    "total_loss": -1345.3588928841054
  },
  {
    "episode": 91,
    "avg_reward_per_step": 58.834976689698,
    "episode_length": 341,
    "policy_loss": -989.7560729980469,
    "value_loss": 0.5509325712919235,
    "entropy": 0.26999685168266296,
    "total_loss": -989.2186402693391
  },
  {
    "episode": 92,
    "avg_reward_per_step": 71.86895842925824,
    "episode_length": 280,
    "policy_loss": -1221.2032775878906,
    "value_loss": 0.5640660971403122,
    "entropy": 0.3521750420331955,
    "total_loss": -1220.656820242852
  },
  {
    "episode": 93,
    "avg_reward_per_step": 121.99859667834782,
    "episode_length": 165,
    "policy_loss": -2068.198486328125,
    "value_loss": 0.6197784841060638,
    "entropy": 0.38670720905065536,
    "total_loss": -2067.5980432044717
  },
  {
    "episode": 94,
    "avg_reward_per_step": 60.18036858608373,
    "episode_length": 334,
    "policy_loss": -1021.2118225097656,
    "value_loss": 0.5523456484079361,
    "entropy": 0.29933376610279083,
    "total_loss": -1020.6744435496628
  },
  {
    "episode": 95,
    "avg_reward_per_step": 62.253229914705194,
    "episode_length": 323,
    "policy_loss": -1053.6480407714844,
    "value_loss": 0.5544002503156662,
    "entropy": 0.2985370382666588,
    "total_loss": -1053.108567373082
  },
  {
    "episode": 96,
    "avg_reward_per_step": 84.67080904562923,
    "episode_length": 238,
    "policy_loss": -1439.1235046386719,
    "value_loss": 0.5772362053394318,
    "entropy": 0.31000126898288727,
    "total_loss": -1438.5617684967815
  },
  {
    "episode": 97,
    "avg_reward_per_step": 123.07093276521141,
    "episode_length": 164,
    "policy_loss": -2078.1351318359375,
    "value_loss": 0.6213964521884918,
    "entropy": 0.3847547248005867,
    "total_loss": -2077.532973119989
  },
  {
    "episode": 98,
    "avg_reward_per_step": 117.48048333274697,
    "episode_length": 171,
    "policy_loss": -2004.6602783203125,
    "value_loss": 0.6139157116413116,
    "entropy": 0.39408306777477264,
    "total_loss": -2004.06606676206
  },
  {
    "episode": 99,
    "avg_reward_per_step": 149.78594536211855,
    "episode_length": 134,
    "policy_loss": -2548.2841186523438,
    "value_loss": 0.6552128493785858,
    "entropy": 0.39236363023519516,
    "total_loss": -2547.648523984477
  },
  {
    "episode": 100,
    "avg_reward_per_step": 133.10428071792523,
    "episode_length": 151,
    "policy_loss": -2248.0662231445312,
    "value_loss": 0.6332075595855713,
    "entropy": 0.38053203374147415,
    "total_loss": -2247.4520421866328
  },
  {
    "episode": 101,
    "avg_reward_per_step": 134.25656967102887,
    "episode_length": 150,
    "policy_loss": -2263.7758178710938,
    "value_loss": 0.6350068300962448,
    "entropy": 0.384900763630867,
    "total_loss": -2263.160056079179
  },
  {
    "episode": 102,
    "avg_reward_per_step": 99.8698759599655,
    "episode_length": 202,
    "policy_loss": -1694.8786926269531,
    "value_loss": 0.5939138531684875,
    "entropy": 0.2634923458099365,
    "total_loss": -1694.2979533910752
  },
  {
    "episode": 103,
    "avg_reward_per_step": 98.71293962537017,
    "episode_length": 204,
    "policy_loss": -1658.7025451660156,
    "value_loss": 0.5924136340618134,
    "entropy": 0.2538878731429577,
    "total_loss": -1658.1228259256109
  },
  {
    "episode": 104,
    "avg_reward_per_step": 83.09666566177579,
    "episode_length": 243,
    "policy_loss": -1410.4565124511719,
    "value_loss": 0.5757351368665695,
    "entropy": 0.26484014838933945,
    "total_loss": -1409.8940193217247
  },
  {
    "episode": 105,
    "avg_reward_per_step": 81.2569592115043,
    "episode_length": 248,
    "policy_loss": -1379.2099304199219,
    "value_loss": 0.5735595375299454,
    "entropy": 0.2564813569188118,
    "total_loss": -1378.6491949502379
  },
  {
    "episode": 106,
    "avg_reward_per_step": 53.28416167759878,
    "episode_length": 375,
    "policy_loss": -897.3968353271484,
    "value_loss": 0.5453388690948486,
    "entropy": 0.21958358958363533,
    "total_loss": -896.8624756375327
  },
  {
    "episode": 107,
    "avg_reward_per_step": 65.07840907059672,
    "episode_length": 309,
    "policy_loss": -1102.2171936035156,
    "value_loss": 0.5569827258586884,
    "entropy": 0.25770723819732666,
    "total_loss": -1101.6730962395668
  },
  {
    "episode": 108,
    "avg_reward_per_step": 64.88475583043706,
    "episode_length": 309,
    "policy_loss": -1090.43798828125,
    "value_loss": 0.556532233953476,
    "entropy": 0.27781498432159424,
    "total_loss": -1089.8953467965125
  },
  {
    "episode": 109,
    "avg_reward_per_step": 104.8636545247001,
    "episode_length": 192,
    "policy_loss": -1777.7248229980469,
    "value_loss": 0.5992711633443832,
    "entropy": 0.29521970450878143,
    "total_loss": -1777.1403128199279
  },
  {
    "episode": 110,
    "avg_reward_per_step": 85.78401356680294,
    "episode_length": 235,
    "policy_loss": -1442.250732421875,
    "value_loss": 0.5782836973667145,
    "entropy": 0.22551489621400833,
    "total_loss": -1441.683724469319
  },
  {
    "episode": 111,
    "avg_reward_per_step": 86.7948866315772,
    "episode_length": 233,
    "policy_loss": -1464.2452392578125,
    "value_loss": 0.5796636343002319,
    "entropy": 0.2633163034915924,
    "total_loss": -1463.6787414386868
  },
  {
    "episode": 112,
    "avg_reward_per_step": 79.64623816319646,
    "episode_length": 254,
    "policy_loss": -1352.2597351074219,
    "value_loss": 0.5721316784620285,
    "entropy": 0.26563381403684616,
    "total_loss": -1351.7008851196617
  },
  {
    "episode": 113,
    "avg_reward_per_step": 86.03522152063906,
    "episode_length": 235,
    "policy_loss": -1450.1134948730469,
    "value_loss": 0.5788712650537491,
    "entropy": 0.22004050761461258,
    "total_loss": -1449.545625633374
  },
  {
    "episode": 114,
    "avg_reward_per_step": 71.47710976744624,
    "episode_length": 283,
    "policy_loss": -1205.6472778320312,
    "value_loss": 0.5636940002441406,
    "entropy": 0.2661497965455055,
    "total_loss": -1205.0968913216143
  },
  {
    "episode": 115,
    "avg_reward_per_step": 96.05547937306619,
    "episode_length": 210,
    "policy_loss": -1615.1268310546875,
    "value_loss": 0.5894752889871597,
    "entropy": 0.2429676279425621,
    "total_loss": -1614.5495041470974
  },
  {
    "episode": 116,
    "avg_reward_per_step": 41.3084044949587,
    "episode_length": 488,
    "policy_loss": -692.2342224121094,
    "value_loss": 0.5344627052545547,
    "entropy": 0.2238670513033867,
    "total_loss": -691.71095305942
  },
  {
    "episode": 117,
    "avg_reward_per_step": 86.0786255107361,
    "episode_length": 235,
    "policy_loss": -1450.5562438964844,
    "value_loss": 0.578906923532486,
    "entropy": 0.22134820744395256,
    "total_loss": -1449.988404383324
  },
  {
    "episode": 118,
    "avg_reward_per_step": 55.04428755613318,
    "episode_length": 365,
    "policy_loss": -922.0320281982422,
    "value_loss": 0.5470417588949203,
    "entropy": 0.2056109942495823,
    "total_loss": -921.4952669890597
  },
  {
    "episode": 119,
    "avg_reward_per_step": 66.61316199028019,
    "episode_length": 302,
    "policy_loss": -1117.3919982910156,
    "value_loss": 0.5583241730928421,
    "entropy": 0.1958315744996071,
    "total_loss": -1116.8434656966479
  },
  {
    "episode": 120,
    "avg_reward_per_step": 105.83970041356314,
    "episode_length": 190,
    "policy_loss": -1784.4066467285156,
    "value_loss": 0.600068986415863,
    "entropy": 0.22660654410719872,
    "total_loss": -1783.817908069305
  },
  {
    "episode": 121,
    "avg_reward_per_step": 53.98802966693744,
    "episode_length": 372,
    "policy_loss": -910.6452026367188,
    "value_loss": 0.5459740906953812,
    "entropy": 0.1935541145503521,
    "total_loss": -910.1089062517509
  },
  {
    "episode": 122,
    "avg_reward_per_step": 93.24213872979152,
    "episode_length": 216,
    "policy_loss": -1571.6089782714844,
    "value_loss": 0.5860978364944458,
    "entropy": 0.2186245508491993,
    "total_loss": -1571.0338116625323
  },
  {
    "episode": 123,
    "avg_reward_per_step": 154.63321199308288,
    "episode_length": 130,
    "policy_loss": -2606.4651489257812,
    "value_loss": 0.6617276221513748,
    "entropy": 0.286789171397686,
    "total_loss": -2605.8177607621997
  },
  {
    "episode": 124,
    "avg_reward_per_step": 101.32458963791267,
    "episode_length": 199,
    "policy_loss": -1702.8685607910156,
    "value_loss": 0.5951634496450424,
    "entropy": 0.2055537961423397,
    "total_loss": -1702.2836750311776
  },
  {
    "episode": 125,
    "avg_reward_per_step": 65.28876829111901,
    "episode_length": 309,
    "policy_loss": -1100.2474060058594,
    "value_loss": 0.5571092814207077,
    "entropy": 0.19294115155935287,
    "total_loss": -1099.6999437820166
  },
  {
    "episode": 126,
    "avg_reward_per_step": 41.839217579429985,
    "episode_length": 480,
    "policy_loss": -701.3566589355469,
    "value_loss": 0.5347308665513992,
    "entropy": 0.16074076667428017,
    "total_loss": -700.8299651073291
  },
  {
    "episode": 127,
    "avg_reward_per_step": 95.31332476037106,
    "episode_length": 212,
    "policy_loss": -1602.3524169921875,
    "value_loss": 0.5886062532663345,
    "entropy": 0.22603139653801918,
    "total_loss": -1601.775112308748
  },
  {
    "episode": 128,
    "avg_reward_per_step": 64.46845429500435,
    "episode_length": 312,
    "policy_loss": -1084.8961791992188,
    "value_loss": 0.5560609251260757,
    "entropy": 0.1837783008813858,
    "total_loss": -1084.3493071891367
  },
  {
    "episode": 129,
    "avg_reward_per_step": 88.20575746086728,
    "episode_length": 229,
    "policy_loss": -1482.4268493652344,
    "value_loss": 0.5807415544986725,
    "entropy": 0.210687555372715,
    "total_loss": -1481.8566421885043
  },
  {
    "episode": 130,
    "avg_reward_per_step": 29.409608356666702,
    "episode_length": 674,
    "policy_loss": -493.531494140625,
    "value_loss": 0.5232417583465576,
    "entropy": 0.17264188081026077,
    "total_loss": -493.016884476319
  },
  {
    "episode": 131,
    "avg_reward_per_step": 88.85185734387072,
    "episode_length": 227,
    "policy_loss": -1495.4566345214844,
    "value_loss": 0.5813245624303818,
    "entropy": 0.20991046726703644,
    "total_loss": -1494.8858054824173
  },
  {
    "episode": 132,
    "avg_reward_per_step": 90.59841326430991,
    "episode_length": 223,
    "policy_loss": -1517.6819152832031,
    "value_loss": 0.5833377093076706,
    "entropy": 0.19439958781003952,
    "total_loss": -1517.1082975532859
  },
  {
    "episode": 133,
    "avg_reward_per_step": 84.24041721041853,
    "episode_length": 239,
    "policy_loss": -1416.4493408203125,
    "value_loss": 0.5760891139507294,
    "entropy": 0.20835021883249283,
    "total_loss": -1415.8836692173033
  },
  {
    "episode": 134,
    "avg_reward_per_step": 106.16276651032494,
    "episode_length": 190,
    "policy_loss": -1782.9432067871094,
    "value_loss": 0.6004288494586945,
    "entropy": 0.23675478249788284,
    "total_loss": -1782.3546156767757
  },
  {
    "episode": 135,
    "avg_reward_per_step": 106.6327611135619,
    "episode_length": 189,
    "policy_loss": -1792.8638916015625,
    "value_loss": 0.6008348912000656,
    "entropy": 0.2255251668393612,
    "total_loss": -1792.2743329687044
  },
  {
    "episode": 136,
    "avg_reward_per_step": 159.49515385016915,
    "episode_length": 126,
    "policy_loss": -2682.1353149414062,
    "value_loss": 0.6683655381202698,
    "entropy": 0.25762685388326645,
    "total_loss": -2681.47983074598
  },
  {
    "episode": 137,
    "avg_reward_per_step": 90.517080863621,
    "episode_length": 222,
    "policy_loss": -1525.6214904785156,
    "value_loss": 0.5825782269239426,
    "entropy": 0.2103588879108429,
    "total_loss": -1525.0494301959873
  },
  {
    "episode": 138,
    "avg_reward_per_step": 108.07375009577878,
    "episode_length": 186,
    "policy_loss": -1811.9580078125,
    "value_loss": 0.6021155267953873,
    "entropy": 0.16181911900639534,
    "total_loss": -1811.363983241655
  },
  {
    "episode": 139,
    "avg_reward_per_step": 110.2461517863614,
    "episode_length": 183,
    "policy_loss": -1849.5755004882812,
    "value_loss": 0.605147123336792,
    "entropy": 0.17595938965678215,
    "total_loss": -1848.9791513344273
  },
  {
    "episode": 140,
    "avg_reward_per_step": 70.83613444556163,
    "episode_length": 283,
    "policy_loss": -1187.2303161621094,
    "value_loss": 0.5617786347866058,
    "entropy": 0.2302163764834404,
    "total_loss": -1186.680048346147
  },
  {
    "episode": 141,
    "avg_reward_per_step": 158.20648111940469,
    "episode_length": 127,
    "policy_loss": -2654.4879150390625,
    "value_loss": 0.6662858873605728,
    "entropy": 0.21828873828053474,
    "total_loss": -2653.832543588616
  },
  {
    "episode": 142,
    "avg_reward_per_step": 132.7030769357785,
    "episode_length": 152,
    "policy_loss": -2224.9795532226562,
    "value_loss": 0.632439449429512,
    "entropy": 0.20473184809088707,
    "total_loss": -2224.357350365631
  },
  {
    "episode": 143,
    "avg_reward_per_step": 140.0728387929634,
    "episode_length": 144,
    "policy_loss": -2331.7898559570312,
    "value_loss": 0.6420186161994934,
    "entropy": 0.2077162079513073,
    "total_loss": -2331.1582231512293
  },
  {
    "episode": 144,
    "avg_reward_per_step": 159.88228642389424,
    "episode_length": 126,
    "policy_loss": -2673.3694458007812,
    "value_loss": 0.6691165417432785,
    "entropy": 0.22274785116314888,
    "total_loss": -2672.7114666515963
  },
  {
    "episode": 145,
    "avg_reward_per_step": 159.8063621068646,
    "episode_length": 126,
    "policy_loss": -2676.3736572265625,
    "value_loss": 0.6690464168787003,
    "entropy": 0.17996250465512276,
    "total_loss": -2675.7136089349165
  },
  {
    "episode": 146,
    "avg_reward_per_step": 86.51256530076687,
    "episode_length": 232,
    "policy_loss": -1447.3632202148438,
    "value_loss": 0.5779193043708801,
    "entropy": 0.2480040304362774,
    "total_loss": -1446.7977011119947
  },
  {
    "episode": 147,
    "avg_reward_per_step": 103.47222479172018,
    "episode_length": 194,
    "policy_loss": -1733.334228515625,
    "value_loss": 0.596598282456398,
    "entropy": 0.20983874797821045,
    "total_loss": -1732.7481221705675
  },
  {
    "episode": 148,
    "avg_reward_per_step": 84.31724273213962,
    "episode_length": 237,
    "policy_loss": -1413.7349853515625,
    "value_loss": 0.5751407593488693,
    "entropy": 0.21721675992012024,
    "total_loss": -1413.1707054302096
  },
  {
    "episode": 149,
    "avg_reward_per_step": 159.70385608996932,
    "episode_length": 126,
    "policy_loss": -2674.7757568359375,
    "value_loss": 0.6684605628252029,
    "entropy": 0.19924471527338028,
    "total_loss": -2674.117258508876
  },
  {
    "episode": 150,
    "avg_reward_per_step": 159.42794430046683,
    "episode_length": 126,
    "policy_loss": -2672.4832153320312,
    "value_loss": 0.6677650064229965,
    "entropy": 0.21323714777827263,
    "total_loss": -2671.8261121829973
  },
  {
    "episode": 151,
    "avg_reward_per_step": 59.039377158883326,
    "episode_length": 336,
    "policy_loss": -988.7899475097656,
    "value_loss": 0.5496248155832291,
    "entropy": 0.2236085683107376,
    "total_loss": -988.2515031225979
  },
  {
    "episode": 152,
    "avg_reward_per_step": 98.22969857864345,
    "episode_length": 204,
    "policy_loss": -1640.1931762695312,
    "value_loss": 0.5903285443782806,
    "entropy": 0.21013469621539116,
    "total_loss": -1639.6133544599638
  },
  {
    "episode": 153,
    "avg_reward_per_step": 44.51669550258804,
    "episode_length": 443,
    "policy_loss": -740.0834045410156,
    "value_loss": 0.5358317047357559,
    "entropy": 0.23078488186001778,
    "total_loss": -739.5591120803729
  },
  {
    "episode": 154,
    "avg_reward_per_step": 89.56654485548165,
    "episode_length": 223,
    "policy_loss": -1497.7539672851562,
    "value_loss": 0.5804090052843094,
    "entropy": 0.21624970063567162,
    "total_loss": -1497.1843707649036
  },
  {
    "episode": 155,
    "avg_reward_per_step": 75.28822575494499,
    "episode_length": 265,
    "policy_loss": -1269.7140502929688,
    "value_loss": 0.5656010955572128,
    "entropy": 0.21957070752978325,
    "total_loss": -1269.1594277327881
  },
  {
    "episode": 156,
    "avg_reward_per_step": 159.44754430839333,
    "episode_length": 126,
    "policy_loss": -2671.630126953125,
    "value_loss": 0.6675813943147659,
    "entropy": 0.17994369193911552,
    "total_loss": -2670.971542743407
  },
  {
    "episode": 157,
    "avg_reward_per_step": 159.5033448108356,
    "episode_length": 126,
    "policy_loss": -2664.2269287109375,
    "value_loss": 0.6676854342222214,
    "entropy": 0.15628715604543686,
    "total_loss": -2663.5670576345174
  },
  {
    "episode": 158,
    "avg_reward_per_step": 54.76103471097148,
    "episode_length": 363,
    "policy_loss": -914.2576293945312,
    "value_loss": 0.5453284531831741,
    "entropy": 0.21166538447141647,
    "total_loss": -913.7228842105717
  },
  {
    "episode": 159,
    "avg_reward_per_step": 159.5249599540744,
    "episode_length": 126,
    "policy_loss": -2675.05712890625,
    "value_loss": 0.6674870401620865,
    "entropy": 0.19886762276291847,
    "total_loss": -2674.3995852472262
  },
  {
    "episode": 160,
    "avg_reward_per_step": 159.6530262839422,
    "episode_length": 126,
    "policy_loss": -2668.3763427734375,
    "value_loss": 0.6680287420749664,
    "entropy": 0.15686989575624466,
    "total_loss": -2667.7161575261503
  },
  {
    "episode": 161,
    "avg_reward_per_step": 159.58127633421643,
    "episode_length": 126,
    "policy_loss": -2667.8138427734375,
    "value_loss": 0.6677628010511398,
    "entropy": 0.15760889276862144,
    "total_loss": -2667.153960417025
  },
  {
    "episode": 162,
    "avg_reward_per_step": 159.40108879166388,
    "episode_length": 126,
    "policy_loss": -2666.62890625,
    "value_loss": 0.6672184467315674,
    "entropy": 0.15776841342449188,
    "total_loss": -2665.96957622394
  },
  {
    "episode": 163,
    "avg_reward_per_step": 163.36030423980452,
    "episode_length": 123,
    "policy_loss": -2752.0991821289062,
    "value_loss": 0.6729709506034851,
    "entropy": 0.21728558093309402,
    "total_loss": -2751.4370754573492
  },
  {
    "episode": 164,
    "avg_reward_per_step": 176.43020633790164,
    "episode_length": 114,
    "policy_loss": -2947.7750244140625,
    "value_loss": 0.6936283260583878,
    "entropy": 0.14996033534407616,
    "total_loss": -2947.0888941047715
  },
  {
    "episode": 165,
    "avg_reward_per_step": 159.42138359890268,
    "episode_length": 126,
    "policy_loss": -2670.311279296875,
    "value_loss": 0.6671804487705231,
    "entropy": 0.17305366694927216,
    "total_loss": -2669.652751531452
  },
  {
    "episode": 166,
    "avg_reward_per_step": 158.1700865726508,
    "episode_length": 127,
    "policy_loss": -2640.6387939453125,
    "value_loss": 0.6653514355421066,
    "entropy": 0.16091712564229965,
    "total_loss": -2639.9814883660524
  },
  {
    "episode": 167,
    "avg_reward_per_step": 100.69128390616727,
    "episode_length": 199,
    "policy_loss": -1678.3041076660156,
    "value_loss": 0.5925226956605911,
    "entropy": 0.18117021024227142,
    "total_loss": -1677.7206434808672
  },
  {
    "episode": 168,
    "avg_reward_per_step": 157.00025949900157,
    "episode_length": 128,
    "policy_loss": -2619.7635498046875,
    "value_loss": 0.6636932045221329,
    "entropy": 0.16858574002981186,
    "total_loss": -2619.108285887167
  },
  {
    "episode": 169,
    "avg_reward_per_step": 159.411322894261,
    "episode_length": 126,
    "policy_loss": -2636.9242553710938,
    "value_loss": 0.6668797731399536,
    "entropy": 0.16892081499099731,
    "total_loss": -2636.2658216387035
  },
  {
    "episode": 170,
    "avg_reward_per_step": 158.32563059366802,
    "episode_length": 127,
    "policy_loss": -2647.4366455078125,
    "value_loss": 0.665543869137764,
    "entropy": 0.174995768815279,
    "total_loss": -2646.7798514271153
  },
  {
    "episode": 171,
    "avg_reward_per_step": 159.6105620813706,
    "episode_length": 126,
    "policy_loss": -2649.3598022460938,
    "value_loss": 0.6673760563135147,
    "entropy": 0.16158800944685936,
    "total_loss": -2648.7005055902528
  },
  {
    "episode": 172,
    "avg_reward_per_step": 158.34075735352474,
    "episode_length": 127,
    "policy_loss": -2645.1046142578125,
    "value_loss": 0.6655832678079605,
    "entropy": 0.168583732098341,
    "total_loss": -2644.4474601766096
  },
  {
    "episode": 173,
    "avg_reward_per_step": 106.23067492337685,
    "episode_length": 189,
    "policy_loss": -1776.8573303222656,
    "value_loss": 0.5991184115409851,
    "entropy": 0.22180141881108284,
    "total_loss": -1776.2693019816652
  },
  {
    "episode": 174,
    "avg_reward_per_step": 32.202495393801335,
    "episode_length": 617,
    "policy_loss": -532.6385498046875,
    "value_loss": 0.5246216505765915,
    "entropy": 0.1139914020895958,
    "total_loss": -532.1196277242154
  },
  {
    "episode": 175,
    "avg_reward_per_step": 81.1368604735949,
    "episode_length": 248,
    "policy_loss": -1352.8638610839844,
    "value_loss": 0.5715728551149368,
    "entropy": 0.11929433979094028,
    "total_loss": -1352.298252945859
  },
  {
    "episode": 176,
    "avg_reward_per_step": 39.841531636164824,
    "episode_length": 502,
    "policy_loss": -658.5338439941406,
    "value_loss": 0.5314801335334778,
    "entropy": 0.0965416319668293,
    "total_loss": -658.0071909422055
  },
  {
    "episode": 177,
    "avg_reward_per_step": 40.28761996665022,
    "episode_length": 496,
    "policy_loss": -664.5872802734375,
    "value_loss": 0.5318059921264648,
    "entropy": 0.09751713275909424,
    "total_loss": -664.060350137949
  },
  {
    "episode": 178,
    "avg_reward_per_step": 97.25637983541164,
    "episode_length": 207,
    "policy_loss": -1619.3134155273438,
    "value_loss": 0.5890143811702728,
    "entropy": 0.1487848423421383,
    "total_loss": -1618.7318403882905
  },
  {
    "episode": 179,
    "avg_reward_per_step": 178.20136917897898,
    "episode_length": 113,
    "policy_loss": -2951.4077758789062,
    "value_loss": 0.6962048262357712,
    "entropy": 0.1613505594432354,
    "total_loss": -2950.719638580643
  },
  {
    "episode": 180,
    "avg_reward_per_step": 154.88775235104592,
    "episode_length": 130,
    "policy_loss": -2569.8378295898438,
    "value_loss": 0.6607875823974609,
    "entropy": 0.20474347099661827,
    "total_loss": -2569.187279180996
  },
  {
    "episode": 181,
    "avg_reward_per_step": 109.43037594103119,
    "episode_length": 184,
    "policy_loss": -1829.7937927246094,
    "value_loss": 0.6026739627122879,
    "entropy": 0.1840430423617363,
    "total_loss": -1829.2003209140153
  },
  {
    "episode": 182,
    "avg_reward_per_step": 78.06657847677349,
    "episode_length": 256,
    "policy_loss": -1292.7405090332031,
    "value_loss": 0.5676521509885788,
    "entropy": 0.21428024768829346,
    "total_loss": -1292.183570894599
  },
  {
    "episode": 183,
    "avg_reward_per_step": 159.32308946366499,
    "episode_length": 126,
    "policy_loss": -2667.9266357421875,
    "value_loss": 0.6663194894790649,
    "entropy": 0.18203656747937202,
    "total_loss": -2667.269418081082
  },
  {
    "episode": 184,
    "avg_reward_per_step": 158.22172805610282,
    "episode_length": 127,
    "policy_loss": -2568.9861450195312,
    "value_loss": 0.6648829281330109,
    "entropy": 0.1649652160704136,
    "total_loss": -2568.329510352202
  },
  {
    "episode": 185,
    "avg_reward_per_step": 162.19184992835008,
    "episode_length": 124,
    "policy_loss": -2729.2137451171875,
    "value_loss": 0.6705495417118073,
    "entropy": 0.15720561146736145,
    "total_loss": -2728.551055856049
  },
  {
    "episode": 186,
    "avg_reward_per_step": 113.22752370717345,
    "episode_length": 178,
    "policy_loss": -1883.3576049804688,
    "value_loss": 0.6070380061864853,
    "entropy": 0.18971821665763855,
    "total_loss": -1882.760052885115
  },
  {
    "episode": 187,
    "avg_reward_per_step": 92.6849227033,
    "episode_length": 217,
    "policy_loss": -1532.3153381347656,
    "value_loss": 0.583480179309845,
    "entropy": 0.17980139702558517,
    "total_loss": -1531.740848025307
  },
  {
    "episode": 188,
    "avg_reward_per_step": 98.22156257789575,
    "episode_length": 204,
    "policy_loss": -1644.11181640625,
    "value_loss": 0.5890563130378723,
    "entropy": 0.19217800721526146,
    "total_loss": -1643.5323689935728
  },
  {
    "episode": 189,
    "avg_reward_per_step": 158.21884694542752,
    "episode_length": 127,
    "policy_loss": -2630.8299560546875,
    "value_loss": 0.6644681692123413,
    "entropy": 0.1471581794321537,
    "total_loss": -2630.172845794447
  },
  {
    "episode": 190,
    "avg_reward_per_step": 159.48448554154527,
    "episode_length": 126,
    "policy_loss": -2646.5525512695312,
    "value_loss": 0.6664167195558548,
    "entropy": 0.15314914286136627,
    "total_loss": -2645.8937920071185
  },
  {
    "episode": 191,
    "avg_reward_per_step": 158.58820426494688,
    "episode_length": 127,
    "policy_loss": -2646.3947143554688,
    "value_loss": 0.6653421819210052,
    "entropy": 0.15433548763394356,
    "total_loss": -2645.7370889479294
  },
  {
    "episode": 192,
    "avg_reward_per_step": 159.46601722771007,
    "episode_length": 126,
    "policy_loss": -2660.1898803710938,
    "value_loss": 0.6662100553512573,
    "entropy": 0.15359530597925186,
    "total_loss": -2659.5313500810416
  },
  {
    "episode": 193,
    "avg_reward_per_step": 82.80099441076528,
    "episode_length": 243,
    "policy_loss": -1363.1444091796875,
    "value_loss": 0.5725408494472504,
    "entropy": 0.1577623412013054,
    "total_loss": -1362.5797564473003
  },
  {
    "episode": 194,
    "avg_reward_per_step": 159.54532063113248,
    "episode_length": 126,
    "policy_loss": -2653.211181640625,
    "value_loss": 0.666145533323288,
    "entropy": 0.138844545930624,
    "total_loss": -2652.551978334598
  },
  {
    "episode": 195,
    "avg_reward_per_step": 71.11583377468492,
    "episode_length": 280,
    "policy_loss": -1172.0369873046875,
    "value_loss": 0.5596278011798859,
    "entropy": 0.17638838291168213,
    "total_loss": -1171.4861789226532
  },
  {
    "episode": 196,
    "avg_reward_per_step": 50.5132995114217,
    "episode_length": 397,
    "policy_loss": -827.5406341552734,
    "value_loss": 0.5403323173522949,
    "entropy": 0.11847064644098282,
    "total_loss": -827.0062253702432
  },
  {
    "episode": 197,
    "avg_reward_per_step": 159.63238100525626,
    "episode_length": 126,
    "policy_loss": -2650.1588745117188,
    "value_loss": 0.666211262345314,
    "entropy": 0.13836714252829552,
    "total_loss": -2649.4995816064998
  },
  {
    "episode": 198,
    "avg_reward_per_step": 158.09820664672353,
    "episode_length": 127,
    "policy_loss": -2633.2645263671875,
    "value_loss": 0.6636229753494263,
    "entropy": 0.1466566026210785,
    "total_loss": -2632.608236221969
  },
  {
    "episode": 199,
    "avg_reward_per_step": 159.66654767298644,
    "episode_length": 126,
    "policy_loss": -2656.6976928710938,
    "value_loss": 0.6662377566099167,
    "entropy": 0.12481990084052086,
    "total_loss": -2656.0376961095258
  },
  {
    "episode": 200,
    "avg_reward_per_step": 160.74949109348137,
    "episode_length": 125,
    "policy_loss": -2667.6708374023438,
    "value_loss": 0.6675342321395874,
    "entropy": 0.13742687553167343,
    "total_loss": -2667.010174513981
  },
  {
    "episode": 201,
    "avg_reward_per_step": 160.84425565573287,
    "episode_length": 125,
    "policy_loss": -2673.2950439453125,
    "value_loss": 0.6677062660455704,
    "entropy": 0.11620663106441498,
    "total_loss": -2672.63314801082
  },
  {
    "episode": 202,
    "avg_reward_per_step": 98.13386601779922,
    "episode_length": 204,
    "policy_loss": -1622.0133056640625,
    "value_loss": 0.5879934281110764,
    "entropy": 0.14890064299106598,
    "total_loss": -1621.4327572681009
  },
  {
    "episode": 203,
    "avg_reward_per_step": 104.85955411603244,
    "episode_length": 191,
    "policy_loss": -1768.4767150878906,
    "value_loss": 0.5954991281032562,
    "entropy": 0.16241679713129997,
    "total_loss": -1767.8893367996438
  },
  {
    "episode": 204,
    "avg_reward_per_step": 162.39045860973272,
    "episode_length": 124,
    "policy_loss": -2692.5470581054688,
    "value_loss": 0.6702250987291336,
    "entropy": 0.13463392108678818,
    "total_loss": -2691.883564702794
  },
  {
    "episode": 205,
    "avg_reward_per_step": 159.69917442177695,
    "episode_length": 126,
    "policy_loss": -2651.2272338867188,
    "value_loss": 0.6661179959774017,
    "entropy": 0.10503755137324333,
    "total_loss": -2650.56636776831
  },
  {
    "episode": 206,
    "avg_reward_per_step": 160.87904503380858,
    "episode_length": 125,
    "policy_loss": -2672.7640991210938,
    "value_loss": 0.6676163673400879,
    "entropy": 0.12227869220077991,
    "total_loss": -2672.1025966883635
  },
  {
    "episode": 207,
    "avg_reward_per_step": 179.85434476952065,
    "episode_length": 112,
    "policy_loss": -2989.1741333007812,
    "value_loss": 0.6970719397068024,
    "entropy": 0.1011071540415287,
    "total_loss": -2988.4821167187765
  },
  {
    "episode": 208,
    "avg_reward_per_step": 161.0395786226463,
    "episode_length": 125,
    "policy_loss": -2672.3460693359375,
    "value_loss": 0.6679145991802216,
    "entropy": 0.10428904928267002,
    "total_loss": -2671.6833691892216
  },
  {
    "episode": 209,
    "avg_reward_per_step": 159.50598397984677,
    "episode_length": 126,
    "policy_loss": -2657.536376953125,
    "value_loss": 0.6651986539363861,
    "entropy": 0.11148690432310104,
    "total_loss": -2656.876752644405
  },
  {
    "episode": 210,
    "avg_reward_per_step": 135.9297343452354,
    "episode_length": 148,
    "policy_loss": -2251.1865234375,
    "value_loss": 0.6334894895553589,
    "entropy": 0.15379464998841286,
    "total_loss": -2250.560723680444
  },
  {
    "episode": 211,
    "avg_reward_per_step": 161.0284773927947,
    "episode_length": 125,
    "policy_loss": -2672.3373413085938,
    "value_loss": 0.6677608042955399,
    "entropy": 0.10336615703999996,
    "total_loss": -2671.67474881215
  },
  {
    "episode": 212,
    "avg_reward_per_step": 159.68251733491348,
    "episode_length": 126,
    "policy_loss": -2641.6140747070312,
    "value_loss": 0.6656646728515625,
    "entropy": 0.11620988510549068,
    "total_loss": -2640.954220528435
  },
  {
    "episode": 213,
    "avg_reward_per_step": 160.9424248686134,
    "episode_length": 125,
    "policy_loss": -2664.1176147460938,
    "value_loss": 0.6674119532108307,
    "entropy": 0.0872800387442112,
    "total_loss": -2663.45456679482
  },
  {
    "episode": 214,
    "avg_reward_per_step": 178.26165569781554,
    "episode_length": 113,
    "policy_loss": -2959.6427001953125,
    "value_loss": 0.6944360285997391,
    "entropy": 0.09422300197184086,
    "total_loss": -2958.9529753168113
  },
  {
    "episode": 215,
    "avg_reward_per_step": 161.03959243115017,
    "episode_length": 125,
    "policy_loss": -2665.3329467773438,
    "value_loss": 0.6675896048545837,
    "entropy": 0.11452704295516014,
    "total_loss": -2664.6710835246367
  },
  {
    "episode": 216,
    "avg_reward_per_step": 160.9020659131527,
    "episode_length": 125,
    "policy_loss": -2663.022705078125,
    "value_loss": 0.6671614050865173,
    "entropy": 0.10737246461212635,
    "total_loss": -2662.360912296269
  },
  {
    "episode": 217,
    "avg_reward_per_step": 85.99225376880307,
    "episode_length": 232,
    "policy_loss": -1412.4111938476562,
    "value_loss": 0.5742885917425156,
    "entropy": 0.13210423290729523,
    "total_loss": -1411.843510467559
  },
  {
    "episode": 218,
    "avg_reward_per_step": 160.99699402929912,
    "episode_length": 125,
    "policy_loss": -2663.2997436523438,
    "value_loss": 0.6672837138175964,
    "entropy": 0.1317114643752575,
    "total_loss": -2662.639045511745
  },
  {
    "episode": 219,
    "avg_reward_per_step": 161.0498176873967,
    "episode_length": 125,
    "policy_loss": -2637.262451171875,
    "value_loss": 0.6671359986066818,
    "entropy": 0.12265766225755215,
    "total_loss": -2636.6014480563813
  },
  {
    "episode": 220,
    "avg_reward_per_step": 163.4636038550236,
    "episode_length": 123,
    "policy_loss": -2715.5015869140625,
    "value_loss": 0.6703809350728989,
    "entropy": 0.1144462414085865,
    "total_loss": -2714.83692829106
  },
  {
    "episode": 221,
    "avg_reward_per_step": 163.48165923408052,
    "episode_length": 123,
    "policy_loss": -2709.5071411132812,
    "value_loss": 0.6705172657966614,
    "entropy": 0.12347769737243652,
    "total_loss": -2708.842797732353
  },
  {
    "episode": 222,
    "avg_reward_per_step": 158.47980502145327,
    "episode_length": 127,
    "policy_loss": -2624.6653442382812,
    "value_loss": 0.6634967774152756,
    "entropy": 0.1167184580117464,
    "total_loss": -2624.0076833837666
  },
  {
    "episode": 223,
    "avg_reward_per_step": 182.0532135615484,
    "episode_length": 111,
    "policy_loss": -3015.0186767578125,
    "value_loss": 0.7001733928918839,
    "entropy": 0.08957486785948277,
    "total_loss": -3014.3229821083137
  },
  {
    "episode": 224,
    "avg_reward_per_step": 183.5840322099858,
    "episode_length": 110,
    "policy_loss": -3026.144287109375,
    "value_loss": 0.70231893658638,
    "entropy": 0.09890829585492611,
    "total_loss": -3025.4469135875815
  },
  {
    "episode": 225,
    "avg_reward_per_step": 159.70036427520006,
    "episode_length": 126,
    "policy_loss": -2567.2701416015625,
    "value_loss": 0.6649674773216248,
    "entropy": 0.11961707659065723,
    "total_loss": -2566.6111549780703
  },
  {
    "episode": 226,
    "avg_reward_per_step": 158.45844152834553,
    "episode_length": 127,
    "policy_loss": -2570.8282470703125,
    "value_loss": 0.6633384972810745,
    "entropy": 0.10874010995030403,
    "total_loss": -2570.170345578529
  },
  {
    "episode": 227,
    "avg_reward_per_step": 173.49043752530795,
    "episode_length": 116,
    "policy_loss": -2878.475341796875,
    "value_loss": 0.6860931068658829,
    "entropy": 0.1073676310479641,
    "total_loss": -2877.7946170715613
  },
  {
    "episode": 228,
    "avg_reward_per_step": 174.9671998378232,
    "episode_length": 115,
    "policy_loss": -2896.3468627929688,
    "value_loss": 0.6881762444972992,
    "entropy": 0.1034200880676508,
    "total_loss": -2895.663857552875
  },
  {
    "episode": 229,
    "avg_reward_per_step": 181.69564404662648,
    "episode_length": 111,
    "policy_loss": -2988.5032958984375,
    "value_loss": 0.6990819126367569,
    "entropy": 0.11164494790136814,
    "total_loss": -2987.809796233196
  },
  {
    "episode": 230,
    "avg_reward_per_step": 98.14540481556865,
    "episode_length": 204,
    "policy_loss": -1619.1702880859375,
    "value_loss": 0.5873681753873825,
    "entropy": 0.14562225341796875,
    "total_loss": -1618.590201023221
  },
  {
    "episode": 231,
    "avg_reward_per_step": 173.50021455677913,
    "episode_length": 116,
    "policy_loss": -2881.0853881835938,
    "value_loss": 0.6857166141271591,
    "entropy": 0.08319234661757946,
    "total_loss": -2880.4038311867976
  },
  {
    "episode": 232,
    "avg_reward_per_step": 13.241750973891065,
    "episode_length": 1474,
    "policy_loss": -189.51891326904297,
    "value_loss": 0.50611512362957,
    "entropy": 0.025648340117186308,
    "total_loss": -189.01408056241925
  },
  {
    "episode": 233,
    "avg_reward_per_step": 154.68739577409755,
    "episode_length": 130,
    "policy_loss": -2560.7316284179688,
    "value_loss": 0.6570801585912704,
    "entropy": 0.10864278115332127,
    "total_loss": -2560.079980398435
  },
  {
    "episode": 234,
    "avg_reward_per_step": 153.64767128671676,
    "episode_length": 131,
    "policy_loss": -2531.313232421875,
    "value_loss": 0.6558896452188492,
    "entropy": 0.12977820448577404,
    "total_loss": -2530.6638316868803
  },
  {
    "episode": 235,
    "avg_reward_per_step": 158.4310070753201,
    "episode_length": 127,
    "policy_loss": -2607.7086181640625,
    "value_loss": 0.662588581442833,
    "entropy": 0.11628615856170654,
    "total_loss": -2607.051843890548
  },
  {
    "episode": 236,
    "avg_reward_per_step": 171.85711385946084,
    "episode_length": 117,
    "policy_loss": -2850.5525512695312,
    "value_loss": 0.6828519403934479,
    "entropy": 0.10155059397220612,
    "total_loss": -2849.8747768588364
  },
  {
    "episode": 237,
    "avg_reward_per_step": 155.93388490188786,
    "episode_length": 129,
    "policy_loss": -2563.7520751953125,
    "value_loss": 0.6587208211421967,
    "entropy": 0.11858787387609482,
    "total_loss": -2563.099283767864
  },
  {
    "episode": 238,
    "avg_reward_per_step": 147.7001212513236,
    "episode_length": 136,
    "policy_loss": -2431.310302734375,
    "value_loss": 0.6475201100111008,
    "entropy": 0.1228315569460392,
    "total_loss": -2430.668924202211
  },
  {
    "episode": 239,
    "avg_reward_per_step": 147.67317695927622,
    "episode_length": 136,
    "policy_loss": -2435.9339599609375,
    "value_loss": 0.6470201164484024,
    "entropy": 0.12831775099039078,
    "total_loss": -2435.2933557320384
  },
  {
    "episode": 240,
    "avg_reward_per_step": 157.0366513419026,
    "episode_length": 128,
    "policy_loss": -2471.4186401367188,
    "value_loss": 0.6597128063440323,
    "entropy": 0.13050195574760437,
    "total_loss": -2470.765452428162
  },
  {
    "episode": 241,
    "avg_reward_per_step": 154.73002135363387,
    "episode_length": 130,
    "policy_loss": -2542.0372924804688,
    "value_loss": 0.6564732939004898,
    "entropy": 0.12283030897378922,
    "total_loss": -2541.386960702017
  },
  {
    "episode": 242,
    "avg_reward_per_step": 155.84296436297296,
    "episode_length": 129,
    "policy_loss": -2518.8424072265625,
    "value_loss": 0.6578434854745865,
    "entropy": 0.13885324820876122,
    "total_loss": -2518.1915064034984
  },
  {
    "episode": 243,
    "avg_reward_per_step": 151.233356188797,
    "episode_length": 133,
    "policy_loss": -2496.4447631835938,
    "value_loss": 0.6513436138629913,
    "entropy": 0.12572906538844109,
    "total_loss": -2495.799706023
  },
  {
    "episode": 244,
    "avg_reward_per_step": 104.23035102172794,
    "episode_length": 193,
    "policy_loss": -1709.2787170410156,
    "value_loss": 0.5925758630037308,
    "entropy": 0.11603644117712975,
    "total_loss": -1708.6919430000708
  },
  {
    "episode": 245,
    "avg_reward_per_step": 152.4046313969284,
    "episode_length": 132,
    "policy_loss": -2503.9911499023438,
    "value_loss": 0.6527653336524963,
    "entropy": 0.10503963753581047,
    "total_loss": -2503.343636550568
  },
  {
    "episode": 246,
    "avg_reward_per_step": 152.4754562162919,
    "episode_length": 132,
    "policy_loss": -2504.5968627929688,
    "value_loss": 0.6529724895954132,
    "entropy": 0.10668068192899227,
    "total_loss": -2503.94922433747
  },
  {
    "episode": 247,
    "avg_reward_per_step": 152.26226272483888,
    "episode_length": 132,
    "policy_loss": -2486.8804931640625,
    "value_loss": 0.6521234512329102,
    "entropy": 0.10151398368179798,
    "total_loss": -2486.2334454120137
  },
  {
    "episode": 248,
    "avg_reward_per_step": 152.3609071015362,
    "episode_length": 132,
    "policy_loss": -2499.873291015625,
    "value_loss": 0.6520884335041046,
    "entropy": 0.10747355222702026,
    "total_loss": -2499.226576259732
  },
  {
    "episode": 249,
    "avg_reward_per_step": 74.07641425833269,
    "episode_length": 270,
    "policy_loss": -1199.1302490234375,
    "value_loss": 0.5590484142303467,
    "entropy": 0.12749172002077103,
    "total_loss": -1198.5775751952083
  },
  {
    "episode": 250,
    "avg_reward_per_step": 151.26519673005046,
    "episode_length": 133,
    "policy_loss": -2495.4701538085938,
    "value_loss": 0.6503651738166809,
    "entropy": 0.09846283309161663,
    "total_loss": -2494.8247117764317
  },
  {
    "episode": 251,
    "avg_reward_per_step": 152.2667982972319,
    "episode_length": 132,
    "policy_loss": -2498.6370849609375,
    "value_loss": 0.6516285836696625,
    "entropy": 0.11506572738289833,
    "total_loss": -2497.991209663637
  },
  {
    "episode": 252,
    "avg_reward_per_step": 151.22525923819268,
    "episode_length": 133,
    "policy_loss": -2486.6454467773438,
    "value_loss": 0.650622770190239,
    "entropy": 0.10678419843316078,
    "total_loss": -2486.000163217075
  },
  {
    "episode": 253,
    "avg_reward_per_step": 152.1182201831073,
    "episode_length": 132,
    "policy_loss": -2510.474609375,
    "value_loss": 0.6514614522457123,
    "entropy": 0.11124485917389393,
    "total_loss": -2509.828710165713
  },
  {
    "episode": 254,
    "avg_reward_per_step": 155.75948029497516,
    "episode_length": 129,
    "policy_loss": -2535.7385864257812,
    "value_loss": 0.6571391075849533,
    "entropy": 0.10902197659015656,
    "total_loss": -2535.0868984170256
  },
  {
    "episode": 255,
    "avg_reward_per_step": 153.3081135327417,
    "episode_length": 131,
    "policy_loss": -2510.048828125,
    "value_loss": 0.6537100672721863,
    "entropy": 0.10263453423976898,
    "total_loss": -2509.40024978444
  },
  {
    "episode": 256,
    "avg_reward_per_step": 180.19238114213934,
    "episode_length": 112,
    "policy_loss": -2978.733642578125,
    "value_loss": 0.6949947476387024,
    "entropy": 0.08462918922305107,
    "total_loss": -2978.0428792899475
  },
  {
    "episode": 257,
    "avg_reward_per_step": 154.56943247031109,
    "episode_length": 130,
    "policy_loss": -2536.114990234375,
    "value_loss": 0.6559048295021057,
    "entropy": 0.09518924541771412,
    "total_loss": -2535.463844867144
  },
  {
    "episode": 258,
    "avg_reward_per_step": 154.75480006911772,
    "episode_length": 130,
    "policy_loss": -2535.8204345703125,
    "value_loss": 0.6562610119581223,
    "entropy": 0.09486747905611992,
    "total_loss": -2535.168916932307
  },
  {
    "episode": 259,
    "avg_reward_per_step": 159.58515039853228,
    "episode_length": 126,
    "policy_loss": -2588.0870971679688,
    "value_loss": 0.6631937026977539,
    "entropy": 0.10318469814956188,
    "total_loss": -2587.4290627001783
  },
  {
    "episode": 260,
    "avg_reward_per_step": 158.31740352793256,
    "episode_length": 127,
    "policy_loss": -2587.2197875976562,
    "value_loss": 0.6609514057636261,
    "entropy": 0.09202194958925247,
    "total_loss": -2586.563437289372
  },
  {
    "episode": 261,
    "avg_reward_per_step": 158.39879661007072,
    "episode_length": 127,
    "policy_loss": -2590.0535888671875,
    "value_loss": 0.6610122472047806,
    "entropy": 0.0873604267835617,
    "total_loss": -2589.396944641322
  },
  {
    "episode": 262,
    "avg_reward_per_step": 157.19665670607557,
    "episode_length": 128,
    "policy_loss": -2577.12158203125,
    "value_loss": 0.6592922210693359,
    "entropy": 0.07844276912510395,
    "total_loss": -2576.466211948637
  },
  {
    "episode": 263,
    "avg_reward_per_step": 156.03585169620484,
    "episode_length": 129,
    "policy_loss": -2554.1206665039062,
    "value_loss": 0.6575827896595001,
    "entropy": 0.08370359055697918,
    "total_loss": -2553.4672688937744
  },
  {
    "episode": 264,
    "avg_reward_per_step": 130.93718337116562,
    "episode_length": 154,
    "policy_loss": -2132.1786499023438,
    "value_loss": 0.6242690533399582,
    "entropy": 0.10989242047071457,
    "total_loss": -2131.5598754700272
  },
  {
    "episode": 265,
    "avg_reward_per_step": 157.2432651020229,
    "episode_length": 128,
    "policy_loss": -2571.2188110351562,
    "value_loss": 0.6592067033052444,
    "entropy": 0.07282320410013199,
    "total_loss": -2570.563245492056
  },
  {
    "episode": 266,
    "avg_reward_per_step": 155.9284803898393,
    "episode_length": 129,
    "policy_loss": -2534.5509643554688,
    "value_loss": 0.6568102389574051,
    "entropy": 0.08302460424602032,
    "total_loss": -2533.8983053467236
  },
  {
    "episode": 267,
    "avg_reward_per_step": 157.12007703158378,
    "episode_length": 128,
    "policy_loss": -2549.633056640625,
    "value_loss": 0.6585549563169479,
    "entropy": 0.07994133420288563,
    "total_loss": -2548.9784987510184
  },
  {
    "episode": 268,
    "avg_reward_per_step": 159.6558672578044,
    "episode_length": 126,
    "policy_loss": -2606.7242431640625,
    "value_loss": 0.6620442271232605,
    "entropy": 0.09283298812806606,
    "total_loss": -2606.0668405863457
  },
  {
    "episode": 269,
    "avg_reward_per_step": 158.4409328668635,
    "episode_length": 127,
    "policy_loss": -2583.27783203125,
    "value_loss": 0.6600825488567352,
    "entropy": 0.09207777865231037,
    "total_loss": -2582.622353371326
  },
  {
    "episode": 270,
    "avg_reward_per_step": 157.28457669633542,
    "episode_length": 128,
    "policy_loss": -2565.3212890625,
    "value_loss": 0.6585611253976822,
    "entropy": 0.08228551037609577,
    "total_loss": -2564.6668422126213
  },
  {
    "episode": 271,
    "avg_reward_per_step": 154.4884854094019,
    "episode_length": 130,
    "policy_loss": -2522.3003540039062,
    "value_loss": 0.6541600674390793,
    "entropy": 0.09272903949022293,
    "total_loss": -2521.6508303884416
  },
  {
    "episode": 272,
    "avg_reward_per_step": 155.96482491252226,
    "episode_length": 129,
    "policy_loss": -2527.0160522460938,
    "value_loss": 0.6560161709785461,
    "entropy": 0.10382761061191559,
    "total_loss": -2526.3652274556457
  },
  {
    "episode": 273,
    "avg_reward_per_step": 158.39526759384185,
    "episode_length": 127,
    "policy_loss": -2572.9047241210938,
    "value_loss": 0.6597950309514999,
    "entropy": 0.07898899726569653,
    "total_loss": -2572.2488785400055
  },
  {
    "episode": 274,
    "avg_reward_per_step": 154.6727829041807,
    "episode_length": 130,
    "policy_loss": -2519.4929809570312,
    "value_loss": 0.6543942540884018,
    "entropy": 0.08245472609996796,
    "total_loss": -2518.8427094392478
  },
  {
    "episode": 275,
    "avg_reward_per_step": 154.5654257997387,
    "episode_length": 130,
    "policy_loss": -2517.177490234375,
    "value_loss": 0.654156282544136,
    "entropy": 0.08940176665782928,
    "total_loss": -2516.5278040401636
  },
  {
    "episode": 276,
    "avg_reward_per_step": 154.7035420766735,
    "episode_length": 130,
    "policy_loss": -2521.8746948242188,
    "value_loss": 0.6545523852109909,
    "entropy": 0.07666418515145779,
    "total_loss": -2521.2239756482654
  },
  {
    "episode": 277,
    "avg_reward_per_step": 155.89547189888572,
    "episode_length": 129,
    "policy_loss": -2533.0083618164062,
    "value_loss": 0.656062975525856,
    "entropy": 0.09671019203960896,
    "total_loss": -2532.3571343504823
  },
  {
    "episode": 278,
    "avg_reward_per_step": 159.6332636380393,
    "episode_length": 126,
    "policy_loss": -2594.2349853515625,
    "value_loss": 0.661438912153244,
    "entropy": 0.058014966547489166,
    "total_loss": -2593.5764471877364
  },
  {
    "episode": 279,
    "avg_reward_per_step": 157.28230581729136,
    "episode_length": 128,
    "policy_loss": -2553.8155517578125,
    "value_loss": 0.6580566316843033,
    "entropy": 0.08167792670428753,
    "total_loss": -2553.1615790224632
  },
  {
    "episode": 280,
    "avg_reward_per_step": 157.10827142262332,
    "episode_length": 128,
    "policy_loss": -2553.1865234375,
    "value_loss": 0.6576863676309586,
    "entropy": 0.08748657070100307,
    "total_loss": -2552.533211398404
  },
  {
    "episode": 281,
    "avg_reward_per_step": 157.19119100845964,
    "episode_length": 128,
    "policy_loss": -2560.478759765625,
    "value_loss": 0.6578123271465302,
    "entropy": 0.08433975093066692,
    "total_loss": -2559.825164426025
  },
  {
    "episode": 282,
    "avg_reward_per_step": 157.14447408150087,
    "episode_length": 128,
    "policy_loss": -2555.1203002929688,
    "value_loss": 0.6574915051460266,
    "entropy": 0.09813720174133778,
    "total_loss": -2554.4677156479097
  },
  {
    "episode": 283,
    "avg_reward_per_step": 159.66535941027308,
    "episode_length": 126,
    "policy_loss": -2588.6627197265625,
    "value_loss": 0.6613417267799377,
    "entropy": 0.0688974130898714,
    "total_loss": -2588.0048228704372
  },
  {
    "episode": 284,
    "avg_reward_per_step": 160.852519262054,
    "episode_length": 125,
    "policy_loss": -2619.4478149414062,
    "value_loss": 0.6628135293722153,
    "entropy": 0.061254614032804966,
    "total_loss": -2618.7880641427355
  },
  {
    "episode": 285,
    "avg_reward_per_step": 158.38152965181968,
    "episode_length": 127,
    "policy_loss": -2562.1099243164062,
    "value_loss": 0.6588787287473679,
    "entropy": 0.06844698823988438,
    "total_loss": -2561.454467937071
  },
  {
    "episode": 286,
    "avg_reward_per_step": 159.75333294628248,
    "episode_length": 126,
    "policy_loss": -2589.7474365234375,
    "value_loss": 0.6609954535961151,
    "entropy": 0.07123173959553242,
    "total_loss": -2589.090002656821
  },
  {
    "episode": 287,
    "avg_reward_per_step": 158.42131813984275,
    "episode_length": 127,
    "policy_loss": -2564.9254760742188,
    "value_loss": 0.6592327505350113,
    "entropy": 0.07281755283474922,
    "total_loss": -2564.2698842013256
  },
  {
    "episode": 288,
    "avg_reward_per_step": 154.57497305557357,
    "episode_length": 130,
    "policy_loss": -2502.7221069335938,
    "value_loss": 0.6532958596944809,
    "entropy": 0.11812494695186615,
    "total_loss": -2502.0747173212467
  },
  {
    "episode": 289,
    "avg_reward_per_step": 158.18706282079995,
    "episode_length": 127,
    "policy_loss": -2560.2862548828125,
    "value_loss": 0.6584320217370987,
    "entropy": 0.04573153518140316,
    "total_loss": -2559.6301094378346
  },
  {
    "episode": 290,
    "avg_reward_per_step": 159.72324509410979,
    "episode_length": 126,
    "policy_loss": -2583.60546875,
    "value_loss": 0.6607120931148529,
    "entropy": 0.0746501088142395,
    "total_loss": -2582.948489162326
  },
  {
    "episode": 291,
    "avg_reward_per_step": 158.49880339900466,
    "episode_length": 127,
    "policy_loss": -2563.2570190429688,
    "value_loss": 0.6587149947881699,
    "entropy": 0.07180887460708618,
    "total_loss": -2562.601894491911
  },
  {
    "episode": 292,
    "avg_reward_per_step": 160.91593295403686,
    "episode_length": 125,
    "policy_loss": -2602.5833129882812,
    "value_loss": 0.6620090752840042,
    "entropy": 0.05851317476481199,
    "total_loss": -2601.9242295717354
  },
  {
    "episode": 293,
    "avg_reward_per_step": 158.4057459603938,
    "episode_length": 127,
    "policy_loss": -2559.732177734375,
    "value_loss": 0.6581406444311142,
    "entropy": 0.07457025721669197,
    "total_loss": -2559.077765602805
  },
  {
    "episode": 294,
    "avg_reward_per_step": 161.04348292582384,
    "episode_length": 125,
    "policy_loss": -2602.73828125,
    "value_loss": 0.6622391194105148,
    "entropy": 0.0674857571721077,
    "total_loss": -2602.079416418448
  },
  {
    "episode": 295,
    "avg_reward_per_step": 102.95590052296153,
    "episode_length": 195,
    "policy_loss": -1642.0261840820312,
    "value_loss": 0.587971493601799,
    "entropy": 0.08603520691394806,
    "total_loss": -1641.4425143487751
  },
  {
    "episode": 296,
    "avg_reward_per_step": 161.01418940686037,
    "episode_length": 125,
    "policy_loss": -2599.4583129882812,
    "value_loss": 0.6618542224168777,
    "entropy": 0.05828274041414261,
    "total_loss": -2598.799372902885
  },
  {
    "episode": 297,
    "avg_reward_per_step": 159.84336304447848,
    "episode_length": 126,
    "policy_loss": -2579.7828979492188,
    "value_loss": 0.6602686494588852,
    "entropy": 0.06883919425308704,
    "total_loss": -2579.1260712594726
  },
  {
    "episode": 298,
    "avg_reward_per_step": 160.91593295403686,
    "episode_length": 125,
    "policy_loss": -2597.476318359375,
    "value_loss": 0.6614527255296707,
    "entropy": 0.05423935130238533,
    "total_loss": -2596.8175776014104
  },
  {
    "episode": 299,
    "avg_reward_per_step": 159.70595328656543,
    "episode_length": 126,
    "policy_loss": -2573.7075805664062,
    "value_loss": 0.6595883369445801,
    "entropy": 0.06014112289994955,
    "total_loss": -2573.050999285607
  },
  {
    "episode": 300,
    "avg_reward_per_step": 158.3496931412127,
    "episode_length": 127,
    "policy_loss": -2551.4439697265625,
    "value_loss": 0.6576019525527954,
    "entropy": 0.03964325599372387,
    "total_loss": -2550.7883499368095
  }
]