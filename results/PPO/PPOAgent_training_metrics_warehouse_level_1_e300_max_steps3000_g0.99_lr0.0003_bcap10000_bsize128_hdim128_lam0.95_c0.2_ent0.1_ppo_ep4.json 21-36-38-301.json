[
  {
    "episode": 1,
    "avg_reward_per_step": -4.413377929231763,
    "episode_length": 3000,
    "policy_loss": 73.5735912322998,
    "value_loss": 2.5403998494148254,
    "entropy": 1.3814310729503632,
    "total_loss": 75.9758479744196
  },
  {
    "episode": 2,
    "avg_reward_per_step": 13.07271992955263,
    "episode_length": 1323,
    "policy_loss": -224.40029525756836,
    "value_loss": 0.5090679228305817,
    "entropy": 1.3741511404514313,
    "total_loss": -224.02864244878293
  },
  {
    "episode": 3,
    "avg_reward_per_step": 76.51196634054159,
    "episode_length": 258,
    "policy_loss": -1315.359619140625,
    "value_loss": 0.5682404488325119,
    "entropy": 1.3549271821975708,
    "total_loss": -1314.9268714100122
  },
  {
    "episode": 4,
    "avg_reward_per_step": 14.876311017735258,
    "episode_length": 1163,
    "policy_loss": -251.82353591918945,
    "value_loss": 0.5103367567062378,
    "entropy": 1.327569842338562,
    "total_loss": -251.44595614671707
  },
  {
    "episode": 5,
    "avg_reward_per_step": 46.38651699878213,
    "episode_length": 412,
    "policy_loss": -791.5445098876953,
    "value_loss": 0.5378342419862747,
    "entropy": 1.301310658454895,
    "total_loss": -791.1368067115545
  },
  {
    "episode": 6,
    "avg_reward_per_step": 10.658278263211267,
    "episode_length": 1559,
    "policy_loss": -179.8860321044922,
    "value_loss": 0.507036417722702,
    "entropy": 1.3033124506473541,
    "total_loss": -179.5093269318342
  },
  {
    "episode": 7,
    "avg_reward_per_step": -2.4834305388557585,
    "episode_length": 3000,
    "policy_loss": 41.44711208343506,
    "value_loss": 1.4287230670452118,
    "entropy": 1.2973125278949738,
    "total_loss": 42.74610389769077
  },
  {
    "episode": 8,
    "avg_reward_per_step": 87.61767681541535,
    "episode_length": 222,
    "policy_loss": -1489.2157897949219,
    "value_loss": 0.5785893350839615,
    "entropy": 1.291259914636612,
    "total_loss": -1488.7663264513017
  },
  {
    "episode": 9,
    "avg_reward_per_step": 40.48410873109635,
    "episode_length": 474,
    "policy_loss": -683.3721313476562,
    "value_loss": 0.5327838659286499,
    "entropy": 1.2745014429092407,
    "total_loss": -682.9667976260185
  },
  {
    "episode": 10,
    "avg_reward_per_step": 32.150593100512836,
    "episode_length": 594,
    "policy_loss": -542.5990905761719,
    "value_loss": 0.5255561470985413,
    "entropy": 1.2588580548763275,
    "total_loss": -542.199420234561
  },
  {
    "episode": 11,
    "avg_reward_per_step": 10.373477253201484,
    "episode_length": 1498,
    "policy_loss": -175.38677978515625,
    "value_loss": 0.5063592493534088,
    "entropy": 1.245241105556488,
    "total_loss": -175.0049446463585
  },
  {
    "episode": 12,
    "avg_reward_per_step": 14.031395030610536,
    "episode_length": 1282,
    "policy_loss": -236.8018035888672,
    "value_loss": 0.5101726651191711,
    "entropy": 1.243815839290619,
    "total_loss": -236.41601250767707
  },
  {
    "episode": 13,
    "avg_reward_per_step": 34.95961198658998,
    "episode_length": 554,
    "policy_loss": -590.3475799560547,
    "value_loss": 0.5283737182617188,
    "entropy": 1.2326374053955078,
    "total_loss": -589.9424699783325
  },
  {
    "episode": 14,
    "avg_reward_per_step": 5.204295010941037,
    "episode_length": 2590,
    "policy_loss": -88.22575569152832,
    "value_loss": 0.5027095377445221,
    "entropy": 1.2167727947235107,
    "total_loss": -87.84472343325615
  },
  {
    "episode": 15,
    "avg_reward_per_step": 27.50487655303277,
    "episode_length": 692,
    "policy_loss": -464.8928680419922,
    "value_loss": 0.5216084718704224,
    "entropy": 1.216409295797348,
    "total_loss": -464.4929004997015
  },
  {
    "episode": 16,
    "avg_reward_per_step": 27.462948759946727,
    "episode_length": 678,
    "policy_loss": -466.10791015625,
    "value_loss": 0.5211241692304611,
    "entropy": 1.2206328809261322,
    "total_loss": -465.70884927511213
  },
  {
    "episode": 17,
    "avg_reward_per_step": 25.730270716312972,
    "episode_length": 712,
    "policy_loss": -437.7606735229492,
    "value_loss": 0.5193839818239212,
    "entropy": 1.230994701385498,
    "total_loss": -437.3643890112638
  },
  {
    "episode": 18,
    "avg_reward_per_step": 9.0594135560914,
    "episode_length": 1746,
    "policy_loss": -153.36473846435547,
    "value_loss": 0.5056687742471695,
    "entropy": 1.2298199236392975,
    "total_loss": -152.98205168247222
  },
  {
    "episode": 19,
    "avg_reward_per_step": 45.451305417569806,
    "episode_length": 416,
    "policy_loss": -769.4034881591797,
    "value_loss": 0.536499947309494,
    "entropy": 1.2323813438415527,
    "total_loss": -768.9902263462543
  },
  {
    "episode": 20,
    "avg_reward_per_step": 38.4916727775943,
    "episode_length": 479,
    "policy_loss": -652.1531372070312,
    "value_loss": 0.5298470556735992,
    "entropy": 1.2295699417591095,
    "total_loss": -651.7462471455335
  },
  {
    "episode": 21,
    "avg_reward_per_step": 6.84465123312508,
    "episode_length": 1866,
    "policy_loss": -116.11639785766602,
    "value_loss": 0.5033300668001175,
    "entropy": 1.203775703907013,
    "total_loss": -115.7334453612566
  },
  {
    "episode": 22,
    "avg_reward_per_step": 53.531531924217305,
    "episode_length": 350,
    "policy_loss": -906.2062530517578,
    "value_loss": 0.5433718413114548,
    "entropy": 1.1969743967056274,
    "total_loss": -905.7825786501169
  },
  {
    "episode": 23,
    "avg_reward_per_step": 34.251433872688544,
    "episode_length": 517,
    "policy_loss": -577.2288665771484,
    "value_loss": 0.5251005440950394,
    "entropy": 1.1521835029125214,
    "total_loss": -576.8189843833446
  },
  {
    "episode": 24,
    "avg_reward_per_step": 30.934261938824502,
    "episode_length": 547,
    "policy_loss": -523.4251251220703,
    "value_loss": 0.5214950144290924,
    "entropy": 1.1415118277072906,
    "total_loss": -523.0177812904119
  },
  {
    "episode": 25,
    "avg_reward_per_step": 71.17958670366058,
    "episode_length": 267,
    "policy_loss": -1208.921875,
    "value_loss": 0.5602144598960876,
    "entropy": 1.119750738143921,
    "total_loss": -1208.4736356139183
  },
  {
    "episode": 26,
    "avg_reward_per_step": 85.26547547377012,
    "episode_length": 229,
    "policy_loss": -1434.8985900878906,
    "value_loss": 0.5764269381761551,
    "entropy": 1.092125803232193,
    "total_loss": -1434.4313757300376
  },
  {
    "episode": 27,
    "avg_reward_per_step": 30.02846596776352,
    "episode_length": 607,
    "policy_loss": -506.7309036254883,
    "value_loss": 0.5227445811033249,
    "entropy": 1.1091770827770233,
    "total_loss": -506.3190767526627
  },
  {
    "episode": 28,
    "avg_reward_per_step": 77.80422534726954,
    "episode_length": 249,
    "policy_loss": -1326.0904541015625,
    "value_loss": 0.5680847615003586,
    "entropy": 1.103899508714676,
    "total_loss": -1325.6327592909336
  },
  {
    "episode": 29,
    "avg_reward_per_step": 90.19442669451884,
    "episode_length": 217,
    "policy_loss": -1526.6999816894531,
    "value_loss": 0.581762045621872,
    "entropy": 1.053324580192566,
    "total_loss": -1526.2235521018506
  },
  {
    "episode": 30,
    "avg_reward_per_step": 105.83528855940702,
    "episode_length": 186,
    "policy_loss": -1791.8274230957031,
    "value_loss": 0.5993918031454086,
    "entropy": 0.9979169070720673,
    "total_loss": -1791.327822983265
  },
  {
    "episode": 31,
    "avg_reward_per_step": 79.94627052266756,
    "episode_length": 244,
    "policy_loss": -1354.3876342773438,
    "value_loss": 0.5709135681390762,
    "entropy": 0.9534650444984436,
    "total_loss": -1353.9120672136546
  },
  {
    "episode": 32,
    "avg_reward_per_step": 38.30992044977804,
    "episode_length": 489,
    "policy_loss": -647.1308746337891,
    "value_loss": 0.5301860719919205,
    "entropy": 0.9230889827013016,
    "total_loss": -646.6929974600673
  },
  {
    "episode": 33,
    "avg_reward_per_step": 77.86840373455682,
    "episode_length": 246,
    "policy_loss": -1316.1065063476562,
    "value_loss": 0.5673593878746033,
    "entropy": 0.8989375084638596,
    "total_loss": -1315.629040710628
  },
  {
    "episode": 34,
    "avg_reward_per_step": 8.032802785889391,
    "episode_length": 1813,
    "policy_loss": -136.06313705444336,
    "value_loss": 0.5045637339353561,
    "entropy": 0.8967746645212173,
    "total_loss": -135.64825078696012
  },
  {
    "episode": 35,
    "avg_reward_per_step": 22.4740212467214,
    "episode_length": 797,
    "policy_loss": -379.4998092651367,
    "value_loss": 0.5163535475730896,
    "entropy": 0.8958610445261002,
    "total_loss": -379.07304182201625
  },
  {
    "episode": 36,
    "avg_reward_per_step": 35.96704278178722,
    "episode_length": 511,
    "policy_loss": -609.6350708007812,
    "value_loss": 0.5276257693767548,
    "entropy": 0.8666651844978333,
    "total_loss": -609.1941115498543
  },
  {
    "episode": 37,
    "avg_reward_per_step": 71.01841608596422,
    "episode_length": 274,
    "policy_loss": -1203.1377868652344,
    "value_loss": 0.5618740320205688,
    "entropy": 0.8625506460666656,
    "total_loss": -1202.6621678978204
  },
  {
    "episode": 38,
    "avg_reward_per_step": 105.01702102960758,
    "episode_length": 189,
    "policy_loss": -1778.1262817382812,
    "value_loss": 0.5993075966835022,
    "entropy": 0.8482386022806168,
    "total_loss": -1777.6117980018257
  },
  {
    "episode": 39,
    "avg_reward_per_step": 30.985228117785574,
    "episode_length": 571,
    "policy_loss": -527.7579956054688,
    "value_loss": 0.5226231664419174,
    "entropy": 0.7983806878328323,
    "total_loss": -527.3152105078101
  },
  {
    "episode": 40,
    "avg_reward_per_step": 118.68932887058017,
    "episode_length": 163,
    "policy_loss": -2003.84619140625,
    "value_loss": 0.6124422252178192,
    "entropy": 0.7812979966402054,
    "total_loss": -2003.3118789806963
  },
  {
    "episode": 41,
    "avg_reward_per_step": 142.23649444923998,
    "episode_length": 138,
    "policy_loss": -2401.4221801757812,
    "value_loss": 0.6436638087034225,
    "entropy": 0.76835797727108,
    "total_loss": -2400.855352164805
  },
  {
    "episode": 42,
    "avg_reward_per_step": 63.48863993335859,
    "episode_length": 303,
    "policy_loss": -1071.0029907226562,
    "value_loss": 0.5539277642965317,
    "entropy": 0.7489291876554489,
    "total_loss": -1070.5239558771252
  },
  {
    "episode": 43,
    "avg_reward_per_step": 92.57890557147294,
    "episode_length": 211,
    "policy_loss": -1560.346435546875,
    "value_loss": 0.5837417542934418,
    "entropy": 0.7263388782739639,
    "total_loss": -1559.835327680409
  },
  {
    "episode": 44,
    "avg_reward_per_step": 89.62005095859219,
    "episode_length": 213,
    "policy_loss": -1530.096923828125,
    "value_loss": 0.5784662365913391,
    "entropy": 0.6987101435661316,
    "total_loss": -1529.5883286058902
  },
  {
    "episode": 45,
    "avg_reward_per_step": 6.7748463346504115,
    "episode_length": 1562,
    "policy_loss": -111.21639633178711,
    "value_loss": 0.5026417225599289,
    "entropy": 0.6378443241119385,
    "total_loss": -110.77753904163838
  },
  {
    "episode": 46,
    "avg_reward_per_step": 12.359455855729623,
    "episode_length": 1041,
    "policy_loss": -207.8745346069336,
    "value_loss": 0.5061374306678772,
    "entropy": 0.5957315266132355,
    "total_loss": -207.42797032892705
  },
  {
    "episode": 47,
    "avg_reward_per_step": -10.193243762132061,
    "episode_length": 3000,
    "policy_loss": 170.87989807128906,
    "value_loss": 3.0525094270706177,
    "entropy": 0.5624983310699463,
    "total_loss": 173.8761576652527
  },
  {
    "episode": 48,
    "avg_reward_per_step": -11.558412720028253,
    "episode_length": 3000,
    "policy_loss": 193.9230499267578,
    "value_loss": 3.622044086456299,
    "entropy": 0.5124895721673965,
    "total_loss": 197.49384505599738
  },
  {
    "episode": 49,
    "avg_reward_per_step": 3.378856099336964,
    "episode_length": 1509,
    "policy_loss": -58.15350341796875,
    "value_loss": 0.5003823190927505,
    "entropy": 0.5327746272087097,
    "total_loss": -57.70639856159687
  },
  {
    "episode": 50,
    "avg_reward_per_step": -10.278226545324243,
    "episode_length": 3000,
    "policy_loss": 171.92337799072266,
    "value_loss": 2.7729671597480774,
    "entropy": 0.5527462810277939,
    "total_loss": 174.64107052236795
  },
  {
    "episode": 51,
    "avg_reward_per_step": -10.278955505935482,
    "episode_length": 3000,
    "policy_loss": 171.97232055664062,
    "value_loss": 2.8750266432762146,
    "entropy": 0.5618568658828735,
    "total_loss": 174.79116151332855
  },
  {
    "episode": 52,
    "avg_reward_per_step": -4.171650871686707,
    "episode_length": 2934,
    "policy_loss": 69.23385047912598,
    "value_loss": 0.5018017739057541,
    "entropy": 0.5385719686746597,
    "total_loss": 69.68179505616426
  },
  {
    "episode": 53,
    "avg_reward_per_step": 4.369196080334807,
    "episode_length": 1320,
    "policy_loss": -75.10163307189941,
    "value_loss": 0.5006896406412125,
    "entropy": 0.5568318217992783,
    "total_loss": -74.65662661343814
  },
  {
    "episode": 54,
    "avg_reward_per_step": 3.311727943786524,
    "episode_length": 1634,
    "policy_loss": -57.79789924621582,
    "value_loss": 0.5004366338253021,
    "entropy": 0.6106794476509094,
    "total_loss": -57.35853055715561
  },
  {
    "episode": 55,
    "avg_reward_per_step": -0.5712460826177335,
    "episode_length": 2317,
    "policy_loss": 7.556661009788513,
    "value_loss": 0.4998146593570709,
    "entropy": 0.6129623800516129,
    "total_loss": 7.995179431140423
  },
  {
    "episode": 56,
    "avg_reward_per_step": 59.45136354280105,
    "episode_length": 316,
    "policy_loss": -1014.5795135498047,
    "value_loss": 0.5489866584539413,
    "entropy": 0.6891479343175888,
    "total_loss": -1014.0994416847825
  },
  {
    "episode": 57,
    "avg_reward_per_step": 5.021178817836345,
    "episode_length": 1973,
    "policy_loss": -85.61697387695312,
    "value_loss": 0.5018294006586075,
    "entropy": 0.7114056646823883,
    "total_loss": -85.18628504276276
  },
  {
    "episode": 58,
    "avg_reward_per_step": 177.45054520568456,
    "episode_length": 111,
    "policy_loss": -3015.8956909179688,
    "value_loss": 0.6932225078344345,
    "entropy": 0.6883350759744644,
    "total_loss": -3015.2713019177318
  },
  {
    "episode": 59,
    "avg_reward_per_step": 15.162123569972698,
    "episode_length": 903,
    "policy_loss": -255.57902145385742,
    "value_loss": 0.5081002414226532,
    "entropy": 0.6379156112670898,
    "total_loss": -255.1347127735615
  },
  {
    "episode": 60,
    "avg_reward_per_step": 54.09441267903019,
    "episode_length": 322,
    "policy_loss": -911.0997161865234,
    "value_loss": 0.5400825589895248,
    "entropy": 0.5674742311239243,
    "total_loss": -910.6163810506463
  },
  {
    "episode": 61,
    "avg_reward_per_step": 1.0847712892188397,
    "episode_length": 1904,
    "policy_loss": -20.09018325805664,
    "value_loss": 0.49984873086214066,
    "entropy": 0.5979077070951462,
    "total_loss": -19.650125297904015
  },
  {
    "episode": 62,
    "avg_reward_per_step": -9.601109007741998,
    "episode_length": 3000,
    "policy_loss": 160.15516662597656,
    "value_loss": 2.818496525287628,
    "entropy": 0.5988012552261353,
    "total_loss": 162.91378302574157
  },
  {
    "episode": 63,
    "avg_reward_per_step": 15.666953598767412,
    "episode_length": 840,
    "policy_loss": -266.7904357910156,
    "value_loss": 0.5080443918704987,
    "entropy": 0.649206206202507,
    "total_loss": -266.34731201976535
  },
  {
    "episode": 64,
    "avg_reward_per_step": 5.277078588657701,
    "episode_length": 1540,
    "policy_loss": -91.45035934448242,
    "value_loss": 0.5014703422784805,
    "entropy": 0.6614097356796265,
    "total_loss": -91.01502997577191
  },
  {
    "episode": 65,
    "avg_reward_per_step": 16.37792394192993,
    "episode_length": 870,
    "policy_loss": -278.8593292236328,
    "value_loss": 0.5092272609472275,
    "entropy": 0.6952963322401047,
    "total_loss": -278.4196315959096
  },
  {
    "episode": 66,
    "avg_reward_per_step": 179.63117839190497,
    "episode_length": 111,
    "policy_loss": -3103.7321166992188,
    "value_loss": 0.70002681016922,
    "entropy": 0.7103310525417328,
    "total_loss": -3103.1031229943037
  },
  {
    "episode": 67,
    "avg_reward_per_step": 0.14158568245319622,
    "episode_length": 2573,
    "policy_loss": -0.8972717225551605,
    "value_loss": 0.49981964379549026,
    "entropy": 0.6172208935022354,
    "total_loss": -0.4591741681098938
  },
  {
    "episode": 68,
    "avg_reward_per_step": -11.708484936858525,
    "episode_length": 3000,
    "policy_loss": 195.75756454467773,
    "value_loss": 3.4588964581489563,
    "entropy": 0.4870501905679703,
    "total_loss": 199.1677559837699
  },
  {
    "episode": 69,
    "avg_reward_per_step": -11.692015117801066,
    "episode_length": 3000,
    "policy_loss": 195.2557487487793,
    "value_loss": 3.445294201374054,
    "entropy": 0.47674332559108734,
    "total_loss": 198.65336861759425
  },
  {
    "episode": 70,
    "avg_reward_per_step": -12.382061859555279,
    "episode_length": 3000,
    "policy_loss": 206.37057495117188,
    "value_loss": 3.3462552428245544,
    "entropy": 0.3996701315045357,
    "total_loss": 209.67686318084597
  },
  {
    "episode": 71,
    "avg_reward_per_step": -12.837422287563214,
    "episode_length": 3000,
    "policy_loss": 214.08139038085938,
    "value_loss": 3.625994026660919,
    "entropy": 0.44130171835422516,
    "total_loss": 217.66325423568486
  },
  {
    "episode": 72,
    "avg_reward_per_step": -12.804540225546019,
    "episode_length": 3000,
    "policy_loss": 213.44498443603516,
    "value_loss": 3.1777637004852295,
    "entropy": 0.44189417362213135,
    "total_loss": 216.57855871915817
  },
  {
    "episode": 73,
    "avg_reward_per_step": -12.36029964679205,
    "episode_length": 3000,
    "policy_loss": 205.8613739013672,
    "value_loss": 3.291959524154663,
    "entropy": 0.439434714615345,
    "total_loss": 209.1093899540603
  },
  {
    "episode": 74,
    "avg_reward_per_step": -13.063941175505107,
    "episode_length": 3000,
    "policy_loss": 217.3758773803711,
    "value_loss": 3.5802001357078552,
    "entropy": 0.41704265028238297,
    "total_loss": 220.9143732510507
  },
  {
    "episode": 75,
    "avg_reward_per_step": -12.73430089448757,
    "episode_length": 3000,
    "policy_loss": 211.53544998168945,
    "value_loss": 3.4212287068367004,
    "entropy": 0.4573438912630081,
    "total_loss": 214.91094429939986
  },
  {
    "episode": 76,
    "avg_reward_per_step": -12.557495907429175,
    "episode_length": 3000,
    "policy_loss": 208.29392623901367,
    "value_loss": 3.511357605457306,
    "entropy": 0.46990081667900085,
    "total_loss": 211.75829376280308
  },
  {
    "episode": 77,
    "avg_reward_per_step": -12.589283504558086,
    "episode_length": 3000,
    "policy_loss": 208.43294143676758,
    "value_loss": 3.670044243335724,
    "entropy": 0.4928845688700676,
    "total_loss": 212.0536972232163
  },
  {
    "episode": 78,
    "avg_reward_per_step": -6.200300853161072,
    "episode_length": 3000,
    "policy_loss": 101.05954551696777,
    "value_loss": 0.9674891531467438,
    "entropy": 0.5750200003385544,
    "total_loss": 101.96953267008067
  },
  {
    "episode": 79,
    "avg_reward_per_step": -11.804022502887053,
    "episode_length": 3000,
    "policy_loss": 195.0899200439453,
    "value_loss": 3.4319774508476257,
    "entropy": 0.5236377716064453,
    "total_loss": 198.4695337176323
  },
  {
    "episode": 80,
    "avg_reward_per_step": -11.783858142611217,
    "episode_length": 3000,
    "policy_loss": 194.46085357666016,
    "value_loss": 3.4824824929237366,
    "entropy": 0.5425402820110321,
    "total_loss": 197.88908204138278
  },
  {
    "episode": 81,
    "avg_reward_per_step": 86.509480999691,
    "episode_length": 212,
    "policy_loss": -1467.3380126953125,
    "value_loss": 0.572698563337326,
    "entropy": 0.41950051486492157,
    "total_loss": -1466.8072641834617
  },
  {
    "episode": 82,
    "avg_reward_per_step": 64.54033303979074,
    "episode_length": 272,
    "policy_loss": -1091.6763000488281,
    "value_loss": 0.5496165156364441,
    "entropy": 0.4401978999376297,
    "total_loss": -1091.1707033231855
  },
  {
    "episode": 83,
    "avg_reward_per_step": -11.294767611733462,
    "episode_length": 3000,
    "policy_loss": 185.72160720825195,
    "value_loss": 2.6850574612617493,
    "entropy": 0.5040571615099907,
    "total_loss": 188.3562589533627
  },
  {
    "episode": 84,
    "avg_reward_per_step": 1.9900980173447418,
    "episode_length": 1656,
    "policy_loss": -38.43731689453125,
    "value_loss": 0.5000658631324768,
    "entropy": 0.5648863613605499,
    "total_loss": -37.993739667534825
  },
  {
    "episode": 85,
    "avg_reward_per_step": -3.2143792183198507,
    "episode_length": 2821,
    "policy_loss": 48.53455352783203,
    "value_loss": 0.5008065402507782,
    "entropy": 0.5893430858850479,
    "total_loss": 48.976425759494305
  },
  {
    "episode": 86,
    "avg_reward_per_step": -9.707809232921829,
    "episode_length": 3000,
    "policy_loss": 158.0414161682129,
    "value_loss": 3.352799713611603,
    "entropy": 0.6347203701734543,
    "total_loss": 161.33074384480716
  },
  {
    "episode": 87,
    "avg_reward_per_step": 1.4657956430662242,
    "episode_length": 1961,
    "policy_loss": -30.486056327819824,
    "value_loss": 0.5000278353691101,
    "entropy": 0.6694763451814651,
    "total_loss": -30.05297612696886
  },
  {
    "episode": 88,
    "avg_reward_per_step": 1.0482384354753935,
    "episode_length": 2409,
    "policy_loss": -22.77687406539917,
    "value_loss": 0.5000203251838684,
    "entropy": 0.6987064331769943,
    "total_loss": -22.346724383533
  },
  {
    "episode": 89,
    "avg_reward_per_step": -8.554159459698912,
    "episode_length": 3000,
    "policy_loss": 138.5025749206543,
    "value_loss": 3.0909072756767273,
    "entropy": 0.6613264977931976,
    "total_loss": 141.5273495465517
  },
  {
    "episode": 90,
    "avg_reward_per_step": 92.14174397094779,
    "episode_length": 210,
    "policy_loss": -1579.979248046875,
    "value_loss": 0.5834121555089951,
    "entropy": 0.6174608170986176,
    "total_loss": -1579.4575819730758
  },
  {
    "episode": 91,
    "avg_reward_per_step": 0.3410926737645882,
    "episode_length": 2189,
    "policy_loss": -10.437472105026245,
    "value_loss": 0.4997835159301758,
    "entropy": 0.554589033126831,
    "total_loss": -9.993147492408752
  },
  {
    "episode": 92,
    "avg_reward_per_step": 36.269524064397274,
    "episode_length": 465,
    "policy_loss": -623.8660583496094,
    "value_loss": 0.5256475508213043,
    "entropy": 0.5636896193027496,
    "total_loss": -623.3967797607183
  },
  {
    "episode": 93,
    "avg_reward_per_step": -10.665637964748809,
    "episode_length": 3000,
    "policy_loss": 174.01393127441406,
    "value_loss": 2.2094162702560425,
    "entropy": 0.5139441937208176,
    "total_loss": 176.17195312529802
  },
  {
    "episode": 94,
    "avg_reward_per_step": 50.122110966538216,
    "episode_length": 334,
    "policy_loss": -851.2196655273438,
    "value_loss": 0.5357978940010071,
    "entropy": 0.27616556733846664,
    "total_loss": -850.7114841900766
  },
  {
    "episode": 95,
    "avg_reward_per_step": -12.28757862460216,
    "episode_length": 3000,
    "policy_loss": 201.01815795898438,
    "value_loss": 2.3032495379447937,
    "entropy": 0.29655294120311737,
    "total_loss": 203.29175220280885
  },
  {
    "episode": 96,
    "avg_reward_per_step": 26.51277082102075,
    "episode_length": 558,
    "policy_loss": -456.27745819091797,
    "value_loss": 0.5161196142435074,
    "entropy": 0.22341430559754372,
    "total_loss": -455.78368000723424
  },
  {
    "episode": 97,
    "avg_reward_per_step": -11.844299356737395,
    "episode_length": 3000,
    "policy_loss": 193.41708374023438,
    "value_loss": 2.8858776688575745,
    "entropy": 0.43579432368278503,
    "total_loss": 196.25938197672366
  },
  {
    "episode": 98,
    "avg_reward_per_step": -11.379312719959165,
    "episode_length": 3000,
    "policy_loss": 185.28558349609375,
    "value_loss": 2.7085115909576416,
    "entropy": 0.4622179791331291,
    "total_loss": 187.94787328913807
  },
  {
    "episode": 99,
    "avg_reward_per_step": -11.564761901545229,
    "episode_length": 3000,
    "policy_loss": 188.26372146606445,
    "value_loss": 2.6855989694595337,
    "entropy": 0.49752913415431976,
    "total_loss": 190.89956752210855
  },
  {
    "episode": 100,
    "avg_reward_per_step": 557.0675154893404,
    "episode_length": 36,
    "policy_loss": -8395.2705078125,
    "value_loss": 1.7917433381080627,
    "entropy": 0.29424138367176056,
    "total_loss": -8393.50818861276
  },
  {
    "episode": 101,
    "avg_reward_per_step": -11.473487158721694,
    "episode_length": 3000,
    "policy_loss": 186.91236114501953,
    "value_loss": 2.7119630575180054,
    "entropy": 0.48917578905820847,
    "total_loss": 189.57540662363172
  },
  {
    "episode": 102,
    "avg_reward_per_step": 43.78204584351246,
    "episode_length": 367,
    "policy_loss": -745.1887817382812,
    "value_loss": 0.5297028571367264,
    "entropy": 0.34814659506082535,
    "total_loss": -744.6938935406506
  },
  {
    "episode": 103,
    "avg_reward_per_step": -12.890630615234327,
    "episode_length": 3000,
    "policy_loss": 209.86650848388672,
    "value_loss": 3.181023895740509,
    "entropy": 0.4098438695073128,
    "total_loss": 213.0065479926765
  },
  {
    "episode": 104,
    "avg_reward_per_step": -12.768494574754783,
    "episode_length": 3000,
    "policy_loss": 207.64397811889648,
    "value_loss": 3.5497294068336487,
    "entropy": 0.45391061902046204,
    "total_loss": 211.14831646382808
  },
  {
    "episode": 105,
    "avg_reward_per_step": -12.698387889580927,
    "episode_length": 3000,
    "policy_loss": 206.24378967285156,
    "value_loss": 2.98823881149292,
    "entropy": 0.44932974874973297,
    "total_loss": 209.18709550946951
  },
  {
    "episode": 106,
    "avg_reward_per_step": 86.40705266954689,
    "episode_length": 214,
    "policy_loss": -1471.1436767578125,
    "value_loss": 0.5738704353570938,
    "entropy": 0.411685474216938,
    "total_loss": -1470.610974869877
  },
  {
    "episode": 107,
    "avg_reward_per_step": -11.855509601309983,
    "episode_length": 3000,
    "policy_loss": 191.2228126525879,
    "value_loss": 3.0565892457962036,
    "entropy": 0.4969318062067032,
    "total_loss": 194.22970871776343
  },
  {
    "episode": 108,
    "avg_reward_per_step": -12.508009710809517,
    "episode_length": 3000,
    "policy_loss": 201.8648796081543,
    "value_loss": 2.8444591760635376,
    "entropy": 0.4528173729777336,
    "total_loss": 204.66405704692005
  },
  {
    "episode": 109,
    "avg_reward_per_step": -11.13935681861327,
    "episode_length": 3000,
    "policy_loss": 178.73431777954102,
    "value_loss": 2.740876078605652,
    "entropy": 0.527490958571434,
    "total_loss": 181.42244476228953
  },
  {
    "episode": 110,
    "avg_reward_per_step": 86.26689593205336,
    "episode_length": 221,
    "policy_loss": -1479.7096252441406,
    "value_loss": 0.5767097324132919,
    "entropy": 0.5753109157085419,
    "total_loss": -1479.1904466032981
  },
  {
    "episode": 111,
    "avg_reward_per_step": -11.215422980736175,
    "episode_length": 3000,
    "policy_loss": 179.67545700073242,
    "value_loss": 2.1259977221488953,
    "entropy": 0.44626545906066895,
    "total_loss": 181.75682817697526
  },
  {
    "episode": 112,
    "avg_reward_per_step": -12.508134171181371,
    "episode_length": 3000,
    "policy_loss": 201.04588317871094,
    "value_loss": 2.640266537666321,
    "entropy": 0.41395173221826553,
    "total_loss": 203.64475454315544
  },
  {
    "episode": 113,
    "avg_reward_per_step": -11.852483857805021,
    "episode_length": 3000,
    "policy_loss": 189.56163024902344,
    "value_loss": 2.7374081015586853,
    "entropy": 0.49538882821798325,
    "total_loss": 192.24949946776033
  },
  {
    "episode": 114,
    "avg_reward_per_step": -12.505403624298209,
    "episode_length": 3000,
    "policy_loss": 200.27183532714844,
    "value_loss": 2.6655900478363037,
    "entropy": 0.3905244246125221,
    "total_loss": 202.8983729325235
  },
  {
    "episode": 115,
    "avg_reward_per_step": -11.096616289885066,
    "episode_length": 3000,
    "policy_loss": 176.24885940551758,
    "value_loss": 2.48228520154953,
    "entropy": 0.4189160093665123,
    "total_loss": 178.68925300613046
  },
  {
    "episode": 116,
    "avg_reward_per_step": 107.09308241077585,
    "episode_length": 177,
    "policy_loss": -1846.0961608886719,
    "value_loss": 0.5980672836303711,
    "entropy": 0.47358449548482895,
    "total_loss": -1845.54545205459
  },
  {
    "episode": 117,
    "avg_reward_per_step": -10.815491518977138,
    "episode_length": 3000,
    "policy_loss": 170.78915786743164,
    "value_loss": 2.3885008692741394,
    "entropy": 0.5295971482992172,
    "total_loss": 173.12469902187587
  },
  {
    "episode": 118,
    "avg_reward_per_step": 125.36475678185164,
    "episode_length": 152,
    "policy_loss": -2135.9745483398438,
    "value_loss": 0.6197453588247299,
    "entropy": 0.497546948492527,
    "total_loss": -2135.404557675868
  },
  {
    "episode": 119,
    "avg_reward_per_step": -9.380616397083461,
    "episode_length": 3000,
    "policy_loss": 146.0885009765625,
    "value_loss": 2.3922292590141296,
    "entropy": 0.5774689465761185,
    "total_loss": 148.42298334091902
  },
  {
    "episode": 120,
    "avg_reward_per_step": 5.988949928979911,
    "episode_length": 1397,
    "policy_loss": -113.9894905090332,
    "value_loss": 0.5024680346250534,
    "entropy": 0.5949182063341141,
    "total_loss": -113.54651429504156
  },
  {
    "episode": 121,
    "avg_reward_per_step": -9.173643238625983,
    "episode_length": 3000,
    "policy_loss": 141.89733123779297,
    "value_loss": 1.9003824293613434,
    "entropy": 0.5785161256790161,
    "total_loss": 143.7398620545864
  },
  {
    "episode": 122,
    "avg_reward_per_step": 80.83745808170792,
    "episode_length": 232,
    "policy_loss": -1394.8064575195312,
    "value_loss": 0.5706307888031006,
    "entropy": 0.5969144850969315,
    "total_loss": -1394.295518179238
  },
  {
    "episode": 123,
    "avg_reward_per_step": -1.33744498295301,
    "episode_length": 1994,
    "policy_loss": 9.918710470199585,
    "value_loss": 0.4998091459274292,
    "entropy": 0.48375311493873596,
    "total_loss": 10.37014430463314
  },
  {
    "episode": 124,
    "avg_reward_per_step": -9.548927449670208,
    "episode_length": 3000,
    "policy_loss": 147.96805572509766,
    "value_loss": 2.2317395210266113,
    "entropy": 0.5413348376750946,
    "total_loss": 150.14566176235675
  },
  {
    "episode": 125,
    "avg_reward_per_step": -10.1810930628329,
    "episode_length": 3000,
    "policy_loss": 158.2875862121582,
    "value_loss": 2.4581422209739685,
    "entropy": 0.5089522302150726,
    "total_loss": 160.69483321011066
  },
  {
    "episode": 126,
    "avg_reward_per_step": -10.980557192060157,
    "episode_length": 3000,
    "policy_loss": 171.32720947265625,
    "value_loss": 2.865419328212738,
    "entropy": 0.48363492637872696,
    "total_loss": 174.14426530823113
  },
  {
    "episode": 127,
    "avg_reward_per_step": -10.428878207331437,
    "episode_length": 3000,
    "policy_loss": 161.66717147827148,
    "value_loss": 2.804126799106598,
    "entropy": 0.47918930649757385,
    "total_loss": 164.42337934672832
  },
  {
    "episode": 128,
    "avg_reward_per_step": 5.292791299231011,
    "episode_length": 1331,
    "policy_loss": -104.5429859161377,
    "value_loss": 0.5018477886915207,
    "entropy": 0.48848477005958557,
    "total_loss": -104.08998660445214
  },
  {
    "episode": 129,
    "avg_reward_per_step": -11.131458019304453,
    "episode_length": 3000,
    "policy_loss": 172.6267318725586,
    "value_loss": 2.746623456478119,
    "entropy": 0.49430274218320847,
    "total_loss": 175.3239250548184
  },
  {
    "episode": 130,
    "avg_reward_per_step": -11.540398013506442,
    "episode_length": 3000,
    "policy_loss": 179.16997146606445,
    "value_loss": 2.967883288860321,
    "entropy": 0.44251877814531326,
    "total_loss": 182.09360287711024
  },
  {
    "episode": 131,
    "avg_reward_per_step": -10.06491166569013,
    "episode_length": 3000,
    "policy_loss": 153.8177947998047,
    "value_loss": 2.8471614718437195,
    "entropy": 0.5213815122842789,
    "total_loss": 156.61281812041997
  },
  {
    "episode": 132,
    "avg_reward_per_step": 1.8388245825586058,
    "episode_length": 1959,
    "policy_loss": -47.60529708862305,
    "value_loss": 0.5004726946353912,
    "entropy": 0.5366249531507492,
    "total_loss": -47.15848688930273
  },
  {
    "episode": 133,
    "avg_reward_per_step": -9.503871374702163,
    "episode_length": 3000,
    "policy_loss": 143.61566925048828,
    "value_loss": 2.3271259665489197,
    "entropy": 0.5434713959693909,
    "total_loss": 145.88844807744027
  },
  {
    "episode": 134,
    "avg_reward_per_step": -9.741687674323005,
    "episode_length": 3000,
    "policy_loss": 146.89882278442383,
    "value_loss": 2.3278017044067383,
    "entropy": 0.5607511401176453,
    "total_loss": 149.1705493748188
  },
  {
    "episode": 135,
    "avg_reward_per_step": -9.588148269434724,
    "episode_length": 3000,
    "policy_loss": 143.8743896484375,
    "value_loss": 2.111168086528778,
    "entropy": 0.5655089914798737,
    "total_loss": 145.92900683581829
  },
  {
    "episode": 136,
    "avg_reward_per_step": 170.67021186039776,
    "episode_length": 117,
    "policy_loss": -2914.60546875,
    "value_loss": 0.6889088451862335,
    "entropy": 0.532972127199173,
    "total_loss": -2913.9698571175336
  },
  {
    "episode": 137,
    "avg_reward_per_step": 71.15242447163868,
    "episode_length": 264,
    "policy_loss": -1230.4080200195312,
    "value_loss": 0.5616874396800995,
    "entropy": 0.4909151643514633,
    "total_loss": -1229.8954240962862
  },
  {
    "episode": 138,
    "avg_reward_per_step": 15.699293582281301,
    "episode_length": 881,
    "policy_loss": -286.4955596923828,
    "value_loss": 0.5096127986907959,
    "entropy": 0.5987971872091293,
    "total_loss": -286.04582661241295
  },
  {
    "episode": 139,
    "avg_reward_per_step": 66.89592004591718,
    "episode_length": 281,
    "policy_loss": -1158.43359375,
    "value_loss": 0.558137446641922,
    "entropy": 0.5860002487897873,
    "total_loss": -1157.9340563282371
  },
  {
    "episode": 140,
    "avg_reward_per_step": 80.22713719042149,
    "episode_length": 242,
    "policy_loss": -1395.4062194824219,
    "value_loss": 0.5734938383102417,
    "entropy": 0.6097109466791153,
    "total_loss": -1394.8936967387795
  },
  {
    "episode": 141,
    "avg_reward_per_step": 134.72663548172218,
    "episode_length": 146,
    "policy_loss": -2304.4105224609375,
    "value_loss": 0.6373448818922043,
    "entropy": 0.6236354112625122,
    "total_loss": -2303.8355411201715
  },
  {
    "episode": 142,
    "avg_reward_per_step": 139.00019599492637,
    "episode_length": 143,
    "policy_loss": -2404.2025756835938,
    "value_loss": 0.643514946103096,
    "entropy": 0.6389802247285843,
    "total_loss": -2403.6229587599637
  },
  {
    "episode": 143,
    "avg_reward_per_step": 23.891999202614873,
    "episode_length": 775,
    "policy_loss": -422.91182708740234,
    "value_loss": 0.5205437988042831,
    "entropy": 0.6016522943973541,
    "total_loss": -422.4514485180378
  },
  {
    "episode": 144,
    "avg_reward_per_step": 163.81066475064625,
    "episode_length": 121,
    "policy_loss": -2822.78125,
    "value_loss": 0.6781270653009415,
    "entropy": 0.6284979283809662,
    "total_loss": -2822.1659727275373
  },
  {
    "episode": 145,
    "avg_reward_per_step": 34.34926237089347,
    "episode_length": 541,
    "policy_loss": -599.3583068847656,
    "value_loss": 0.5290078371763229,
    "entropy": 0.6326611042022705,
    "total_loss": -598.8925651580096
  },
  {
    "episode": 146,
    "avg_reward_per_step": 52.77504136476453,
    "episode_length": 365,
    "policy_loss": -915.7882843017578,
    "value_loss": 0.5461779236793518,
    "entropy": 0.6559137105941772,
    "total_loss": -915.3076977491379
  },
  {
    "episode": 147,
    "avg_reward_per_step": 106.25328999887101,
    "episode_length": 186,
    "policy_loss": -1829.0792236328125,
    "value_loss": 0.6034411191940308,
    "entropy": 0.6379214823246002,
    "total_loss": -1828.539574661851
  },
  {
    "episode": 148,
    "avg_reward_per_step": 23.879923648634332,
    "episode_length": 791,
    "policy_loss": -423.6232452392578,
    "value_loss": 0.5207220613956451,
    "entropy": 0.6288417428731918,
    "total_loss": -423.1654073521495
  },
  {
    "episode": 149,
    "avg_reward_per_step": 67.27206172981715,
    "episode_length": 283,
    "policy_loss": -1160.9972534179688,
    "value_loss": 0.5585464090108871,
    "entropy": 0.6679694801568985,
    "total_loss": -1160.5055039569736
  },
  {
    "episode": 150,
    "avg_reward_per_step": 150.23437833831602,
    "episode_length": 132,
    "policy_loss": -2598.8451538085938,
    "value_loss": 0.6583534777164459,
    "entropy": 0.6431195288896561,
    "total_loss": -2598.2511122837664
  },
  {
    "episode": 151,
    "avg_reward_per_step": 97.08924414389159,
    "episode_length": 199,
    "policy_loss": -1661.7099304199219,
    "value_loss": 0.5902457982301712,
    "entropy": 0.6597555726766586,
    "total_loss": -1661.1856601789593
  },
  {
    "episode": 152,
    "avg_reward_per_step": 107.39561838139036,
    "episode_length": 181,
    "policy_loss": -1859.2404479980469,
    "value_loss": 0.6019733101129532,
    "entropy": 0.6270238161087036,
    "total_loss": -1858.7011770695449
  },
  {
    "episode": 153,
    "avg_reward_per_step": 110.63059208415929,
    "episode_length": 176,
    "policy_loss": -1919.5089111328125,
    "value_loss": 0.6062724143266678,
    "entropy": 0.6047459840774536,
    "total_loss": -1918.9631133168937
  },
  {
    "episode": 154,
    "avg_reward_per_step": 58.325496928308525,
    "episode_length": 338,
    "policy_loss": -1012.4275360107422,
    "value_loss": 0.5526477694511414,
    "entropy": 0.49502982944250107,
    "total_loss": -1011.9243912242353
  },
  {
    "episode": 155,
    "avg_reward_per_step": 85.57694566700596,
    "episode_length": 229,
    "policy_loss": -1468.572265625,
    "value_loss": 0.5792474895715714,
    "entropy": 0.5879799872636795,
    "total_loss": -1468.0518161341547
  },
  {
    "episode": 156,
    "avg_reward_per_step": 142.1413606803673,
    "episode_length": 138,
    "policy_loss": -2460.9231567382812,
    "value_loss": 0.6461886912584305,
    "entropy": 0.596420481801033,
    "total_loss": -2460.336610095203
  },
  {
    "episode": 157,
    "avg_reward_per_step": 69.66951543672268,
    "episode_length": 274,
    "policy_loss": -1199.4114990234375,
    "value_loss": 0.5616774708032608,
    "entropy": 0.5606663972139359,
    "total_loss": -1198.9058881923556
  },
  {
    "episode": 158,
    "avg_reward_per_step": 101.27423711271555,
    "episode_length": 189,
    "policy_loss": -1733.5582885742188,
    "value_loss": 0.5932846963405609,
    "entropy": 0.5718449354171753,
    "total_loss": -1733.0221883714198
  },
  {
    "episode": 159,
    "avg_reward_per_step": 123.56007357055613,
    "episode_length": 157,
    "policy_loss": -2139.2379760742188,
    "value_loss": 0.6219857484102249,
    "entropy": 0.5312829315662384,
    "total_loss": -2138.669118618965
  },
  {
    "episode": 160,
    "avg_reward_per_step": -7.602803034289191,
    "episode_length": 3000,
    "policy_loss": 109.27896690368652,
    "value_loss": 1.7232840359210968,
    "entropy": 0.5073782727122307,
    "total_loss": 110.9515131123364
  },
  {
    "episode": 161,
    "avg_reward_per_step": 135.7665564805357,
    "episode_length": 145,
    "policy_loss": -2337.2498168945312,
    "value_loss": 0.6375074535608292,
    "entropy": 0.41450217366218567,
    "total_loss": -2336.6537596583366
  },
  {
    "episode": 162,
    "avg_reward_per_step": 57.079106860597385,
    "episode_length": 315,
    "policy_loss": -979.2002258300781,
    "value_loss": 0.5460308939218521,
    "entropy": 0.4127901569008827,
    "total_loss": -978.6954739518463
  },
  {
    "episode": 163,
    "avg_reward_per_step": 152.39645975451677,
    "episode_length": 131,
    "policy_loss": -2600.6647338867188,
    "value_loss": 0.6629658043384552,
    "entropy": 0.41898418217897415,
    "total_loss": -2600.043666500598
  },
  {
    "episode": 164,
    "avg_reward_per_step": -9.79338155493231,
    "episode_length": 3000,
    "policy_loss": 145.37833404541016,
    "value_loss": 1.8232949078083038,
    "entropy": 0.4156334772706032,
    "total_loss": 147.1600656054914
  },
  {
    "episode": 165,
    "avg_reward_per_step": 226.59773758291675,
    "episode_length": 88,
    "policy_loss": -3863.4417114257812,
    "value_loss": 0.7829445004463196,
    "entropy": 0.42378026992082596,
    "total_loss": -3862.701144952327
  },
  {
    "episode": 166,
    "avg_reward_per_step": 160.12795261934545,
    "episode_length": 125,
    "policy_loss": -2734.607421875,
    "value_loss": 0.6746838986873627,
    "entropy": 0.3820686712861061,
    "total_loss": -2733.9709448434414
  },
  {
    "episode": 167,
    "avg_reward_per_step": -12.442405590549123,
    "episode_length": 3000,
    "policy_loss": 188.90905380249023,
    "value_loss": 1.7317604422569275,
    "entropy": 0.33226344734430313,
    "total_loss": 190.60758790001273
  },
  {
    "episode": 168,
    "avg_reward_per_step": 188.9134384449464,
    "episode_length": 106,
    "policy_loss": -3222.6668090820312,
    "value_loss": 0.7191659510135651,
    "entropy": 0.4084821343421936,
    "total_loss": -3221.988491344452
  },
  {
    "episode": 169,
    "avg_reward_per_step": 194.17000064613458,
    "episode_length": 103,
    "policy_loss": -3348.8643798828125,
    "value_loss": 0.7272263169288635,
    "entropy": 0.3869037926197052,
    "total_loss": -3348.1758439451455
  },
  {
    "episode": 170,
    "avg_reward_per_step": 24.267928837562103,
    "episode_length": 671,
    "policy_loss": -430.4447937011719,
    "value_loss": 0.5180166512727737,
    "entropy": 0.2385205179452896,
    "total_loss": -429.9506291016936
  },
  {
    "episode": 171,
    "avg_reward_per_step": -13.801616147442694,
    "episode_length": 3000,
    "policy_loss": 211.65673065185547,
    "value_loss": 1.6899045407772064,
    "entropy": 0.1680852249264717,
    "total_loss": 213.32982667014002
  },
  {
    "episode": 172,
    "avg_reward_per_step": -13.721113290351969,
    "episode_length": 3000,
    "policy_loss": 210.2879180908203,
    "value_loss": 1.8326518833637238,
    "entropy": 0.14985065162181854,
    "total_loss": 212.10558490902184
  },
  {
    "episode": 173,
    "avg_reward_per_step": 11.68847124302559,
    "episode_length": 1020,
    "policy_loss": -219.02556991577148,
    "value_loss": 0.5069119185209274,
    "entropy": 0.09053405188024044,
    "total_loss": -218.52771140243857
  },
  {
    "episode": 174,
    "avg_reward_per_step": -13.832088960419608,
    "episode_length": 3000,
    "policy_loss": 211.71253204345703,
    "value_loss": 1.6998814940452576,
    "entropy": 0.1481427289545536,
    "total_loss": 213.39759926460684
  },
  {
    "episode": 175,
    "avg_reward_per_step": -16.018231711057535,
    "episode_length": 3000,
    "policy_loss": 248.0203742980957,
    "value_loss": 2.3348944783210754,
    "entropy": 0.1081873420625925,
    "total_loss": 250.34445004221052
  },
  {
    "episode": 176,
    "avg_reward_per_step": -15.53024853177245,
    "episode_length": 3000,
    "policy_loss": 239.2927131652832,
    "value_loss": 2.2622278332710266,
    "entropy": 0.1272561326622963,
    "total_loss": 241.542215385288
  },
  {
    "episode": 177,
    "avg_reward_per_step": -8.518824196999557,
    "episode_length": 3000,
    "policy_loss": 121.25390243530273,
    "value_loss": 0.871387243270874,
    "entropy": 0.17042843997478485,
    "total_loss": 122.10824683457614
  },
  {
    "episode": 178,
    "avg_reward_per_step": -11.291709100539013,
    "episode_length": 3000,
    "policy_loss": 167.53355407714844,
    "value_loss": 1.2403680682182312,
    "entropy": 0.15769005566835403,
    "total_loss": 168.75815313979984
  },
  {
    "episode": 179,
    "avg_reward_per_step": 8.46374057495674,
    "episode_length": 1238,
    "policy_loss": -166.9033966064453,
    "value_loss": 0.5047771036624908,
    "entropy": 0.10473984479904175,
    "total_loss": -166.40909348726274
  },
  {
    "episode": 180,
    "avg_reward_per_step": 39.24854216649189,
    "episode_length": 490,
    "policy_loss": -687.4421997070312,
    "value_loss": 0.5345602333545685,
    "entropy": 0.14327914640307426,
    "total_loss": -686.921967388317
  },
  {
    "episode": 181,
    "avg_reward_per_step": 48.90356432821472,
    "episode_length": 397,
    "policy_loss": -855.0817260742188,
    "value_loss": 0.5434470623731613,
    "entropy": 0.25250813364982605,
    "total_loss": -854.5635298252106
  },
  {
    "episode": 182,
    "avg_reward_per_step": 4.946435467437452,
    "episode_length": 1239,
    "policy_loss": -108.81574440002441,
    "value_loss": 0.501846045255661,
    "entropy": 0.10624096542596817,
    "total_loss": -108.32452245131135
  },
  {
    "episode": 183,
    "avg_reward_per_step": -9.137381321799134,
    "episode_length": 3000,
    "policy_loss": 130.30875778198242,
    "value_loss": 1.0553675293922424,
    "entropy": 0.16629941016435623,
    "total_loss": 131.34749537035822
  },
  {
    "episode": 184,
    "avg_reward_per_step": 12.334163945107765,
    "episode_length": 1451,
    "policy_loss": -231.86240005493164,
    "value_loss": 0.5116751492023468,
    "entropy": 0.24663687869906425,
    "total_loss": -231.3753885935992
  },
  {
    "episode": 185,
    "avg_reward_per_step": -12.09976173587715,
    "episode_length": 3000,
    "policy_loss": 179.96109008789062,
    "value_loss": 1.4829221367835999,
    "entropy": 0.19266291335225105,
    "total_loss": 181.424745933339
  },
  {
    "episode": 186,
    "avg_reward_per_step": -13.765937915931966,
    "episode_length": 3000,
    "policy_loss": 207.8038215637207,
    "value_loss": 1.933985024690628,
    "entropy": 0.19373534992337227,
    "total_loss": 209.718433053419
  },
  {
    "episode": 187,
    "avg_reward_per_step": 21.07330513994206,
    "episode_length": 664,
    "policy_loss": -389.38819122314453,
    "value_loss": 0.5136287361383438,
    "entropy": 0.14330995455384254,
    "total_loss": -388.8888934824616
  },
  {
    "episode": 188,
    "avg_reward_per_step": -10.964281375292796,
    "episode_length": 3000,
    "policy_loss": 160.16082000732422,
    "value_loss": 1.2822852432727814,
    "entropy": 0.20788941904902458,
    "total_loss": 161.4223163086921
  },
  {
    "episode": 189,
    "avg_reward_per_step": -11.90823930576055,
    "episode_length": 3000,
    "policy_loss": 175.71566009521484,
    "value_loss": 1.300379365682602,
    "entropy": 0.18771552294492722,
    "total_loss": 176.99726790860296
  },
  {
    "episode": 190,
    "avg_reward_per_step": -11.79287521178821,
    "episode_length": 3000,
    "policy_loss": 173.7774429321289,
    "value_loss": 1.5442349314689636,
    "entropy": 0.21455355361104012,
    "total_loss": 175.30022250823677
  },
  {
    "episode": 191,
    "avg_reward_per_step": -13.713705536325882,
    "episode_length": 3000,
    "policy_loss": 205.14529037475586,
    "value_loss": 1.8393181562423706,
    "entropy": 0.1915152333676815,
    "total_loss": 206.96545700766146
  },
  {
    "episode": 192,
    "avg_reward_per_step": -12.430039311702306,
    "episode_length": 3000,
    "policy_loss": 183.62469863891602,
    "value_loss": 1.6651829779148102,
    "entropy": 0.22337942942976952,
    "total_loss": 185.26754367388784
  },
  {
    "episode": 193,
    "avg_reward_per_step": 19.64740954278533,
    "episode_length": 743,
    "policy_loss": -360.30428314208984,
    "value_loss": 0.5136525630950928,
    "entropy": 0.12424235418438911,
    "total_loss": -359.8030548144132
  },
  {
    "episode": 194,
    "avg_reward_per_step": -11.522806117765183,
    "episode_length": 3000,
    "policy_loss": 167.29516983032227,
    "value_loss": 1.5064672827720642,
    "entropy": 0.23185088112950325,
    "total_loss": 168.7784520249814
  },
  {
    "episode": 195,
    "avg_reward_per_step": 24.378719394507183,
    "episode_length": 618,
    "policy_loss": -442.01915740966797,
    "value_loss": 0.5170615464448929,
    "entropy": 0.13796758651733398,
    "total_loss": -441.5158926218748
  },
  {
    "episode": 196,
    "avg_reward_per_step": -12.12651147506997,
    "episode_length": 3000,
    "policy_loss": 176.83839416503906,
    "value_loss": 1.6341869235038757,
    "entropy": 0.24223796278238297,
    "total_loss": 178.4483572922647
  },
  {
    "episode": 197,
    "avg_reward_per_step": -10.970820468229608,
    "episode_length": 3000,
    "policy_loss": 157.03586196899414,
    "value_loss": 1.3836830854415894,
    "entropy": 0.26746563613414764,
    "total_loss": 158.39279849082232
  },
  {
    "episode": 198,
    "avg_reward_per_step": -12.70479259145793,
    "episode_length": 3000,
    "policy_loss": 185.93626403808594,
    "value_loss": 1.5362776517868042,
    "entropy": 0.2796851322054863,
    "total_loss": 187.4445731766522
  },
  {
    "episode": 199,
    "avg_reward_per_step": 19.99299454643952,
    "episode_length": 799,
    "policy_loss": -369.64095306396484,
    "value_loss": 0.5154976546764374,
    "entropy": 0.20790735632181168,
    "total_loss": -369.1462461449206
  },
  {
    "episode": 200,
    "avg_reward_per_step": 102.13943144594799,
    "episode_length": 195,
    "policy_loss": -1759.8505859375,
    "value_loss": 0.6005888730287552,
    "entropy": 0.2303040623664856,
    "total_loss": -1759.2730274707078
  },
  {
    "episode": 201,
    "avg_reward_per_step": 154.62822259322735,
    "episode_length": 129,
    "policy_loss": -2652.9696044921875,
    "value_loss": 0.6667483597993851,
    "entropy": 0.37124285101890564,
    "total_loss": -2652.33998041749
  },
  {
    "episode": 202,
    "avg_reward_per_step": 100.01151603059081,
    "episode_length": 198,
    "policy_loss": -1729.8610534667969,
    "value_loss": 0.597107782959938,
    "entropy": 0.3297194242477417,
    "total_loss": -1729.2969176262618
  },
  {
    "episode": 203,
    "avg_reward_per_step": -11.29612417101024,
    "episode_length": 3000,
    "policy_loss": 161.01184463500977,
    "value_loss": 1.411069542169571,
    "entropy": 0.2729017734527588,
    "total_loss": 162.39562399983407
  },
  {
    "episode": 204,
    "avg_reward_per_step": -11.65125869668962,
    "episode_length": 3000,
    "policy_loss": 166.93457794189453,
    "value_loss": 1.3096973896026611,
    "entropy": 0.23675183579325676,
    "total_loss": 168.22060014791788
  },
  {
    "episode": 205,
    "avg_reward_per_step": 40.07854628052691,
    "episode_length": 428,
    "policy_loss": -711.5684509277344,
    "value_loss": 0.5317135453224182,
    "entropy": 0.1758413128554821,
    "total_loss": -711.0543215136975
  },
  {
    "episode": 206,
    "avg_reward_per_step": -9.620405127653072,
    "episode_length": 3000,
    "policy_loss": 132.41856002807617,
    "value_loss": 1.118989259004593,
    "entropy": 0.2554803341627121,
    "total_loss": 133.5120012536645
  },
  {
    "episode": 207,
    "avg_reward_per_step": 70.85603477897332,
    "episode_length": 280,
    "policy_loss": -1233.4896850585938,
    "value_loss": 0.5666458755731583,
    "entropy": 0.22776471078395844,
    "total_loss": -1232.945815654099
  },
  {
    "episode": 208,
    "avg_reward_per_step": 27.853794699934483,
    "episode_length": 583,
    "policy_loss": -505.95066833496094,
    "value_loss": 0.5214280039072037,
    "entropy": 0.2295949086546898,
    "total_loss": -505.4521998219192
  },
  {
    "episode": 209,
    "avg_reward_per_step": 68.24809014445742,
    "episode_length": 285,
    "policy_loss": -1188.9874267578125,
    "value_loss": 0.5623450130224228,
    "entropy": 0.2945386692881584,
    "total_loss": -1188.454535611719
  },
  {
    "episode": 210,
    "avg_reward_per_step": 59.97104241674525,
    "episode_length": 331,
    "policy_loss": -1052.8942260742188,
    "value_loss": 0.5557389110326767,
    "entropy": 0.26662154495716095,
    "total_loss": -1052.3651493176817
  },
  {
    "episode": 211,
    "avg_reward_per_step": 48.57033840441596,
    "episode_length": 376,
    "policy_loss": -861.7306976318359,
    "value_loss": 0.5412066131830215,
    "entropy": 0.3099503070116043,
    "total_loss": -861.2204860493541
  },
  {
    "episode": 212,
    "avg_reward_per_step": 66.23704400992904,
    "episode_length": 283,
    "policy_loss": -1157.0250549316406,
    "value_loss": 0.5584135204553604,
    "entropy": 0.39966409653425217,
    "total_loss": -1156.5066078208388
  },
  {
    "episode": 213,
    "avg_reward_per_step": 102.74036184074815,
    "episode_length": 191,
    "policy_loss": -1778.6405944824219,
    "value_loss": 0.5989770442247391,
    "entropy": 0.41353901475667953,
    "total_loss": -1778.082971339673
  },
  {
    "episode": 214,
    "avg_reward_per_step": 198.2459822397053,
    "episode_length": 101,
    "policy_loss": -3393.9454956054688,
    "value_loss": 0.735986739397049,
    "entropy": 0.42936286330223083,
    "total_loss": -3393.252445152402
  },
  {
    "episode": 215,
    "avg_reward_per_step": 154.71317400307484,
    "episode_length": 129,
    "policy_loss": -2665.9295654296875,
    "value_loss": 0.6671481728553772,
    "entropy": 0.3732246309518814,
    "total_loss": -2665.2997397199274
  },
  {
    "episode": 216,
    "avg_reward_per_step": 260.2979501840333,
    "episode_length": 77,
    "policy_loss": -4427.6771240234375,
    "value_loss": 0.8534330576658249,
    "entropy": 0.4190634489059448,
    "total_loss": -4426.865597310662
  },
  {
    "episode": 217,
    "avg_reward_per_step": 196.09910394356191,
    "episode_length": 102,
    "policy_loss": -3356.54052734375,
    "value_loss": 0.7326332330703735,
    "entropy": 0.41237445175647736,
    "total_loss": -3355.8491315558554
  },
  {
    "episode": 218,
    "avg_reward_per_step": 173.8237467348693,
    "episode_length": 115,
    "policy_loss": -2973.3126220703125,
    "value_loss": 0.6954691112041473,
    "entropy": 0.3439756706357002,
    "total_loss": -2972.651550526172
  },
  {
    "episode": 219,
    "avg_reward_per_step": 152.69563510318562,
    "episode_length": 131,
    "policy_loss": -2624.338623046875,
    "value_loss": 0.665705531835556,
    "entropy": 0.3551945611834526,
    "total_loss": -2623.708436971158
  },
  {
    "episode": 220,
    "avg_reward_per_step": 50.453767714226494,
    "episode_length": 357,
    "policy_loss": -889.4258728027344,
    "value_loss": 0.5421612709760666,
    "entropy": 0.29818908870220184,
    "total_loss": -888.9135304406285
  },
  {
    "episode": 221,
    "avg_reward_per_step": 63.644472359497,
    "episode_length": 311,
    "policy_loss": -1111.4312744140625,
    "value_loss": 0.5590576827526093,
    "entropy": 0.32476038485765457,
    "total_loss": -1110.9046927697957
  },
  {
    "episode": 222,
    "avg_reward_per_step": 46.21288705392946,
    "episode_length": 379,
    "policy_loss": -816.6409301757812,
    "value_loss": 0.5374964028596878,
    "entropy": 0.33423912525177,
    "total_loss": -816.1368576854468
  },
  {
    "episode": 223,
    "avg_reward_per_step": 224.96923340927887,
    "episode_length": 89,
    "policy_loss": -3869.0397338867188,
    "value_loss": 0.7822414487600327,
    "entropy": 0.3342110812664032,
    "total_loss": -3868.2909135460854
  },
  {
    "episode": 224,
    "avg_reward_per_step": 247.07692218543542,
    "episode_length": 81,
    "policy_loss": -4219.2032470703125,
    "value_loss": 0.8255127221345901,
    "entropy": 0.3048740550875664,
    "total_loss": -4218.408221753687
  },
  {
    "episode": 225,
    "avg_reward_per_step": 244.21381860204437,
    "episode_length": 82,
    "policy_loss": -4177.4447021484375,
    "value_loss": 0.8201743364334106,
    "entropy": 0.2559208534657955,
    "total_loss": -4176.650119897351
  },
  {
    "episode": 226,
    "avg_reward_per_step": 264.0979168386206,
    "episode_length": 76,
    "policy_loss": -4523.02392578125,
    "value_loss": 0.8616538643836975,
    "entropy": 0.2709218040108681,
    "total_loss": -4522.189364097268
  },
  {
    "episode": 227,
    "avg_reward_per_step": 144.2048550073301,
    "episode_length": 139,
    "policy_loss": -2550.1305541992188,
    "value_loss": 0.6537785530090332,
    "entropy": 0.2370339035987854,
    "total_loss": -2549.5004790365697
  },
  {
    "episode": 228,
    "avg_reward_per_step": 125.80131568891706,
    "episode_length": 159,
    "policy_loss": -2153.1842041015625,
    "value_loss": 0.6306327283382416,
    "entropy": 0.19165485352277756,
    "total_loss": -2152.5727368585767
  },
  {
    "episode": 229,
    "avg_reward_per_step": 156.00772935041584,
    "episode_length": 128,
    "policy_loss": -2691.150634765625,
    "value_loss": 0.6692286431789398,
    "entropy": 0.200248334556818,
    "total_loss": -2690.501430955902
  },
  {
    "episode": 230,
    "avg_reward_per_step": 263.89748637780144,
    "episode_length": 76,
    "policy_loss": -4498.550537109375,
    "value_loss": 0.8602300435304642,
    "entropy": 0.16950764134526253,
    "total_loss": -4497.707257829979
  },
  {
    "episode": 231,
    "avg_reward_per_step": 130.84482465119152,
    "episode_length": 153,
    "policy_loss": -2244.49365234375,
    "value_loss": 0.6362858265638351,
    "entropy": 0.15523933246731758,
    "total_loss": -2243.872890450433
  },
  {
    "episode": 232,
    "avg_reward_per_step": 206.6618605398822,
    "episode_length": 97,
    "policy_loss": -3524.3275146484375,
    "value_loss": 0.7512709200382233,
    "entropy": 0.16381463780999184,
    "total_loss": -3523.59262519218
  },
  {
    "episode": 233,
    "avg_reward_per_step": 149.0507001019698,
    "episode_length": 134,
    "policy_loss": -2557.337158203125,
    "value_loss": 0.6603049635887146,
    "entropy": 0.16862721741199493,
    "total_loss": -2556.6937159612776
  },
  {
    "episode": 234,
    "avg_reward_per_step": 14.765506065329792,
    "episode_length": 896,
    "policy_loss": -278.28897857666016,
    "value_loss": 0.5094161331653595,
    "entropy": 0.10665299370884895,
    "total_loss": -277.7902277428657
  },
  {
    "episode": 235,
    "avg_reward_per_step": 12.39945738714089,
    "episode_length": 920,
    "policy_loss": -238.77975463867188,
    "value_loss": 0.5068985968828201,
    "entropy": 0.11187858320772648,
    "total_loss": -238.28404390010982
  },
  {
    "episode": 236,
    "avg_reward_per_step": 222.7173683673495,
    "episode_length": 90,
    "policy_loss": -3784.7137451171875,
    "value_loss": 0.7799802869558334,
    "entropy": 0.17578240856528282,
    "total_loss": -3783.951343071088
  },
  {
    "episode": 237,
    "avg_reward_per_step": 85.16177368271293,
    "episode_length": 234,
    "policy_loss": -1469.7099914550781,
    "value_loss": 0.5822106450796127,
    "entropy": 0.16212397068738937,
    "total_loss": -1469.1439932070673
  },
  {
    "episode": 238,
    "avg_reward_per_step": 260.36566344072975,
    "episode_length": 77,
    "policy_loss": -4408.321533203125,
    "value_loss": 0.8533153533935547,
    "entropy": 0.15569177269935608,
    "total_loss": -4407.483787027001
  },
  {
    "episode": 239,
    "avg_reward_per_step": 217.83885720294688,
    "episode_length": 92,
    "policy_loss": -3800.6875610351562,
    "value_loss": 0.7714337855577469,
    "entropy": 0.14903270080685616,
    "total_loss": -3799.931030519679
  },
  {
    "episode": 240,
    "avg_reward_per_step": 206.9311699185113,
    "episode_length": 97,
    "policy_loss": -3493.967529296875,
    "value_loss": 0.7524724006652832,
    "entropy": 0.1342206373810768,
    "total_loss": -3493.228478959948
  },
  {
    "episode": 241,
    "avg_reward_per_step": -0.7875771329449438,
    "episode_length": 3000,
    "policy_loss": -14.278148174285889,
    "value_loss": 0.6670099496841431,
    "entropy": 0.033671571873128414,
    "total_loss": -13.614505381789058
  },
  {
    "episode": 242,
    "avg_reward_per_step": 174.20091914722394,
    "episode_length": 115,
    "policy_loss": -2979.2927856445312,
    "value_loss": 0.6980661898851395,
    "entropy": 0.10636542737483978,
    "total_loss": -2978.6053559973834
  },
  {
    "episode": 243,
    "avg_reward_per_step": 222.70538082076163,
    "episode_length": 90,
    "policy_loss": -3791.9144287109375,
    "value_loss": 0.7799202650785446,
    "entropy": 0.11776171810925007,
    "total_loss": -3791.14628461767
  },
  {
    "episode": 244,
    "avg_reward_per_step": 125.9450687553978,
    "episode_length": 159,
    "policy_loss": -2158.7142333984375,
    "value_loss": 0.6308851391077042,
    "entropy": 0.12746792286634445,
    "total_loss": -2158.0960950516164
  },
  {
    "episode": 245,
    "avg_reward_per_step": 235.98011327219368,
    "episode_length": 85,
    "policy_loss": -4012.6251831054688,
    "value_loss": 0.8050394207239151,
    "entropy": 0.10133803449571133,
    "total_loss": -4011.8302774881945
  },
  {
    "episode": 246,
    "avg_reward_per_step": 194.69975747039342,
    "episode_length": 103,
    "policy_loss": -3316.1671142578125,
    "value_loss": 0.731124758720398,
    "entropy": 0.11981287598609924,
    "total_loss": -3315.447970786691
  },
  {
    "episode": 247,
    "avg_reward_per_step": 196.41095737127566,
    "episode_length": 102,
    "policy_loss": -3345.439697265625,
    "value_loss": 0.7336555868387222,
    "entropy": 0.13250067457556725,
    "total_loss": -3344.719291746244
  },
  {
    "episode": 248,
    "avg_reward_per_step": 218.21144832849353,
    "episode_length": 92,
    "policy_loss": -3710.1692504882812,
    "value_loss": 0.7722865641117096,
    "entropy": 0.14512544125318527,
    "total_loss": -3709.411476468295
  },
  {
    "episode": 249,
    "avg_reward_per_step": 260.35186666435214,
    "episode_length": 77,
    "policy_loss": -4413.523681640625,
    "value_loss": 0.8533776104450226,
    "entropy": 0.1346191167831421,
    "total_loss": -4412.683765941858
  },
  {
    "episode": 250,
    "avg_reward_per_step": 213.3641283845532,
    "episode_length": 94,
    "policy_loss": -3647.2026977539062,
    "value_loss": 0.7633879780769348,
    "entropy": 0.14131904393434525,
    "total_loss": -3646.4534416802226
  },
  {
    "episode": 251,
    "avg_reward_per_step": 267.96618733392785,
    "episode_length": 75,
    "policy_loss": -4522.3460693359375,
    "value_loss": 0.8699499666690826,
    "entropy": 0.11625314876437187,
    "total_loss": -4521.487744684145
  },
  {
    "episode": 252,
    "avg_reward_per_step": 213.6866067653142,
    "episode_length": 94,
    "policy_loss": -3626.5581665039062,
    "value_loss": 0.7642621994018555,
    "entropy": 0.16695940122008324,
    "total_loss": -3625.8106002446266
  },
  {
    "episode": 253,
    "avg_reward_per_step": 250.30687306419742,
    "episode_length": 80,
    "policy_loss": -4236.45458984375,
    "value_loss": 0.8325030952692032,
    "entropy": 0.10249999538064003,
    "total_loss": -4235.632336748019
  },
  {
    "episode": 254,
    "avg_reward_per_step": 247.99622252905087,
    "episode_length": 81,
    "policy_loss": -4195.314208984375,
    "value_loss": 0.8289780616760254,
    "entropy": 0.1443195529282093,
    "total_loss": -4194.499662877992
  },
  {
    "episode": 255,
    "avg_reward_per_step": 247.8969540543972,
    "episode_length": 81,
    "policy_loss": -4196.173583984375,
    "value_loss": 0.8287396132946014,
    "entropy": 0.14856718853116035,
    "total_loss": -4195.359701089934
  },
  {
    "episode": 256,
    "avg_reward_per_step": 264.1380498770743,
    "episode_length": 76,
    "policy_loss": -4471.5440673828125,
    "value_loss": 0.8612511456012726,
    "entropy": 0.07594293542206287,
    "total_loss": -4470.690410530753
  },
  {
    "episode": 257,
    "avg_reward_per_step": 257.491916445221,
    "episode_length": 78,
    "policy_loss": -4351.0804443359375,
    "value_loss": 0.8478674292564392,
    "entropy": 0.09939373470842838,
    "total_loss": -4350.242516280152
  },
  {
    "episode": 258,
    "avg_reward_per_step": 264.3226678944197,
    "episode_length": 76,
    "policy_loss": -4470.239501953125,
    "value_loss": 0.862003356218338,
    "entropy": 0.12544147670269012,
    "total_loss": -4469.390042744577
  },
  {
    "episode": 259,
    "avg_reward_per_step": 271.2792089266683,
    "episode_length": 74,
    "policy_loss": -4579.78173828125,
    "value_loss": 0.8765520602464676,
    "entropy": 0.10250199027359486,
    "total_loss": -4578.915436420031
  },
  {
    "episode": 260,
    "avg_reward_per_step": 271.5333590238338,
    "episode_length": 74,
    "policy_loss": -4589.5885009765625,
    "value_loss": 0.8771468251943588,
    "entropy": 0.1171465814113617,
    "total_loss": -4588.72306880951
  },
  {
    "episode": 261,
    "avg_reward_per_step": 115.54124762860974,
    "episode_length": 173,
    "policy_loss": -1987.3751220703125,
    "value_loss": 0.6159842312335968,
    "entropy": 0.09837750904262066,
    "total_loss": -1986.7689755899833
  },
  {
    "episode": 262,
    "avg_reward_per_step": 271.03609513998595,
    "episode_length": 74,
    "policy_loss": -4637.8707275390625,
    "value_loss": 0.8754889816045761,
    "entropy": 0.10712916031479836,
    "total_loss": -4637.005951473489
  },
  {
    "episode": 263,
    "avg_reward_per_step": 264.2683116168425,
    "episode_length": 76,
    "policy_loss": -4462.951904296875,
    "value_loss": 0.8610511124134064,
    "entropy": 0.07860464416444302,
    "total_loss": -4462.098713648878
  },
  {
    "episode": 264,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4539.141357421875,
    "value_loss": 0.8674906194210052,
    "entropy": 0.07891380973160267,
    "total_loss": -4538.281758183427
  },
  {
    "episode": 265,
    "avg_reward_per_step": 271.35835702290734,
    "episode_length": 74,
    "policy_loss": -4584.5958251953125,
    "value_loss": 0.8754929900169373,
    "entropy": 0.08051327057182789,
    "total_loss": -4583.728383532352
  },
  {
    "episode": 266,
    "avg_reward_per_step": 270.8295728007577,
    "episode_length": 74,
    "policy_loss": -4561.733642578125,
    "value_loss": 0.8738410025835037,
    "entropy": 0.06999893486499786,
    "total_loss": -4560.866801469028
  },
  {
    "episode": 267,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4517.424560546875,
    "value_loss": 0.8667740523815155,
    "entropy": 0.062448471784591675,
    "total_loss": -4516.564031341672
  },
  {
    "episode": 268,
    "avg_reward_per_step": 270.7992635982787,
    "episode_length": 74,
    "policy_loss": -4595.0611572265625,
    "value_loss": 0.8733147829771042,
    "entropy": 0.0666611660271883,
    "total_loss": -4594.194508560188
  },
  {
    "episode": 269,
    "avg_reward_per_step": 267.7874434256969,
    "episode_length": 75,
    "policy_loss": -4523.599365234375,
    "value_loss": 0.8670790046453476,
    "entropy": 0.0563065716996789,
    "total_loss": -4522.737916886899
  },
  {
    "episode": 270,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4504.2950439453125,
    "value_loss": 0.8660607933998108,
    "entropy": 0.050460812635719776,
    "total_loss": -4503.434029233176
  },
  {
    "episode": 271,
    "avg_reward_per_step": 271.35835702290734,
    "episode_length": 74,
    "policy_loss": -4562.48974609375,
    "value_loss": 0.8741289526224136,
    "entropy": 0.051510244607925415,
    "total_loss": -4561.620768165589
  },
  {
    "episode": 272,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4500.3111572265625,
    "value_loss": 0.8657529801130295,
    "entropy": 0.03423057682812214,
    "total_loss": -4499.4488273041325
  },
  {
    "episode": 273,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4501.013916015625,
    "value_loss": 0.8656312376260757,
    "entropy": 0.031151653733104467,
    "total_loss": -4500.151399943372
  },
  {
    "episode": 274,
    "avg_reward_per_step": 271.140047146186,
    "episode_length": 74,
    "policy_loss": -4559.5250244140625,
    "value_loss": 0.8734443932771683,
    "entropy": 0.03715023770928383,
    "total_loss": -4558.655295044557
  },
  {
    "episode": 275,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4499.7833251953125,
    "value_loss": 0.8656122982501984,
    "entropy": 0.02550118835642934,
    "total_loss": -4498.920263015898
  },
  {
    "episode": 276,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4499.40576171875,
    "value_loss": 0.8656208366155624,
    "entropy": 0.021707676351070404,
    "total_loss": -4498.5423116497695
  },
  {
    "episode": 277,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4499.3218994140625,
    "value_loss": 0.8656237423419952,
    "entropy": 0.019193132407963276,
    "total_loss": -4498.458194984962
  },
  {
    "episode": 278,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4499.124755859375,
    "value_loss": 0.8656238317489624,
    "entropy": 0.017015716060996056,
    "total_loss": -4498.260833599232
  },
  {
    "episode": 279,
    "avg_reward_per_step": 161.7196495619241,
    "episode_length": 124,
    "policy_loss": -2753.7244873046875,
    "value_loss": 0.6755824834108353,
    "entropy": 0.04124604910612106,
    "total_loss": -2753.053029426187
  },
  {
    "episode": 280,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4498.404052734375,
    "value_loss": 0.8656003326177597,
    "entropy": 0.015152638079598546,
    "total_loss": -4497.539967665565
  },
  {
    "episode": 281,
    "avg_reward_per_step": 278.8173322736349,
    "episode_length": 72,
    "policy_loss": -4681.220947265625,
    "value_loss": 0.8902809619903564,
    "entropy": 0.028668192215263844,
    "total_loss": -4680.333533122856
  },
  {
    "episode": 282,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4497.316162109375,
    "value_loss": 0.8655741214752197,
    "entropy": 0.014972006902098656,
    "total_loss": -4496.45208518859
  },
  {
    "episode": 283,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4498.0743408203125,
    "value_loss": 0.8655197322368622,
    "entropy": 0.015600282000377774,
    "total_loss": -4497.210381116276
  },
  {
    "episode": 284,
    "avg_reward_per_step": 274.9943359426109,
    "episode_length": 73,
    "policy_loss": -4619.89794921875,
    "value_loss": 0.8818871825933456,
    "entropy": 0.028935678768903017,
    "total_loss": -4619.018955604033
  },
  {
    "episode": 285,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4497.553466796875,
    "value_loss": 0.8655081689357758,
    "entropy": 0.013934551971033216,
    "total_loss": -4496.689352083136
  },
  {
    "episode": 286,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4497.04541015625,
    "value_loss": 0.8655138909816742,
    "entropy": 0.013508772477507591,
    "total_loss": -4496.181247142516
  },
  {
    "episode": 287,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4496.6807861328125,
    "value_loss": 0.8655019253492355,
    "entropy": 0.013257324695587158,
    "total_loss": -4495.816609939933
  },
  {
    "episode": 288,
    "avg_reward_per_step": 267.57121725508284,
    "episode_length": 75,
    "policy_loss": -4496.4097900390625,
    "value_loss": 0.8654802441596985,
    "entropy": 0.012858758214861155,
    "total_loss": -4495.545595670725
  },
  {
    "episode": 289,
    "avg_reward_per_step": 274.9943359426109,
    "episode_length": 73,
    "policy_loss": -4615.894775390625,
    "value_loss": 0.8818680047988892,
    "entropy": 0.022039056289941072,
    "total_loss": -4615.0151112914555
  },
  {
    "episode": 290,
    "avg_reward_per_step": 271.0709355335812,
    "episode_length": 74,
    "policy_loss": -4553.93505859375,
    "value_loss": 0.8728694915771484,
    "entropy": 0.028740206267684698,
    "total_loss": -4553.0650631228
  },
  {
    "episode": 291,
    "avg_reward_per_step": 271.0709355335812,
    "episode_length": 74,
    "policy_loss": -4560.3582763671875,
    "value_loss": 0.872719869017601,
    "entropy": 0.03066195547580719,
    "total_loss": -4559.488622693718
  },
  {
    "episode": 292,
    "avg_reward_per_step": 164.19585996791622,
    "episode_length": 122,
    "policy_loss": -2794.6988525390625,
    "value_loss": 0.6789783537387848,
    "entropy": 0.040072337724268436,
    "total_loss": -2794.023881419096
  },
  {
    "episode": 293,
    "avg_reward_per_step": 271.0709355335812,
    "episode_length": 74,
    "policy_loss": -4550.2249755859375,
    "value_loss": 0.8726358413696289,
    "entropy": 0.026808216236531734,
    "total_loss": -4549.355020566191
  },
  {
    "episode": 294,
    "avg_reward_per_step": 47.731040980916035,
    "episode_length": 416,
    "policy_loss": -823.9188385009766,
    "value_loss": 0.5419968515634537,
    "entropy": 0.05433354154229164,
    "total_loss": -823.3822750035673
  },
  {
    "episode": 295,
    "avg_reward_per_step": 271.0709355335812,
    "episode_length": 74,
    "policy_loss": -4549.8717041015625,
    "value_loss": 0.8725595474243164,
    "entropy": 0.026364707853645086,
    "total_loss": -4549.001781024924
  },
  {
    "episode": 296,
    "avg_reward_per_step": 164.39069151400167,
    "episode_length": 122,
    "policy_loss": -2798.458984375,
    "value_loss": 0.6792716681957245,
    "entropy": 0.03537442162632942,
    "total_loss": -2797.783250148967
  },
  {
    "episode": 297,
    "avg_reward_per_step": 162.81653996085853,
    "episode_length": 123,
    "policy_loss": -2766.2986450195312,
    "value_loss": 0.6767154783010483,
    "entropy": 0.033830742351710796,
    "total_loss": -2765.625312615465
  },
  {
    "episode": 298,
    "avg_reward_per_step": 271.0709355335812,
    "episode_length": 74,
    "policy_loss": -4548.3450927734375,
    "value_loss": 0.8724247068166733,
    "entropy": 0.01645395951345563,
    "total_loss": -4547.474313462572
  },
  {
    "episode": 299,
    "avg_reward_per_step": 271.0709355335812,
    "episode_length": 74,
    "policy_loss": -4548.390380859375,
    "value_loss": 0.8724012672901154,
    "entropy": 0.015642310958355665,
    "total_loss": -4547.51954382318
  },
  {
    "episode": 300,
    "avg_reward_per_step": 90.900814121505,
    "episode_length": 220,
    "policy_loss": -1552.7905578613281,
    "value_loss": 0.5856507420539856,
    "entropy": 0.040035590529441833,
    "total_loss": -1552.2089106783271
  }
]