[
  {
    "episode": 1,
    "avg_reward_per_step": 13.620401758870596,
    "episode_length": 1202,
    "policy_loss": -231.9122657775879,
    "value_loss": 0.508885532617569,
    "entropy": 1.3799085021018982,
    "total_loss": -231.95534364581107
  },
  {
    "episode": 2,
    "avg_reward_per_step": 6.63991885732265,
    "episode_length": 2039,
    "policy_loss": -112.66701126098633,
    "value_loss": 0.5034457743167877,
    "entropy": 1.3767490684986115,
    "total_loss": -112.71426511406898
  },
  {
    "episode": 3,
    "avg_reward_per_step": 12.634344029826016,
    "episode_length": 1313,
    "policy_loss": -214.42752838134766,
    "value_loss": 0.5083425641059875,
    "entropy": 1.3684301972389221,
    "total_loss": -214.46655789613723
  },
  {
    "episode": 4,
    "avg_reward_per_step": 39.56396552588856,
    "episode_length": 471,
    "policy_loss": -674.0931243896484,
    "value_loss": 0.5310026258230209,
    "entropy": 1.372273325920105,
    "total_loss": -674.1110310941934
  },
  {
    "episode": 5,
    "avg_reward_per_step": 68.21444735631815,
    "episode_length": 283,
    "policy_loss": -1176.0616760253906,
    "value_loss": 0.5584735721349716,
    "entropy": 1.341781497001648,
    "total_loss": -1176.0399150520564
  },
  {
    "episode": 6,
    "avg_reward_per_step": 6.4001724857646805,
    "episode_length": 1952,
    "policy_loss": -108.49236488342285,
    "value_loss": 0.5030011236667633,
    "entropy": 1.3359863460063934,
    "total_loss": -108.52375829815864
  },
  {
    "episode": 7,
    "avg_reward_per_step": 27.19550701737197,
    "episode_length": 662,
    "policy_loss": -459.5796585083008,
    "value_loss": 0.5201050341129303,
    "entropy": 1.329681158065796,
    "total_loss": -459.59142593741416
  },
  {
    "episode": 8,
    "avg_reward_per_step": 1.821358751759995,
    "episode_length": 2865,
    "policy_loss": -29.979284286499023,
    "value_loss": 0.5001931488513947,
    "entropy": 1.3012671172618866,
    "total_loss": -29.999597984552384
  },
  {
    "episode": 9,
    "avg_reward_per_step": 10.947387145540814,
    "episode_length": 1394,
    "policy_loss": -184.1406364440918,
    "value_loss": 0.5064899027347565,
    "entropy": 1.3167655169963837,
    "total_loss": -184.1608527481556
  },
  {
    "episode": 10,
    "avg_reward_per_step": 13.157503064753143,
    "episode_length": 1214,
    "policy_loss": -221.47293090820312,
    "value_loss": 0.5082474797964096,
    "entropy": 1.2911747992038727,
    "total_loss": -221.48115334808827
  },
  {
    "episode": 11,
    "avg_reward_per_step": 11.403269682051636,
    "episode_length": 1193,
    "policy_loss": -192.70496368408203,
    "value_loss": 0.5059870630502701,
    "entropy": 1.293357789516449,
    "total_loss": -192.71631973683833
  },
  {
    "episode": 12,
    "avg_reward_per_step": 18.87558377077113,
    "episode_length": 854,
    "policy_loss": -318.58642578125,
    "value_loss": 0.5121850520372391,
    "entropy": 1.282553642988205,
    "total_loss": -318.58726218640805
  },
  {
    "episode": 13,
    "avg_reward_per_step": 24.11315724978003,
    "episode_length": 758,
    "policy_loss": -407.15042877197266,
    "value_loss": 0.5179360657930374,
    "entropy": 1.3017766177654266,
    "total_loss": -407.1532033532858
  },
  {
    "episode": 14,
    "avg_reward_per_step": 3.459208585694814,
    "episode_length": 2734,
    "policy_loss": -57.979570388793945,
    "value_loss": 0.5010773241519928,
    "entropy": 1.286542922258377,
    "total_loss": -57.9931102335453
  },
  {
    "episode": 15,
    "avg_reward_per_step": 46.95320528611486,
    "episode_length": 388,
    "policy_loss": -794.2535705566406,
    "value_loss": 0.5362886488437653,
    "entropy": 1.2529639899730682,
    "total_loss": -794.2184675037861
  },
  {
    "episode": 16,
    "avg_reward_per_step": 93.4891167040944,
    "episode_length": 207,
    "policy_loss": -1597.9335632324219,
    "value_loss": 0.5841551572084427,
    "entropy": 1.2525534629821777,
    "total_loss": -1597.8504294604063
  },
  {
    "episode": 17,
    "avg_reward_per_step": 13.806291650036345,
    "episode_length": 1047,
    "policy_loss": -233.5815658569336,
    "value_loss": 0.5076682865619659,
    "entropy": 1.1470405757427216,
    "total_loss": -233.53271380066872
  },
  {
    "episode": 18,
    "avg_reward_per_step": -4.981480403920552,
    "episode_length": 3000,
    "policy_loss": 84.20332908630371,
    "value_loss": 1.6377184092998505,
    "entropy": 1.1781014800071716,
    "total_loss": 85.36980690360069
  },
  {
    "episode": 19,
    "avg_reward_per_step": 22.99076849643341,
    "episode_length": 719,
    "policy_loss": -388.9482421875,
    "value_loss": 0.5152956694364548,
    "entropy": 1.139760673046112,
    "total_loss": -388.88885078728197
  },
  {
    "episode": 20,
    "avg_reward_per_step": 63.747512039452126,
    "episode_length": 295,
    "policy_loss": -1080.712646484375,
    "value_loss": 0.5523645281791687,
    "entropy": 1.1049724519252777,
    "total_loss": -1080.6022709369659
  },
  {
    "episode": 21,
    "avg_reward_per_step": 20.74756493697003,
    "episode_length": 763,
    "policy_loss": -351.16990661621094,
    "value_loss": 0.5129770636558533,
    "entropy": 1.0278813242912292,
    "total_loss": -351.0680820822716
  },
  {
    "episode": 22,
    "avg_reward_per_step": 51.89315017493256,
    "episode_length": 341,
    "policy_loss": -873.5525054931641,
    "value_loss": 0.5391321629285812,
    "entropy": 0.9421143084764481,
    "total_loss": -873.3902190536261
  },
  {
    "episode": 23,
    "avg_reward_per_step": 150.53894602988942,
    "episode_length": 132,
    "policy_loss": -2552.3880004882812,
    "value_loss": 0.65639927983284,
    "entropy": 1.1340750753879547,
    "total_loss": -2552.1852312386036
  },
  {
    "episode": 24,
    "avg_reward_per_step": 6.841574044048396,
    "episode_length": 1265,
    "policy_loss": -114.38730430603027,
    "value_loss": 0.5019949972629547,
    "entropy": 0.8567009419202805,
    "total_loss": -114.22798968553543
  },
  {
    "episode": 25,
    "avg_reward_per_step": 45.516763389735,
    "episode_length": 398,
    "policy_loss": -767.5790100097656,
    "value_loss": 0.5349374115467072,
    "entropy": 0.9951589107513428,
    "total_loss": -767.4421361625194
  },
  {
    "episode": 26,
    "avg_reward_per_step": 32.340324534307214,
    "episode_length": 477,
    "policy_loss": -548.9724578857422,
    "value_loss": 0.5201793015003204,
    "entropy": 0.8319852203130722,
    "total_loss": -548.785072672367
  },
  {
    "episode": 27,
    "avg_reward_per_step": 7.912877558285585,
    "episode_length": 1166,
    "policy_loss": -133.32334518432617,
    "value_loss": 0.5024686604738235,
    "entropy": 0.8209035694599152,
    "total_loss": -133.1492379516363
  },
  {
    "episode": 28,
    "avg_reward_per_step": -1.6134666811341933,
    "episode_length": 2169,
    "policy_loss": 27.112510204315186,
    "value_loss": 0.499944843351841,
    "entropy": 0.8137141913175583,
    "total_loss": 27.286969371140003
  },
  {
    "episode": 29,
    "avg_reward_per_step": 3.325813214743751,
    "episode_length": 1615,
    "policy_loss": -56.44573402404785,
    "value_loss": 0.5003464221954346,
    "entropy": 0.8360594362020493,
    "total_loss": -56.279811376333235
  },
  {
    "episode": 30,
    "avg_reward_per_step": 3.4125532775845446,
    "episode_length": 1601,
    "policy_loss": -58.13224697113037,
    "value_loss": 0.5003961771726608,
    "entropy": 0.860187828540802,
    "total_loss": -57.97592592537403
  },
  {
    "episode": 31,
    "avg_reward_per_step": -0.9176261201069468,
    "episode_length": 2183,
    "policy_loss": 15.009916067123413,
    "value_loss": 0.49978479743003845,
    "entropy": 0.8579826951026917,
    "total_loss": 15.166507786512375
  },
  {
    "episode": 32,
    "avg_reward_per_step": 475.68066925293385,
    "episode_length": 42,
    "policy_loss": -7519.1910400390625,
    "value_loss": 1.462410718202591,
    "entropy": 0.8150456547737122,
    "total_loss": -7518.05464758277
  },
  {
    "episode": 33,
    "avg_reward_per_step": 8.300369536781798,
    "episode_length": 1194,
    "policy_loss": -139.55334854125977,
    "value_loss": 0.5029201656579971,
    "entropy": 0.8155901432037354,
    "total_loss": -139.37666443288327
  },
  {
    "episode": 34,
    "avg_reward_per_step": -12.869625288977705,
    "episode_length": 3000,
    "policy_loss": 216.55997467041016,
    "value_loss": 2.988184928894043,
    "entropy": 0.6122245192527771,
    "total_loss": 219.3032697916031
  },
  {
    "episode": 35,
    "avg_reward_per_step": 184.78326717114876,
    "episode_length": 108,
    "policy_loss": -3113.2183837890625,
    "value_loss": 0.7080003768205643,
    "entropy": 0.4180508852005005,
    "total_loss": -3112.677603766322
  },
  {
    "episode": 36,
    "avg_reward_per_step": 1.379092426445529,
    "episode_length": 1391,
    "policy_loss": -23.170196533203125,
    "value_loss": 0.4997040405869484,
    "entropy": 0.5341568738222122,
    "total_loss": -22.884155242145063
  },
  {
    "episode": 37,
    "avg_reward_per_step": -2.8668132233310972,
    "episode_length": 2309,
    "policy_loss": 47.92048931121826,
    "value_loss": 0.5005045980215073,
    "entropy": 0.5030659288167953,
    "total_loss": 48.219767537713054
  },
  {
    "episode": 38,
    "avg_reward_per_step": -12.893645667854182,
    "episode_length": 3000,
    "policy_loss": 216.58340072631836,
    "value_loss": 3.073080062866211,
    "entropy": 0.47384069114923477,
    "total_loss": 219.46694451272487
  },
  {
    "episode": 39,
    "avg_reward_per_step": 2.569944546445109,
    "episode_length": 1620,
    "policy_loss": -43.67088222503662,
    "value_loss": 0.5000684261322021,
    "entropy": 0.7231168895959854,
    "total_loss": -43.46006055474281
  },
  {
    "episode": 40,
    "avg_reward_per_step": 16.398576802768062,
    "episode_length": 878,
    "policy_loss": -277.1382141113281,
    "value_loss": 0.5090930163860321,
    "entropy": 0.901463657617569,
    "total_loss": -276.9897065579891
  },
  {
    "episode": 41,
    "avg_reward_per_step": -0.8240736404629504,
    "episode_length": 2026,
    "policy_loss": 11.995712041854858,
    "value_loss": 0.4997647851705551,
    "entropy": 0.6699247062206268,
    "total_loss": 12.227506944537163
  },
  {
    "episode": 42,
    "avg_reward_per_step": -1.4254570100992425,
    "episode_length": 2657,
    "policy_loss": 22.77039670944214,
    "value_loss": 0.49996865540742874,
    "entropy": 0.8067226707935333,
    "total_loss": 22.947676296532155
  },
  {
    "episode": 43,
    "avg_reward_per_step": 72.63963810732736,
    "episode_length": 245,
    "policy_loss": -1226.2723388671875,
    "value_loss": 0.557179793715477,
    "entropy": 0.6087031811475754,
    "total_loss": -1225.9586403459311
  },
  {
    "episode": 44,
    "avg_reward_per_step": -11.25007617652812,
    "episode_length": 3000,
    "policy_loss": 188.81056213378906,
    "value_loss": 2.7761456966400146,
    "entropy": 0.7030055671930313,
    "total_loss": 191.30550560355186
  },
  {
    "episode": 45,
    "avg_reward_per_step": 15.590283942397932,
    "episode_length": 755,
    "policy_loss": -264.53015899658203,
    "value_loss": 0.506951093673706,
    "entropy": 0.524674192070961,
    "total_loss": -264.2330775797367
  },
  {
    "episode": 46,
    "avg_reward_per_step": 20.872747078760177,
    "episode_length": 688,
    "policy_loss": -355.3434143066406,
    "value_loss": 0.5119363069534302,
    "entropy": 0.842237189412117,
    "total_loss": -355.16837287545206
  },
  {
    "episode": 47,
    "avg_reward_per_step": 1.2544684769862746,
    "episode_length": 1724,
    "policy_loss": -22.489538192749023,
    "value_loss": 0.49980536848306656,
    "entropy": 0.6841949224472046,
    "total_loss": -22.263410793244837
  },
  {
    "episode": 48,
    "avg_reward_per_step": 16.421337689635475,
    "episode_length": 851,
    "policy_loss": -278.80899810791016,
    "value_loss": 0.5088686496019363,
    "entropy": 0.7886817008256912,
    "total_loss": -278.6156021386385
  },
  {
    "episode": 49,
    "avg_reward_per_step": 34.671296611633615,
    "episode_length": 490,
    "policy_loss": -584.7786865234375,
    "value_loss": 0.5240862518548965,
    "entropy": 0.7815079689025879,
    "total_loss": -584.5672034591437
  },
  {
    "episode": 50,
    "avg_reward_per_step": 26.987440230773174,
    "episode_length": 587,
    "policy_loss": -457.1361999511719,
    "value_loss": 0.517368420958519,
    "entropy": 0.730114534497261,
    "total_loss": -456.91087734401225
  },
  {
    "episode": 51,
    "avg_reward_per_step": 14.431483180399674,
    "episode_length": 824,
    "policy_loss": -244.97922134399414,
    "value_loss": 0.5065212249755859,
    "entropy": 0.7355575710535049,
    "total_loss": -244.76692314743997
  },
  {
    "episode": 52,
    "avg_reward_per_step": 59.79525626138126,
    "episode_length": 306,
    "policy_loss": -1012.1499176025391,
    "value_loss": 0.5472762435674667,
    "entropy": 0.9131505787372589,
    "total_loss": -1011.9679015904665
  },
  {
    "episode": 53,
    "avg_reward_per_step": 11.670924028674554,
    "episode_length": 968,
    "policy_loss": -196.15884017944336,
    "value_loss": 0.5048631429672241,
    "entropy": 0.7349584251642227,
    "total_loss": -195.94796040654182
  },
  {
    "episode": 54,
    "avg_reward_per_step": 17.564641559726226,
    "episode_length": 796,
    "policy_loss": -298.26100158691406,
    "value_loss": 0.5095161497592926,
    "entropy": 0.7301177829504013,
    "total_loss": -298.04353255033493
  },
  {
    "episode": 55,
    "avg_reward_per_step": -2.545258770824119,
    "episode_length": 2890,
    "policy_loss": 41.90638256072998,
    "value_loss": 0.5005087107419968,
    "entropy": 0.7187514007091522,
    "total_loss": 42.119390711188316
  },
  {
    "episode": 56,
    "avg_reward_per_step": -8.758108620059101,
    "episode_length": 3000,
    "policy_loss": 146.45299911499023,
    "value_loss": 2.110210418701172,
    "entropy": 0.7281798273324966,
    "total_loss": 148.2719376027584
  },
  {
    "episode": 57,
    "avg_reward_per_step": 182.40627408863998,
    "episode_length": 109,
    "policy_loss": -3074.3797607421875,
    "value_loss": 0.702627643942833,
    "entropy": 0.6228830069303513,
    "total_loss": -3073.9262863010167
  },
  {
    "episode": 58,
    "avg_reward_per_step": 28.49629220990792,
    "episode_length": 591,
    "policy_loss": -486.4559097290039,
    "value_loss": 0.5194454044103622,
    "entropy": 0.9015955477952957,
    "total_loss": -486.2971025437117
  },
  {
    "episode": 59,
    "avg_reward_per_step": 9.285970771004031,
    "episode_length": 944,
    "policy_loss": -156.23346710205078,
    "value_loss": 0.502812460064888,
    "entropy": 0.5996896475553513,
    "total_loss": -155.97053050100803
  },
  {
    "episode": 60,
    "avg_reward_per_step": -1.6573285231165802,
    "episode_length": 2401,
    "policy_loss": 26.942387104034424,
    "value_loss": 0.5000167340040207,
    "entropy": 0.6533284038305283,
    "total_loss": 27.181072476506234
  },
  {
    "episode": 61,
    "avg_reward_per_step": -11.091634006207777,
    "episode_length": 3000,
    "policy_loss": 185.48125457763672,
    "value_loss": 3.0108322501182556,
    "entropy": 0.6264325082302094,
    "total_loss": 188.24151382446288
  },
  {
    "episode": 62,
    "avg_reward_per_step": -11.323781077636726,
    "episode_length": 3000,
    "policy_loss": 189.27223205566406,
    "value_loss": 3.408878982067108,
    "entropy": 0.568499431014061,
    "total_loss": 192.45371126532555
  },
  {
    "episode": 63,
    "avg_reward_per_step": 10.307425327539994,
    "episode_length": 1091,
    "policy_loss": -175.7170295715332,
    "value_loss": 0.504441037774086,
    "entropy": 0.746432289481163,
    "total_loss": -175.5111614495516
  },
  {
    "episode": 64,
    "avg_reward_per_step": 6.864330176863999,
    "episode_length": 1108,
    "policy_loss": -118.8491382598877,
    "value_loss": 0.5017503798007965,
    "entropy": 0.6034464836120605,
    "total_loss": -118.58876647353172
  },
  {
    "episode": 65,
    "avg_reward_per_step": 52.863764184845415,
    "episode_length": 357,
    "policy_loss": -893.5154266357422,
    "value_loss": 0.5427585542201996,
    "entropy": 0.8894574046134949,
    "total_loss": -893.3284510433674
  },
  {
    "episode": 66,
    "avg_reward_per_step": 53.7366085812736,
    "episode_length": 332,
    "policy_loss": -908.7745208740234,
    "value_loss": 0.5413509011268616,
    "entropy": 0.7496307790279388,
    "total_loss": -908.5330222845078
  },
  {
    "episode": 67,
    "avg_reward_per_step": -0.3129005102360019,
    "episode_length": 1862,
    "policy_loss": 3.206252694129944,
    "value_loss": 0.4997343122959137,
    "entropy": 0.6925546824932098,
    "total_loss": 3.428965133428574
  },
  {
    "episode": 68,
    "avg_reward_per_step": 42.9206695194387,
    "episode_length": 410,
    "policy_loss": -724.7391052246094,
    "value_loss": 0.5314976722002029,
    "entropy": 0.7844193577766418,
    "total_loss": -724.5213752955199
  },
  {
    "episode": 69,
    "avg_reward_per_step": -8.245518152470368,
    "episode_length": 3000,
    "policy_loss": 137.05112838745117,
    "value_loss": 1.9032766222953796,
    "entropy": 0.7966492921113968,
    "total_loss": 138.635745292902
  },
  {
    "episode": 70,
    "avg_reward_per_step": 66.44680383275688,
    "episode_length": 292,
    "policy_loss": -1124.1062927246094,
    "value_loss": 0.5567299425601959,
    "entropy": 0.9741386324167252,
    "total_loss": -1123.939218235016
  },
  {
    "episode": 71,
    "avg_reward_per_step": 58.48394780306404,
    "episode_length": 327,
    "policy_loss": -990.5369262695312,
    "value_loss": 0.5486553907394409,
    "entropy": 0.9041571617126465,
    "total_loss": -990.3499337434769
  },
  {
    "episode": 72,
    "avg_reward_per_step": 43.156648281968565,
    "episode_length": 398,
    "policy_loss": -731.2227630615234,
    "value_loss": 0.5313336998224258,
    "entropy": 0.6663517504930496,
    "total_loss": -730.9579700618982
  },
  {
    "episode": 73,
    "avg_reward_per_step": -9.68772458023209,
    "episode_length": 3000,
    "policy_loss": 161.2496223449707,
    "value_loss": 2.5646613240242004,
    "entropy": 0.6758599877357483,
    "total_loss": 163.5439396739006
  },
  {
    "episode": 74,
    "avg_reward_per_step": 134.14068239682464,
    "episode_length": 147,
    "policy_loss": -2268.317626953125,
    "value_loss": 0.6332863420248032,
    "entropy": 0.8421664535999298,
    "total_loss": -2268.0212071925403
  },
  {
    "episode": 75,
    "avg_reward_per_step": 15.308809173203871,
    "episode_length": 1097,
    "policy_loss": -257.8866271972656,
    "value_loss": 0.5104940831661224,
    "entropy": 1.0141669511795044,
    "total_loss": -257.7817998945713
  },
  {
    "episode": 76,
    "avg_reward_per_step": 77.40456371919709,
    "episode_length": 239,
    "policy_loss": -1311.9440307617188,
    "value_loss": 0.564536526799202,
    "entropy": 0.8425347059965134,
    "total_loss": -1311.7165081173182
  },
  {
    "episode": 77,
    "avg_reward_per_step": 42.92801399476551,
    "episode_length": 413,
    "policy_loss": -731.2867736816406,
    "value_loss": 0.5323366224765778,
    "entropy": 0.5682160556316376,
    "total_loss": -730.9817234814167
  },
  {
    "episode": 78,
    "avg_reward_per_step": 5.150324489737186,
    "episode_length": 1337,
    "policy_loss": -88.64590072631836,
    "value_loss": 0.5011371076107025,
    "entropy": 0.5678949803113937,
    "total_loss": -88.37192161083222
  },
  {
    "episode": 79,
    "avg_reward_per_step": 7.372293263909627,
    "episode_length": 1354,
    "policy_loss": -125.48895454406738,
    "value_loss": 0.5027566701173782,
    "entropy": 0.6114474833011627,
    "total_loss": -125.23077686727046
  },
  {
    "episode": 80,
    "avg_reward_per_step": 2.0101526297762558,
    "episode_length": 1419,
    "policy_loss": -36.5106086730957,
    "value_loss": 0.49990300089120865,
    "entropy": 0.48323123902082443,
    "total_loss": -36.20399816781283
  },
  {
    "episode": 81,
    "avg_reward_per_step": 26.65883428088282,
    "episode_length": 551,
    "policy_loss": -451.97581481933594,
    "value_loss": 0.51558817923069,
    "entropy": 0.5774385035037994,
    "total_loss": -451.69120204150676
  },
  {
    "episode": 82,
    "avg_reward_per_step": 82.13776832332319,
    "episode_length": 239,
    "policy_loss": -1396.1104125976562,
    "value_loss": 0.5736907720565796,
    "entropy": 1.0693502724170685,
    "total_loss": -1395.9644619345665
  },
  {
    "episode": 83,
    "avg_reward_per_step": 2.566953813063676,
    "episode_length": 1607,
    "policy_loss": -45.74288272857666,
    "value_loss": 0.5001660883426666,
    "entropy": 0.5980987995862961,
    "total_loss": -45.48195616006851
  },
  {
    "episode": 84,
    "avg_reward_per_step": 146.9720304219011,
    "episode_length": 135,
    "policy_loss": -2480.205810546875,
    "value_loss": 0.6514043062925339,
    "entropy": 0.7190281450748444,
    "total_loss": -2479.842017498612
  },
  {
    "episode": 85,
    "avg_reward_per_step": 90.9653464737761,
    "episode_length": 215,
    "policy_loss": -1545.3609619140625,
    "value_loss": 0.5824755728244781,
    "entropy": 0.9644695967435837,
    "total_loss": -1545.1642741799355
  },
  {
    "episode": 86,
    "avg_reward_per_step": 100.729784367943,
    "episode_length": 193,
    "policy_loss": -1708.0690612792969,
    "value_loss": 0.5921842306852341,
    "entropy": 0.7011974304914474,
    "total_loss": -1707.7573560208082
  },
  {
    "episode": 87,
    "avg_reward_per_step": 72.88847526291622,
    "episode_length": 271,
    "policy_loss": -1230.9926147460938,
    "value_loss": 0.5644787698984146,
    "entropy": 0.7328738570213318,
    "total_loss": -1230.721285519004
  },
  {
    "episode": 88,
    "avg_reward_per_step": 11.44989647634896,
    "episode_length": 1486,
    "policy_loss": -195.48379135131836,
    "value_loss": 0.5079714506864548,
    "entropy": 0.8510595858097076,
    "total_loss": -195.31624373495578
  },
  {
    "episode": 89,
    "avg_reward_per_step": 48.23550746767369,
    "episode_length": 386,
    "policy_loss": -816.5580749511719,
    "value_loss": 0.5387587994337082,
    "entropy": 0.6568941026926041,
    "total_loss": -816.2820737928153
  },
  {
    "episode": 90,
    "avg_reward_per_step": 17.38846897006251,
    "episode_length": 855,
    "policy_loss": -296.2635192871094,
    "value_loss": 0.5102289468050003,
    "entropy": 0.6449442505836487,
    "total_loss": -296.01126804053786
  },
  {
    "episode": 91,
    "avg_reward_per_step": 37.847075166414214,
    "episode_length": 495,
    "policy_loss": -640.9202117919922,
    "value_loss": 0.5300943404436111,
    "entropy": 0.47613557428121567,
    "total_loss": -640.5805716812611
  },
  {
    "episode": 92,
    "avg_reward_per_step": 62.96636800822793,
    "episode_length": 300,
    "policy_loss": -1062.693359375,
    "value_loss": 0.5525710731744766,
    "entropy": 0.5833330452442169,
    "total_loss": -1062.3741215199232
  },
  {
    "episode": 93,
    "avg_reward_per_step": 32.22466147269209,
    "episode_length": 581,
    "policy_loss": -544.4297943115234,
    "value_loss": 0.5254257768392563,
    "entropy": 0.65720434486866,
    "total_loss": -544.1672502726317
  },
  {
    "episode": 94,
    "avg_reward_per_step": 110.90363424843676,
    "episode_length": 179,
    "policy_loss": -1874.6329956054688,
    "value_loss": 0.6062162816524506,
    "entropy": 0.6792334914207458,
    "total_loss": -1874.2984727203846
  },
  {
    "episode": 95,
    "avg_reward_per_step": 65.88688514772856,
    "episode_length": 295,
    "policy_loss": -1118.3486022949219,
    "value_loss": 0.5567900538444519,
    "entropy": 0.7715815603733063,
    "total_loss": -1118.1004448652268
  },
  {
    "episode": 96,
    "avg_reward_per_step": 119.52604258098945,
    "episode_length": 166,
    "policy_loss": -2028.4565734863281,
    "value_loss": 0.6163916289806366,
    "entropy": 0.7325887531042099,
    "total_loss": -2028.1332173585893
  },
  {
    "episode": 97,
    "avg_reward_per_step": 18.0246444677567,
    "episode_length": 1015,
    "policy_loss": -305.45043182373047,
    "value_loss": 0.5134289711713791,
    "entropy": 0.716615617275238,
    "total_loss": -305.2236490994692
  },
  {
    "episode": 98,
    "avg_reward_per_step": 29.02464207850097,
    "episode_length": 631,
    "policy_loss": -492.3033752441406,
    "value_loss": 0.5222060233354568,
    "entropy": 0.519708663225174,
    "total_loss": -491.98905268609525
  },
  {
    "episode": 99,
    "avg_reward_per_step": 109.21202226186989,
    "episode_length": 182,
    "policy_loss": -1843.7439575195312,
    "value_loss": 0.6039296239614487,
    "entropy": 0.5457767695188522,
    "total_loss": -1843.3583386033774
  },
  {
    "episode": 100,
    "avg_reward_per_step": -7.8723187842488125,
    "episode_length": 3000,
    "policy_loss": 130.47630310058594,
    "value_loss": 1.2755271792411804,
    "entropy": 0.5583978742361069,
    "total_loss": 131.5284711301327
  },
  {
    "episode": 101,
    "avg_reward_per_step": 58.092276011530146,
    "episode_length": 340,
    "policy_loss": -981.0379638671875,
    "value_loss": 0.5500813275575638,
    "entropy": 0.5660388171672821,
    "total_loss": -980.7142980664969
  },
  {
    "episode": 102,
    "avg_reward_per_step": 122.78071758621294,
    "episode_length": 162,
    "policy_loss": -2087.9918212890625,
    "value_loss": 0.6208514273166656,
    "entropy": 0.7368178218603134,
    "total_loss": -2087.66569699049
  },
  {
    "episode": 103,
    "avg_reward_per_step": 59.1846974250093,
    "episode_length": 299,
    "policy_loss": -1002.4918975830078,
    "value_loss": 0.5454321801662445,
    "entropy": 0.5496882349252701,
    "total_loss": -1002.1663406968116
  },
  {
    "episode": 104,
    "avg_reward_per_step": 31.36300006903781,
    "episode_length": 582,
    "policy_loss": -529.9751892089844,
    "value_loss": 0.5236399471759796,
    "entropy": 0.7117731869220734,
    "total_loss": -529.7362585365772
  },
  {
    "episode": 105,
    "avg_reward_per_step": 142.3580713921025,
    "episode_length": 140,
    "policy_loss": -2400.166015625,
    "value_loss": 0.6453536748886108,
    "entropy": 0.5498459339141846,
    "total_loss": -2399.740600323677
  },
  {
    "episode": 106,
    "avg_reward_per_step": 5.249147906945038,
    "episode_length": 2445,
    "policy_loss": -90.56347274780273,
    "value_loss": 0.5026468634605408,
    "entropy": 0.6307410299777985,
    "total_loss": -90.31312229633332
  },
  {
    "episode": 107,
    "avg_reward_per_step": 67.86790854376089,
    "episode_length": 291,
    "policy_loss": -1154.48193359375,
    "value_loss": 0.5596226006746292,
    "entropy": 0.6601751744747162,
    "total_loss": -1154.1863810628652
  },
  {
    "episode": 108,
    "avg_reward_per_step": 38.33073637002848,
    "episode_length": 454,
    "policy_loss": -648.3292846679688,
    "value_loss": 0.5280223190784454,
    "entropy": 0.33645032346248627,
    "total_loss": -647.9358424782753
  },
  {
    "episode": 109,
    "avg_reward_per_step": 63.19549442293712,
    "episode_length": 312,
    "policy_loss": -1066.7010803222656,
    "value_loss": 0.554736852645874,
    "entropy": 0.5159495621919632,
    "total_loss": -1066.3527232944966
  },
  {
    "episode": 110,
    "avg_reward_per_step": 47.26936627007367,
    "episode_length": 369,
    "policy_loss": -808.6100006103516,
    "value_loss": 0.5348120629787445,
    "entropy": 0.5014042034745216,
    "total_loss": -808.2757502287626
  },
  {
    "episode": 111,
    "avg_reward_per_step": 95.74562465452222,
    "episode_length": 208,
    "policy_loss": -1615.9029541015625,
    "value_loss": 0.5890561193227768,
    "entropy": 0.4281388521194458,
    "total_loss": -1615.4851535230875
  },
  {
    "episode": 112,
    "avg_reward_per_step": 85.60867538131774,
    "episode_length": 227,
    "policy_loss": -1444.7420043945312,
    "value_loss": 0.5758671313524246,
    "entropy": 0.5237864404916763,
    "total_loss": -1444.3756518393755
  },
  {
    "episode": 113,
    "avg_reward_per_step": 27.152131640540887,
    "episode_length": 623,
    "policy_loss": -460.89794158935547,
    "value_loss": 0.5191095173358917,
    "entropy": 0.36168622225522995,
    "total_loss": -460.52350656092165
  },
  {
    "episode": 114,
    "avg_reward_per_step": 37.0740266500409,
    "episode_length": 502,
    "policy_loss": -627.1029052734375,
    "value_loss": 0.528824970126152,
    "entropy": 0.6142999231815338,
    "total_loss": -626.819800272584
  },
  {
    "episode": 115,
    "avg_reward_per_step": 150.6810394354794,
    "episode_length": 130,
    "policy_loss": -2545.8052978515625,
    "value_loss": 0.6546629071235657,
    "entropy": 0.47662777453660965,
    "total_loss": -2545.3412860542535
  },
  {
    "episode": 116,
    "avg_reward_per_step": 57.318353555253196,
    "episode_length": 329,
    "policy_loss": -971.8586883544922,
    "value_loss": 0.5467517822980881,
    "entropy": 0.5278255939483643,
    "total_loss": -971.5230668097735
  },
  {
    "episode": 117,
    "avg_reward_per_step": 63.87517285707107,
    "episode_length": 309,
    "policy_loss": -1077.5239562988281,
    "value_loss": 0.5554642081260681,
    "entropy": 0.4829012528061867,
    "total_loss": -1077.1616525918246
  },
  {
    "episode": 118,
    "avg_reward_per_step": 20.702925000496332,
    "episode_length": 770,
    "policy_loss": -350.8249816894531,
    "value_loss": 0.5132253915071487,
    "entropy": 0.475128635764122,
    "total_loss": -350.50180775225164
  },
  {
    "episode": 119,
    "avg_reward_per_step": 12.312928615388623,
    "episode_length": 862,
    "policy_loss": -212.13744354248047,
    "value_loss": 0.5048480480909348,
    "entropy": 0.47491031885147095,
    "total_loss": -211.8225596219301
  },
  {
    "episode": 120,
    "avg_reward_per_step": 19.640382044383255,
    "episode_length": 934,
    "policy_loss": -332.8020706176758,
    "value_loss": 0.5149544924497604,
    "entropy": 0.48882922530174255,
    "total_loss": -332.4826478153467
  },
  {
    "episode": 121,
    "avg_reward_per_step": 151.33473783691593,
    "episode_length": 132,
    "policy_loss": -2549.9572143554688,
    "value_loss": 0.6583459675312042,
    "entropy": 0.4867696687579155,
    "total_loss": -2549.4935762554405
  },
  {
    "episode": 122,
    "avg_reward_per_step": 35.94831967914344,
    "episode_length": 485,
    "policy_loss": -608.787109375,
    "value_loss": 0.5259309262037277,
    "entropy": 0.4745369255542755,
    "total_loss": -608.450993219018
  },
  {
    "episode": 123,
    "avg_reward_per_step": 192.5539269798714,
    "episode_length": 104,
    "policy_loss": -3244.929931640625,
    "value_loss": 0.7203884273767471,
    "entropy": 0.48493459075689316,
    "total_loss": -3244.403517049551
  },
  {
    "episode": 124,
    "avg_reward_per_step": 45.03163424123895,
    "episode_length": 421,
    "policy_loss": -761.4833221435547,
    "value_loss": 0.536264106631279,
    "entropy": 0.5123763531446457,
    "total_loss": -761.1520085781813
  },
  {
    "episode": 125,
    "avg_reward_per_step": 20.6694005419018,
    "episode_length": 869,
    "policy_loss": -350.5027618408203,
    "value_loss": 0.5151617079973221,
    "entropy": 0.5233268141746521,
    "total_loss": -350.19693085849286
  },
  {
    "episode": 126,
    "avg_reward_per_step": 67.41362851187243,
    "episode_length": 293,
    "policy_loss": -1142.5587158203125,
    "value_loss": 0.5590754300355911,
    "entropy": 0.4723905697464943,
    "total_loss": -1142.1885966181756
  },
  {
    "episode": 127,
    "avg_reward_per_step": 72.65746925976507,
    "episode_length": 273,
    "policy_loss": -1223.7667846679688,
    "value_loss": 0.564581885933876,
    "entropy": 0.4642806351184845,
    "total_loss": -1223.3879150360822
  },
  {
    "episode": 128,
    "avg_reward_per_step": 139.45488113896988,
    "episode_length": 143,
    "policy_loss": -2356.6033935546875,
    "value_loss": 0.6420204639434814,
    "entropy": 0.4472424238920212,
    "total_loss": -2356.1402700603007
  },
  {
    "episode": 129,
    "avg_reward_per_step": 371.1667259920829,
    "episode_length": 54,
    "policy_loss": -6048.05712890625,
    "value_loss": 1.1221564412117004,
    "entropy": 0.2478111945092678,
    "total_loss": -6047.034096942842
  },
  {
    "episode": 130,
    "avg_reward_per_step": 81.7422126101367,
    "episode_length": 240,
    "policy_loss": -1379.6013488769531,
    "value_loss": 0.5726827085018158,
    "entropy": 0.3489118292927742,
    "total_loss": -1379.1682309001685
  },
  {
    "episode": 131,
    "avg_reward_per_step": 121.2547391636068,
    "episode_length": 165,
    "policy_loss": -2039.8201599121094,
    "value_loss": 0.6197959929704666,
    "entropy": 0.11204283125698566,
    "total_loss": -2039.2451810516418
  },
  {
    "episode": 132,
    "avg_reward_per_step": 110.66980925099759,
    "episode_length": 180,
    "policy_loss": -1866.1551818847656,
    "value_loss": 0.6057782173156738,
    "entropy": 0.18039610609412193,
    "total_loss": -1865.6215621098877
  },
  {
    "episode": 133,
    "avg_reward_per_step": 129.6420407273133,
    "episode_length": 154,
    "policy_loss": -2185.33984375,
    "value_loss": 0.6292798519134521,
    "entropy": 0.17951306700706482,
    "total_loss": -2184.7823691248896
  },
  {
    "episode": 134,
    "avg_reward_per_step": 4.990653274490395,
    "episode_length": 1371,
    "policy_loss": -86.41458129882812,
    "value_loss": 0.5010788440704346,
    "entropy": 0.24864130839705467,
    "total_loss": -86.01295897811652
  },
  {
    "episode": 135,
    "avg_reward_per_step": -12.732529752963295,
    "episode_length": 3000,
    "policy_loss": 212.10552215576172,
    "value_loss": 2.4715306162834167,
    "entropy": 0.20157640799880028,
    "total_loss": 214.49642220884562
  },
  {
    "episode": 136,
    "avg_reward_per_step": 20.087272111185584,
    "episode_length": 736,
    "policy_loss": -340.3553009033203,
    "value_loss": 0.5117631554603577,
    "entropy": 0.2799515277147293,
    "total_loss": -339.9555183589458
  },
  {
    "episode": 137,
    "avg_reward_per_step": 1.553008264979292,
    "episode_length": 2069,
    "policy_loss": -28.27444076538086,
    "value_loss": 0.500007688999176,
    "entropy": 0.09232518449425697,
    "total_loss": -27.811363150179385
  },
  {
    "episode": 138,
    "avg_reward_per_step": -13.196166505037894,
    "episode_length": 3000,
    "policy_loss": 219.61494064331055,
    "value_loss": 2.1308324933052063,
    "entropy": 0.2092716172337532,
    "total_loss": 221.66206448972224
  },
  {
    "episode": 139,
    "avg_reward_per_step": 74.28935747722618,
    "episode_length": 260,
    "policy_loss": -1257.3003234863281,
    "value_loss": 0.5642178952693939,
    "entropy": 0.3557276725769043,
    "total_loss": -1256.8783966600895
  },
  {
    "episode": 140,
    "avg_reward_per_step": 156.23823903762218,
    "episode_length": 128,
    "policy_loss": -2635.8906860351562,
    "value_loss": 0.6651287972927094,
    "entropy": 0.19516347348690033,
    "total_loss": -2635.3036226272584
  },
  {
    "episode": 141,
    "avg_reward_per_step": 3.891921024929621,
    "episode_length": 1739,
    "policy_loss": -67.8981761932373,
    "value_loss": 0.5008756220340729,
    "entropy": 0.09915699250996113,
    "total_loss": -67.43696336820722
  },
  {
    "episode": 142,
    "avg_reward_per_step": -3.138375336990516,
    "episode_length": 1881,
    "policy_loss": 49.71462917327881,
    "value_loss": 0.5003652721643448,
    "entropy": 0.1532553844153881,
    "total_loss": 50.153692291677
  },
  {
    "episode": 143,
    "avg_reward_per_step": -5.164733766287523,
    "episode_length": 2423,
    "policy_loss": 84.07718467712402,
    "value_loss": 0.5021333992481232,
    "entropy": 0.22601065039634705,
    "total_loss": 84.48891381621361
  },
  {
    "episode": 144,
    "avg_reward_per_step": -12.246232323735521,
    "episode_length": 3000,
    "policy_loss": 203.24225234985352,
    "value_loss": 2.489197015762329,
    "entropy": 0.1617773100733757,
    "total_loss": 205.6667384415865
  },
  {
    "episode": 145,
    "avg_reward_per_step": 4.688781884539359,
    "episode_length": 1493,
    "policy_loss": -82.35362815856934,
    "value_loss": 0.501093253493309,
    "entropy": 0.2591601386666298,
    "total_loss": -81.95619896054268
  },
  {
    "episode": 146,
    "avg_reward_per_step": 65.96441082473895,
    "episode_length": 290,
    "policy_loss": -1115.8964233398438,
    "value_loss": 0.555719643831253,
    "entropy": 0.2917802855372429,
    "total_loss": -1115.4574158102273
  },
  {
    "episode": 147,
    "avg_reward_per_step": 263.4802169380392,
    "episode_length": 76,
    "policy_loss": -4401.9195556640625,
    "value_loss": 0.8533929735422134,
    "entropy": 0.10522539168596268,
    "total_loss": -4401.108252847194
  },
  {
    "episode": 148,
    "avg_reward_per_step": -2.7952451744033806,
    "episode_length": 2038,
    "policy_loss": 43.63850975036621,
    "value_loss": 0.5002747774124146,
    "entropy": 0.22276943176984787,
    "total_loss": 44.049676755070685
  },
  {
    "episode": 149,
    "avg_reward_per_step": 56.6700391205262,
    "episode_length": 336,
    "policy_loss": -959.1190032958984,
    "value_loss": 0.546925351023674,
    "entropy": 0.27332088351249695,
    "total_loss": -958.6814062982797
  },
  {
    "episode": 150,
    "avg_reward_per_step": 129.71121728587673,
    "episode_length": 154,
    "policy_loss": -2187.8555297851562,
    "value_loss": 0.6295474320650101,
    "entropy": 0.19741949439048767,
    "total_loss": -2187.3049501508476
  },
  {
    "episode": 151,
    "avg_reward_per_step": 2.8198825746108804,
    "episode_length": 1564,
    "policy_loss": -50.4149866104126,
    "value_loss": 0.50025574862957,
    "entropy": 0.2588544487953186,
    "total_loss": -50.01827264130115
  },
  {
    "episode": 152,
    "avg_reward_per_step": 128.1892870367186,
    "episode_length": 156,
    "policy_loss": -2171.5105590820312,
    "value_loss": 0.6282123476266861,
    "entropy": 0.23359332978725433,
    "total_loss": -2170.9757840663196
  },
  {
    "episode": 153,
    "avg_reward_per_step": 11.334717431975513,
    "episode_length": 903,
    "policy_loss": -193.97642517089844,
    "value_loss": 0.5042972713708878,
    "entropy": 0.2824655547738075,
    "total_loss": -193.58511412143707
  },
  {
    "episode": 154,
    "avg_reward_per_step": 76.66527282296207,
    "episode_length": 260,
    "policy_loss": -1294.5165100097656,
    "value_loss": 0.5690571963787079,
    "entropy": 0.323747418820858,
    "total_loss": -1294.0769517809154
  },
  {
    "episode": 155,
    "avg_reward_per_step": 123.28272890820026,
    "episode_length": 162,
    "policy_loss": -2080.5610961914062,
    "value_loss": 0.6217922866344452,
    "entropy": 0.14884884655475616,
    "total_loss": -2079.9988434433935
  },
  {
    "episode": 156,
    "avg_reward_per_step": 7.414801944390961,
    "episode_length": 1018,
    "policy_loss": -128.5701675415039,
    "value_loss": 0.5019104033708572,
    "entropy": 0.27032242715358734,
    "total_loss": -128.17638610899448
  },
  {
    "episode": 157,
    "avg_reward_per_step": 170.88912360705143,
    "episode_length": 117,
    "policy_loss": -2880.45654296875,
    "value_loss": 0.6863075494766235,
    "entropy": 0.1597129963338375,
    "total_loss": -2879.834120617807
  },
  {
    "episode": 158,
    "avg_reward_per_step": 2.733131789418837,
    "episode_length": 1432,
    "policy_loss": -49.53129196166992,
    "value_loss": 0.5001285523176193,
    "entropy": 0.26088445633649826,
    "total_loss": -49.135517191886905
  },
  {
    "episode": 159,
    "avg_reward_per_step": 50.80765502785709,
    "episode_length": 391,
    "policy_loss": -861.0424346923828,
    "value_loss": 0.5436890572309494,
    "entropy": 0.050394714809954166,
    "total_loss": -860.5189035210758
  },
  {
    "episode": 160,
    "avg_reward_per_step": 24.4432369838361,
    "episode_length": 594,
    "policy_loss": -414.5201644897461,
    "value_loss": 0.5141121745109558,
    "entropy": 0.28227345645427704,
    "total_loss": -414.11896169781687
  },
  {
    "episode": 161,
    "avg_reward_per_step": 417.74048896778754,
    "episode_length": 48,
    "policy_loss": -6684.0416259765625,
    "value_loss": 1.2682234942913055,
    "entropy": 0.21806060895323753,
    "total_loss": -6682.860626725853
  },
  {
    "episode": 162,
    "avg_reward_per_step": 110.22133309175832,
    "episode_length": 181,
    "policy_loss": -1858.375,
    "value_loss": 0.6059987097978592,
    "entropy": 0.17207253351807594,
    "total_loss": -1857.8378303036093
  },
  {
    "episode": 163,
    "avg_reward_per_step": 201.686898216335,
    "episode_length": 99,
    "policy_loss": -3399.9805297851562,
    "value_loss": 0.7344628721475601,
    "entropy": 0.14399417117238045,
    "total_loss": -3399.3036645814777
  },
  {
    "episode": 164,
    "avg_reward_per_step": 153.65363772387033,
    "episode_length": 130,
    "policy_loss": -2593.5748291015625,
    "value_loss": 0.6611877381801605,
    "entropy": 0.19695140048861504,
    "total_loss": -2592.9924219235777
  },
  {
    "episode": 165,
    "avg_reward_per_step": -12.660998143874421,
    "episode_length": 3000,
    "policy_loss": 209.81553268432617,
    "value_loss": 2.219847559928894,
    "entropy": 0.235916368663311,
    "total_loss": 211.94101369678975
  },
  {
    "episode": 166,
    "avg_reward_per_step": 217.40757147209385,
    "episode_length": 92,
    "policy_loss": -3663.435791015625,
    "value_loss": 0.7634590417146683,
    "entropy": 0.3323711007833481,
    "total_loss": -3662.8052804142235
  },
  {
    "episode": 167,
    "avg_reward_per_step": 21.613369421739375,
    "episode_length": 768,
    "policy_loss": -369.56324768066406,
    "value_loss": 0.5148721635341644,
    "entropy": 0.2278306782245636,
    "total_loss": -369.13950778841973
  },
  {
    "episode": 168,
    "avg_reward_per_step": 167.9248906552213,
    "episode_length": 119,
    "policy_loss": -2831.7068481445312,
    "value_loss": 0.6820560097694397,
    "entropy": 0.1463441327214241,
    "total_loss": -2831.0833297878503
  },
  {
    "episode": 169,
    "avg_reward_per_step": 62.435483758766786,
    "episode_length": 297,
    "policy_loss": -1058.1383972167969,
    "value_loss": 0.5506158620119095,
    "entropy": 0.25198880583047867,
    "total_loss": -1057.6885768771172
  },
  {
    "episode": 170,
    "avg_reward_per_step": 110.8325562833736,
    "episode_length": 180,
    "policy_loss": -1871.3971862792969,
    "value_loss": 0.6066757291555405,
    "entropy": 0.1565505713224411,
    "total_loss": -1870.8531307786702
  },
  {
    "episode": 171,
    "avg_reward_per_step": 3.025381838548988,
    "episode_length": 1295,
    "policy_loss": -54.53535747528076,
    "value_loss": 0.5001893937587738,
    "entropy": 0.1644146665930748,
    "total_loss": -54.100933948159216
  },
  {
    "episode": 172,
    "avg_reward_per_step": 131.4245227462,
    "episode_length": 152,
    "policy_loss": -2217.733642578125,
    "value_loss": 0.6318753063678741,
    "entropy": 0.1254896316677332,
    "total_loss": -2217.151963124424
  },
  {
    "episode": 173,
    "avg_reward_per_step": 328.7069621924198,
    "episode_length": 61,
    "policy_loss": -5412.1334228515625,
    "value_loss": 1.0085859894752502,
    "entropy": 0.12774819135665894,
    "total_loss": -5411.17593613863
  },
  {
    "episode": 174,
    "avg_reward_per_step": -5.710767337266324,
    "episode_length": 2808,
    "policy_loss": 92.62680053710938,
    "value_loss": 0.5031051933765411,
    "entropy": 0.2270154468715191,
    "total_loss": 93.03909955173731
  },
  {
    "episode": 175,
    "avg_reward_per_step": 72.10892594268518,
    "episode_length": 276,
    "policy_loss": -1217.6889953613281,
    "value_loss": 0.564363643527031,
    "entropy": 0.2736881449818611,
    "total_loss": -1217.2341069757938
  },
  {
    "episode": 176,
    "avg_reward_per_step": 56.4674196673723,
    "episode_length": 352,
    "policy_loss": -954.3756713867188,
    "value_loss": 0.5490569174289703,
    "entropy": 0.10523674823343754,
    "total_loss": -953.8687091685831
  },
  {
    "episode": 177,
    "avg_reward_per_step": 136.84607847549577,
    "episode_length": 146,
    "policy_loss": -2307.5607299804688,
    "value_loss": 0.6389541029930115,
    "entropy": 0.12359334155917168,
    "total_loss": -2306.9712132140994
  },
  {
    "episode": 178,
    "avg_reward_per_step": 204.21933167405862,
    "episode_length": 98,
    "policy_loss": -3435.75732421875,
    "value_loss": 0.7399401813745499,
    "entropy": 0.08222906105220318,
    "total_loss": -3435.050275661796
  },
  {
    "episode": 179,
    "avg_reward_per_step": 162.4277390732497,
    "episode_length": 123,
    "policy_loss": -2742.7261962890625,
    "value_loss": 0.6737555712461472,
    "entropy": 0.13587822765111923,
    "total_loss": -2742.1067920088767
  },
  {
    "episode": 180,
    "avg_reward_per_step": 46.33606687958402,
    "episode_length": 426,
    "policy_loss": -784.8904266357422,
    "value_loss": 0.5392927080392838,
    "entropy": 0.2830752059817314,
    "total_loss": -784.4643640100956
  },
  {
    "episode": 181,
    "avg_reward_per_step": 153.82688151402758,
    "episode_length": 130,
    "policy_loss": -2592.181884765625,
    "value_loss": 0.6618209332227707,
    "entropy": 0.13547630980610847,
    "total_loss": -2591.5742543563247
  },
  {
    "episode": 182,
    "avg_reward_per_step": 47.70166572014149,
    "episode_length": 401,
    "policy_loss": -808.9679260253906,
    "value_loss": 0.5396171361207962,
    "entropy": 0.21945099160075188,
    "total_loss": -808.5160892859101
  },
  {
    "episode": 183,
    "avg_reward_per_step": 144.80817001467403,
    "episode_length": 138,
    "policy_loss": -2442.3118286132812,
    "value_loss": 0.6494995951652527,
    "entropy": 0.1487417221069336,
    "total_loss": -2441.721825706959
  },
  {
    "episode": 184,
    "avg_reward_per_step": 257.0063394592875,
    "episode_length": 78,
    "policy_loss": -4306.007568359375,
    "value_loss": 0.8407927006483078,
    "entropy": 0.1579207442700863,
    "total_loss": -4305.229943956435
  },
  {
    "episode": 185,
    "avg_reward_per_step": 17.389169143541903,
    "episode_length": 709,
    "policy_loss": -294.9263000488281,
    "value_loss": 0.5082920789718628,
    "entropy": 0.23913462087512016,
    "total_loss": -294.5136618182063
  },
  {
    "episode": 186,
    "avg_reward_per_step": 15.10109459235706,
    "episode_length": 819,
    "policy_loss": -258.0257797241211,
    "value_loss": 0.5072412490844727,
    "entropy": 0.22589852288365364,
    "total_loss": -257.60889788419007
  },
  {
    "episode": 187,
    "avg_reward_per_step": 136.13479862321105,
    "episode_length": 147,
    "policy_loss": -2297.85693359375,
    "value_loss": 0.6387403756380081,
    "entropy": 0.16383397206664085,
    "total_loss": -2297.283726806939
  },
  {
    "episode": 188,
    "avg_reward_per_step": 56.59940367006893,
    "episode_length": 351,
    "policy_loss": -959.5720520019531,
    "value_loss": 0.5491817444562912,
    "entropy": 0.08528066612780094,
    "total_loss": -959.0569825239479
  },
  {
    "episode": 189,
    "avg_reward_per_step": 10.543172623159416,
    "episode_length": 946,
    "policy_loss": -182.28600692749023,
    "value_loss": 0.5039090365171432,
    "entropy": 0.3355817124247551,
    "total_loss": -181.916330575943
  },
  {
    "episode": 190,
    "avg_reward_per_step": 30.503547067330274,
    "episode_length": 609,
    "policy_loss": -518.6187744140625,
    "value_loss": 0.5236325412988663,
    "entropy": 0.4167327582836151,
    "total_loss": -518.2618349760771
  },
  {
    "episode": 191,
    "avg_reward_per_step": 244.242796522771,
    "episode_length": 82,
    "policy_loss": -4093.82958984375,
    "value_loss": 0.8153009116649628,
    "entropy": 0.20188432186841965,
    "total_loss": -4093.0950426608324
  },
  {
    "episode": 192,
    "avg_reward_per_step": 80.25108191243957,
    "episode_length": 248,
    "policy_loss": -1356.0344848632812,
    "value_loss": 0.572777509689331,
    "entropy": 0.19838405773043633,
    "total_loss": -1355.541060976684
  },
  {
    "episode": 193,
    "avg_reward_per_step": 169.26209184472026,
    "episode_length": 118,
    "policy_loss": -2857.3461303710938,
    "value_loss": 0.6838226318359375,
    "entropy": 0.20084140077233315,
    "total_loss": -2856.7426442995666
  },
  {
    "episode": 194,
    "avg_reward_per_step": 123.23903738027195,
    "episode_length": 162,
    "policy_loss": -2080.7867431640625,
    "value_loss": 0.6215465068817139,
    "entropy": 0.3389146327972412,
    "total_loss": -2080.3007625102996
  },
  {
    "episode": 195,
    "avg_reward_per_step": 263.65166650210136,
    "episode_length": 76,
    "policy_loss": -4409.9136962890625,
    "value_loss": 0.8544643372297287,
    "entropy": 0.218516007065773,
    "total_loss": -4409.146638354659
  },
  {
    "episode": 196,
    "avg_reward_per_step": 501.63735762060895,
    "episode_length": 40,
    "policy_loss": -7737.376220703125,
    "value_loss": 1.566509485244751,
    "entropy": 0.166113693267107,
    "total_loss": -7735.876156695187
  },
  {
    "episode": 197,
    "avg_reward_per_step": 417.9478016213422,
    "episode_length": 48,
    "policy_loss": -6677.511474609375,
    "value_loss": 1.2685484886169434,
    "entropy": 0.15697867050766945,
    "total_loss": -6676.305717588961
  },
  {
    "episode": 198,
    "avg_reward_per_step": 154.02573165990162,
    "episode_length": 130,
    "policy_loss": -2603.3915405273438,
    "value_loss": 0.6626188308000565,
    "entropy": 0.2904519885778427,
    "total_loss": -2602.845102491975
  },
  {
    "episode": 199,
    "avg_reward_per_step": 455.98851393596686,
    "episode_length": 44,
    "policy_loss": -7182.208984375,
    "value_loss": 1.3976509869098663,
    "entropy": 0.1434505097568035,
    "total_loss": -7180.868713591993
  },
  {
    "episode": 200,
    "avg_reward_per_step": 557.4302864475901,
    "episode_length": 36,
    "policy_loss": -8340.3466796875,
    "value_loss": 1.7941139042377472,
    "entropy": 0.10592370480298996,
    "total_loss": -8338.594935265184
  },
  {
    "episode": 201,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8729.076416015625,
    "value_loss": 1.9389119446277618,
    "entropy": 0.0911781582981348,
    "total_loss": -8727.173975334317
  },
  {
    "episode": 202,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8556.12890625,
    "value_loss": 1.86341392993927,
    "entropy": 0.0863378457725048,
    "total_loss": -8554.30002745837
  },
  {
    "episode": 203,
    "avg_reward_per_step": 528.0655822999855,
    "episode_length": 38,
    "policy_loss": -8051.7911376953125,
    "value_loss": 1.671196848154068,
    "entropy": 0.09727207757532597,
    "total_loss": -8050.158849678189
  },
  {
    "episode": 204,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8541.780029296875,
    "value_loss": 1.8633490800857544,
    "entropy": 0.05923694185912609,
    "total_loss": -8539.940374993534
  },
  {
    "episode": 205,
    "avg_reward_per_step": 401.20984254798225,
    "episode_length": 50,
    "policy_loss": -6460.905029296875,
    "value_loss": 1.2144190669059753,
    "entropy": 0.16842420026659966,
    "total_loss": -6459.757979910076
  },
  {
    "episode": 206,
    "avg_reward_per_step": 455.9884574408889,
    "episode_length": 44,
    "policy_loss": -7160.8800048828125,
    "value_loss": 1.3968585133552551,
    "entropy": 0.07802137918770313,
    "total_loss": -7159.5143549211325
  },
  {
    "episode": 207,
    "avg_reward_per_step": 466.6044680790491,
    "episode_length": 43,
    "policy_loss": -7296.0478515625,
    "value_loss": 1.4347966015338898,
    "entropy": 0.077318474650383,
    "total_loss": -7294.643982350826
  },
  {
    "episode": 208,
    "avg_reward_per_step": 436.1411332043285,
    "episode_length": 46,
    "policy_loss": -6905.9835205078125,
    "value_loss": 1.3281206786632538,
    "entropy": 0.0760314092040062,
    "total_loss": -6904.6858123928305
  },
  {
    "episode": 209,
    "avg_reward_per_step": 313.33581449061114,
    "episode_length": 64,
    "policy_loss": -5173.8590087890625,
    "value_loss": 0.9682877659797668,
    "entropy": 0.1380605660378933,
    "total_loss": -5172.9459452494975
  },
  {
    "episode": 210,
    "avg_reward_per_step": 210.92623291999067,
    "episode_length": 95,
    "policy_loss": -3543.7418823242188,
    "value_loss": 0.7522178143262863,
    "entropy": 0.1669909916818142,
    "total_loss": -3543.056460906565
  },
  {
    "episode": 211,
    "avg_reward_per_step": 466.6044680790491,
    "episode_length": 43,
    "policy_loss": -7293.6358642578125,
    "value_loss": 1.4347448945045471,
    "entropy": 0.06286797113716602,
    "total_loss": -7292.226266551763
  },
  {
    "episode": 212,
    "avg_reward_per_step": 501.6373031849779,
    "episode_length": 40,
    "policy_loss": -7717.8612060546875,
    "value_loss": 1.5659533143043518,
    "entropy": 0.05616787634789944,
    "total_loss": -7716.3177198909225
  },
  {
    "episode": 213,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8525.1220703125,
    "value_loss": 1.8631483614444733,
    "entropy": 0.02612845040857792,
    "total_loss": -8523.269373331219
  },
  {
    "episode": 214,
    "avg_reward_per_step": 417.9477526541482,
    "episode_length": 48,
    "policy_loss": -6667.202392578125,
    "value_loss": 1.2676562666893005,
    "entropy": 0.12468569539487362,
    "total_loss": -6665.984610589594
  },
  {
    "episode": 215,
    "avg_reward_per_step": 514.5126186512597,
    "episode_length": 39,
    "policy_loss": -7867.7027587890625,
    "value_loss": 1.6164192259311676,
    "entropy": 0.056860475800931454,
    "total_loss": -7866.109083753452
  },
  {
    "episode": 216,
    "avg_reward_per_step": 235.24131086001952,
    "episode_length": 85,
    "policy_loss": -3936.853759765625,
    "value_loss": 0.7947213053703308,
    "entropy": 0.10153739526867867,
    "total_loss": -3936.0996534183623
  },
  {
    "episode": 217,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8700.65185546875,
    "value_loss": 1.938571721315384,
    "entropy": 0.02514476701617241,
    "total_loss": -8698.72334165424
  },
  {
    "episode": 218,
    "avg_reward_per_step": 542.3511385785692,
    "episode_length": 37,
    "policy_loss": -8180.885009765625,
    "value_loss": 1.729893296957016,
    "entropy": 0.06858785450458527,
    "total_loss": -8179.18255161047
  },
  {
    "episode": 219,
    "avg_reward_per_step": 436.1411332043285,
    "episode_length": 46,
    "policy_loss": -6920.9658203125,
    "value_loss": 1.3280025720596313,
    "entropy": 0.1400717906653881,
    "total_loss": -6919.6938464567065
  },
  {
    "episode": 220,
    "avg_reward_per_step": 542.3511385785692,
    "episode_length": 37,
    "policy_loss": -8182.953369140625,
    "value_loss": 1.7298309803009033,
    "entropy": 0.04241302702575922,
    "total_loss": -8181.240503371135
  },
  {
    "episode": 221,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8700.147216796875,
    "value_loss": 1.9384635984897614,
    "entropy": 0.022476710844784975,
    "total_loss": -8698.217743882724
  },
  {
    "episode": 222,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8699.421142578125,
    "value_loss": 1.9384253919124603,
    "entropy": 0.029148603323847055,
    "total_loss": -8697.494376627543
  },
  {
    "episode": 223,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8699.640869140625,
    "value_loss": 1.938379853963852,
    "entropy": 0.03406750410795212,
    "total_loss": -8697.716116288304
  },
  {
    "episode": 224,
    "avg_reward_per_step": 528.0655822999855,
    "episode_length": 38,
    "policy_loss": -8024.7109375,
    "value_loss": 1.6707316935062408,
    "entropy": 0.09022344090044498,
    "total_loss": -8023.076295182854
  },
  {
    "episode": 225,
    "avg_reward_per_step": 436.1411332043285,
    "episode_length": 46,
    "policy_loss": -6915.250244140625,
    "value_loss": 1.3278120160102844,
    "entropy": 0.1236595120280981,
    "total_loss": -6913.971895929426
  },
  {
    "episode": 226,
    "avg_reward_per_step": 308.5075711907556,
    "episode_length": 65,
    "policy_loss": -5094.9989013671875,
    "value_loss": 0.9561499059200287,
    "entropy": 0.09477736428380013,
    "total_loss": -5094.080662406981
  },
  {
    "episode": 227,
    "avg_reward_per_step": 140.94712765774023,
    "episode_length": 142,
    "policy_loss": -2371.8867797851562,
    "value_loss": 0.6445252448320389,
    "entropy": 0.10023259930312634,
    "total_loss": -2371.2823475800456
  },
  {
    "episode": 228,
    "avg_reward_per_step": 385.7594639884445,
    "episode_length": 52,
    "policy_loss": -6225.142333984375,
    "value_loss": 1.1665694117546082,
    "entropy": 0.05667854193598032,
    "total_loss": -6223.998435989395
  },
  {
    "episode": 229,
    "avg_reward_per_step": 345.80158840343296,
    "episode_length": 58,
    "policy_loss": -5654.310791015625,
    "value_loss": 1.0521928369998932,
    "entropy": 0.07213366217911243,
    "total_loss": -5653.287451643497
  },
  {
    "episode": 230,
    "avg_reward_per_step": 393.33317896861007,
    "episode_length": 51,
    "policy_loss": -6328.5848388671875,
    "value_loss": 1.1895546317100525,
    "entropy": 0.06826980970799923,
    "total_loss": -6327.422592159361
  },
  {
    "episode": 231,
    "avg_reward_per_step": 466.6044680790491,
    "episode_length": 43,
    "policy_loss": -7287.655029296875,
    "value_loss": 1.4342899918556213,
    "entropy": 0.055878627113997936,
    "total_loss": -7286.243090755865
  },
  {
    "episode": 232,
    "avg_reward_per_step": 528.0655822999855,
    "episode_length": 38,
    "policy_loss": -8020.310546875,
    "value_loss": 1.6704784333705902,
    "entropy": 0.040497115813195705,
    "total_loss": -8018.6562672879545
  },
  {
    "episode": 233,
    "avg_reward_per_step": 466.6044680790491,
    "episode_length": 43,
    "policy_loss": -7287.168212890625,
    "value_loss": 1.4342360496520996,
    "entropy": 0.07409115880727768,
    "total_loss": -7285.763613304496
  },
  {
    "episode": 234,
    "avg_reward_per_step": 378.47154957356815,
    "episode_length": 53,
    "policy_loss": -6121.160400390625,
    "value_loss": 1.1447118520736694,
    "entropy": 0.12540357001125813,
    "total_loss": -6120.065849966556
  },
  {
    "episode": 235,
    "avg_reward_per_step": 542.3511385785692,
    "episode_length": 37,
    "policy_loss": -8178.722900390625,
    "value_loss": 1.729310154914856,
    "entropy": 0.03727374132722616,
    "total_loss": -8177.008499732241
  },
  {
    "episode": 236,
    "avg_reward_per_step": 489.3900518877833,
    "episode_length": 41,
    "policy_loss": -7564.2711181640625,
    "value_loss": 1.5184228420257568,
    "entropy": 0.07883586548268795,
    "total_loss": -7562.78422966823
  },
  {
    "episode": 237,
    "avg_reward_per_step": 514.5126186512597,
    "episode_length": 39,
    "policy_loss": -7859.724365234375,
    "value_loss": 1.6157990097999573,
    "entropy": 0.05956333130598068,
    "total_loss": -7858.132391557097
  },
  {
    "episode": 238,
    "avg_reward_per_step": 455.9884574408889,
    "episode_length": 44,
    "policy_loss": -7151.5401611328125,
    "value_loss": 1.3961302936077118,
    "entropy": 0.10618504136800766,
    "total_loss": -7150.186504855752
  },
  {
    "episode": 239,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8693.3974609375,
    "value_loss": 1.9377377927303314,
    "entropy": 0.018094396218657494,
    "total_loss": -8691.466960903257
  },
  {
    "episode": 240,
    "avg_reward_per_step": 557.4303368774697,
    "episode_length": 36,
    "policy_loss": -8340.3671875,
    "value_loss": 1.7929315268993378,
    "entropy": 0.049141195602715015,
    "total_loss": -8338.593912451342
  },
  {
    "episode": 241,
    "avg_reward_per_step": 501.6373031849779,
    "episode_length": 40,
    "policy_loss": -7712.716552734375,
    "value_loss": 1.5651133060455322,
    "entropy": 0.09835900366306305,
    "total_loss": -7711.190783029795
  },
  {
    "episode": 242,
    "avg_reward_per_step": 557.4303368774697,
    "episode_length": 36,
    "policy_loss": -8336.37548828125,
    "value_loss": 1.792828530073166,
    "entropy": 0.039313044399023056,
    "total_loss": -8334.598384968936
  },
  {
    "episode": 243,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8691.63916015625,
    "value_loss": 1.937516450881958,
    "entropy": 0.02253840072080493,
    "total_loss": -8689.710659065657
  },
  {
    "episode": 244,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8511.935302734375,
    "value_loss": 1.8620419800281525,
    "entropy": 0.0381606500595808,
    "total_loss": -8510.088525014371
  },
  {
    "episode": 245,
    "avg_reward_per_step": 542.3511385785692,
    "episode_length": 37,
    "policy_loss": -8172.84765625,
    "value_loss": 1.7288446426391602,
    "entropy": 0.07240995205938816,
    "total_loss": -8171.147775588184
  },
  {
    "episode": 246,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8688.451416015625,
    "value_loss": 1.9373587369918823,
    "entropy": 0.028758713975548744,
    "total_loss": -8686.525560764223
  },
  {
    "episode": 247,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8688.769287109375,
    "value_loss": 1.9373112916946411,
    "entropy": 0.03399449214339256,
    "total_loss": -8686.845573614537
  },
  {
    "episode": 248,
    "avg_reward_per_step": 557.4629550672245,
    "episode_length": 36,
    "policy_loss": -8341.981201171875,
    "value_loss": 1.7925057113170624,
    "entropy": 0.06658894196152687,
    "total_loss": -8340.215331037343
  },
  {
    "episode": 249,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8682.755859375,
    "value_loss": 1.9371269941329956,
    "entropy": 0.042708282358944416,
    "total_loss": -8680.83581569381
  },
  {
    "episode": 250,
    "avg_reward_per_step": 528.0655822999855,
    "episode_length": 38,
    "policy_loss": -8019.0255126953125,
    "value_loss": 1.6695330142974854,
    "entropy": 0.09986105374991894,
    "total_loss": -8017.395924102515
  },
  {
    "episode": 251,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8681.390869140625,
    "value_loss": 1.9369108080863953,
    "entropy": 0.03429209068417549,
    "total_loss": -8679.467675168813
  },
  {
    "episode": 252,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8505.76611328125,
    "value_loss": 1.8614720702171326,
    "entropy": 0.04518817365169525,
    "total_loss": -8503.922716480494
  },
  {
    "episode": 253,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8505.42138671875,
    "value_loss": 1.861387848854065,
    "entropy": 0.04504950065165758,
    "total_loss": -8503.578018670156
  },
  {
    "episode": 254,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8504.806396484375,
    "value_loss": 1.8613478541374207,
    "entropy": 0.044626953080296516,
    "total_loss": -8502.96289941147
  },
  {
    "episode": 255,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8682.7734375,
    "value_loss": 1.936741054058075,
    "entropy": 0.03478976059705019,
    "total_loss": -8680.850612350181
  },
  {
    "episode": 256,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8681.939208984375,
    "value_loss": 1.9367250800132751,
    "entropy": 0.03734038211405277,
    "total_loss": -8680.017420057207
  },
  {
    "episode": 257,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8503.6416015625,
    "value_loss": 1.8612558543682098,
    "entropy": 0.04079157393425703,
    "total_loss": -8501.796662337705
  },
  {
    "episode": 258,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8502.943359375,
    "value_loss": 1.8611548244953156,
    "entropy": 0.04147955775260925,
    "total_loss": -8501.098796373606
  },
  {
    "episode": 259,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8502.376708984375,
    "value_loss": 1.861138492822647,
    "entropy": 0.04155519511550665,
    "total_loss": -8500.532192569599
  },
  {
    "episode": 260,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8500.5556640625,
    "value_loss": 1.861064851284027,
    "entropy": 0.04133289493620396,
    "total_loss": -8498.71113236919
  },
  {
    "episode": 261,
    "avg_reward_per_step": 542.3511385785692,
    "episode_length": 37,
    "policy_loss": -8166.087890625,
    "value_loss": 1.727911651134491,
    "entropy": 0.07461545057594776,
    "total_loss": -8164.389825154096
  },
  {
    "episode": 262,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8680.807373046875,
    "value_loss": 1.9363665580749512,
    "entropy": 0.019359333906322718,
    "total_loss": -8678.878750222362
  },
  {
    "episode": 263,
    "avg_reward_per_step": 514.5126186512597,
    "episode_length": 39,
    "policy_loss": -7859.813720703125,
    "value_loss": 1.6144743859767914,
    "entropy": 0.10443143174052238,
    "total_loss": -7858.241018889845
  },
  {
    "episode": 264,
    "avg_reward_per_step": 528.0655822999855,
    "episode_length": 38,
    "policy_loss": -8006.1544189453125,
    "value_loss": 1.668887972831726,
    "entropy": 0.0833272859454155,
    "total_loss": -8004.518861886859
  },
  {
    "episode": 265,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8678.964111328125,
    "value_loss": 1.9362065494060516,
    "entropy": 0.01687522465363145,
    "total_loss": -8677.034654868581
  },
  {
    "episode": 266,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8496.05810546875,
    "value_loss": 1.8608222305774689,
    "entropy": 0.0393671253696084,
    "total_loss": -8494.21303008832
  },
  {
    "episode": 267,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8677.701416015625,
    "value_loss": 1.936174064874649,
    "entropy": 0.02573860203847289,
    "total_loss": -8675.775537391566
  },
  {
    "episode": 268,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8676.238525390625,
    "value_loss": 1.9361738860607147,
    "entropy": 0.027830179780721664,
    "total_loss": -8674.313483576476
  },
  {
    "episode": 269,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8674.44970703125,
    "value_loss": 1.936172366142273,
    "entropy": 0.02860698150470853,
    "total_loss": -8672.52497745771
  },
  {
    "episode": 270,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8672.822998046875,
    "value_loss": 1.9361366629600525,
    "entropy": 0.027344484347850084,
    "total_loss": -8670.897799177654
  },
  {
    "episode": 271,
    "avg_reward_per_step": 627.2121517930385,
    "episode_length": 32,
    "policy_loss": -9055.307373046875,
    "value_loss": 2.1087872982025146,
    "entropy": 0.030394368339329958,
    "total_loss": -9053.210743496009
  },
  {
    "episode": 272,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8671.515625,
    "value_loss": 1.9360587894916534,
    "entropy": 0.03260969743132591,
    "total_loss": -8669.592610089481
  },
  {
    "episode": 273,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8675.780029296875,
    "value_loss": 1.9358981549739838,
    "entropy": 0.024863259866833687,
    "total_loss": -8673.854076445848
  },
  {
    "episode": 274,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8670.337158203125,
    "value_loss": 1.9357871413230896,
    "entropy": 0.018000799231231213,
    "total_loss": -8668.408571381495
  },
  {
    "episode": 275,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8667.62353515625,
    "value_loss": 1.9356984496116638,
    "entropy": 0.015941826393827796,
    "total_loss": -8665.694213437197
  },
  {
    "episode": 276,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8668.691162109375,
    "value_loss": 1.9356474578380585,
    "entropy": 0.013876042561605573,
    "total_loss": -8666.761065068562
  },
  {
    "episode": 277,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8667.2939453125,
    "value_loss": 1.9356066286563873,
    "entropy": 0.011386902071535587,
    "total_loss": -8665.362893444671
  },
  {
    "episode": 278,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8666.20263671875,
    "value_loss": 1.9355551898479462,
    "entropy": 0.010166361695155501,
    "total_loss": -8664.27114807358
  },
  {
    "episode": 279,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8665.584716796875,
    "value_loss": 1.935492604970932,
    "entropy": 0.009148590732365847,
    "total_loss": -8663.652883628198
  },
  {
    "episode": 280,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8664.954833984375,
    "value_loss": 1.9354212582111359,
    "entropy": 0.008018408087082207,
    "total_loss": -8663.0226200894
  },
  {
    "episode": 281,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8664.231689453125,
    "value_loss": 1.9353456497192383,
    "entropy": 0.0069562498247250915,
    "total_loss": -8662.299126303336
  },
  {
    "episode": 282,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8663.496337890625,
    "value_loss": 1.9352687001228333,
    "entropy": 0.0061246337136253715,
    "total_loss": -8661.563519043988
  },
  {
    "episode": 283,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8662.7890625,
    "value_loss": 1.9351893067359924,
    "entropy": 0.005491663818247616,
    "total_loss": -8660.856069858792
  },
  {
    "episode": 284,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8662.093017578125,
    "value_loss": 1.9351096153259277,
    "entropy": 0.0049791967030614614,
    "total_loss": -8660.15989964148
  },
  {
    "episode": 285,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8661.404296875,
    "value_loss": 1.9350308775901794,
    "entropy": 0.004541408619843423,
    "total_loss": -8659.471082560858
  },
  {
    "episode": 286,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8660.715087890625,
    "value_loss": 1.9349525272846222,
    "entropy": 0.0041614092187955976,
    "total_loss": -8658.781799927028
  },
  {
    "episode": 287,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8660.0224609375,
    "value_loss": 1.9348743557929993,
    "entropy": 0.0038388363318517804,
    "total_loss": -8658.08912211624
  },
  {
    "episode": 288,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8659.3271484375,
    "value_loss": 1.934793770313263,
    "entropy": 0.003563401463907212,
    "total_loss": -8657.393780027773
  },
  {
    "episode": 289,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8658.6328125,
    "value_loss": 1.934712529182434,
    "entropy": 0.003323183860629797,
    "total_loss": -8656.699429244361
  },
  {
    "episode": 290,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8657.932373046875,
    "value_loss": 1.934632033109665,
    "entropy": 0.0031148777343332767,
    "total_loss": -8655.99898696486
  },
  {
    "episode": 291,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8657.226318359375,
    "value_loss": 1.9345501065254211,
    "entropy": 0.002932026924099773,
    "total_loss": -8655.292941063619
  },
  {
    "episode": 292,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8656.519775390625,
    "value_loss": 1.934467613697052,
    "entropy": 0.002765036129858345,
    "total_loss": -8654.58641379138
  },
  {
    "episode": 293,
    "avg_reward_per_step": 573.3712038049149,
    "episode_length": 35,
    "policy_loss": -8485.304931640625,
    "value_loss": 1.8590306043624878,
    "entropy": 0.0044579103123396635,
    "total_loss": -8483.447684200388
  },
  {
    "episode": 294,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8654.3212890625,
    "value_loss": 1.9342568218708038,
    "entropy": 0.004568780248519033,
    "total_loss": -8652.38885975273
  },
  {
    "episode": 295,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8654.1171875,
    "value_loss": 1.9341831505298615,
    "entropy": 0.005451845936477184,
    "total_loss": -8652.185185087845
  },
  {
    "episode": 296,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8653.711669921875,
    "value_loss": 1.9341259002685547,
    "entropy": 0.0047002630308270454,
    "total_loss": -8651.779424126818
  },
  {
    "episode": 297,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8652.923828125,
    "value_loss": 1.9340686798095703,
    "entropy": 0.003953266830649227,
    "total_loss": -8650.991340751923
  },
  {
    "episode": 298,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8652.197021484375,
    "value_loss": 1.9340076744556427,
    "entropy": 0.003502311243209988,
    "total_loss": -8650.264414734416
  },
  {
    "episode": 299,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8651.487060546875,
    "value_loss": 1.9339399635791779,
    "entropy": 0.0032691097585484385,
    "total_loss": -8649.554428227199
  },
  {
    "episode": 300,
    "avg_reward_per_step": 590.2521937105539,
    "episode_length": 34,
    "policy_loss": -8650.781005859375,
    "value_loss": 1.9338673055171967,
    "entropy": 0.0031359695713035762,
    "total_loss": -8648.848392941687
  }
]