[
  {
    "episode": 1,
    "avg_reward_per_step": -1.8526086235586057,
    "episode_length": 3000,
    "policy_loss": 30.830781936645508,
    "value_loss": 1.877444326877594,
    "entropy": 1.382984697818756,
    "total_loss": 32.1550323843956
  },
  {
    "episode": 2,
    "avg_reward_per_step": 5.887872763433994,
    "episode_length": 2725,
    "policy_loss": -99.37066268920898,
    "value_loss": 0.5036934614181519,
    "entropy": 1.3808130025863647,
    "total_loss": -99.41929442882538
  },
  {
    "episode": 3,
    "avg_reward_per_step": 12.045262029345823,
    "episode_length": 1475,
    "policy_loss": -203.49823760986328,
    "value_loss": 0.5085753798484802,
    "entropy": 1.3810157775878906,
    "total_loss": -203.54206854104996
  },
  {
    "episode": 4,
    "avg_reward_per_step": -1.5080406916963387,
    "episode_length": 3000,
    "policy_loss": 25.203246116638184,
    "value_loss": 1.4716373682022095,
    "entropy": 1.3763603568077087,
    "total_loss": 26.12433934211731
  },
  {
    "episode": 5,
    "avg_reward_per_step": -1.5206206854481115,
    "episode_length": 3000,
    "policy_loss": 25.42993450164795,
    "value_loss": 1.4711595177650452,
    "entropy": 1.3753882050514221,
    "total_loss": 26.350938737392426
  },
  {
    "episode": 6,
    "avg_reward_per_step": 17.266589108257072,
    "episode_length": 1087,
    "policy_loss": -290.83302307128906,
    "value_loss": 0.5131333768367767,
    "entropy": 1.3718452453613281,
    "total_loss": -290.86862779259684
  },
  {
    "episode": 7,
    "avg_reward_per_step": 23.529478455964924,
    "episode_length": 811,
    "policy_loss": -397.49171447753906,
    "value_loss": 0.5183873474597931,
    "entropy": 1.375760793685913,
    "total_loss": -397.5236314475536
  },
  {
    "episode": 8,
    "avg_reward_per_step": 7.033494606525841,
    "episode_length": 2364,
    "policy_loss": -118.55595016479492,
    "value_loss": 0.5046248435974121,
    "entropy": 1.3774116039276123,
    "total_loss": -118.60228996276855
  },
  {
    "episode": 9,
    "avg_reward_per_step": 14.220148112085193,
    "episode_length": 1283,
    "policy_loss": -239.96566772460938,
    "value_loss": 0.5104385614395142,
    "entropy": 1.3784425258636475,
    "total_loss": -240.0066061735153
  },
  {
    "episode": 10,
    "avg_reward_per_step": -1.4828583211808664,
    "episode_length": 3000,
    "policy_loss": 24.788172721862793,
    "value_loss": 1.3247981667518616,
    "entropy": 1.3794691562652588,
    "total_loss": 25.56118322610855
  },
  {
    "episode": 11,
    "avg_reward_per_step": 6.368983967426764,
    "episode_length": 2562,
    "policy_loss": -107.58666229248047,
    "value_loss": 0.5040816366672516,
    "entropy": 1.3801684379577637,
    "total_loss": -107.63464803099632
  },
  {
    "episode": 12,
    "avg_reward_per_step": 11.166772564445322,
    "episode_length": 1567,
    "policy_loss": -189.0475082397461,
    "value_loss": 0.5078149735927582,
    "entropy": 1.3799434304237366,
    "total_loss": -189.09167063832282
  },
  {
    "episode": 13,
    "avg_reward_per_step": -1.5906964055545407,
    "episode_length": 3000,
    "policy_loss": 26.5969181060791,
    "value_loss": 1.4557583332061768,
    "entropy": 1.3774633407592773,
    "total_loss": 27.501691102981567
  },
  {
    "episode": 14,
    "avg_reward_per_step": -1.575795596516133,
    "episode_length": 3000,
    "policy_loss": 26.316268920898438,
    "value_loss": 1.3671384453773499,
    "entropy": 1.374685823917389,
    "total_loss": 27.133533036708833
  },
  {
    "episode": 15,
    "avg_reward_per_step": 12.677818689066823,
    "episode_length": 1422,
    "policy_loss": -213.52922821044922,
    "value_loss": 0.5091458261013031,
    "entropy": 1.3731308579444885,
    "total_loss": -213.5693347275257
  },
  {
    "episode": 16,
    "avg_reward_per_step": 11.67776144576775,
    "episode_length": 1505,
    "policy_loss": -196.86226654052734,
    "value_loss": 0.5082233250141144,
    "entropy": 1.3722854256629944,
    "total_loss": -196.90295738577842
  },
  {
    "episode": 17,
    "avg_reward_per_step": -1.5998139411742422,
    "episode_length": 3000,
    "policy_loss": 26.69445037841797,
    "value_loss": 1.057544231414795,
    "entropy": 1.3633836507797241,
    "total_loss": 27.206641149520873
  },
  {
    "episode": 18,
    "avg_reward_per_step": 15.07201261581333,
    "episode_length": 1219,
    "policy_loss": -253.96163177490234,
    "value_loss": 0.5111313164234161,
    "entropy": 1.363248348236084,
    "total_loss": -253.99579979777337
  },
  {
    "episode": 19,
    "avg_reward_per_step": 11.88837476626588,
    "episode_length": 1518,
    "policy_loss": -199.90280151367188,
    "value_loss": 0.5085337162017822,
    "entropy": 1.3633564710617065,
    "total_loss": -199.93961038589478
  },
  {
    "episode": 20,
    "avg_reward_per_step": 13.95873822512732,
    "episode_length": 1291,
    "policy_loss": -235.51714324951172,
    "value_loss": 0.5101064145565033,
    "entropy": 1.3585194945335388,
    "total_loss": -235.55044463276863
  },
  {
    "episode": 21,
    "avg_reward_per_step": 11.618759782628151,
    "episode_length": 1555,
    "policy_loss": -196.17300415039062,
    "value_loss": 0.5084117949008942,
    "entropy": 1.3609105348587036,
    "total_loss": -196.2089565694332
  },
  {
    "episode": 22,
    "avg_reward_per_step": 7.753896746174393,
    "episode_length": 2152,
    "policy_loss": -130.9546661376953,
    "value_loss": 0.505104273557663,
    "entropy": 1.3643032312393188,
    "total_loss": -130.99528315663338
  },
  {
    "episode": 23,
    "avg_reward_per_step": 27.988838224638517,
    "episode_length": 689,
    "policy_loss": -472.2727813720703,
    "value_loss": 0.5222190320491791,
    "entropy": 1.3518810272216797,
    "total_loss": -472.2913147509098
  },
  {
    "episode": 24,
    "avg_reward_per_step": 35.97329935252758,
    "episode_length": 540,
    "policy_loss": -606.0854797363281,
    "value_loss": 0.5293483436107635,
    "entropy": 1.346635341644287,
    "total_loss": -606.094785529375
  },
  {
    "episode": 25,
    "avg_reward_per_step": 7.935212011494943,
    "episode_length": 2059,
    "policy_loss": -133.9605255126953,
    "value_loss": 0.5051027536392212,
    "entropy": 1.350335955619812,
    "total_loss": -133.995557141304
  },
  {
    "episode": 26,
    "avg_reward_per_step": 13.308137065548468,
    "episode_length": 1375,
    "policy_loss": -224.7395248413086,
    "value_loss": 0.5097929537296295,
    "entropy": 1.3486207127571106,
    "total_loss": -224.7691801726818
  },
  {
    "episode": 27,
    "avg_reward_per_step": 10.24891090470227,
    "episode_length": 1722,
    "policy_loss": -173.02822875976562,
    "value_loss": 0.5072164237499237,
    "entropy": 1.353759765625,
    "total_loss": -173.0625162422657
  },
  {
    "episode": 28,
    "avg_reward_per_step": 13.66442824819726,
    "episode_length": 1326,
    "policy_loss": -230.79895782470703,
    "value_loss": 0.5099195539951324,
    "entropy": 1.3550139665603638,
    "total_loss": -230.83104385733606
  },
  {
    "episode": 29,
    "avg_reward_per_step": 12.197525234992188,
    "episode_length": 1476,
    "policy_loss": -206.38778686523438,
    "value_loss": 0.5088086128234863,
    "entropy": 1.3511475324630737,
    "total_loss": -206.4194372653961
  },
  {
    "episode": 30,
    "avg_reward_per_step": 18.487610998672444,
    "episode_length": 1013,
    "policy_loss": -312.0696105957031,
    "value_loss": 0.5140725374221802,
    "entropy": 1.360451340675354,
    "total_loss": -312.09971859455106
  },
  {
    "episode": 31,
    "avg_reward_per_step": 71.70199592172395,
    "episode_length": 277,
    "policy_loss": -1215.4891357421875,
    "value_loss": 0.5638958513736725,
    "entropy": 1.3626461625099182,
    "total_loss": -1215.4702983558177
  },
  {
    "episode": 32,
    "avg_reward_per_step": 6.262494882874355,
    "episode_length": 2665,
    "policy_loss": -105.64456939697266,
    "value_loss": 0.5041345953941345,
    "entropy": 1.3615872859954834,
    "total_loss": -105.68506971597671
  },
  {
    "episode": 33,
    "avg_reward_per_step": 82.72154912971243,
    "episode_length": 240,
    "policy_loss": -1394.5609130859375,
    "value_loss": 0.575223445892334,
    "entropy": 1.371180772781372,
    "total_loss": -1394.5341619491578
  },
  {
    "episode": 34,
    "avg_reward_per_step": 12.817901110981186,
    "episode_length": 1412,
    "policy_loss": -216.64747619628906,
    "value_loss": 0.5093178451061249,
    "entropy": 1.3671795725822449,
    "total_loss": -216.68503018021585
  },
  {
    "episode": 35,
    "avg_reward_per_step": 6.4453591352391655,
    "episode_length": 2545,
    "policy_loss": -108.80777740478516,
    "value_loss": 0.5041637420654297,
    "entropy": 1.3700547218322754,
    "total_loss": -108.85163555145263
  },
  {
    "episode": 36,
    "avg_reward_per_step": 15.32475292799786,
    "episode_length": 1190,
    "policy_loss": -258.74229431152344,
    "value_loss": 0.511259913444519,
    "entropy": 1.369381844997406,
    "total_loss": -258.7787871360779
  },
  {
    "episode": 37,
    "avg_reward_per_step": 7.703843190258453,
    "episode_length": 2176,
    "policy_loss": -130.13726043701172,
    "value_loss": 0.5051054060459137,
    "entropy": 1.368755042552948,
    "total_loss": -130.17965704798698
  },
  {
    "episode": 38,
    "avg_reward_per_step": 6.425056207315588,
    "episode_length": 2477,
    "policy_loss": -108.3714485168457,
    "value_loss": 0.5040124952793121,
    "entropy": 1.3655524849891663,
    "total_loss": -108.41365701556205
  },
  {
    "episode": 39,
    "avg_reward_per_step": -1.48177612801681,
    "episode_length": 3000,
    "policy_loss": 24.58121109008789,
    "value_loss": 1.1689568758010864,
    "entropy": 1.365245282649994,
    "total_loss": 25.20406985282898
  },
  {
    "episode": 40,
    "avg_reward_per_step": -1.5073388251989093,
    "episode_length": 3000,
    "policy_loss": 24.93667507171631,
    "value_loss": 1.31880784034729,
    "entropy": 1.36244535446167,
    "total_loss": 25.71050477027893
  },
  {
    "episode": 41,
    "avg_reward_per_step": -1.4405218840978145,
    "episode_length": 3000,
    "policy_loss": 23.909180641174316,
    "value_loss": 0.9931468367576599,
    "entropy": 1.357299268245697,
    "total_loss": 24.359407770633698
  },
  {
    "episode": 42,
    "avg_reward_per_step": 6.202314427417354,
    "episode_length": 2671,
    "policy_loss": -104.73999404907227,
    "value_loss": 0.504057377576828,
    "entropy": 1.3559691309928894,
    "total_loss": -104.77832432389259
  },
  {
    "episode": 43,
    "avg_reward_per_step": -1.436291791080149,
    "episode_length": 3000,
    "policy_loss": 23.705408096313477,
    "value_loss": 1.0630202293395996,
    "entropy": 1.3581798672676086,
    "total_loss": 24.225156378746032
  },
  {
    "episode": 44,
    "avg_reward_per_step": -1.3733887449436644,
    "episode_length": 3000,
    "policy_loss": 22.677855491638184,
    "value_loss": 1.176661193370819,
    "entropy": 1.3585405945777893,
    "total_loss": 23.311100447177886
  },
  {
    "episode": 45,
    "avg_reward_per_step": -1.47331138435731,
    "episode_length": 3000,
    "policy_loss": 24.329174995422363,
    "value_loss": 1.030875563621521,
    "entropy": 1.3518804907798767,
    "total_loss": 24.819298362731935
  },
  {
    "episode": 46,
    "avg_reward_per_step": -1.2272808190024738,
    "episode_length": 3000,
    "policy_loss": 20.21981430053711,
    "value_loss": 0.9006227254867554,
    "entropy": 1.3553003668785095,
    "total_loss": 20.57831687927246
  },
  {
    "episode": 47,
    "avg_reward_per_step": -1.402372642799748,
    "episode_length": 3000,
    "policy_loss": 22.86228847503662,
    "value_loss": 1.047415316104889,
    "entropy": 1.3504772782325745,
    "total_loss": 23.36951287984848
  },
  {
    "episode": 48,
    "avg_reward_per_step": -1.3904180536779498,
    "episode_length": 3000,
    "policy_loss": 22.85496234893799,
    "value_loss": 1.0575429797172546,
    "entropy": 1.3451368808746338,
    "total_loss": 23.37445057630539
  },
  {
    "episode": 49,
    "avg_reward_per_step": -1.357935783779675,
    "episode_length": 3000,
    "policy_loss": 22.202669143676758,
    "value_loss": 0.9782144725322723,
    "entropy": 1.351961612701416,
    "total_loss": 22.640098971128463
  },
  {
    "episode": 50,
    "avg_reward_per_step": -1.3888644298083137,
    "episode_length": 3000,
    "policy_loss": 22.77424907684326,
    "value_loss": 1.1220147609710693,
    "entropy": 1.3446257710456848,
    "total_loss": 23.358413529396056
  },
  {
    "episode": 51,
    "avg_reward_per_step": -1.4964987288260332,
    "episode_length": 3000,
    "policy_loss": 24.378347396850586,
    "value_loss": 1.2420717477798462,
    "entropy": 1.335670828819275,
    "total_loss": 25.086150813102723
  },
  {
    "episode": 52,
    "avg_reward_per_step": 37.01197393737095,
    "episode_length": 528,
    "policy_loss": -623.3752136230469,
    "value_loss": 0.5303997695446014,
    "entropy": 1.3374601006507874,
    "total_loss": -623.3797978937625
  },
  {
    "episode": 53,
    "avg_reward_per_step": -1.3536890430064792,
    "episode_length": 3000,
    "policy_loss": 21.955238342285156,
    "value_loss": 1.0587373971939087,
    "entropy": 1.3413586020469666,
    "total_loss": 22.47743229866028
  },
  {
    "episode": 54,
    "avg_reward_per_step": 5.557336239517082,
    "episode_length": 2956,
    "policy_loss": -94.32637405395508,
    "value_loss": 0.5036329329013824,
    "entropy": 1.3426808714866638,
    "total_loss": -94.35981346964836
  },
  {
    "episode": 55,
    "avg_reward_per_step": -1.1883721301255739,
    "episode_length": 3000,
    "policy_loss": 18.9565372467041,
    "value_loss": 0.9241340756416321,
    "entropy": 1.335770070552826,
    "total_loss": 19.346363294124604
  },
  {
    "episode": 56,
    "avg_reward_per_step": 13.70958841966141,
    "episode_length": 1361,
    "policy_loss": -231.72136688232422,
    "value_loss": 0.5103838741779327,
    "entropy": 1.3354086875915527,
    "total_loss": -231.7451464831829
  },
  {
    "episode": 57,
    "avg_reward_per_step": -1.3745878073875717,
    "episode_length": 3000,
    "policy_loss": 22.163883209228516,
    "value_loss": 0.945266455411911,
    "entropy": 1.3386369347572327,
    "total_loss": 22.573694890737535
  },
  {
    "episode": 58,
    "avg_reward_per_step": 6.648316283555742,
    "episode_length": 2589,
    "policy_loss": -112.78930282592773,
    "value_loss": 0.5045658946037292,
    "entropy": 1.3282668590545654,
    "total_loss": -112.81604367494583
  },
  {
    "episode": 59,
    "avg_reward_per_step": -1.4133486744230919,
    "episode_length": 3000,
    "policy_loss": 22.646103858947754,
    "value_loss": 1.1360903978347778,
    "entropy": 1.3367054462432861,
    "total_loss": 23.24751207828522
  },
  {
    "episode": 60,
    "avg_reward_per_step": -1.47850401463126,
    "episode_length": 3000,
    "policy_loss": 23.791020393371582,
    "value_loss": 1.0568057298660278,
    "entropy": 1.339559018611908,
    "total_loss": 24.312002515792848
  },
  {
    "episode": 61,
    "avg_reward_per_step": 7.049748306906356,
    "episode_length": 2517,
    "policy_loss": -119.81625366210938,
    "value_loss": 0.5050254464149475,
    "entropy": 1.3149641156196594,
    "total_loss": -119.83721386194229
  },
  {
    "episode": 62,
    "avg_reward_per_step": 8.836745852711628,
    "episode_length": 1979,
    "policy_loss": -149.82067108154297,
    "value_loss": 0.5061954855918884,
    "entropy": 1.3305789828300476,
    "total_loss": -149.8467071890831
  },
  {
    "episode": 63,
    "avg_reward_per_step": -1.1835471964715856,
    "episode_length": 3000,
    "policy_loss": 18.66925621032715,
    "value_loss": 0.8848477900028229,
    "entropy": 1.3243157267570496,
    "total_loss": 19.024377709627153
  },
  {
    "episode": 64,
    "avg_reward_per_step": 12.881079117545312,
    "episode_length": 1450,
    "policy_loss": -218.47484588623047,
    "value_loss": 0.5097366273403168,
    "entropy": 1.3062551617622375,
    "total_loss": -218.48761132359505
  },
  {
    "episode": 65,
    "avg_reward_per_step": 11.858888115667316,
    "episode_length": 1527,
    "policy_loss": -201.52948760986328,
    "value_loss": 0.5086937546730042,
    "entropy": 1.3325991034507751,
    "total_loss": -201.55383349657058
  },
  {
    "episode": 66,
    "avg_reward_per_step": 27.436529171862354,
    "episode_length": 696,
    "policy_loss": -463.14479064941406,
    "value_loss": 0.521621435880661,
    "entropy": 1.3268072605133057,
    "total_loss": -463.15389211773874
  },
  {
    "episode": 67,
    "avg_reward_per_step": 31.24218293477299,
    "episode_length": 621,
    "policy_loss": -527.1248779296875,
    "value_loss": 0.5253474116325378,
    "entropy": 1.3089436888694763,
    "total_loss": -527.1231079936027
  },
  {
    "episode": 68,
    "avg_reward_per_step": -1.1951526820072054,
    "episode_length": 3000,
    "policy_loss": 18.723061561584473,
    "value_loss": 0.9832086861133575,
    "entropy": 1.316448450088501,
    "total_loss": 19.17969086766243
  },
  {
    "episode": 69,
    "avg_reward_per_step": -1.2946073541623144,
    "episode_length": 3000,
    "policy_loss": 20.33839988708496,
    "value_loss": 0.7929144203662872,
    "entropy": 1.3204587697982788,
    "total_loss": 20.603130799531936
  },
  {
    "episode": 70,
    "avg_reward_per_step": 27.7874465515271,
    "episode_length": 696,
    "policy_loss": -470.2255096435547,
    "value_loss": 0.5223211348056793,
    "entropy": 1.3122797012329102,
    "total_loss": -470.2281003892422
  },
  {
    "episode": 71,
    "avg_reward_per_step": 21.890905741401422,
    "episode_length": 874,
    "policy_loss": -370.5028839111328,
    "value_loss": 0.5172373950481415,
    "entropy": 1.3023905754089355,
    "total_loss": -370.50660274624823
  },
  {
    "episode": 72,
    "avg_reward_per_step": 16.865996406505122,
    "episode_length": 1114,
    "policy_loss": -285.59825134277344,
    "value_loss": 0.5129232704639435,
    "entropy": 1.3155331015586853,
    "total_loss": -285.61154131293296
  },
  {
    "episode": 73,
    "avg_reward_per_step": 11.839243564904447,
    "episode_length": 1596,
    "policy_loss": -200.55371856689453,
    "value_loss": 0.5091305375099182,
    "entropy": 1.2564700841903687,
    "total_loss": -200.54717606306076
  },
  {
    "episode": 74,
    "avg_reward_per_step": 16.002036725337984,
    "episode_length": 1154,
    "policy_loss": -271.1284942626953,
    "value_loss": 0.5120114386081696,
    "entropy": 1.3104661703109741,
    "total_loss": -271.14066929221156
  },
  {
    "episode": 75,
    "avg_reward_per_step": 10.853311583322121,
    "episode_length": 1651,
    "policy_loss": -184.97230529785156,
    "value_loss": 0.5078680515289307,
    "entropy": 1.3092687726020813,
    "total_loss": -184.98814475536346
  },
  {
    "episode": 76,
    "avg_reward_per_step": 8.299770259812568,
    "episode_length": 2046,
    "policy_loss": -142.13436126708984,
    "value_loss": 0.5056769847869873,
    "entropy": 1.2832521796226501,
    "total_loss": -142.1419851541519
  },
  {
    "episode": 77,
    "avg_reward_per_step": 19.73743745186642,
    "episode_length": 957,
    "policy_loss": -333.2375946044922,
    "value_loss": 0.5152983963489532,
    "entropy": 1.2810064554214478,
    "total_loss": -333.2346987903118
  },
  {
    "episode": 78,
    "avg_reward_per_step": 8.01388693300927,
    "episode_length": 2138,
    "policy_loss": -136.7743911743164,
    "value_loss": 0.5055510103702545,
    "entropy": 1.271718978881836,
    "total_loss": -136.77752775549888
  },
  {
    "episode": 79,
    "avg_reward_per_step": 20.66647949739766,
    "episode_length": 904,
    "policy_loss": -350.2286682128906,
    "value_loss": 0.5157974362373352,
    "entropy": 1.277207374572754,
    "total_loss": -350.2237537264824
  },
  {
    "episode": 80,
    "avg_reward_per_step": 64.86616610839114,
    "episode_length": 305,
    "policy_loss": -1094.00732421875,
    "value_loss": 0.5566914975643158,
    "entropy": 1.240976870059967,
    "total_loss": -1093.9470234692096
  },
  {
    "episode": 81,
    "avg_reward_per_step": 51.82958185172111,
    "episode_length": 378,
    "policy_loss": -876.7026672363281,
    "value_loss": 0.5438354313373566,
    "entropy": 1.2503885626792908,
    "total_loss": -876.6589872300625
  },
  {
    "episode": 82,
    "avg_reward_per_step": 25.864782769744302,
    "episode_length": 736,
    "policy_loss": -437.23326110839844,
    "value_loss": 0.520321249961853,
    "entropy": 1.1983413696289062,
    "total_loss": -437.19227640628816
  },
  {
    "episode": 83,
    "avg_reward_per_step": 9.326673784772007,
    "episode_length": 1859,
    "policy_loss": -158.42073822021484,
    "value_loss": 0.5065616071224213,
    "entropy": 1.1565982699394226,
    "total_loss": -158.3768159210682
  },
  {
    "episode": 84,
    "avg_reward_per_step": 110.73990968428113,
    "episode_length": 180,
    "policy_loss": -1877.466552734375,
    "value_loss": 0.6063758134841919,
    "entropy": 1.2330947518348694,
    "total_loss": -1877.3534148216247
  },
  {
    "episode": 85,
    "avg_reward_per_step": 6.109100939559962,
    "episode_length": 2633,
    "policy_loss": -104.32754516601562,
    "value_loss": 0.5039092302322388,
    "entropy": 1.1293941140174866,
    "total_loss": -104.27539358139038
  },
  {
    "episode": 86,
    "avg_reward_per_step": 90.49223835908873,
    "episode_length": 219,
    "policy_loss": -1540.45849609375,
    "value_loss": 0.5826599597930908,
    "entropy": 1.2261154651641846,
    "total_loss": -1540.3662823200225
  },
  {
    "episode": 87,
    "avg_reward_per_step": 32.3860415595913,
    "episode_length": 603,
    "policy_loss": -549.1459045410156,
    "value_loss": 0.5264890789985657,
    "entropy": 1.074612557888031,
    "total_loss": -549.0492604851722
  },
  {
    "episode": 88,
    "avg_reward_per_step": -1.8907825982849595,
    "episode_length": 3000,
    "policy_loss": 30.081522941589355,
    "value_loss": 0.7946299910545349,
    "entropy": 0.9769131243228912,
    "total_loss": 30.485387682914734
  },
  {
    "episode": 89,
    "avg_reward_per_step": 5.749307831993591,
    "episode_length": 2701,
    "policy_loss": -98.27116394042969,
    "value_loss": 0.5036098062992096,
    "entropy": 0.9364347457885742,
    "total_loss": -98.14212803244591
  },
  {
    "episode": 90,
    "avg_reward_per_step": 7.158362428264262,
    "episode_length": 2214,
    "policy_loss": -121.43696975708008,
    "value_loss": 0.5045388042926788,
    "entropy": 0.787781149148941,
    "total_loss": -121.24754341244697
  },
  {
    "episode": 91,
    "avg_reward_per_step": 8.427916244791527,
    "episode_length": 1983,
    "policy_loss": -143.34961700439453,
    "value_loss": 0.5056862831115723,
    "entropy": 0.7764997780323029,
    "total_loss": -143.1545306324959
  },
  {
    "episode": 92,
    "avg_reward_per_step": 13.659262332427769,
    "episode_length": 1331,
    "policy_loss": -231.66500091552734,
    "value_loss": 0.5101333856582642,
    "entropy": 0.7852039635181427,
    "total_loss": -231.46894911527633
  },
  {
    "episode": 93,
    "avg_reward_per_step": -1.90148150805483,
    "episode_length": 3000,
    "policy_loss": 30.206917762756348,
    "value_loss": 0.7816982269287109,
    "entropy": 0.7810690701007843,
    "total_loss": 30.676188361644744
  },
  {
    "episode": 94,
    "avg_reward_per_step": 81.64315888519985,
    "episode_length": 244,
    "policy_loss": -1376.6508178710938,
    "value_loss": 0.5737661719322205,
    "entropy": 0.5982794463634491,
    "total_loss": -1376.316363477707
  },
  {
    "episode": 95,
    "avg_reward_per_step": 17.856414053723345,
    "episode_length": 1027,
    "policy_loss": -303.3572235107422,
    "value_loss": 0.5133522748947144,
    "entropy": 0.7443098723888397,
    "total_loss": -303.141595184803
  },
  {
    "episode": 96,
    "avg_reward_per_step": 5.145429098428343,
    "episode_length": 2755,
    "policy_loss": -88.1713981628418,
    "value_loss": 0.5029249489307404,
    "entropy": 0.8390253782272339,
    "total_loss": -88.00408336520195
  },
  {
    "episode": 97,
    "avg_reward_per_step": 20.082956387730572,
    "episode_length": 912,
    "policy_loss": -339.7427978515625,
    "value_loss": 0.5150262713432312,
    "entropy": 0.8939574956893921,
    "total_loss": -339.585354578495
  },
  {
    "episode": 98,
    "avg_reward_per_step": 9.258963402864074,
    "episode_length": 1741,
    "policy_loss": -157.6402816772461,
    "value_loss": 0.5059666335582733,
    "entropy": 0.8515877723693848,
    "total_loss": -157.47495015263559
  },
  {
    "episode": 99,
    "avg_reward_per_step": 116.15207621767054,
    "episode_length": 171,
    "policy_loss": -1969.21484375,
    "value_loss": 0.6118982136249542,
    "entropy": 0.8582053184509277,
    "total_loss": -1968.9462276637555
  },
  {
    "episode": 100,
    "avg_reward_per_step": 40.89317104616833,
    "episode_length": 472,
    "policy_loss": -703.6456604003906,
    "value_loss": 0.5335238873958588,
    "entropy": 1.1024137735366821,
    "total_loss": -703.5531020224095
  },
  {
    "episode": 101,
    "avg_reward_per_step": 14.247770375217629,
    "episode_length": 1212,
    "policy_loss": -242.09967041015625,
    "value_loss": 0.5099941194057465,
    "entropy": 1.1446606516838074,
    "total_loss": -242.04754055142402
  },
  {
    "episode": 102,
    "avg_reward_per_step": 9.151212808834694,
    "episode_length": 1794,
    "policy_loss": -154.92218017578125,
    "value_loss": 0.5060849785804749,
    "entropy": 1.2079020738601685,
    "total_loss": -154.89925602674484
  },
  {
    "episode": 103,
    "avg_reward_per_step": 30.850742669612266,
    "episode_length": 606,
    "policy_loss": -522.8114624023438,
    "value_loss": 0.5241028368473053,
    "entropy": 1.1687957048416138,
    "total_loss": -522.7548778474331
  },
  {
    "episode": 104,
    "avg_reward_per_step": 16.275972603896538,
    "episode_length": 1098,
    "policy_loss": -276.1281280517578,
    "value_loss": 0.5119009613990784,
    "entropy": 1.141876995563507,
    "total_loss": -276.07297788858415
  },
  {
    "episode": 105,
    "avg_reward_per_step": 5.374007283730321,
    "episode_length": 2818,
    "policy_loss": -91.7263298034668,
    "value_loss": 0.5032868981361389,
    "entropy": 1.1276506781578064,
    "total_loss": -91.67410317659377
  },
  {
    "episode": 106,
    "avg_reward_per_step": -1.8052234624745482,
    "episode_length": 3000,
    "policy_loss": 28.66143798828125,
    "value_loss": 1.2474388480186462,
    "entropy": 1.1297267079353333,
    "total_loss": 29.45698615312576
  },
  {
    "episode": 107,
    "avg_reward_per_step": -1.994396250576279,
    "episode_length": 3000,
    "policy_loss": 31.824875831604004,
    "value_loss": 1.3647298216819763,
    "entropy": 1.1129180192947388,
    "total_loss": 32.744438445568086
  },
  {
    "episode": 108,
    "avg_reward_per_step": 6.955692192684792,
    "episode_length": 2366,
    "policy_loss": -119.03958511352539,
    "value_loss": 0.5046682357788086,
    "entropy": 1.1258195638656616,
    "total_loss": -118.98524470329285
  },
  {
    "episode": 109,
    "avg_reward_per_step": 11.554505790148474,
    "episode_length": 1551,
    "policy_loss": -196.42481231689453,
    "value_loss": 0.5084675252437592,
    "entropy": 1.081812560558319,
    "total_loss": -196.3490698158741
  },
  {
    "episode": 110,
    "avg_reward_per_step": -1.5135564314346015,
    "episode_length": 3000,
    "policy_loss": 23.60135841369629,
    "value_loss": 1.0555798411369324,
    "entropy": 1.136124312877655,
    "total_loss": 24.20248852968216
  },
  {
    "episode": 111,
    "avg_reward_per_step": 9.355710437532817,
    "episode_length": 1792,
    "policy_loss": -159.23907470703125,
    "value_loss": 0.5063619017601013,
    "entropy": 1.0593709349632263,
    "total_loss": -159.15646117925644
  },
  {
    "episode": 112,
    "avg_reward_per_step": -1.300988215670783,
    "episode_length": 3000,
    "policy_loss": 19.955172538757324,
    "value_loss": 0.8279032707214355,
    "entropy": 1.0547142624855042,
    "total_loss": 20.361190104484557
  },
  {
    "episode": 113,
    "avg_reward_per_step": 8.972722508786415,
    "episode_length": 1955,
    "policy_loss": -153.05038452148438,
    "value_loss": 0.5064097046852112,
    "entropy": 1.0610088109970093,
    "total_loss": -152.96837834119796
  },
  {
    "episode": 114,
    "avg_reward_per_step": 34.3947336371599,
    "episode_length": 561,
    "policy_loss": -581.9205932617188,
    "value_loss": 0.5280334055423737,
    "entropy": 1.0283122658729553,
    "total_loss": -581.8038847625255
  },
  {
    "episode": 115,
    "avg_reward_per_step": -1.745179558345095,
    "episode_length": 3000,
    "policy_loss": 27.285554885864258,
    "value_loss": 1.216719150543213,
    "entropy": 1.0611529350280762,
    "total_loss": 28.07781286239624
  },
  {
    "episode": 116,
    "avg_reward_per_step": 6.212706871582873,
    "episode_length": 2569,
    "policy_loss": -106.72663879394531,
    "value_loss": 0.5040648579597473,
    "entropy": 1.1166914105415344,
    "total_loss": -106.66925050020218
  },
  {
    "episode": 117,
    "avg_reward_per_step": 20.419733630062378,
    "episode_length": 941,
    "policy_loss": -346.05482482910156,
    "value_loss": 0.5162334442138672,
    "entropy": 1.0472622513771057,
    "total_loss": -345.95749628543854
  },
  {
    "episode": 118,
    "avg_reward_per_step": 17.8914250411841,
    "episode_length": 1048,
    "policy_loss": -303.3169708251953,
    "value_loss": 0.5137958526611328,
    "entropy": 1.0529829859733582,
    "total_loss": -303.2243681669235
  },
  {
    "episode": 119,
    "avg_reward_per_step": 15.311135403539318,
    "episode_length": 1183,
    "policy_loss": -260.6499786376953,
    "value_loss": 0.5113949477672577,
    "entropy": 1.119856595993042,
    "total_loss": -260.58652632832525
  },
  {
    "episode": 120,
    "avg_reward_per_step": 33.616237792011404,
    "episode_length": 566,
    "policy_loss": -569.5870056152344,
    "value_loss": 0.526927649974823,
    "entropy": 1.133130669593811,
    "total_loss": -569.5133302330971
  },
  {
    "episode": 121,
    "avg_reward_per_step": 6.484512643421304,
    "episode_length": 2388,
    "policy_loss": -112.03290557861328,
    "value_loss": 0.5040704905986786,
    "entropy": 1.11245459318161,
    "total_loss": -111.97381692528725
  },
  {
    "episode": 122,
    "avg_reward_per_step": 5.13102932509133,
    "episode_length": 2828,
    "policy_loss": -89.19792938232422,
    "value_loss": 0.5030164420604706,
    "entropy": 1.1156969666481018,
    "total_loss": -89.14119172692298
  },
  {
    "episode": 123,
    "avg_reward_per_step": 220.33707240319504,
    "episode_length": 91,
    "policy_loss": -3765.6329345703125,
    "value_loss": 0.7682061195373535,
    "entropy": 1.102770209312439,
    "total_loss": -3765.3058365345
  },
  {
    "episode": 124,
    "avg_reward_per_step": 21.743937858803502,
    "episode_length": 835,
    "policy_loss": -370.0723114013672,
    "value_loss": 0.5162742137908936,
    "entropy": 1.1532139778137207,
    "total_loss": -370.0173227787018
  },
  {
    "episode": 125,
    "avg_reward_per_step": 21.09144143726681,
    "episode_length": 877,
    "policy_loss": -354.80628967285156,
    "value_loss": 0.5159263908863068,
    "entropy": 1.0912789106369019,
    "total_loss": -354.72687484622
  },
  {
    "episode": 126,
    "avg_reward_per_step": 39.885269936155645,
    "episode_length": 483,
    "policy_loss": -671.1430053710938,
    "value_loss": 0.5325578153133392,
    "entropy": 1.073531448841095,
    "total_loss": -671.0398601353169
  },
  {
    "episode": 127,
    "avg_reward_per_step": 12.099794741535444,
    "episode_length": 1416,
    "policy_loss": -205.84666442871094,
    "value_loss": 0.5083932876586914,
    "entropy": 1.0168640613555908,
    "total_loss": -205.74501676559447
  },
  {
    "episode": 128,
    "avg_reward_per_step": 195.71830895404457,
    "episode_length": 103,
    "policy_loss": -3308.246337890625,
    "value_loss": 0.7285361289978027,
    "entropy": 0.9801943898200989,
    "total_loss": -3307.909879517555
  },
  {
    "episode": 129,
    "avg_reward_per_step": 9.515205020733323,
    "episode_length": 1770,
    "policy_loss": -162.07128143310547,
    "value_loss": 0.5064296424388885,
    "entropy": 1.0391282439231873,
    "total_loss": -161.98050308823585
  },
  {
    "episode": 130,
    "avg_reward_per_step": 6.123178300013891,
    "episode_length": 2550,
    "policy_loss": -104.8935546875,
    "value_loss": 0.5038512647151947,
    "entropy": 1.1118433475494385,
    "total_loss": -104.83444076180459
  },
  {
    "episode": 131,
    "avg_reward_per_step": -1.9405142322782618,
    "episode_length": 3000,
    "policy_loss": 30.265896797180176,
    "value_loss": 0.800614982843399,
    "entropy": 1.117840826511383,
    "total_loss": 30.61937544941902
  },
  {
    "episode": 132,
    "avg_reward_per_step": 10.596068958637492,
    "episode_length": 1619,
    "policy_loss": -179.51915740966797,
    "value_loss": 0.5073042213916779,
    "entropy": 1.1283963322639465,
    "total_loss": -179.46321172118186
  },
  {
    "episode": 133,
    "avg_reward_per_step": 5.010312597619329,
    "episode_length": 2904,
    "policy_loss": -86.47341918945312,
    "value_loss": 0.502927839756012,
    "entropy": 1.1416451334953308,
    "total_loss": -86.42714940309524
  },
  {
    "episode": 134,
    "avg_reward_per_step": 387.4372618311711,
    "episode_length": 52,
    "policy_loss": -6284.623779296875,
    "value_loss": 1.1718645095825195,
    "entropy": 0.9983867406845093,
    "total_loss": -6283.851269483566
  },
  {
    "episode": 135,
    "avg_reward_per_step": 16.088915835540075,
    "episode_length": 1140,
    "policy_loss": -272.4835968017578,
    "value_loss": 0.5119591951370239,
    "entropy": 1.082990050315857,
    "total_loss": -272.4048336267471
  },
  {
    "episode": 136,
    "avg_reward_per_step": 7.407121389977109,
    "episode_length": 2182,
    "policy_loss": -126.16393280029297,
    "value_loss": 0.5048022270202637,
    "entropy": 1.0281344652175903,
    "total_loss": -126.07038435935974
  },
  {
    "episode": 137,
    "avg_reward_per_step": 9.533706559525875,
    "episode_length": 1770,
    "policy_loss": -161.54989624023438,
    "value_loss": 0.5064663589000702,
    "entropy": 0.9989509284496307,
    "total_loss": -161.44301025271415
  },
  {
    "episode": 138,
    "avg_reward_per_step": 5.932867463696717,
    "episode_length": 2644,
    "policy_loss": -101.49497604370117,
    "value_loss": 0.5038104951381683,
    "entropy": 0.946586936712265,
    "total_loss": -101.36980032324792
  },
  {
    "episode": 139,
    "avg_reward_per_step": -1.6383195473860697,
    "episode_length": 3000,
    "policy_loss": 25.350239753723145,
    "value_loss": 0.7901816666126251,
    "entropy": 0.9412502646446228,
    "total_loss": 25.76392131447792
  },
  {
    "episode": 140,
    "avg_reward_per_step": 10.084012957951122,
    "episode_length": 1791,
    "policy_loss": -171.9509048461914,
    "value_loss": 0.5074312388896942,
    "entropy": 0.9850525856018066,
    "total_loss": -171.83749464154243
  },
  {
    "episode": 141,
    "avg_reward_per_step": 17.619591789799074,
    "episode_length": 1066,
    "policy_loss": -298.13609313964844,
    "value_loss": 0.5135014653205872,
    "entropy": 0.817743331193924,
    "total_loss": -297.94968900680544
  },
  {
    "episode": 142,
    "avg_reward_per_step": 22.8357806951918,
    "episode_length": 837,
    "policy_loss": -386.19854736328125,
    "value_loss": 0.5179271101951599,
    "entropy": 0.8816472291946411,
    "total_loss": -386.0332791447639
  },
  {
    "episode": 143,
    "avg_reward_per_step": 38.866346711990786,
    "episode_length": 507,
    "policy_loss": -656.0154113769531,
    "value_loss": 0.532220333814621,
    "entropy": 0.7833018898963928,
    "total_loss": -655.7965117990971
  },
  {
    "episode": 144,
    "avg_reward_per_step": -1.5077708312449598,
    "episode_length": 3000,
    "policy_loss": 23.180477142333984,
    "value_loss": 0.6663656234741211,
    "entropy": 0.8780436515808105,
    "total_loss": 23.495625305175782
  },
  {
    "episode": 145,
    "avg_reward_per_step": -1.6710647755237924,
    "episode_length": 3000,
    "policy_loss": 26.071127891540527,
    "value_loss": 0.880109578371048,
    "entropy": 0.8504960536956787,
    "total_loss": 26.611039048433305
  },
  {
    "episode": 146,
    "avg_reward_per_step": 47.060985030899275,
    "episode_length": 421,
    "policy_loss": -794.1076965332031,
    "value_loss": 0.5398322343826294,
    "entropy": 0.8376687467098236,
    "total_loss": -793.9029317975044
  },
  {
    "episode": 147,
    "avg_reward_per_step": 18.830631129191698,
    "episode_length": 1027,
    "policy_loss": -320.5072937011719,
    "value_loss": 0.5149869620800018,
    "entropy": 0.9493699669837952,
    "total_loss": -320.3720547258854
  },
  {
    "episode": 148,
    "avg_reward_per_step": 21.210703188808758,
    "episode_length": 898,
    "policy_loss": -361.1405792236328,
    "value_loss": 0.5166614055633545,
    "entropy": 0.9811063706874847,
    "total_loss": -361.01636036634443
  },
  {
    "episode": 149,
    "avg_reward_per_step": 11.830700105740814,
    "episode_length": 1512,
    "policy_loss": -201.2398681640625,
    "value_loss": 0.5085881650447845,
    "entropy": 1.0047819912433624,
    "total_loss": -201.13319279551507
  },
  {
    "episode": 150,
    "avg_reward_per_step": 31.500850910283823,
    "episode_length": 608,
    "policy_loss": -534.2779235839844,
    "value_loss": 0.5251293778419495,
    "entropy": 0.9618354737758636,
    "total_loss": -534.1375283956528
  },
  {
    "episode": 151,
    "avg_reward_per_step": 7.193431878162247,
    "episode_length": 2322,
    "policy_loss": -123.83973693847656,
    "value_loss": 0.5049066245555878,
    "entropy": 1.1018633246421814,
    "total_loss": -123.77557564377784
  },
  {
    "episode": 152,
    "avg_reward_per_step": -1.5112021030957412,
    "episode_length": 3000,
    "policy_loss": 22.57044506072998,
    "value_loss": 0.623513400554657,
    "entropy": 1.1207976341247559,
    "total_loss": 22.745639407634734
  },
  {
    "episode": 153,
    "avg_reward_per_step": -1.7764237551422433,
    "episode_length": 3000,
    "policy_loss": 27.379490852355957,
    "value_loss": 0.7171058654785156,
    "entropy": 1.128136932849884,
    "total_loss": 27.64534194469452
  },
  {
    "episode": 154,
    "avg_reward_per_step": 41.296561237551614,
    "episode_length": 471,
    "policy_loss": -695.7332153320312,
    "value_loss": 0.5337580740451813,
    "entropy": 1.1211139559745789,
    "total_loss": -695.6479028403759
  },
  {
    "episode": 155,
    "avg_reward_per_step": 53.34077677170441,
    "episode_length": 371,
    "policy_loss": -901.6181945800781,
    "value_loss": 0.5457256138324738,
    "entropy": 1.1203952431678772,
    "total_loss": -901.5206270635128
  },
  {
    "episode": 156,
    "avg_reward_per_step": 23.330404961308865,
    "episode_length": 811,
    "policy_loss": -396.96697998046875,
    "value_loss": 0.5183084309101105,
    "entropy": 1.1788115501403809,
    "total_loss": -396.92019616961477
  },
  {
    "episode": 157,
    "avg_reward_per_step": 18.643661936157987,
    "episode_length": 1004,
    "policy_loss": -316.8447265625,
    "value_loss": 0.5143411457538605,
    "entropy": 1.2050654292106628,
    "total_loss": -316.8124115884304
  },
  {
    "episode": 158,
    "avg_reward_per_step": -1.720623465509433,
    "episode_length": 3000,
    "policy_loss": 26.495067596435547,
    "value_loss": 0.7356537580490112,
    "entropy": 1.235044777393341,
    "total_loss": 26.736703443527222
  },
  {
    "episode": 159,
    "avg_reward_per_step": 7.054749302004838,
    "episode_length": 2287,
    "policy_loss": -121.61603927612305,
    "value_loss": 0.5046086311340332,
    "entropy": 1.245000422000885,
    "total_loss": -121.60943081378937
  },
  {
    "episode": 160,
    "avg_reward_per_step": 58.20629395109055,
    "episode_length": 340,
    "policy_loss": -984.207763671875,
    "value_loss": 0.5505249798297882,
    "entropy": 1.273729920387268,
    "total_loss": -984.1667306602001
  },
  {
    "episode": 161,
    "avg_reward_per_step": 11.929919224169394,
    "episode_length": 1431,
    "policy_loss": -203.1529998779297,
    "value_loss": 0.5082088708877563,
    "entropy": 1.2622140049934387,
    "total_loss": -203.14967660903932
  },
  {
    "episode": 162,
    "avg_reward_per_step": 10.699994310934757,
    "episode_length": 1627,
    "policy_loss": -182.92908477783203,
    "value_loss": 0.5075395405292511,
    "entropy": 1.2675545811653137,
    "total_loss": -182.92856706976892
  },
  {
    "episode": 163,
    "avg_reward_per_step": 12.402849201994194,
    "episode_length": 1460,
    "policy_loss": -212.06763458251953,
    "value_loss": 0.5091839134693146,
    "entropy": 1.2680311799049377,
    "total_loss": -212.06566314101218
  },
  {
    "episode": 164,
    "avg_reward_per_step": 28.337441885693558,
    "episode_length": 657,
    "policy_loss": -480.91505432128906,
    "value_loss": 0.5218803584575653,
    "entropy": 1.3010857105255127,
    "total_loss": -480.9136082470417
  },
  {
    "episode": 165,
    "avg_reward_per_step": 81.15656267386342,
    "episode_length": 243,
    "policy_loss": -1369.0819091796875,
    "value_loss": 0.5726096034049988,
    "entropy": 1.2511532306671143,
    "total_loss": -1369.0097608685494
  },
  {
    "episode": 166,
    "avg_reward_per_step": 13.395667830047332,
    "episode_length": 1336,
    "policy_loss": -227.7212905883789,
    "value_loss": 0.509756863117218,
    "entropy": 1.2933403253555298,
    "total_loss": -227.7288698554039
  },
  {
    "episode": 167,
    "avg_reward_per_step": 16.84203402561341,
    "episode_length": 1092,
    "policy_loss": -285.775390625,
    "value_loss": 0.5126354992389679,
    "entropy": 1.2738313674926758,
    "total_loss": -285.7722876727581
  },
  {
    "episode": 168,
    "avg_reward_per_step": 69.66391998591125,
    "episode_length": 284,
    "policy_loss": -1176.0901489257812,
    "value_loss": 0.5616505444049835,
    "entropy": 1.259339988231659,
    "total_loss": -1176.0322343766688
  },
  {
    "episode": 169,
    "avg_reward_per_step": 23.33332687315748,
    "episode_length": 802,
    "policy_loss": -396.0599365234375,
    "value_loss": 0.5180128812789917,
    "entropy": 1.2928919792175293,
    "total_loss": -396.0590804338455
  },
  {
    "episode": 170,
    "avg_reward_per_step": 42.3066067847834,
    "episode_length": 461,
    "policy_loss": -716.0704956054688,
    "value_loss": 0.5349504351615906,
    "entropy": 1.25336754322052,
    "total_loss": -716.0368921875954
  },
  {
    "episode": 171,
    "avg_reward_per_step": 6.9938333164934035,
    "episode_length": 2308,
    "policy_loss": -120.16978454589844,
    "value_loss": 0.5046136379241943,
    "entropy": 1.2735214829444885,
    "total_loss": -120.17457950115204
  },
  {
    "episode": 172,
    "avg_reward_per_step": 29.688562618307415,
    "episode_length": 647,
    "policy_loss": -503.3847351074219,
    "value_loss": 0.5238524675369263,
    "entropy": 1.229450762271881,
    "total_loss": -503.3526629447937
  },
  {
    "episode": 173,
    "avg_reward_per_step": 233.01280776863962,
    "episode_length": 86,
    "policy_loss": -3919.82080078125,
    "value_loss": 0.7923882901668549,
    "entropy": 1.1394713521003723,
    "total_loss": -3919.4842010319235
  },
  {
    "episode": 174,
    "avg_reward_per_step": 24.06615555538456,
    "episode_length": 784,
    "policy_loss": -412.3655548095703,
    "value_loss": 0.5189570188522339,
    "entropy": 1.289401113986969,
    "total_loss": -412.36235823631284
  },
  {
    "episode": 175,
    "avg_reward_per_step": 124.69936494590499,
    "episode_length": 160,
    "policy_loss": -2096.947998046875,
    "value_loss": 0.622989684343338,
    "entropy": 1.2444497346878052,
    "total_loss": -2096.822788256407
  },
  {
    "episode": 176,
    "avg_reward_per_step": 6.251494567650464,
    "episode_length": 2419,
    "policy_loss": -107.53973007202148,
    "value_loss": 0.5038798749446869,
    "entropy": 1.3421549797058105,
    "total_loss": -107.57271218895912
  },
  {
    "episode": 177,
    "avg_reward_per_step": 25.210374328492026,
    "episode_length": 760,
    "policy_loss": -425.0569763183594,
    "value_loss": 0.5198564231395721,
    "entropy": 1.3269264101982117,
    "total_loss": -425.06789045929906
  },
  {
    "episode": 178,
    "avg_reward_per_step": 88.96642744108394,
    "episode_length": 223,
    "policy_loss": -1500.9630126953125,
    "value_loss": 0.5820953547954559,
    "entropy": 1.3051902055740356,
    "total_loss": -1500.9029934227467
  },
  {
    "episode": 179,
    "avg_reward_per_step": 17.05212358888153,
    "episode_length": 1053,
    "policy_loss": -289.7012176513672,
    "value_loss": 0.512517124414444,
    "entropy": 1.309596598148346,
    "total_loss": -289.7125391662121
  },
  {
    "episode": 180,
    "avg_reward_per_step": 38.2242453273478,
    "episode_length": 505,
    "policy_loss": -646.9411926269531,
    "value_loss": 0.5312031507492065,
    "entropy": 1.316071629524231,
    "total_loss": -646.9364181280137
  },
  {
    "episode": 181,
    "avg_reward_per_step": 320.67496390935133,
    "episode_length": 63,
    "policy_loss": -5347.78955078125,
    "value_loss": 0.9892867505550385,
    "entropy": 1.1215234994888306,
    "total_loss": -5347.248873430491
  },
  {
    "episode": 182,
    "avg_reward_per_step": 115.02128126625442,
    "episode_length": 174,
    "policy_loss": -1951.8031616210938,
    "value_loss": 0.6121695339679718,
    "entropy": 1.2715694904327393,
    "total_loss": -1951.699619883299
  },
  {
    "episode": 183,
    "avg_reward_per_step": 276.1631996327932,
    "episode_length": 73,
    "policy_loss": -4604.725341796875,
    "value_loss": 0.8817689716815948,
    "entropy": 1.071039617061615,
    "total_loss": -4604.271988672018
  },
  {
    "episode": 184,
    "avg_reward_per_step": -2.209328413183515,
    "episode_length": 3000,
    "policy_loss": 34.4818229675293,
    "value_loss": 0.9472834467887878,
    "entropy": 1.1437380909919739,
    "total_loss": 34.9716111779213
  },
  {
    "episode": 185,
    "avg_reward_per_step": 6.996925239362633,
    "episode_length": 2245,
    "policy_loss": -120.37358856201172,
    "value_loss": 0.5044729113578796,
    "entropy": 1.0944870710372925,
    "total_loss": -120.30691047906876
  },
  {
    "episode": 186,
    "avg_reward_per_step": 48.228983656636245,
    "episode_length": 405,
    "policy_loss": -812.1216430664062,
    "value_loss": 0.5404888987541199,
    "entropy": 1.044791042804718,
    "total_loss": -811.999070584774
  },
  {
    "episode": 187,
    "avg_reward_per_step": -2.0208872626548695,
    "episode_length": 3000,
    "policy_loss": 31.202810287475586,
    "value_loss": 0.7746246755123138,
    "entropy": 0.9928672611713409,
    "total_loss": 31.580288058519365
  },
  {
    "episode": 188,
    "avg_reward_per_step": 10.850325623844823,
    "episode_length": 1567,
    "policy_loss": -185.81287384033203,
    "value_loss": 0.5075187683105469,
    "entropy": 0.9851847589015961,
    "total_loss": -185.69942897558212
  },
  {
    "episode": 189,
    "avg_reward_per_step": -1.8179632698786026,
    "episode_length": 3000,
    "policy_loss": 27.78276824951172,
    "value_loss": 0.6859444975852966,
    "entropy": 0.9384364187717438,
    "total_loss": 28.09333817958832
  },
  {
    "episode": 190,
    "avg_reward_per_step": -1.9233110853208646,
    "episode_length": 3000,
    "policy_loss": 29.518115997314453,
    "value_loss": 0.7143197953701019,
    "entropy": 0.9426994025707245,
    "total_loss": 29.855356031656264
  },
  {
    "episode": 191,
    "avg_reward_per_step": 37.38645894873545,
    "episode_length": 512,
    "policy_loss": -631.423828125,
    "value_loss": 0.5299727916717529,
    "entropy": 0.9343675076961517,
    "total_loss": -631.2676023364068
  },
  {
    "episode": 192,
    "avg_reward_per_step": 19.77891990105014,
    "episode_length": 934,
    "policy_loss": -335.48912048339844,
    "value_loss": 0.5149275064468384,
    "entropy": 0.913597971200943,
    "total_loss": -335.33963216543196
  },
  {
    "episode": 193,
    "avg_reward_per_step": 12.844710318347351,
    "episode_length": 1369,
    "policy_loss": -219.01039123535156,
    "value_loss": 0.5092509686946869,
    "entropy": 0.9200244545936584,
    "total_loss": -218.86915004849433
  },
  {
    "episode": 194,
    "avg_reward_per_step": -2.0033201413804225,
    "episode_length": 3000,
    "policy_loss": 30.960186004638672,
    "value_loss": 0.7858312427997589,
    "entropy": 0.9368879795074463,
    "total_loss": 31.37126205563545
  },
  {
    "episode": 195,
    "avg_reward_per_step": 12.631417730973459,
    "episode_length": 1385,
    "policy_loss": -215.4489974975586,
    "value_loss": 0.5090343058109283,
    "entropy": 0.911388486623764,
    "total_loss": -215.30451858639717
  },
  {
    "episode": 196,
    "avg_reward_per_step": -1.838876808348869,
    "episode_length": 3000,
    "policy_loss": 27.91030979156494,
    "value_loss": 0.6895515620708466,
    "entropy": 0.8877435326576233,
    "total_loss": 28.24476394057274
  },
  {
    "episode": 197,
    "avg_reward_per_step": 13.407832425073906,
    "episode_length": 1346,
    "policy_loss": -228.27806091308594,
    "value_loss": 0.5099055171012878,
    "entropy": 0.9080222845077515,
    "total_loss": -228.13136430978776
  },
  {
    "episode": 198,
    "avg_reward_per_step": -1.6297373875321048,
    "episode_length": 3000,
    "policy_loss": 24.232336044311523,
    "value_loss": 0.6361314654350281,
    "entropy": 0.9142275452613831,
    "total_loss": 24.502776491642
  },
  {
    "episode": 199,
    "avg_reward_per_step": 348.36144928634036,
    "episode_length": 58,
    "policy_loss": -5701.494873046875,
    "value_loss": 1.05843186378479,
    "entropy": 0.7832228541374207,
    "total_loss": -5700.7497303247455
  },
  {
    "episode": 200,
    "avg_reward_per_step": 21.133623840643175,
    "episode_length": 890,
    "policy_loss": -359.1894073486328,
    "value_loss": 0.5163912773132324,
    "entropy": 0.8580022156238556,
    "total_loss": -359.0162169575691
  },
  {
    "episode": 201,
    "avg_reward_per_step": -1.6297794179552196,
    "episode_length": 3000,
    "policy_loss": 24.019269943237305,
    "value_loss": 0.6165390014648438,
    "entropy": 0.8587837815284729,
    "total_loss": 24.29229543209076
  },
  {
    "episode": 202,
    "avg_reward_per_step": 17.735291592303913,
    "episode_length": 1042,
    "policy_loss": -300.97698974609375,
    "value_loss": 0.5134549140930176,
    "entropy": 0.8683850467205048,
    "total_loss": -300.8108888506889
  },
  {
    "episode": 203,
    "avg_reward_per_step": 22.671245821236802,
    "episode_length": 829,
    "policy_loss": -383.86505126953125,
    "value_loss": 0.5176146626472473,
    "entropy": 0.8296151459217072,
    "total_loss": -383.6792826652527
  },
  {
    "episode": 204,
    "avg_reward_per_step": 14.08293322960611,
    "episode_length": 1312,
    "policy_loss": -239.9952163696289,
    "value_loss": 0.5107129514217377,
    "entropy": 0.8518891632556915,
    "total_loss": -239.82525908350945
  },
  {
    "episode": 205,
    "avg_reward_per_step": -1.7503820442399372,
    "episode_length": 3000,
    "policy_loss": 25.896366119384766,
    "value_loss": 0.6744448840618134,
    "entropy": 0.8964821398258209,
    "total_loss": 26.21221814751625
  },
  {
    "episode": 206,
    "avg_reward_per_step": 17.038089327551052,
    "episode_length": 1091,
    "policy_loss": -289.9893341064453,
    "value_loss": 0.5130475759506226,
    "entropy": 0.8656715452671051,
    "total_loss": -289.8225551486015
  },
  {
    "episode": 207,
    "avg_reward_per_step": 5.990873642744688,
    "episode_length": 2667,
    "policy_loss": -104.19342803955078,
    "value_loss": 0.504062682390213,
    "entropy": 0.8495346903800964,
    "total_loss": -104.0291792333126
  },
  {
    "episode": 208,
    "avg_reward_per_step": 186.47664370571314,
    "episode_length": 108,
    "policy_loss": -3154.791748046875,
    "value_loss": 0.7113584578037262,
    "entropy": 0.8973853588104248,
    "total_loss": -3154.4393437325953
  },
  {
    "episode": 209,
    "avg_reward_per_step": -1.8816098333728626,
    "episode_length": 3000,
    "policy_loss": 28.097763061523438,
    "value_loss": 0.789870023727417,
    "entropy": 1.0207543969154358,
    "total_loss": 28.47933132648468
  },
  {
    "episode": 210,
    "avg_reward_per_step": 71.91186627500544,
    "episode_length": 275,
    "policy_loss": -1215.4175415039062,
    "value_loss": 0.5638700127601624,
    "entropy": 1.09079110622406,
    "total_loss": -1215.2899879336358
  },
  {
    "episode": 211,
    "avg_reward_per_step": 373.90254295146445,
    "episode_length": 54,
    "policy_loss": -6066.9501953125,
    "value_loss": 1.1327401399612427,
    "entropy": 0.8307134509086609,
    "total_loss": -6066.149740552903
  },
  {
    "episode": 212,
    "avg_reward_per_step": -1.6113617840852,
    "episode_length": 3000,
    "policy_loss": 23.595688819885254,
    "value_loss": 0.6841727793216705,
    "entropy": 1.0303120613098145,
    "total_loss": 23.867736774683
  },
  {
    "episode": 213,
    "avg_reward_per_step": 7.2233516041491415,
    "episode_length": 2340,
    "policy_loss": -125.3521614074707,
    "value_loss": 0.5049997866153717,
    "entropy": 1.0411342978477478,
    "total_loss": -125.26361533999443
  },
  {
    "episode": 214,
    "avg_reward_per_step": 162.18786485955073,
    "episode_length": 124,
    "policy_loss": -2730.3192138671875,
    "value_loss": 0.6747030913829803,
    "entropy": 1.080203354358673,
    "total_loss": -2730.076592117548
  },
  {
    "episode": 215,
    "avg_reward_per_step": 26.717888001739006,
    "episode_length": 710,
    "policy_loss": -454.3294982910156,
    "value_loss": 0.5210135579109192,
    "entropy": 1.1587862968444824,
    "total_loss": -454.2719992518425
  },
  {
    "episode": 216,
    "avg_reward_per_step": -1.5621918005370745,
    "episode_length": 3000,
    "policy_loss": 22.50489616394043,
    "value_loss": 0.7638210356235504,
    "entropy": 1.1842045783996582,
    "total_loss": 22.79503536820412
  },
  {
    "episode": 217,
    "avg_reward_per_step": 45.01506804849997,
    "episode_length": 436,
    "policy_loss": -761.3670043945312,
    "value_loss": 0.5376870930194855,
    "entropy": 1.192613124847412,
    "total_loss": -761.3063625514508
  },
  {
    "episode": 218,
    "avg_reward_per_step": 26.423195650484512,
    "episode_length": 721,
    "policy_loss": -450.0572204589844,
    "value_loss": 0.5210402011871338,
    "entropy": 1.1975452303886414,
    "total_loss": -450.0151983499527
  },
  {
    "episode": 219,
    "avg_reward_per_step": -1.538115885812812,
    "episode_length": 3000,
    "policy_loss": 22.0799560546875,
    "value_loss": 0.7046231925487518,
    "entropy": 1.2350687384605408,
    "total_loss": 22.290551751852036
  },
  {
    "episode": 220,
    "avg_reward_per_step": 5.722815645470146,
    "episode_length": 2829,
    "policy_loss": -100.11111831665039,
    "value_loss": 0.503829836845398,
    "entropy": 1.2601496577262878,
    "total_loss": -100.11134834289551
  },
  {
    "episode": 221,
    "avg_reward_per_step": 20.028893254383956,
    "episode_length": 941,
    "policy_loss": -341.01197814941406,
    "value_loss": 0.5155376195907593,
    "entropy": 1.2406387329101562,
    "total_loss": -340.9926960229874
  },
  {
    "episode": 222,
    "avg_reward_per_step": -1.6629281240805167,
    "episode_length": 3000,
    "policy_loss": 24.18008518218994,
    "value_loss": 0.8807320296764374,
    "entropy": 1.2780646085739136,
    "total_loss": 24.549591368436815
  },
  {
    "episode": 223,
    "avg_reward_per_step": -1.5087820245464543,
    "episode_length": 3000,
    "policy_loss": 21.504334449768066,
    "value_loss": 0.7889067530632019,
    "entropy": 1.2728278040885925,
    "total_loss": 21.78411008119583
  },
  {
    "episode": 224,
    "avg_reward_per_step": 9.786137247223543,
    "episode_length": 1764,
    "policy_loss": -168.62049865722656,
    "value_loss": 0.5069010853767395,
    "entropy": 1.276622235774994,
    "total_loss": -168.62424646615983
  },
  {
    "episode": 225,
    "avg_reward_per_step": -1.4571390175481473,
    "episode_length": 3000,
    "policy_loss": 20.343024253845215,
    "value_loss": 0.717620313167572,
    "entropy": 1.2768873572349548,
    "total_loss": 20.549889624118805
  },
  {
    "episode": 226,
    "avg_reward_per_step": 21.637591091405834,
    "episode_length": 873,
    "policy_loss": -367.8747863769531,
    "value_loss": 0.5168770849704742,
    "entropy": 1.2701205611228943,
    "total_loss": -367.8659575164318
  },
  {
    "episode": 227,
    "avg_reward_per_step": 7.550634487197352,
    "episode_length": 2242,
    "policy_loss": -130.8896942138672,
    "value_loss": 0.5054473280906677,
    "entropy": 1.2779823541641235,
    "total_loss": -130.89543982744217
  },
  {
    "episode": 228,
    "avg_reward_per_step": -1.482084720013493,
    "episode_length": 3000,
    "policy_loss": 20.528096199035645,
    "value_loss": 0.7204886972904205,
    "entropy": 1.2784295678138733,
    "total_loss": 20.737213069200514
  },
  {
    "episode": 229,
    "avg_reward_per_step": -1.5607108948550128,
    "episode_length": 3000,
    "policy_loss": 22.001182556152344,
    "value_loss": 0.7292099893093109,
    "entropy": 1.2890965342521667,
    "total_loss": 22.21475393176079
  },
  {
    "episode": 230,
    "avg_reward_per_step": 64.44847797397593,
    "episode_length": 309,
    "policy_loss": -1089.4464721679688,
    "value_loss": 0.5569419860839844,
    "entropy": 1.23539799451828,
    "total_loss": -1089.383689379692
  },
  {
    "episode": 231,
    "avg_reward_per_step": -1.3539155437973582,
    "episode_length": 3000,
    "policy_loss": 18.025504112243652,
    "value_loss": 0.6550436615943909,
    "entropy": 1.2844740748405457,
    "total_loss": 18.166758143901824
  },
  {
    "episode": 232,
    "avg_reward_per_step": 19.308701156062266,
    "episode_length": 976,
    "policy_loss": -329.2721252441406,
    "value_loss": 0.5150447189807892,
    "entropy": 1.2644543051719666,
    "total_loss": -329.2628622472286
  },
  {
    "episode": 233,
    "avg_reward_per_step": 5.675500733791641,
    "episode_length": 2758,
    "policy_loss": -100.19275665283203,
    "value_loss": 0.503781646490097,
    "entropy": 1.2754838466644287,
    "total_loss": -100.19916854500771
  },
  {
    "episode": 234,
    "avg_reward_per_step": -1.5737726666162735,
    "episode_length": 3000,
    "policy_loss": 21.80202579498291,
    "value_loss": 0.7229829132556915,
    "entropy": 1.2950241565704346,
    "total_loss": 22.006999045610428
  },
  {
    "episode": 235,
    "avg_reward_per_step": 28.727724260837167,
    "episode_length": 672,
    "policy_loss": -487.3677673339844,
    "value_loss": 0.5232439637184143,
    "entropy": 1.263713777065277,
    "total_loss": -487.3500088810921
  },
  {
    "episode": 236,
    "avg_reward_per_step": 29.55474725701018,
    "episode_length": 655,
    "policy_loss": -504.1090087890625,
    "value_loss": 0.5242214202880859,
    "entropy": 1.2894316911697388,
    "total_loss": -504.10056004524233
  },
  {
    "episode": 237,
    "avg_reward_per_step": 32.29558272523729,
    "episode_length": 595,
    "policy_loss": -547.7703857421875,
    "value_loss": 0.5260220766067505,
    "entropy": 1.2836204171180725,
    "total_loss": -547.7578118324279
  },
  {
    "episode": 238,
    "avg_reward_per_step": 6.68659717306216,
    "episode_length": 2481,
    "policy_loss": -117.46503448486328,
    "value_loss": 0.5046826899051666,
    "entropy": 1.276471495628357,
    "total_loss": -117.47094039320946
  },
  {
    "episode": 239,
    "avg_reward_per_step": 188.96045840380245,
    "episode_length": 106,
    "policy_loss": -3192.1326904296875,
    "value_loss": 0.7160090804100037,
    "entropy": 1.2609878778457642,
    "total_loss": -3191.921076500416
  },
  {
    "episode": 240,
    "avg_reward_per_step": 114.67261157299579,
    "episode_length": 175,
    "policy_loss": -1933.0213012695312,
    "value_loss": 0.6119027733802795,
    "entropy": 1.2700932025909424,
    "total_loss": -1932.9174357771874
  },
  {
    "episode": 241,
    "avg_reward_per_step": 20.844282214938794,
    "episode_length": 904,
    "policy_loss": -356.46710205078125,
    "value_loss": 0.5164832472801208,
    "entropy": 1.2896721959114075,
    "total_loss": -356.4664876818657
  },
  {
    "episode": 242,
    "avg_reward_per_step": 149.48363852972633,
    "episode_length": 134,
    "policy_loss": -2524.0194091796875,
    "value_loss": 0.6565349400043488,
    "entropy": 1.2577950954437256,
    "total_loss": -2523.8659922778606
  },
  {
    "episode": 243,
    "avg_reward_per_step": 5.576607517496589,
    "episode_length": 2831,
    "policy_loss": -98.92860794067383,
    "value_loss": 0.5037157237529755,
    "entropy": 1.2992900609970093,
    "total_loss": -98.94460824131966
  },
  {
    "episode": 244,
    "avg_reward_per_step": 29.291674413361495,
    "episode_length": 656,
    "policy_loss": -498.7128448486328,
    "value_loss": 0.5236728489398956,
    "entropy": 1.2830597758293152,
    "total_loss": -498.7023959100246
  },
  {
    "episode": 245,
    "avg_reward_per_step": 5.454036381916067,
    "episode_length": 2895,
    "policy_loss": -96.7186279296875,
    "value_loss": 0.5038614273071289,
    "entropy": 1.2916283011436462,
    "total_loss": -96.73141782283783
  },
  {
    "episode": 246,
    "avg_reward_per_step": 19.408474805330716,
    "episode_length": 970,
    "policy_loss": -332.3047637939453,
    "value_loss": 0.5152124762535095,
    "entropy": 1.285866379737854,
    "total_loss": -332.30389786958693
  },
  {
    "episode": 247,
    "avg_reward_per_step": 11.2924497547472,
    "episode_length": 1598,
    "policy_loss": -195.51463317871094,
    "value_loss": 0.5084594786167145,
    "entropy": 1.2899709939956665,
    "total_loss": -195.5221620976925
  },
  {
    "episode": 248,
    "avg_reward_per_step": 32.540627194003974,
    "episode_length": 598,
    "policy_loss": -553.6369323730469,
    "value_loss": 0.5266346633434296,
    "entropy": 1.278168499469757,
    "total_loss": -553.6215651094914
  },
  {
    "episode": 249,
    "avg_reward_per_step": -1.3367356879230838,
    "episode_length": 3000,
    "policy_loss": 17.269025802612305,
    "value_loss": 0.6768470406532288,
    "entropy": 1.2749862670898438,
    "total_loss": 17.435878336429596
  },
  {
    "episode": 250,
    "avg_reward_per_step": 12.102716323164989,
    "episode_length": 1502,
    "policy_loss": -209.04600524902344,
    "value_loss": 0.5090983211994171,
    "entropy": 1.2718026638031006,
    "total_loss": -209.04562799334525
  },
  {
    "episode": 251,
    "avg_reward_per_step": 32.44153888330683,
    "episode_length": 607,
    "policy_loss": -552.1306457519531,
    "value_loss": 0.5270598530769348,
    "entropy": 1.218876600265503,
    "total_loss": -552.0911365389824
  },
  {
    "episode": 252,
    "avg_reward_per_step": 8.69172611685424,
    "episode_length": 2028,
    "policy_loss": -151.5548324584961,
    "value_loss": 0.506391704082489,
    "entropy": 1.2489064931869507,
    "total_loss": -151.54800335168838
  },
  {
    "episode": 253,
    "avg_reward_per_step": 21.52146593276899,
    "episode_length": 886,
    "policy_loss": -368.10011291503906,
    "value_loss": 0.5172550082206726,
    "entropy": 1.2561128735542297,
    "total_loss": -368.0853030562401
  },
  {
    "episode": 254,
    "avg_reward_per_step": 8.378508138303513,
    "episode_length": 2064,
    "policy_loss": -146.1990509033203,
    "value_loss": 0.5060442388057709,
    "entropy": 1.270826518535614,
    "total_loss": -146.2013372719288
  },
  {
    "episode": 255,
    "avg_reward_per_step": -1.2399121029380733,
    "episode_length": 3000,
    "policy_loss": 15.454873085021973,
    "value_loss": 0.6009641289710999,
    "entropy": 1.237737238407135,
    "total_loss": 15.560742318630219
  },
  {
    "episode": 256,
    "avg_reward_per_step": -1.3369274401936766,
    "episode_length": 3000,
    "policy_loss": 17.282017707824707,
    "value_loss": 0.6805138289928436,
    "entropy": 1.2538105249404907,
    "total_loss": 17.461007326841354
  },
  {
    "episode": 257,
    "avg_reward_per_step": 62.20227268667397,
    "episode_length": 318,
    "policy_loss": -1051.7140502929688,
    "value_loss": 0.553806722164154,
    "entropy": 1.2700971961021423,
    "total_loss": -1051.6682824492455
  },
  {
    "episode": 258,
    "avg_reward_per_step": -1.2125883136519753,
    "episode_length": 3000,
    "policy_loss": 15.049123764038086,
    "value_loss": 0.6159716844558716,
    "entropy": 1.254711091518402,
    "total_loss": 15.163211011886597
  },
  {
    "episode": 259,
    "avg_reward_per_step": -1.0672399668387187,
    "episode_length": 3000,
    "policy_loss": 12.379404067993164,
    "value_loss": 0.5601940155029297,
    "entropy": 1.2185626029968262,
    "total_loss": 12.452173042297364
  },
  {
    "episode": 260,
    "avg_reward_per_step": 9.602526031626152,
    "episode_length": 1863,
    "policy_loss": -167.10748291015625,
    "value_loss": 0.5072256028652191,
    "entropy": 1.228654384613037,
    "total_loss": -167.09171906113625
  },
  {
    "episode": 261,
    "avg_reward_per_step": 7.198417310552531,
    "episode_length": 2370,
    "policy_loss": -126.67309188842773,
    "value_loss": 0.5051842927932739,
    "entropy": 1.224796712398529,
    "total_loss": -126.65782628059387
  },
  {
    "episode": 262,
    "avg_reward_per_step": -1.2335767911630253,
    "episode_length": 3000,
    "policy_loss": 15.122120380401611,
    "value_loss": 0.6126283407211304,
    "entropy": 1.2312267422676086,
    "total_loss": 15.242258024215698
  },
  {
    "episode": 263,
    "avg_reward_per_step": 20.51492383261259,
    "episode_length": 929,
    "policy_loss": -352.2938690185547,
    "value_loss": 0.5163535475730896,
    "entropy": 1.1910379528999329,
    "total_loss": -352.25393065214155
  },
  {
    "episode": 264,
    "avg_reward_per_step": 6.43895738074474,
    "episode_length": 2630,
    "policy_loss": -114.38248443603516,
    "value_loss": 0.5046075582504272,
    "entropy": 1.203370213508606,
    "total_loss": -114.35922496318817
  },
  {
    "episode": 265,
    "avg_reward_per_step": 69.53033699332342,
    "episode_length": 286,
    "policy_loss": -1178.23828125,
    "value_loss": 0.5617993474006653,
    "entropy": 1.2113402485847473,
    "total_loss": -1178.1610180020332
  },
  {
    "episode": 266,
    "avg_reward_per_step": -1.3534111514162708,
    "episode_length": 3000,
    "policy_loss": 17.017473220825195,
    "value_loss": 0.6055161654949188,
    "entropy": 1.1925726532936096,
    "total_loss": 17.14596032500267
  },
  {
    "episode": 267,
    "avg_reward_per_step": 13.140019818403575,
    "episode_length": 1409,
    "policy_loss": -227.07202911376953,
    "value_loss": 0.5101527869701385,
    "entropy": 1.1818331480026245,
    "total_loss": -227.03460958600044
  },
  {
    "episode": 268,
    "avg_reward_per_step": 50.69066456662403,
    "episode_length": 386,
    "policy_loss": -860.963623046875,
    "value_loss": 0.5428702235221863,
    "entropy": 1.2094852924346924,
    "total_loss": -860.9045469403267
  },
  {
    "episode": 269,
    "avg_reward_per_step": 86.22609542647032,
    "episode_length": 232,
    "policy_loss": -1460.8737182617188,
    "value_loss": 0.5800808668136597,
    "entropy": 1.1108550429344177,
    "total_loss": -1460.7379794120789
  },
  {
    "episode": 270,
    "avg_reward_per_step": -1.3296536367689635,
    "episode_length": 3000,
    "policy_loss": 16.22523784637451,
    "value_loss": 0.5704125463962555,
    "entropy": 1.1603076457977295,
    "total_loss": 16.331527334451675
  },
  {
    "episode": 271,
    "avg_reward_per_step": 6.670762969205924,
    "episode_length": 2547,
    "policy_loss": -118.51702117919922,
    "value_loss": 0.5048829317092896,
    "entropy": 1.177433729171753,
    "total_loss": -118.48311173915863
  },
  {
    "episode": 272,
    "avg_reward_per_step": 16.361233811338245,
    "episode_length": 1141,
    "policy_loss": -281.6459655761719,
    "value_loss": 0.5127741396427155,
    "entropy": 1.1638815999031067,
    "total_loss": -281.5987440764904
  },
  {
    "episode": 273,
    "avg_reward_per_step": 34.86029732988667,
    "episode_length": 557,
    "policy_loss": -593.7559509277344,
    "value_loss": 0.5285945236682892,
    "entropy": 1.2043082118034363,
    "total_loss": -593.7090796887875
  },
  {
    "episode": 274,
    "avg_reward_per_step": 28.37390322851277,
    "episode_length": 684,
    "policy_loss": -483.2879180908203,
    "value_loss": 0.5232492983341217,
    "entropy": 1.15352064371109,
    "total_loss": -483.2260770499706
  },
  {
    "episode": 275,
    "avg_reward_per_step": 6.0598540082723185,
    "episode_length": 2748,
    "policy_loss": -108.21426773071289,
    "value_loss": 0.5043180286884308,
    "entropy": 1.1719043254852295,
    "total_loss": -108.17871143221855
  },
  {
    "episode": 276,
    "avg_reward_per_step": 9.256706830893242,
    "episode_length": 1907,
    "policy_loss": -162.03404998779297,
    "value_loss": 0.5068674087524414,
    "entropy": 1.2155947089195251,
    "total_loss": -162.01342046260834
  },
  {
    "episode": 277,
    "avg_reward_per_step": 90.26004851539514,
    "episode_length": 222,
    "policy_loss": -1528.8348999023438,
    "value_loss": 0.5843101739883423,
    "entropy": 1.1573935747146606,
    "total_loss": -1528.7135471582412
  },
  {
    "episode": 278,
    "avg_reward_per_step": 6.138782675411795,
    "episode_length": 2660,
    "policy_loss": -109.89470672607422,
    "value_loss": 0.5043041110038757,
    "entropy": 1.209387719631195,
    "total_loss": -109.87415770292282
  },
  {
    "episode": 279,
    "avg_reward_per_step": 44.460720701942684,
    "episode_length": 442,
    "policy_loss": -754.7242431640625,
    "value_loss": 0.5373847484588623,
    "entropy": 1.1984598636627197,
    "total_loss": -754.6662423610687
  },
  {
    "episode": 280,
    "avg_reward_per_step": 8.472271670260612,
    "episode_length": 2083,
    "policy_loss": -149.1798324584961,
    "value_loss": 0.5065308809280396,
    "entropy": 1.21787029504776,
    "total_loss": -149.16044969558715
  },
  {
    "episode": 281,
    "avg_reward_per_step": 16.500061277105814,
    "episode_length": 1131,
    "policy_loss": -283.8599090576172,
    "value_loss": 0.5127931237220764,
    "entropy": 1.2115757465362549,
    "total_loss": -283.8317462325096
  },
  {
    "episode": 282,
    "avg_reward_per_step": 93.10065563037321,
    "episode_length": 213,
    "policy_loss": -1573.90478515625,
    "value_loss": 0.5858825147151947,
    "entropy": 1.1734062433242798,
    "total_loss": -1573.7882651388645
  },
  {
    "episode": 283,
    "avg_reward_per_step": 7.399335061381,
    "episode_length": 2362,
    "policy_loss": -130.8787841796875,
    "value_loss": 0.5055127739906311,
    "entropy": 1.173847258090973,
    "total_loss": -130.84281030893325
  },
  {
    "episode": 284,
    "avg_reward_per_step": 27.263558718817343,
    "episode_length": 715,
    "policy_loss": -466.14622497558594,
    "value_loss": 0.5224263072013855,
    "entropy": 1.16126149892807,
    "total_loss": -466.0883032679558
  },
  {
    "episode": 285,
    "avg_reward_per_step": -1.2246264917713117,
    "episode_length": 3000,
    "policy_loss": 14.595501899719238,
    "value_loss": 0.5667343735694885,
    "entropy": 1.1683985590934753,
    "total_loss": 14.694876849651337
  },
  {
    "episode": 286,
    "avg_reward_per_step": -1.251352617924772,
    "episode_length": 3000,
    "policy_loss": 15.02001428604126,
    "value_loss": 0.5801855027675629,
    "entropy": 1.189143419265747,
    "total_loss": 15.124542421102523
  },
  {
    "episode": 287,
    "avg_reward_per_step": 7.944362774329187,
    "episode_length": 2176,
    "policy_loss": -140.11658477783203,
    "value_loss": 0.505750834941864,
    "entropy": 1.1969281435012817,
    "total_loss": -140.0896052002907
  },
  {
    "episode": 288,
    "avg_reward_per_step": 35.84298159154055,
    "episode_length": 545,
    "policy_loss": -608.7256469726562,
    "value_loss": 0.5295684039592743,
    "entropy": 1.1414294242858887,
    "total_loss": -608.6526503384114
  },
  {
    "episode": 289,
    "avg_reward_per_step": 6.732133306801534,
    "episode_length": 2471,
    "policy_loss": -119.71300888061523,
    "value_loss": 0.5047864317893982,
    "entropy": 1.1707005500793457,
    "total_loss": -119.67650266885758
  },
  {
    "episode": 290,
    "avg_reward_per_step": 11.60011688320791,
    "episode_length": 1576,
    "policy_loss": -201.20148468017578,
    "value_loss": 0.508860170841217,
    "entropy": 1.1692497730255127,
    "total_loss": -201.16032441854477
  },
  {
    "episode": 291,
    "avg_reward_per_step": 13.46254560934205,
    "episode_length": 1382,
    "policy_loss": -233.0361785888672,
    "value_loss": 0.5104889571666718,
    "entropy": 1.1547853350639343,
    "total_loss": -232.98760376572608
  },
  {
    "episode": 292,
    "avg_reward_per_step": 42.47940039025353,
    "episode_length": 464,
    "policy_loss": -721.9472045898438,
    "value_loss": 0.5358393788337708,
    "entropy": 1.1565280556678772,
    "total_loss": -721.8739764332771
  },
  {
    "episode": 293,
    "avg_reward_per_step": 26.905679533428653,
    "episode_length": 713,
    "policy_loss": -460.0516052246094,
    "value_loss": 0.5217597782611847,
    "entropy": 1.19303297996521,
    "total_loss": -460.0070586383343
  },
  {
    "episode": 294,
    "avg_reward_per_step": -1.2545297947683194,
    "episode_length": 3000,
    "policy_loss": 14.818129539489746,
    "value_loss": 0.5609525442123413,
    "entropy": 1.177030622959137,
    "total_loss": 14.908269834518432
  },
  {
    "episode": 295,
    "avg_reward_per_step": 37.005262285332115,
    "episode_length": 530,
    "policy_loss": -630.6582336425781,
    "value_loss": 0.5309098958969116,
    "entropy": 1.1414915323257446,
    "total_loss": -630.5839203596115
  },
  {
    "episode": 296,
    "avg_reward_per_step": 22.713228844719637,
    "episode_length": 840,
    "policy_loss": -388.2313690185547,
    "value_loss": 0.5180023908615112,
    "entropy": 1.1608591675758362,
    "total_loss": -388.1777102947235
  },
  {
    "episode": 297,
    "avg_reward_per_step": -1.4152248070435414,
    "episode_length": 3000,
    "policy_loss": 17.431208610534668,
    "value_loss": 0.6004981994628906,
    "entropy": 1.1749876141548157,
    "total_loss": 17.561711764335634
  },
  {
    "episode": 298,
    "avg_reward_per_step": 23.31847302516352,
    "episode_length": 834,
    "policy_loss": -398.6400451660156,
    "value_loss": 0.518962174654007,
    "entropy": 1.1425804495811462,
    "total_loss": -398.5781151711941
  },
  {
    "episode": 299,
    "avg_reward_per_step": 55.87440004996283,
    "episode_length": 355,
    "policy_loss": -948.7087097167969,
    "value_loss": 0.5486862361431122,
    "entropy": 1.1809334754943848,
    "total_loss": -948.6323968708515
  },
  {
    "episode": 300,
    "avg_reward_per_step": 13.923454990081146,
    "episode_length": 1321,
    "policy_loss": -241.26160430908203,
    "value_loss": 0.5107141435146332,
    "entropy": 1.1577354669570923,
    "total_loss": -241.21398435235022
  }
]