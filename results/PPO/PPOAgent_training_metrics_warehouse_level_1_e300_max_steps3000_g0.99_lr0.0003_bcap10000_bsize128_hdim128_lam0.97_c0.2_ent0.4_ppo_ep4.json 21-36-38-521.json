[
  {
    "episode": 1,
    "avg_reward_per_step": -4.094195543987375,
    "episode_length": 3000,
    "policy_loss": 101.9615306854248,
    "value_loss": 2.6045640110969543,
    "entropy": 1.378782957792282,
    "total_loss": 104.01458151340485
  },
  {
    "episode": 2,
    "avg_reward_per_step": -2.556634520052675,
    "episode_length": 3000,
    "policy_loss": 64.1595344543457,
    "value_loss": 1.8922866880893707,
    "entropy": 1.368490070104599,
    "total_loss": 65.50442511439323
  },
  {
    "episode": 3,
    "avg_reward_per_step": 4.332035497229119,
    "episode_length": 2989,
    "policy_loss": -111.69221305847168,
    "value_loss": 0.5033628642559052,
    "entropy": 1.3654965460300446,
    "total_loss": -111.7350488126278
  },
  {
    "episode": 4,
    "avg_reward_per_step": 98.43006959160661,
    "episode_length": 201,
    "policy_loss": -2496.6793823242188,
    "value_loss": 0.6561760455369949,
    "entropy": 1.356740653514862,
    "total_loss": -2496.565902540088
  },
  {
    "episode": 5,
    "avg_reward_per_step": 6.682818489359036,
    "episode_length": 2240,
    "policy_loss": -170.48645401000977,
    "value_loss": 0.5060708373785019,
    "entropy": 1.3529620170593262,
    "total_loss": -170.521567979455
  },
  {
    "episode": 6,
    "avg_reward_per_step": -2.4945238974545774,
    "episode_length": 3000,
    "policy_loss": 62.331783294677734,
    "value_loss": 2.1322322487831116,
    "entropy": 1.346421092748642,
    "total_loss": 63.92544710636139
  },
  {
    "episode": 7,
    "avg_reward_per_step": 41.008427489558954,
    "episode_length": 474,
    "policy_loss": -1040.3247375488281,
    "value_loss": 0.5537482500076294,
    "entropy": 1.3380239605903625,
    "total_loss": -1040.3061988830566
  },
  {
    "episode": 8,
    "avg_reward_per_step": 9.159833524060822,
    "episode_length": 1791,
    "policy_loss": -231.29376220703125,
    "value_loss": 0.5092741101980209,
    "entropy": 1.3217620253562927,
    "total_loss": -231.31319290697576
  },
  {
    "episode": 9,
    "avg_reward_per_step": -2.354023891135806,
    "episode_length": 3000,
    "policy_loss": 58.79896831512451,
    "value_loss": 2.2439884543418884,
    "entropy": 1.3116928040981293,
    "total_loss": 60.51827964782715
  },
  {
    "episode": 10,
    "avg_reward_per_step": 18.441181232968773,
    "episode_length": 976,
    "policy_loss": -467.6422882080078,
    "value_loss": 0.5210670977830887,
    "entropy": 1.3040016293525696,
    "total_loss": -467.64282176196576
  },
  {
    "episode": 11,
    "avg_reward_per_step": 13.718035934309198,
    "episode_length": 1243,
    "policy_loss": -347.92193603515625,
    "value_loss": 0.5145933926105499,
    "entropy": 1.3115886449813843,
    "total_loss": -347.93197810053823
  },
  {
    "episode": 12,
    "avg_reward_per_step": -2.532093492388075,
    "episode_length": 3000,
    "policy_loss": 63.09471035003662,
    "value_loss": 1.7015110552310944,
    "entropy": 1.3278527855873108,
    "total_loss": 64.26508029103279
  },
  {
    "episode": 13,
    "avg_reward_per_step": 13.321850109684794,
    "episode_length": 1260,
    "policy_loss": -337.9104690551758,
    "value_loss": 0.5139041990041733,
    "entropy": 1.335402488708496,
    "total_loss": -337.930725851655
  },
  {
    "episode": 14,
    "avg_reward_per_step": 19.016087400129297,
    "episode_length": 923,
    "policy_loss": -486.9206771850586,
    "value_loss": 0.5211201161146164,
    "entropy": 1.3475715517997742,
    "total_loss": -486.9385856896639
  },
  {
    "episode": 15,
    "avg_reward_per_step": 30.390565637173584,
    "episode_length": 604,
    "policy_loss": -779.7399291992188,
    "value_loss": 0.5363849997520447,
    "entropy": 1.3536956012248993,
    "total_loss": -779.7450224399566
  },
  {
    "episode": 16,
    "avg_reward_per_step": 12.181870446728068,
    "episode_length": 1266,
    "policy_loss": -312.77284240722656,
    "value_loss": 0.5115947425365448,
    "entropy": 1.3418878018856049,
    "total_loss": -312.7980027854443
  },
  {
    "episode": 17,
    "avg_reward_per_step": 15.872217757565357,
    "episode_length": 1002,
    "policy_loss": -405.8621826171875,
    "value_loss": 0.5157930552959442,
    "entropy": 1.3110951483249664,
    "total_loss": -405.87082762122157
  },
  {
    "episode": 18,
    "avg_reward_per_step": 7.812272507021161,
    "episode_length": 1382,
    "policy_loss": -197.01163482666016,
    "value_loss": 0.5049802362918854,
    "entropy": 1.2603046298027039,
    "total_loss": -197.01077644228934
  },
  {
    "episode": 19,
    "avg_reward_per_step": 18.762034634065923,
    "episode_length": 753,
    "policy_loss": -478.26050567626953,
    "value_loss": 0.5166802257299423,
    "entropy": 1.2311089038848877,
    "total_loss": -478.23626901209354
  },
  {
    "episode": 20,
    "avg_reward_per_step": 384.5961045828421,
    "episode_length": 52,
    "policy_loss": -8621.858154296875,
    "value_loss": 1.917818933725357,
    "entropy": 1.2180063724517822,
    "total_loss": -8620.42753791213
  },
  {
    "episode": 21,
    "avg_reward_per_step": 19.454400563288377,
    "episode_length": 780,
    "policy_loss": -494.63087463378906,
    "value_loss": 0.5186013430356979,
    "entropy": 1.2308284938335419,
    "total_loss": -494.60460468828677
  },
  {
    "episode": 22,
    "avg_reward_per_step": 416.0266677940679,
    "episode_length": 48,
    "policy_loss": -9348.656005859375,
    "value_loss": 2.1375880241394043,
    "entropy": 1.1178620159626007,
    "total_loss": -9346.96556264162
  },
  {
    "episode": 23,
    "avg_reward_per_step": -8.315174214261473,
    "episode_length": 3000,
    "policy_loss": 209.75826263427734,
    "value_loss": 3.263274610042572,
    "entropy": 1.0588541328907013,
    "total_loss": 212.59799559116362
  },
  {
    "episode": 24,
    "avg_reward_per_step": -9.238423168605722,
    "episode_length": 3000,
    "policy_loss": 231.53671646118164,
    "value_loss": 2.6589118242263794,
    "entropy": 0.9491482228040695,
    "total_loss": 233.8159689962864
  },
  {
    "episode": 25,
    "avg_reward_per_step": 259.1849870628389,
    "episode_length": 77,
    "policy_loss": -6266.4305419921875,
    "value_loss": 1.1900628507137299,
    "entropy": 0.7434589266777039,
    "total_loss": -6265.5378627121445
  },
  {
    "episode": 26,
    "avg_reward_per_step": -12.42359429887793,
    "episode_length": 3000,
    "policy_loss": 311.76024627685547,
    "value_loss": 4.4862998723983765,
    "entropy": 0.7822903990745544,
    "total_loss": 315.933629989624
  },
  {
    "episode": 27,
    "avg_reward_per_step": 8.680102914694407,
    "episode_length": 991,
    "policy_loss": -220.41410446166992,
    "value_loss": 0.5041658282279968,
    "entropy": 0.6693391352891922,
    "total_loss": -220.1776742875576
  },
  {
    "episode": 28,
    "avg_reward_per_step": -9.130329796759469,
    "episode_length": 3000,
    "policy_loss": 228.02666854858398,
    "value_loss": 1.7042886018753052,
    "entropy": 0.7921314537525177,
    "total_loss": 229.4141045689583
  },
  {
    "episode": 29,
    "avg_reward_per_step": -12.216386872190437,
    "episode_length": 3000,
    "policy_loss": 305.6323776245117,
    "value_loss": 4.135181546211243,
    "entropy": 0.7161471098661423,
    "total_loss": 309.4811003267765
  },
  {
    "episode": 30,
    "avg_reward_per_step": 2.4970943985762686,
    "episode_length": 1406,
    "policy_loss": -64.40579605102539,
    "value_loss": 0.5002065449953079,
    "entropy": 0.6258612275123596,
    "total_loss": -64.15593399703502
  },
  {
    "episode": 31,
    "avg_reward_per_step": 14.321984255761485,
    "episode_length": 760,
    "policy_loss": -363.8947067260742,
    "value_loss": 0.5091967880725861,
    "entropy": 0.5967890173196793,
    "total_loss": -363.6242255449295
  },
  {
    "episode": 32,
    "avg_reward_per_step": -14.142439124396253,
    "episode_length": 3000,
    "policy_loss": 354.55567932128906,
    "value_loss": 5.465568900108337,
    "entropy": 0.6565964818000793,
    "total_loss": 359.7586096286774
  },
  {
    "episode": 33,
    "avg_reward_per_step": -9.928859258604026,
    "episode_length": 3000,
    "policy_loss": 247.73843002319336,
    "value_loss": 1.5894106328487396,
    "entropy": 0.7485878467559814,
    "total_loss": 249.0284055173397
  },
  {
    "episode": 34,
    "avg_reward_per_step": 216.8765492370958,
    "episode_length": 92,
    "policy_loss": -5348.276123046875,
    "value_loss": 1.0084327161312103,
    "entropy": 0.5850881785154343,
    "total_loss": -5347.50172560215
  },
  {
    "episode": 35,
    "avg_reward_per_step": -14.78235484624153,
    "episode_length": 3000,
    "policy_loss": 370.05165100097656,
    "value_loss": 6.832089066505432,
    "entropy": 0.6048891544342041,
    "total_loss": 376.64178440570834
  },
  {
    "episode": 36,
    "avg_reward_per_step": 122.61478451508616,
    "episode_length": 162,
    "policy_loss": -3099.263671875,
    "value_loss": 0.7097609341144562,
    "entropy": 0.5624609291553497,
    "total_loss": -3098.778895312548
  },
  {
    "episode": 37,
    "avg_reward_per_step": 14.992756097207613,
    "episode_length": 747,
    "policy_loss": -382.1238708496094,
    "value_loss": 0.510019451379776,
    "entropy": 0.5445421040058136,
    "total_loss": -381.8316682398319
  },
  {
    "episode": 38,
    "avg_reward_per_step": -12.415425926248266,
    "episode_length": 3000,
    "policy_loss": 310.3138961791992,
    "value_loss": 3.153508424758911,
    "entropy": 0.6904988139867783,
    "total_loss": 313.1912050783634
  },
  {
    "episode": 39,
    "avg_reward_per_step": -13.462940937596986,
    "episode_length": 3000,
    "policy_loss": 336.4841613769531,
    "value_loss": 4.7269405126571655,
    "entropy": 0.7217004001140594,
    "total_loss": 340.9224217295647
  },
  {
    "episode": 40,
    "avg_reward_per_step": -1.4263542866490369,
    "episode_length": 1977,
    "policy_loss": 33.24581241607666,
    "value_loss": 0.4999789372086525,
    "entropy": 0.740135982632637,
    "total_loss": 33.44973696023226
  },
  {
    "episode": 41,
    "avg_reward_per_step": -13.250342453211314,
    "episode_length": 3000,
    "policy_loss": 331.35779571533203,
    "value_loss": 4.211008429527283,
    "entropy": 0.7444973587989807,
    "total_loss": 335.27100520133973
  },
  {
    "episode": 42,
    "avg_reward_per_step": -9.80245336943477,
    "episode_length": 3000,
    "policy_loss": 244.15628051757812,
    "value_loss": 2.284014046192169,
    "entropy": 0.8145036995410919,
    "total_loss": 246.11449308395385
  },
  {
    "episode": 43,
    "avg_reward_per_step": -11.396437045242633,
    "episode_length": 3000,
    "policy_loss": 284.23439025878906,
    "value_loss": 3.188754975795746,
    "entropy": 0.8250859677791595,
    "total_loss": 287.09311084747316
  },
  {
    "episode": 44,
    "avg_reward_per_step": -10.811272162587608,
    "episode_length": 3000,
    "policy_loss": 269.86917877197266,
    "value_loss": 2.5890047550201416,
    "entropy": 0.8170160055160522,
    "total_loss": 272.13137712478635
  },
  {
    "episode": 45,
    "avg_reward_per_step": -10.935357839051832,
    "episode_length": 3000,
    "policy_loss": 272.1580047607422,
    "value_loss": 2.883889853954315,
    "entropy": 0.8103337287902832,
    "total_loss": 274.71776112318037
  },
  {
    "episode": 46,
    "avg_reward_per_step": -10.861794635922704,
    "episode_length": 3000,
    "policy_loss": 269.8170623779297,
    "value_loss": 3.799125015735626,
    "entropy": 0.8527012020349503,
    "total_loss": 273.27510691285136
  },
  {
    "episode": 47,
    "avg_reward_per_step": -12.121263546001792,
    "episode_length": 3000,
    "policy_loss": 302.01100158691406,
    "value_loss": 4.2344948053359985,
    "entropy": 0.792654350399971,
    "total_loss": 305.92843465209006
  },
  {
    "episode": 48,
    "avg_reward_per_step": 607.9173373466474,
    "episode_length": 33,
    "policy_loss": -11419.501220703125,
    "value_loss": 3.8755629658699036,
    "entropy": 0.6772923916578293,
    "total_loss": -11415.896574693918
  },
  {
    "episode": 49,
    "avg_reward_per_step": -2.0876161924546954,
    "episode_length": 2313,
    "policy_loss": 47.812767028808594,
    "value_loss": 0.5003287941217422,
    "entropy": 0.8549178242683411,
    "total_loss": 47.971128693223
  },
  {
    "episode": 50,
    "avg_reward_per_step": 25.897304112076306,
    "episode_length": 550,
    "policy_loss": -670.2212677001953,
    "value_loss": 0.5233507305383682,
    "entropy": 0.7998121678829193,
    "total_loss": -670.0178418368101
  },
  {
    "episode": 51,
    "avg_reward_per_step": 38.514018482622255,
    "episode_length": 441,
    "policy_loss": -975.0262451171875,
    "value_loss": 0.5434726923704147,
    "entropy": 0.8534557819366455,
    "total_loss": -974.8241547375917
  },
  {
    "episode": 52,
    "avg_reward_per_step": 10.070577580883134,
    "episode_length": 1004,
    "policy_loss": -259.1874084472656,
    "value_loss": 0.5061438083648682,
    "entropy": 0.9403344094753265,
    "total_loss": -259.05739840269086
  },
  {
    "episode": 53,
    "avg_reward_per_step": -8.791874474645129,
    "episode_length": 3000,
    "policy_loss": 217.38542938232422,
    "value_loss": 3.3977779746055603,
    "entropy": 1.0113249123096466,
    "total_loss": 220.37867739200593
  },
  {
    "episode": 54,
    "avg_reward_per_step": -7.37419060100071,
    "episode_length": 3000,
    "policy_loss": 181.62970352172852,
    "value_loss": 2.2982142567634583,
    "entropy": 1.0321807265281677,
    "total_loss": 183.5150454878807
  },
  {
    "episode": 55,
    "avg_reward_per_step": -7.922752084623273,
    "episode_length": 3000,
    "policy_loss": 194.76237106323242,
    "value_loss": 2.671404778957367,
    "entropy": 1.0461792647838593,
    "total_loss": 197.01530413627626
  },
  {
    "episode": 56,
    "avg_reward_per_step": -7.265168522396394,
    "episode_length": 3000,
    "policy_loss": 178.75425338745117,
    "value_loss": 2.363196015357971,
    "entropy": 1.0582213401794434,
    "total_loss": 180.69416086673738
  },
  {
    "episode": 57,
    "avg_reward_per_step": 5.479777583392083,
    "episode_length": 1674,
    "policy_loss": -144.5616226196289,
    "value_loss": 0.5031260848045349,
    "entropy": 1.089734137058258,
    "total_loss": -144.49439018964767
  },
  {
    "episode": 58,
    "avg_reward_per_step": 53.51617980128828,
    "episode_length": 338,
    "policy_loss": -1358.7031860351562,
    "value_loss": 0.5670874565839767,
    "entropy": 1.0495578944683075,
    "total_loss": -1358.5559217363596
  },
  {
    "episode": 59,
    "avg_reward_per_step": 16.837389713488857,
    "episode_length": 810,
    "policy_loss": -434.5057678222656,
    "value_loss": 0.5146479904651642,
    "entropy": 1.1119607985019684,
    "total_loss": -434.43590415120127
  },
  {
    "episode": 60,
    "avg_reward_per_step": 21.191498623730748,
    "episode_length": 755,
    "policy_loss": -541.1391143798828,
    "value_loss": 0.5218015164136887,
    "entropy": 1.133749544620514,
    "total_loss": -541.0708126813173
  },
  {
    "episode": 61,
    "avg_reward_per_step": 363.5325420952234,
    "episode_length": 55,
    "policy_loss": -8336.47265625,
    "value_loss": 1.7756132185459137,
    "entropy": 1.0040412247180939,
    "total_loss": -8335.098659521342
  },
  {
    "episode": 62,
    "avg_reward_per_step": 5.8189170503160845,
    "episode_length": 1641,
    "policy_loss": -150.67109298706055,
    "value_loss": 0.5034141391515732,
    "entropy": 1.1362005472183228,
    "total_loss": -150.6221590667963
  },
  {
    "episode": 63,
    "avg_reward_per_step": 52.19608893452068,
    "episode_length": 352,
    "policy_loss": -1324.1323852539062,
    "value_loss": 0.5666702389717102,
    "entropy": 1.1143162846565247,
    "total_loss": -1324.0114415287971
  },
  {
    "episode": 64,
    "avg_reward_per_step": 8.891814275259517,
    "episode_length": 1282,
    "policy_loss": -231.24890899658203,
    "value_loss": 0.5063401907682419,
    "entropy": 1.119457721710205,
    "total_loss": -231.19035189449787
  },
  {
    "episode": 65,
    "avg_reward_per_step": 5.6896522433306576,
    "episode_length": 1774,
    "policy_loss": -149.23061752319336,
    "value_loss": 0.5036169439554214,
    "entropy": 1.1293563842773438,
    "total_loss": -149.17874313294888
  },
  {
    "episode": 66,
    "avg_reward_per_step": -5.976267170771914,
    "episode_length": 3000,
    "policy_loss": 145.4144515991211,
    "value_loss": 3.078527569770813,
    "entropy": 1.1513091325759888,
    "total_loss": 148.0324555158615
  },
  {
    "episode": 67,
    "avg_reward_per_step": 425.9747673331241,
    "episode_length": 47,
    "policy_loss": -9226.97607421875,
    "value_loss": 2.2164992690086365,
    "entropy": 1.003014400601387,
    "total_loss": -9225.160780709983
  },
  {
    "episode": 68,
    "avg_reward_per_step": 5.337268464932078,
    "episode_length": 1814,
    "policy_loss": -140.09961318969727,
    "value_loss": 0.5032423585653305,
    "entropy": 1.1582627296447754,
    "total_loss": -140.05967592298984
  },
  {
    "episode": 69,
    "avg_reward_per_step": 105.72918306487473,
    "episode_length": 183,
    "policy_loss": -2685.5443725585938,
    "value_loss": 0.6680564284324646,
    "entropy": 1.0820123851299286,
    "total_loss": -2685.309121084213
  },
  {
    "episode": 70,
    "avg_reward_per_step": 19.98151042303617,
    "episode_length": 799,
    "policy_loss": -513.5935516357422,
    "value_loss": 0.5203417092561722,
    "entropy": 1.20213183760643,
    "total_loss": -513.5540626615286
  },
  {
    "episode": 71,
    "avg_reward_per_step": 6.4971554744522075,
    "episode_length": 1764,
    "policy_loss": -169.8879737854004,
    "value_loss": 0.5047397613525391,
    "entropy": 1.17752605676651,
    "total_loss": -169.85424444675445
  },
  {
    "episode": 72,
    "avg_reward_per_step": 408.62557172740196,
    "episode_length": 49,
    "policy_loss": -9059.2607421875,
    "value_loss": 2.087704300880432,
    "entropy": 1.0747374892234802,
    "total_loss": -9057.60293288231
  },
  {
    "episode": 73,
    "avg_reward_per_step": -6.008303480071406,
    "episode_length": 3000,
    "policy_loss": 145.91474151611328,
    "value_loss": 2.972482919692993,
    "entropy": 1.05936798453331,
    "total_loss": 148.46347724199296
  },
  {
    "episode": 74,
    "avg_reward_per_step": 444.9196804781269,
    "episode_length": 45,
    "policy_loss": -9557.366943359375,
    "value_loss": 2.3631444573402405,
    "entropy": 0.9391834884881973,
    "total_loss": -9555.37947229743
  },
  {
    "episode": 75,
    "avg_reward_per_step": 132.9643304429298,
    "episode_length": 146,
    "policy_loss": -3365.2462768554688,
    "value_loss": 0.7322075515985489,
    "entropy": 0.9992686063051224,
    "total_loss": -3364.913776746392
  },
  {
    "episode": 76,
    "avg_reward_per_step": 117.67077046466916,
    "episode_length": 165,
    "policy_loss": -2994.5987548828125,
    "value_loss": 0.6943449527025223,
    "entropy": 0.993384912610054,
    "total_loss": -2994.301763895154
  },
  {
    "episode": 77,
    "avg_reward_per_step": 513.3382513694453,
    "episode_length": 39,
    "policy_loss": -10395.990478515625,
    "value_loss": 2.937735855579376,
    "entropy": 0.8916319608688354,
    "total_loss": -10393.409395444392
  },
  {
    "episode": 78,
    "avg_reward_per_step": 454.9889660473733,
    "episode_length": 44,
    "policy_loss": -9646.3505859375,
    "value_loss": 2.44422447681427,
    "entropy": 1.020894706249237,
    "total_loss": -9644.314719343185
  },
  {
    "episode": 79,
    "avg_reward_per_step": 52.71188752059446,
    "episode_length": 358,
    "policy_loss": -1357.6353149414062,
    "value_loss": 0.5695894062519073,
    "entropy": 1.0517217516899109,
    "total_loss": -1357.4864142358304
  },
  {
    "episode": 80,
    "avg_reward_per_step": 4.3964018977807005,
    "episode_length": 2492,
    "policy_loss": -118.80627250671387,
    "value_loss": 0.5031497925519943,
    "entropy": 0.9979292452335358,
    "total_loss": -118.70229441225528
  },
  {
    "episode": 81,
    "avg_reward_per_step": 168.71683746307212,
    "episode_length": 118,
    "policy_loss": -4285.6612548828125,
    "value_loss": 0.8401694148778915,
    "entropy": 0.9332545846700668,
    "total_loss": -4285.194387301803
  },
  {
    "episode": 82,
    "avg_reward_per_step": 54.303008732881935,
    "episode_length": 351,
    "policy_loss": -1372.7201843261719,
    "value_loss": 0.5724033415317535,
    "entropy": 0.9287031143903732,
    "total_loss": -1372.5192622303962
  },
  {
    "episode": 83,
    "avg_reward_per_step": 16.722742390338087,
    "episode_length": 1071,
    "policy_loss": -430.37552642822266,
    "value_loss": 0.5193365067243576,
    "entropy": 0.8619969189167023,
    "total_loss": -430.20098868906496
  },
  {
    "episode": 84,
    "avg_reward_per_step": 340.1760913106724,
    "episode_length": 59,
    "policy_loss": -8074.1380615234375,
    "value_loss": 1.632059633731842,
    "entropy": 0.9065374135971069,
    "total_loss": -8072.868616855145
  },
  {
    "episode": 85,
    "avg_reward_per_step": 27.337978578865886,
    "episode_length": 633,
    "policy_loss": -690.6290893554688,
    "value_loss": 0.5308194905519485,
    "entropy": 0.8196031898260117,
    "total_loss": -690.4261111408472
  },
  {
    "episode": 86,
    "avg_reward_per_step": 400.7755153923879,
    "episode_length": 50,
    "policy_loss": -8954.816650390625,
    "value_loss": 2.0336474180221558,
    "entropy": 0.7668807506561279,
    "total_loss": -8953.089755272866
  },
  {
    "episode": 87,
    "avg_reward_per_step": 9.158120990136632,
    "episode_length": 1105,
    "policy_loss": -242.11173629760742,
    "value_loss": 0.5057686567306519,
    "entropy": 0.7914106100797653,
    "total_loss": -241.92253188490866
  },
  {
    "episode": 88,
    "avg_reward_per_step": 572.527424454399,
    "episode_length": 35,
    "policy_loss": -11104.4658203125,
    "value_loss": 3.511637508869171,
    "entropy": 0.6805982738733292,
    "total_loss": -11101.22642211318
  },
  {
    "episode": 89,
    "avg_reward_per_step": 626.1465909250171,
    "episode_length": 32,
    "policy_loss": -11780.3203125,
    "value_loss": 4.078094720840454,
    "entropy": 0.6661856174468994,
    "total_loss": -11776.508692026138
  },
  {
    "episode": 90,
    "avg_reward_per_step": -12.174057900329691,
    "episode_length": 3000,
    "policy_loss": 302.5704116821289,
    "value_loss": 2.6071657538414,
    "entropy": 0.5951526165008545,
    "total_loss": 304.93951638936994
  },
  {
    "episode": 91,
    "avg_reward_per_step": 590.4988192611056,
    "episode_length": 34,
    "policy_loss": -11202.488037109375,
    "value_loss": 3.706010937690735,
    "entropy": 0.5481975823640823,
    "total_loss": -11199.00130520463
  },
  {
    "episode": 92,
    "avg_reward_per_step": 572.8497379978878,
    "episode_length": 35,
    "policy_loss": -11070.13232421875,
    "value_loss": 3.5251986384391785,
    "entropy": 0.549775242805481,
    "total_loss": -11066.827035677434
  },
  {
    "episode": 93,
    "avg_reward_per_step": 626.648941224027,
    "episode_length": 32,
    "policy_loss": -11679.1142578125,
    "value_loss": 4.093651533126831,
    "entropy": 0.4326917827129364,
    "total_loss": -11675.193682992458
  },
  {
    "episode": 94,
    "avg_reward_per_step": 556.6816212319403,
    "episode_length": 36,
    "policy_loss": -11129.666015625,
    "value_loss": 3.364968180656433,
    "entropy": 0.37809546291828156,
    "total_loss": -11126.452285629512
  },
  {
    "episode": 95,
    "avg_reward_per_step": 556.6951645373399,
    "episode_length": 36,
    "policy_loss": -10864.6318359375,
    "value_loss": 3.3615583777427673,
    "entropy": 0.3774510696530342,
    "total_loss": -10861.421257987618
  },
  {
    "episode": 96,
    "avg_reward_per_step": 556.785703581183,
    "episode_length": 36,
    "policy_loss": -11005.58837890625,
    "value_loss": 3.362874746322632,
    "entropy": 0.44742900878190994,
    "total_loss": -11002.40447576344
  },
  {
    "episode": 97,
    "avg_reward_per_step": -2.743104891032793,
    "episode_length": 1502,
    "policy_loss": 61.42743110656738,
    "value_loss": 0.5002206265926361,
    "entropy": 0.269925095140934,
    "total_loss": 61.81968169510365
  },
  {
    "episode": 98,
    "avg_reward_per_step": -15.285482220881839,
    "episode_length": 3000,
    "policy_loss": 378.8821029663086,
    "value_loss": 5.16927695274353,
    "entropy": 0.23677152395248413,
    "total_loss": 383.9566713094711
  },
  {
    "episode": 99,
    "avg_reward_per_step": 72.42865253604297,
    "episode_length": 241,
    "policy_loss": -1852.3907775878906,
    "value_loss": 0.5923337042331696,
    "entropy": 0.4502418786287308,
    "total_loss": -1851.9785406351089
  },
  {
    "episode": 100,
    "avg_reward_per_step": 527.7991358952062,
    "episode_length": 38,
    "policy_loss": -10565.9677734375,
    "value_loss": 3.0884034633636475,
    "entropy": 0.3923937752842903,
    "total_loss": -10563.03632748425
  },
  {
    "episode": 101,
    "avg_reward_per_step": 488.67345463483815,
    "episode_length": 41,
    "policy_loss": -10098.6494140625,
    "value_loss": 2.7245430946350098,
    "entropy": 0.37886829674243927,
    "total_loss": -10096.076418286562
  },
  {
    "episode": 102,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11797.746337890625,
    "value_loss": 4.32106077671051,
    "entropy": 0.2883349880576134,
    "total_loss": -11793.540611109138
  },
  {
    "episode": 103,
    "avg_reward_per_step": 409.4751802921856,
    "episode_length": 49,
    "policy_loss": -9064.8623046875,
    "value_loss": 2.0969664454460144,
    "entropy": 0.6083635538816452,
    "total_loss": -9063.008683663607
  },
  {
    "episode": 104,
    "avg_reward_per_step": 542.5890824361497,
    "episode_length": 37,
    "policy_loss": -10709.762451171875,
    "value_loss": 3.2285194993019104,
    "entropy": 0.38155854493379593,
    "total_loss": -10706.686555090546
  },
  {
    "episode": 105,
    "avg_reward_per_step": 668.2372516618434,
    "episode_length": 30,
    "policy_loss": -11979.279052734375,
    "value_loss": 4.56966757774353,
    "entropy": 0.18583394587039948,
    "total_loss": -11974.78371873498
  },
  {
    "episode": 106,
    "avg_reward_per_step": 514.7383602599369,
    "episode_length": 39,
    "policy_loss": -10430.296875,
    "value_loss": 2.966519296169281,
    "entropy": 0.353830523788929,
    "total_loss": -10427.471887913347
  },
  {
    "episode": 107,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11757.767822265625,
    "value_loss": 4.321057915687561,
    "entropy": 0.12943213805556297,
    "total_loss": -11753.49853720516
  },
  {
    "episode": 108,
    "avg_reward_per_step": 607.9558892484544,
    "episode_length": 33,
    "policy_loss": -11277.546142578125,
    "value_loss": 3.892478585243225,
    "entropy": 0.25134697929024696,
    "total_loss": -11273.754202784598
  },
  {
    "episode": 109,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11777.5078125,
    "value_loss": 4.321081757545471,
    "entropy": 0.10173270851373672,
    "total_loss": -11773.22742382586
  },
  {
    "episode": 110,
    "avg_reward_per_step": 573.3309229052556,
    "episode_length": 35,
    "policy_loss": -11090.258056640625,
    "value_loss": 3.5313759446144104,
    "entropy": 0.19821268320083618,
    "total_loss": -11086.80596576929
  },
  {
    "episode": 111,
    "avg_reward_per_step": 646.5605701784692,
    "episode_length": 31,
    "policy_loss": -11779.59423828125,
    "value_loss": 4.317577242851257,
    "entropy": 0.13003414310514927,
    "total_loss": -11775.32867469564
  },
  {
    "episode": 112,
    "avg_reward_per_step": 608.4180620778741,
    "episode_length": 33,
    "policy_loss": -11368.27978515625,
    "value_loss": 3.900153696537018,
    "entropy": 0.15464674681425095,
    "total_loss": -11364.441490158439
  },
  {
    "episode": 113,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11943.05322265625,
    "value_loss": 4.565354347229004,
    "entropy": 0.09428101032972336,
    "total_loss": -11938.525580713153
  },
  {
    "episode": 114,
    "avg_reward_per_step": 608.4180620778741,
    "episode_length": 33,
    "policy_loss": -11387.404296875,
    "value_loss": 3.8999850153923035,
    "entropy": 0.12220663391053677,
    "total_loss": -11383.553194513172
  },
  {
    "episode": 115,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11665.63818359375,
    "value_loss": 4.320563077926636,
    "entropy": 0.06526084244251251,
    "total_loss": -11661.3437248528
  },
  {
    "episode": 116,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11682.091796875,
    "value_loss": 4.320496678352356,
    "entropy": 0.06027846597135067,
    "total_loss": -11677.795411583036
  },
  {
    "episode": 117,
    "avg_reward_per_step": 668.5536581605955,
    "episode_length": 30,
    "policy_loss": -12018.18505859375,
    "value_loss": 4.575856447219849,
    "entropy": 0.07661590352654457,
    "total_loss": -12013.63984850794
  },
  {
    "episode": 118,
    "avg_reward_per_step": 608.4180620778741,
    "episode_length": 33,
    "policy_loss": -11378.905517578125,
    "value_loss": 3.899661898612976,
    "entropy": 0.1038963608443737,
    "total_loss": -11375.047414223849
  },
  {
    "episode": 119,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11689.084228515625,
    "value_loss": 4.320417165756226,
    "entropy": 0.06266814190894365,
    "total_loss": -11684.788878606632
  },
  {
    "episode": 120,
    "avg_reward_per_step": 608.4180620778741,
    "episode_length": 33,
    "policy_loss": -11310.618408203125,
    "value_loss": 3.899705708026886,
    "entropy": 0.08888157084584236,
    "total_loss": -11306.754255123436
  },
  {
    "episode": 121,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11694.23681640625,
    "value_loss": 4.320231080055237,
    "entropy": 0.05045991484075785,
    "total_loss": -11689.936769292131
  },
  {
    "episode": 122,
    "avg_reward_per_step": 607.6805044341128,
    "episode_length": 33,
    "policy_loss": -11393.167724609375,
    "value_loss": 3.887163281440735,
    "entropy": 0.06794889084994793,
    "total_loss": -11389.307740884275
  },
  {
    "episode": 123,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11645.869384765625,
    "value_loss": 4.319963335990906,
    "entropy": 0.03985134605318308,
    "total_loss": -11641.565361968056
  },
  {
    "episode": 124,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11673.401611328125,
    "value_loss": 4.319872498512268,
    "entropy": 0.04289076663553715,
    "total_loss": -11669.098895136267
  },
  {
    "episode": 125,
    "avg_reward_per_step": 572.9273327521635,
    "episode_length": 35,
    "policy_loss": -10989.89697265625,
    "value_loss": 3.5235025882720947,
    "entropy": 0.04604146629571915,
    "total_loss": -10986.391886654495
  },
  {
    "episode": 126,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11652.155029296875,
    "value_loss": 4.319710373878479,
    "entropy": 0.046509756706655025,
    "total_loss": -11647.85392282568
  },
  {
    "episode": 127,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11687.97802734375,
    "value_loss": 4.319624900817871,
    "entropy": 0.04277794435620308,
    "total_loss": -11683.675513620674
  },
  {
    "episode": 128,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11668.298583984375,
    "value_loss": 4.319520354270935,
    "entropy": 0.0342720951884985,
    "total_loss": -11663.99277246818
  },
  {
    "episode": 129,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11663.802490234375,
    "value_loss": 4.319401144981384,
    "entropy": 0.028654631227254868,
    "total_loss": -11659.494550941885
  },
  {
    "episode": 130,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11661.8505859375,
    "value_loss": 4.319275498390198,
    "entropy": 0.024491018150001764,
    "total_loss": -11657.541106846369
  },
  {
    "episode": 131,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11660.29541015625,
    "value_loss": 4.319149374961853,
    "entropy": 0.021911718416959047,
    "total_loss": -11655.985025468655
  },
  {
    "episode": 132,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11659.384033203125,
    "value_loss": 4.319021940231323,
    "entropy": 0.02027722867205739,
    "total_loss": -11655.073122154363
  },
  {
    "episode": 133,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11658.74365234375,
    "value_loss": 4.318898677825928,
    "entropy": 0.01909342221915722,
    "total_loss": -11654.432391034812
  },
  {
    "episode": 134,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11658.200927734375,
    "value_loss": 4.31877589225769,
    "entropy": 0.018092546612024307,
    "total_loss": -11653.889388860762
  },
  {
    "episode": 135,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11657.617431640625,
    "value_loss": 4.318644046783447,
    "entropy": 0.01721291383728385,
    "total_loss": -11653.305672759376
  },
  {
    "episode": 136,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11657.019287109375,
    "value_loss": 4.318509459495544,
    "entropy": 0.016429454553872347,
    "total_loss": -11652.707349431701
  },
  {
    "episode": 137,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11656.402099609375,
    "value_loss": 4.318375587463379,
    "entropy": 0.015729367500171065,
    "total_loss": -11652.090015768912
  },
  {
    "episode": 138,
    "avg_reward_per_step": 646.665768488776,
    "episode_length": 31,
    "policy_loss": -11655.76220703125,
    "value_loss": 4.3182350397109985,
    "entropy": 0.015104226069524884,
    "total_loss": -11651.450013681966
  },
  {
    "episode": 139,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11926.19482421875,
    "value_loss": 4.562637805938721,
    "entropy": 0.018229322507977486,
    "total_loss": -11921.639478141815
  },
  {
    "episode": 140,
    "avg_reward_per_step": 573.3309229052556,
    "episode_length": 35,
    "policy_loss": -10969.927734375,
    "value_loss": 3.5288246273994446,
    "entropy": 0.08164818212389946,
    "total_loss": -10966.43156902045
  },
  {
    "episode": 141,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11917.4296875,
    "value_loss": 4.5623699426651,
    "entropy": 0.048631384037435055,
    "total_loss": -11912.88677011095
  },
  {
    "episode": 142,
    "avg_reward_per_step": -20.007504030306777,
    "episode_length": 3000,
    "policy_loss": 502.5776138305664,
    "value_loss": 32.59275150299072,
    "entropy": 0.017667553387582302,
    "total_loss": 535.1632983122021
  },
  {
    "episode": 143,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.447265625,
    "value_loss": 4.5632981061935425,
    "entropy": 0.030415577813982964,
    "total_loss": -11857.896133749931
  },
  {
    "episode": 144,
    "avg_reward_per_step": 647.2147755579985,
    "episode_length": 31,
    "policy_loss": -11679.179443359375,
    "value_loss": 4.326348185539246,
    "entropy": 0.08668391965329647,
    "total_loss": -11674.887768741697
  },
  {
    "episode": 145,
    "avg_reward_per_step": 608.1085545494188,
    "episode_length": 33,
    "policy_loss": -11351.190185546875,
    "value_loss": 3.892631471157074,
    "entropy": 0.05605766735970974,
    "total_loss": -11347.319977142663
  },
  {
    "episode": 146,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.931640625,
    "value_loss": 4.563534736633301,
    "entropy": 0.038484648801386356,
    "total_loss": -11861.383499747888
  },
  {
    "episode": 147,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11910.157470703125,
    "value_loss": 4.563554644584656,
    "entropy": 0.051391011103987694,
    "total_loss": -11905.614472462981
  },
  {
    "episode": 148,
    "avg_reward_per_step": -20.080592905222133,
    "episode_length": 3000,
    "policy_loss": 502.3851852416992,
    "value_loss": 42.915236473083496,
    "entropy": 0.020442126784473658,
    "total_loss": 545.292244864069
  },
  {
    "episode": 149,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.9384765625,
    "value_loss": 4.564399242401123,
    "entropy": 0.019500148948282003,
    "total_loss": -11858.381877379677
  },
  {
    "episode": 150,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.40283203125,
    "value_loss": 4.564504861831665,
    "entropy": 0.02653567912057042,
    "total_loss": -11861.848941441067
  },
  {
    "episode": 151,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.24169921875,
    "value_loss": 4.564595937728882,
    "entropy": 0.021178297232836485,
    "total_loss": -11860.685574599915
  },
  {
    "episode": 152,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.03173828125,
    "value_loss": 4.564652323722839,
    "entropy": 0.018348754849284887,
    "total_loss": -11859.474425459466
  },
  {
    "episode": 153,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.968994140625,
    "value_loss": 4.564681887626648,
    "entropy": 0.016783103812485933,
    "total_loss": -11859.411025494523
  },
  {
    "episode": 154,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.0,
    "value_loss": 4.564694762229919,
    "entropy": 0.015603571198880672,
    "total_loss": -11859.44154666625
  },
  {
    "episode": 155,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.978759765625,
    "value_loss": 4.564695835113525,
    "entropy": 0.014619543449953198,
    "total_loss": -11859.419911747891
  },
  {
    "episode": 156,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.908447265625,
    "value_loss": 4.564687013626099,
    "entropy": 0.013785009970888495,
    "total_loss": -11859.349274255987
  },
  {
    "episode": 157,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.80419921875,
    "value_loss": 4.56467604637146,
    "entropy": 0.013072059955447912,
    "total_loss": -11859.24475199636
  },
  {
    "episode": 158,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.68896484375,
    "value_loss": 4.564659953117371,
    "entropy": 0.012459569843485951,
    "total_loss": -11859.12928871857
  },
  {
    "episode": 159,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.56884765625,
    "value_loss": 4.564641356468201,
    "entropy": 0.011924152495339513,
    "total_loss": -11859.00897596078
  },
  {
    "episode": 160,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.441650390625,
    "value_loss": 4.564619421958923,
    "entropy": 0.01145049137994647,
    "total_loss": -11858.881611165218
  },
  {
    "episode": 161,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.312744140625,
    "value_loss": 4.56459653377533,
    "entropy": 0.011026305379346013,
    "total_loss": -11858.752558129001
  },
  {
    "episode": 162,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.184814453125,
    "value_loss": 4.564571738243103,
    "entropy": 0.010642399545758963,
    "total_loss": -11858.624499674701
  },
  {
    "episode": 163,
    "avg_reward_per_step": -20.356098806593945,
    "episode_length": 3000,
    "policy_loss": 505.8066711425781,
    "value_loss": 103.21303749084473,
    "entropy": 0.006806936231441796,
    "total_loss": 609.0169858589303
  },
  {
    "episode": 164,
    "avg_reward_per_step": 668.7716326914923,
    "episode_length": 30,
    "policy_loss": -11864.623046875,
    "value_loss": 4.565670967102051,
    "entropy": 0.009395608678460121,
    "total_loss": -11860.061134151369
  },
  {
    "episode": 165,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.025146484375,
    "value_loss": 4.565798878669739,
    "entropy": 0.009843664709478617,
    "total_loss": -11861.46328507159
  },
  {
    "episode": 166,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.02685546875,
    "value_loss": 4.565914034843445,
    "entropy": 0.009609974222257733,
    "total_loss": -11862.464785423595
  },
  {
    "episode": 167,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.667236328125,
    "value_loss": 4.565986156463623,
    "entropy": 0.009372659493237734,
    "total_loss": -11863.104999235458
  },
  {
    "episode": 168,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.066162109375,
    "value_loss": 4.566026091575623,
    "entropy": 0.009137588320299983,
    "total_loss": -11863.503791053128
  },
  {
    "episode": 169,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.307861328125,
    "value_loss": 4.566051602363586,
    "entropy": 0.008909262251108885,
    "total_loss": -11863.745373430662
  },
  {
    "episode": 170,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.443603515625,
    "value_loss": 4.566060781478882,
    "entropy": 0.008688464993610978,
    "total_loss": -11863.881018120144
  },
  {
    "episode": 171,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.507568359375,
    "value_loss": 4.566063404083252,
    "entropy": 0.008476204006001353,
    "total_loss": -11863.944895436895
  },
  {
    "episode": 172,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.5283203125,
    "value_loss": 4.566059231758118,
    "entropy": 0.0082730648573488,
    "total_loss": -11863.965570306686
  },
  {
    "episode": 173,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.51806640625,
    "value_loss": 4.56605327129364,
    "entropy": 0.008078104816377163,
    "total_loss": -11863.955244376883
  },
  {
    "episode": 174,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.48779296875,
    "value_loss": 4.566045880317688,
    "entropy": 0.007891536690294743,
    "total_loss": -11863.924903703108
  },
  {
    "episode": 175,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.445068359375,
    "value_loss": 4.566035151481628,
    "entropy": 0.007713194354437292,
    "total_loss": -11863.882118485635
  },
  {
    "episode": 176,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.39306640625,
    "value_loss": 4.566022276878357,
    "entropy": 0.007542866398580372,
    "total_loss": -11863.83006127593
  },
  {
    "episode": 177,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.3330078125,
    "value_loss": 4.566009283065796,
    "entropy": 0.007379420450888574,
    "total_loss": -11863.769950297614
  },
  {
    "episode": 178,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.27294921875,
    "value_loss": 4.565998554229736,
    "entropy": 0.007222668617032468,
    "total_loss": -11863.709839731968
  },
  {
    "episode": 179,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.206298828125,
    "value_loss": 4.5659836530685425,
    "entropy": 0.00707225757651031,
    "total_loss": -11863.643144078087
  },
  {
    "episode": 180,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.138671875,
    "value_loss": 4.565971612930298,
    "entropy": 0.006927488138899207,
    "total_loss": -11863.575471257325
  },
  {
    "episode": 181,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.070556640625,
    "value_loss": 4.565958142280579,
    "entropy": 0.006787537015043199,
    "total_loss": -11863.50731351315
  },
  {
    "episode": 182,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11868.00048828125,
    "value_loss": 4.565942406654358,
    "entropy": 0.006652703741565347,
    "total_loss": -11863.437206956092
  },
  {
    "episode": 183,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.929443359375,
    "value_loss": 4.565928816795349,
    "entropy": 0.00652286724653095,
    "total_loss": -11863.366123689479
  },
  {
    "episode": 184,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.855224609375,
    "value_loss": 4.565912961959839,
    "entropy": 0.006398002034984529,
    "total_loss": -11863.291870848228
  },
  {
    "episode": 185,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.783935546875,
    "value_loss": 4.565899133682251,
    "entropy": 0.00627773383166641,
    "total_loss": -11863.220547506726
  },
  {
    "episode": 186,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.708984375,
    "value_loss": 4.5658838748931885,
    "entropy": 0.006161543424241245,
    "total_loss": -11863.145565117477
  },
  {
    "episode": 187,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.6328125,
    "value_loss": 4.565868616104126,
    "entropy": 0.006049203919246793,
    "total_loss": -11863.069363565464
  },
  {
    "episode": 188,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.556884765625,
    "value_loss": 4.565852403640747,
    "entropy": 0.0059406261425465345,
    "total_loss": -11862.993408612441
  },
  {
    "episode": 189,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.47998046875,
    "value_loss": 4.565837740898132,
    "entropy": 0.005835649790242314,
    "total_loss": -11862.916476987768
  },
  {
    "episode": 190,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.400146484375,
    "value_loss": 4.565818190574646,
    "entropy": 0.0057341535575687885,
    "total_loss": -11862.836621955223
  },
  {
    "episode": 191,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.321044921875,
    "value_loss": 4.565803170204163,
    "entropy": 0.005636040819808841,
    "total_loss": -11862.757496167998
  },
  {
    "episode": 192,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.24072265625,
    "value_loss": 4.565788626670837,
    "entropy": 0.0055409923661500216,
    "total_loss": -11862.677150426525
  },
  {
    "episode": 193,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.154052734375,
    "value_loss": 4.565770983695984,
    "entropy": 0.005448909825645387,
    "total_loss": -11862.590461314609
  },
  {
    "episode": 194,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11867.0625,
    "value_loss": 4.565748810768127,
    "entropy": 0.005359828704968095,
    "total_loss": -11862.498895120714
  },
  {
    "episode": 195,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.9697265625,
    "value_loss": 4.565726399421692,
    "entropy": 0.005273352027870715,
    "total_loss": -11862.406109503889
  },
  {
    "episode": 196,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.87646484375,
    "value_loss": 4.565708875656128,
    "entropy": 0.0051888900343328714,
    "total_loss": -11862.312831524108
  },
  {
    "episode": 197,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.78173828125,
    "value_loss": 4.565689325332642,
    "entropy": 0.0051065797451883554,
    "total_loss": -11862.218091587816
  },
  {
    "episode": 198,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.68310546875,
    "value_loss": 4.5656654834747314,
    "entropy": 0.005026467377319932,
    "total_loss": -11862.119450572227
  },
  {
    "episode": 199,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.585205078125,
    "value_loss": 4.565648078918457,
    "entropy": 0.004948540008626878,
    "total_loss": -11862.02153641521
  },
  {
    "episode": 200,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.482421875,
    "value_loss": 4.565624117851257,
    "entropy": 0.004872901481576264,
    "total_loss": -11861.918746917741
  },
  {
    "episode": 201,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.380615234375,
    "value_loss": 4.565603137016296,
    "entropy": 0.004799278220161796,
    "total_loss": -11861.816931808647
  },
  {
    "episode": 202,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.271484375,
    "value_loss": 4.565577983856201,
    "entropy": 0.004727713065221906,
    "total_loss": -11861.70779747637
  },
  {
    "episode": 203,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.162841796875,
    "value_loss": 4.5655529499053955,
    "entropy": 0.004658024292439222,
    "total_loss": -11861.599152056686
  },
  {
    "episode": 204,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11866.0537109375,
    "value_loss": 4.565532207489014,
    "entropy": 0.0045901816338300705,
    "total_loss": -11861.490014802665
  },
  {
    "episode": 205,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.937744140625,
    "value_loss": 4.565503358840942,
    "entropy": 0.004524049232713878,
    "total_loss": -11861.374050401477
  },
  {
    "episode": 206,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.8212890625,
    "value_loss": 4.56547737121582,
    "entropy": 0.004459560266695917,
    "total_loss": -11861.257595515392
  },
  {
    "episode": 207,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.702880859375,
    "value_loss": 4.565450668334961,
    "entropy": 0.004396678530611098,
    "total_loss": -11861.139188862453
  },
  {
    "episode": 208,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.57958984375,
    "value_loss": 4.565422773361206,
    "entropy": 0.0043353792279958725,
    "total_loss": -11861.01590122208
  },
  {
    "episode": 209,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.459228515625,
    "value_loss": 4.565400838851929,
    "entropy": 0.004275675863027573,
    "total_loss": -11860.895537947119
  },
  {
    "episode": 210,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.331787109375,
    "value_loss": 4.565369367599487,
    "entropy": 0.004217411740683019,
    "total_loss": -11860.768104706473
  },
  {
    "episode": 211,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.199462890625,
    "value_loss": 4.565338969230652,
    "entropy": 0.0041605462320148945,
    "total_loss": -11860.635788139887
  },
  {
    "episode": 212,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11865.069580078125,
    "value_loss": 4.565310955047607,
    "entropy": 0.004104988183826208,
    "total_loss": -11860.505911118351
  },
  {
    "episode": 213,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.93115234375,
    "value_loss": 4.56528115272522,
    "entropy": 0.004050579969771206,
    "total_loss": -11860.367491423012
  },
  {
    "episode": 214,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.791748046875,
    "value_loss": 4.5652464628219604,
    "entropy": 0.003997355466708541,
    "total_loss": -11860.22810052624
  },
  {
    "episode": 215,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.64990234375,
    "value_loss": 4.565213918685913,
    "entropy": 0.003945387084968388,
    "total_loss": -11860.086266579898
  },
  {
    "episode": 216,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.505859375,
    "value_loss": 4.565184712409973,
    "entropy": 0.003894597350154072,
    "total_loss": -11859.94223250153
  },
  {
    "episode": 217,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.356201171875,
    "value_loss": 4.565149784088135,
    "entropy": 0.0038448917912319303,
    "total_loss": -11859.792589344503
  },
  {
    "episode": 218,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.20556640625,
    "value_loss": 4.565115451812744,
    "entropy": 0.0037962679052725434,
    "total_loss": -11859.6419694616
  },
  {
    "episode": 219,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11864.052001953125,
    "value_loss": 4.565082430839539,
    "entropy": 0.0037486859364435077,
    "total_loss": -11859.48841899666
  },
  {
    "episode": 220,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.89453125,
    "value_loss": 4.565045118331909,
    "entropy": 0.0037021137541159987,
    "total_loss": -11859.33096697717
  },
  {
    "episode": 221,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.734619140625,
    "value_loss": 4.565008044242859,
    "entropy": 0.0036565003101713955,
    "total_loss": -11859.171073696507
  },
  {
    "episode": 222,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.5693359375,
    "value_loss": 4.564971208572388,
    "entropy": 0.003611791704315692,
    "total_loss": -11859.005809445609
  },
  {
    "episode": 223,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.403076171875,
    "value_loss": 4.564932942390442,
    "entropy": 0.003567996376659721,
    "total_loss": -11858.839570428036
  },
  {
    "episode": 224,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.23388671875,
    "value_loss": 4.564895749092102,
    "entropy": 0.003525105305016041,
    "total_loss": -11858.67040101178
  },
  {
    "episode": 225,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11863.0595703125,
    "value_loss": 4.5648545026779175,
    "entropy": 0.0034829307114705443,
    "total_loss": -11858.496108982106
  },
  {
    "episode": 226,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.882080078125,
    "value_loss": 4.564813494682312,
    "entropy": 0.0034414746332913637,
    "total_loss": -11858.318643173296
  },
  {
    "episode": 227,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.704833984375,
    "value_loss": 4.564774513244629,
    "entropy": 0.0034007818903774023,
    "total_loss": -11858.141419783886
  },
  {
    "episode": 228,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.518798828125,
    "value_loss": 4.564730644226074,
    "entropy": 0.0033609031816013157,
    "total_loss": -11857.955412545172
  },
  {
    "episode": 229,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.332275390625,
    "value_loss": 4.564688444137573,
    "entropy": 0.0033217730815522373,
    "total_loss": -11857.76891565572
  },
  {
    "episode": 230,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11862.143310546875,
    "value_loss": 4.564645171165466,
    "entropy": 0.00328358041588217,
    "total_loss": -11857.579978807877
  },
  {
    "episode": 231,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11861.953369140625,
    "value_loss": 4.564602971076965,
    "entropy": 0.003246101608965546,
    "total_loss": -11857.390064610192
  },
  {
    "episode": 232,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11861.75390625,
    "value_loss": 4.564554691314697,
    "entropy": 0.0032092821784317493,
    "total_loss": -11857.190635271556
  },
  {
    "episode": 233,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11861.552978515625,
    "value_loss": 4.564511179924011,
    "entropy": 0.0031731529743410647,
    "total_loss": -11856.98973659689
  },
  {
    "episode": 234,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11861.349365234375,
    "value_loss": 4.56446385383606,
    "entropy": 0.0031376773840747774,
    "total_loss": -11856.786156451493
  },
  {
    "episode": 235,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11861.143310546875,
    "value_loss": 4.564414858818054,
    "entropy": 0.0031028541270643473,
    "total_loss": -11856.580136829707
  },
  {
    "episode": 236,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11860.933349609375,
    "value_loss": 4.564368724822998,
    "entropy": 0.003068661317229271,
    "total_loss": -11856.370208349079
  },
  {
    "episode": 237,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11860.71875,
    "value_loss": 4.564318656921387,
    "entropy": 0.0030351814930327237,
    "total_loss": -11856.155645415676
  },
  {
    "episode": 238,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11860.500244140625,
    "value_loss": 4.564267516136169,
    "entropy": 0.003002321580424905,
    "total_loss": -11855.937177553122
  },
  {
    "episode": 239,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11860.276123046875,
    "value_loss": 4.56421434879303,
    "entropy": 0.0029700006125494838,
    "total_loss": -11855.713096698328
  },
  {
    "episode": 240,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11860.05322265625,
    "value_loss": 4.564165949821472,
    "entropy": 0.002938288322184235,
    "total_loss": -11855.490232021757
  },
  {
    "episode": 241,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11859.820068359375,
    "value_loss": 4.564110279083252,
    "entropy": 0.002907129586674273,
    "total_loss": -11855.257120932127
  },
  {
    "episode": 242,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11859.58544921875,
    "value_loss": 4.5640541315078735,
    "entropy": 0.0028764924500137568,
    "total_loss": -11855.022545684222
  },
  {
    "episode": 243,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11859.352294921875,
    "value_loss": 4.564004898071289,
    "entropy": 0.0028464693459682167,
    "total_loss": -11854.789428611542
  },
  {
    "episode": 244,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11859.1083984375,
    "value_loss": 4.563948035240173,
    "entropy": 0.002816921391058713,
    "total_loss": -11854.545577170817
  },
  {
    "episode": 245,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11858.8662109375,
    "value_loss": 4.563890695571899,
    "entropy": 0.002787778852507472,
    "total_loss": -11854.30343535347
  },
  {
    "episode": 246,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11858.618896484375,
    "value_loss": 4.563835620880127,
    "entropy": 0.0027590381214395165,
    "total_loss": -11854.056164478743
  },
  {
    "episode": 247,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11858.361328125,
    "value_loss": 4.563774824142456,
    "entropy": 0.0027308196295052767,
    "total_loss": -11853.798645628709
  },
  {
    "episode": 248,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11858.107177734375,
    "value_loss": 4.5637160539627075,
    "entropy": 0.0027030908968299627,
    "total_loss": -11853.54454291677
  },
  {
    "episode": 249,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11857.84423828125,
    "value_loss": 4.563653349876404,
    "entropy": 0.002675792609807104,
    "total_loss": -11853.281655248418
  },
  {
    "episode": 250,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11857.580810546875,
    "value_loss": 4.563594102859497,
    "entropy": 0.0026488876901566982,
    "total_loss": -11853.018275999091
  },
  {
    "episode": 251,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11857.3125,
    "value_loss": 4.563533782958984,
    "entropy": 0.0026224128087051213,
    "total_loss": -11852.750015182164
  },
  {
    "episode": 252,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11857.03662109375,
    "value_loss": 4.563466906547546,
    "entropy": 0.0025963211082853377,
    "total_loss": -11852.474192715646
  },
  {
    "episode": 253,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11856.76123046875,
    "value_loss": 4.5634026527404785,
    "entropy": 0.002570668584667146,
    "total_loss": -11852.198856083443
  },
  {
    "episode": 254,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11856.482177734375,
    "value_loss": 4.563340187072754,
    "entropy": 0.002545391151215881,
    "total_loss": -11851.919855703763
  },
  {
    "episode": 255,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11856.19482421875,
    "value_loss": 4.5632710456848145,
    "entropy": 0.0025204839184880257,
    "total_loss": -11851.632561366632
  },
  {
    "episode": 256,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11855.907470703125,
    "value_loss": 4.56320595741272,
    "entropy": 0.0024958241847343743,
    "total_loss": -11851.345263075385
  },
  {
    "episode": 257,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11855.613037109375,
    "value_loss": 4.563137054443359,
    "entropy": 0.002471515443176031,
    "total_loss": -11851.05088866111
  },
  {
    "episode": 258,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11855.31396484375,
    "value_loss": 4.563063025474548,
    "entropy": 0.002447586681228131,
    "total_loss": -11850.751880852948
  },
  {
    "episode": 259,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11855.013671875,
    "value_loss": 4.562996983528137,
    "entropy": 0.0024239940685220063,
    "total_loss": -11850.4516444891
  },
  {
    "episode": 260,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11854.708984375,
    "value_loss": 4.562926530838013,
    "entropy": 0.0024007432512007654,
    "total_loss": -11850.147018141462
  },
  {
    "episode": 261,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11854.399658203125,
    "value_loss": 4.562855124473572,
    "entropy": 0.0023777466267347336,
    "total_loss": -11849.837754177302
  },
  {
    "episode": 262,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11854.084228515625,
    "value_loss": 4.56277859210968,
    "entropy": 0.0023551551857963204,
    "total_loss": -11849.522391985589
  },
  {
    "episode": 263,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11853.770263671875,
    "value_loss": 4.562710404396057,
    "entropy": 0.002332873293198645,
    "total_loss": -11849.208486416795
  },
  {
    "episode": 264,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11853.44677734375,
    "value_loss": 4.562632203102112,
    "entropy": 0.0023109051398932934,
    "total_loss": -11848.885069502703
  },
  {
    "episode": 265,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11853.12109375,
    "value_loss": 4.562557697296143,
    "entropy": 0.0022892578854225576,
    "total_loss": -11848.559451755858
  },
  {
    "episode": 266,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11852.7900390625,
    "value_loss": 4.562480688095093,
    "entropy": 0.0022679088287986815,
    "total_loss": -11848.228465537937
  },
  {
    "episode": 267,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11852.456298828125,
    "value_loss": 4.5624037981033325,
    "entropy": 0.0022468790994025767,
    "total_loss": -11847.894793781661
  },
  {
    "episode": 268,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11852.1171875,
    "value_loss": 4.562321186065674,
    "entropy": 0.002226144715677947,
    "total_loss": -11847.55575677182
  },
  {
    "episode": 269,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11851.77294921875,
    "value_loss": 4.562240242958069,
    "entropy": 0.0022057127207517624,
    "total_loss": -11847.21159126088
  },
  {
    "episode": 270,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11851.42822265625,
    "value_loss": 4.562161207199097,
    "entropy": 0.0021855676313862205,
    "total_loss": -11846.866935676104
  },
  {
    "episode": 271,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11851.07568359375,
    "value_loss": 4.5620774030685425,
    "entropy": 0.0021657117758877575,
    "total_loss": -11846.514472475392
  },
  {
    "episode": 272,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11850.72216796875,
    "value_loss": 4.561997771263123,
    "entropy": 0.0021461747819557786,
    "total_loss": -11846.1610286674
  },
  {
    "episode": 273,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11850.364990234375,
    "value_loss": 4.561914086341858,
    "entropy": 0.0021269519347697496,
    "total_loss": -11845.803926928807
  },
  {
    "episode": 274,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11850.00146484375,
    "value_loss": 4.561829090118408,
    "entropy": 0.002107987296767533,
    "total_loss": -11845.44047894855
  },
  {
    "episode": 275,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11849.632568359375,
    "value_loss": 4.561740279197693,
    "entropy": 0.002089276153128594,
    "total_loss": -11845.071663790639
  },
  {
    "episode": 276,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11849.261474609375,
    "value_loss": 4.561655163764954,
    "entropy": 0.002070835733320564,
    "total_loss": -11844.700647779904
  },
  {
    "episode": 277,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11848.886962890625,
    "value_loss": 4.5615681409835815,
    "entropy": 0.0020526281441561878,
    "total_loss": -11844.326215800898
  },
  {
    "episode": 278,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11848.504150390625,
    "value_loss": 4.561476349830627,
    "entropy": 0.0020346540259197354,
    "total_loss": -11843.943487902405
  },
  {
    "episode": 279,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11848.119384765625,
    "value_loss": 4.561388254165649,
    "entropy": 0.002016857441049069,
    "total_loss": -11843.558803254436
  },
  {
    "episode": 280,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11847.73486328125,
    "value_loss": 4.561299920082092,
    "entropy": 0.001999247702769935,
    "total_loss": -11843.174363060249
  },
  {
    "episode": 281,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11847.33935546875,
    "value_loss": 4.561205863952637,
    "entropy": 0.0019818421569652855,
    "total_loss": -11842.77894234166
  },
  {
    "episode": 282,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11846.943603515625,
    "value_loss": 4.561115384101868,
    "entropy": 0.0019646493019536138,
    "total_loss": -11842.383273991243
  },
  {
    "episode": 283,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11846.542236328125,
    "value_loss": 4.561017394065857,
    "entropy": 0.0019477061869110912,
    "total_loss": -11841.981998016534
  },
  {
    "episode": 284,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11846.136962890625,
    "value_loss": 4.560924768447876,
    "entropy": 0.0019309684867039323,
    "total_loss": -11841.576810509572
  },
  {
    "episode": 285,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11845.72705078125,
    "value_loss": 4.560830235481262,
    "entropy": 0.001914425054565072,
    "total_loss": -11841.166986315791
  },
  {
    "episode": 286,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11845.31201171875,
    "value_loss": 4.560730576515198,
    "entropy": 0.001898105489090085,
    "total_loss": -11840.75204038443
  },
  {
    "episode": 287,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11844.89208984375,
    "value_loss": 4.560631036758423,
    "entropy": 0.0018819904362317175,
    "total_loss": -11840.332211603167
  },
  {
    "episode": 288,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11844.470458984375,
    "value_loss": 4.560534477233887,
    "entropy": 0.0018660899077076465,
    "total_loss": -11839.910670943103
  },
  {
    "episode": 289,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11844.043212890625,
    "value_loss": 4.560434699058533,
    "entropy": 0.001850365661084652,
    "total_loss": -11839.48351833783
  },
  {
    "episode": 290,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11843.613037109375,
    "value_loss": 4.560335397720337,
    "entropy": 0.0018348405428696424,
    "total_loss": -11839.053435647871
  },
  {
    "episode": 291,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11843.173583984375,
    "value_loss": 4.560229659080505,
    "entropy": 0.0018195096927229315,
    "total_loss": -11838.614082129172
  },
  {
    "episode": 292,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11842.7353515625,
    "value_loss": 4.560130000114441,
    "entropy": 0.0018043587624561042,
    "total_loss": -11838.17594330589
  },
  {
    "episode": 293,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11842.288818359375,
    "value_loss": 4.560022354125977,
    "entropy": 0.001789391360944137,
    "total_loss": -11837.729511761794
  },
  {
    "episode": 294,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11841.839599609375,
    "value_loss": 4.559917449951172,
    "entropy": 0.0017746037628967315,
    "total_loss": -11837.280392000928
  },
  {
    "episode": 295,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11841.384765625,
    "value_loss": 4.559810996055603,
    "entropy": 0.0017600189603399485,
    "total_loss": -11836.825658636528
  },
  {
    "episode": 296,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11840.928466796875,
    "value_loss": 4.559703469276428,
    "entropy": 0.001745601970469579,
    "total_loss": -11836.369461568387
  },
  {
    "episode": 297,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11840.464599609375,
    "value_loss": 4.559594631195068,
    "entropy": 0.0017313630669377744,
    "total_loss": -11835.905697523407
  },
  {
    "episode": 298,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11840.000244140625,
    "value_loss": 4.5594892501831055,
    "entropy": 0.0017173051892314106,
    "total_loss": -11835.441441812518
  },
  {
    "episode": 299,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11839.528564453125,
    "value_loss": 4.559376358985901,
    "entropy": 0.0017034078773576766,
    "total_loss": -11834.96986945729
  },
  {
    "episode": 300,
    "avg_reward_per_step": 668.7716326896863,
    "episode_length": 30,
    "policy_loss": -11839.05224609375,
    "value_loss": 4.559261679649353,
    "entropy": 0.0016896874876692891,
    "total_loss": -11834.493660289096
  }
]