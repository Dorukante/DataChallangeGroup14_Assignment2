[
  {
    "episode": 1,
    "avg_reward_per_step": 15.482164460601062,
    "episode_length": 1191,
    "policy_loss": -264.35546112060547,
    "value_loss": 0.5115133374929428,
    "entropy": 1.378747582435608,
    "total_loss": -264.39544681608675
  },
  {
    "episode": 2,
    "avg_reward_per_step": 25.901538713104348,
    "episode_length": 731,
    "policy_loss": -441.65636444091797,
    "value_loss": 0.5201716274023056,
    "entropy": 1.381075531244278,
    "total_loss": -441.6886230260134
  },
  {
    "episode": 3,
    "avg_reward_per_step": -1.4455108550618303,
    "episode_length": 3000,
    "policy_loss": 24.194653034210205,
    "value_loss": 1.357699990272522,
    "entropy": 1.3758139610290527,
    "total_loss": 25.002027440071107
  },
  {
    "episode": 4,
    "avg_reward_per_step": -1.4154867360734225,
    "episode_length": 3000,
    "policy_loss": 23.595044136047363,
    "value_loss": 1.4236585199832916,
    "entropy": 1.3731226921081543,
    "total_loss": 24.469453579187395
  },
  {
    "episode": 5,
    "avg_reward_per_step": -1.5050663821675339,
    "episode_length": 3000,
    "policy_loss": 25.073227882385254,
    "value_loss": 1.2155847549438477,
    "entropy": 1.3686849772930145,
    "total_loss": 25.741338646411897
  },
  {
    "episode": 6,
    "avg_reward_per_step": 12.922645053722249,
    "episode_length": 1363,
    "policy_loss": -219.56578826904297,
    "value_loss": 0.5090888291597366,
    "entropy": 1.361693799495697,
    "total_loss": -219.60137695968152
  },
  {
    "episode": 7,
    "avg_reward_per_step": -1.4178699133829091,
    "episode_length": 3000,
    "policy_loss": 23.505050659179688,
    "value_loss": 1.3755155801773071,
    "entropy": 1.358984887599945,
    "total_loss": 24.336972284317017
  },
  {
    "episode": 8,
    "avg_reward_per_step": -1.6748449673064922,
    "episode_length": 3000,
    "policy_loss": 28.062384605407715,
    "value_loss": 1.1269021332263947,
    "entropy": 1.3521443903446198,
    "total_loss": 28.648428982496263
  },
  {
    "episode": 9,
    "avg_reward_per_step": 8.137793778973087,
    "episode_length": 2082,
    "policy_loss": -138.94329071044922,
    "value_loss": 0.505450889468193,
    "entropy": 1.3568030297756195,
    "total_loss": -138.98056103289127
  },
  {
    "episode": 10,
    "avg_reward_per_step": 27.39390417532927,
    "episode_length": 692,
    "policy_loss": -466.08741760253906,
    "value_loss": 0.5214390605688095,
    "entropy": 1.3384154438972473,
    "total_loss": -466.10134471952915
  },
  {
    "episode": 11,
    "avg_reward_per_step": 27.358573087904002,
    "episode_length": 700,
    "policy_loss": -461.5757751464844,
    "value_loss": 0.521636426448822,
    "entropy": 1.351726472377777,
    "total_loss": -461.5948293089867
  },
  {
    "episode": 12,
    "avg_reward_per_step": -1.786705681614331,
    "episode_length": 3000,
    "policy_loss": 29.715985774993896,
    "value_loss": 0.9594980776309967,
    "entropy": 1.3336987495422363,
    "total_loss": 30.142004352807998
  },
  {
    "episode": 13,
    "avg_reward_per_step": 8.992407402564304,
    "episode_length": 1910,
    "policy_loss": -152.74632263183594,
    "value_loss": 0.5061307102441788,
    "entropy": 1.2992813885211945,
    "total_loss": -152.75990447700025
  },
  {
    "episode": 14,
    "avg_reward_per_step": 7.7135849591337395,
    "episode_length": 2218,
    "policy_loss": -129.99284744262695,
    "value_loss": 0.5052423030138016,
    "entropy": 1.3453007936477661,
    "total_loss": -130.02572545707227
  },
  {
    "episode": 15,
    "avg_reward_per_step": 16.67430869754245,
    "episode_length": 1124,
    "policy_loss": -284.4691619873047,
    "value_loss": 0.512664794921875,
    "entropy": 1.3223945796489716,
    "total_loss": -284.4854550242424
  },
  {
    "episode": 16,
    "avg_reward_per_step": 15.422032328374408,
    "episode_length": 1194,
    "policy_loss": -264.0609817504883,
    "value_loss": 0.5114580690860748,
    "entropy": 1.2780316174030304,
    "total_loss": -264.0607363283634
  },
  {
    "episode": 17,
    "avg_reward_per_step": 12.92903308931555,
    "episode_length": 1378,
    "policy_loss": -218.01050186157227,
    "value_loss": 0.5092115700244904,
    "entropy": 1.281170666217804,
    "total_loss": -218.0137585580349
  },
  {
    "episode": 18,
    "avg_reward_per_step": 16.209348707007738,
    "episode_length": 1128,
    "policy_loss": -275.2409896850586,
    "value_loss": 0.5119462460279465,
    "entropy": 1.2927131354808807,
    "total_loss": -275.246128693223
  },
  {
    "episode": 19,
    "avg_reward_per_step": -1.2809279630839818,
    "episode_length": 3000,
    "policy_loss": 21.02512788772583,
    "value_loss": 0.8086355626583099,
    "entropy": 1.2819865942001343,
    "total_loss": 21.320968812704088
  },
  {
    "episode": 20,
    "avg_reward_per_step": 110.10667752638905,
    "episode_length": 182,
    "policy_loss": -1875.4703674316406,
    "value_loss": 0.6059775501489639,
    "entropy": 1.0946477949619293,
    "total_loss": -1875.3022489994764
  },
  {
    "episode": 21,
    "avg_reward_per_step": -1.7657278100526554,
    "episode_length": 3000,
    "policy_loss": 29.030444145202637,
    "value_loss": 1.090417206287384,
    "entropy": 1.2698741555213928,
    "total_loss": 29.612911689281464
  },
  {
    "episode": 22,
    "avg_reward_per_step": 32.35795092328104,
    "episode_length": 595,
    "policy_loss": -545.1112976074219,
    "value_loss": 0.5259038209915161,
    "entropy": 1.2536589801311493,
    "total_loss": -545.0868573784828
  },
  {
    "episode": 23,
    "avg_reward_per_step": 7.401520730743923,
    "episode_length": 2274,
    "policy_loss": -124.8806381225586,
    "value_loss": 0.5049697160720825,
    "entropy": 1.250311255455017,
    "total_loss": -124.87579290866852
  },
  {
    "episode": 24,
    "avg_reward_per_step": 6.091212419536337,
    "episode_length": 2716,
    "policy_loss": -103.46497535705566,
    "value_loss": 0.5040011405944824,
    "entropy": 1.2809916734695435,
    "total_loss": -103.473370885849
  },
  {
    "episode": 25,
    "avg_reward_per_step": 43.87132970173434,
    "episode_length": 447,
    "policy_loss": -741.0583648681641,
    "value_loss": 0.5364539474248886,
    "entropy": 1.0961681008338928,
    "total_loss": -740.9603781610728
  },
  {
    "episode": 26,
    "avg_reward_per_step": 36.7673073116594,
    "episode_length": 537,
    "policy_loss": -623.8506011962891,
    "value_loss": 0.5304182469844818,
    "entropy": 1.2163248360157013,
    "total_loss": -623.8067128837108
  },
  {
    "episode": 27,
    "avg_reward_per_step": 30.72980178235101,
    "episode_length": 634,
    "policy_loss": -518.5908355712891,
    "value_loss": 0.5248800814151764,
    "entropy": 1.2035592794418335,
    "total_loss": -518.5473792016506
  },
  {
    "episode": 28,
    "avg_reward_per_step": -1.0980989987875753,
    "episode_length": 3000,
    "policy_loss": 17.630793571472168,
    "value_loss": 0.6966158598661423,
    "entropy": 1.2225197553634644,
    "total_loss": 17.838401529192925
  },
  {
    "episode": 29,
    "avg_reward_per_step": -1.2407853132538502,
    "episode_length": 3000,
    "policy_loss": 20.034437656402588,
    "value_loss": 0.6850826591253281,
    "entropy": 1.1924687027931213,
    "total_loss": 20.242532834410667
  },
  {
    "episode": 30,
    "avg_reward_per_step": 20.613305199724795,
    "episode_length": 894,
    "policy_loss": -348.2312240600586,
    "value_loss": 0.515402227640152,
    "entropy": 1.143513798713684,
    "total_loss": -348.1732273519039
  },
  {
    "episode": 31,
    "avg_reward_per_step": 12.503563121937066,
    "episode_length": 1499,
    "policy_loss": -212.30715942382812,
    "value_loss": 0.5094598829746246,
    "entropy": 1.1964387893676758,
    "total_loss": -212.27627505660058
  },
  {
    "episode": 32,
    "avg_reward_per_step": -1.0655658370288705,
    "episode_length": 3000,
    "policy_loss": 16.943017959594727,
    "value_loss": 0.777804508805275,
    "entropy": 1.1963030993938446,
    "total_loss": 17.242301228642464
  },
  {
    "episode": 33,
    "avg_reward_per_step": -0.9481393052877687,
    "episode_length": 3000,
    "policy_loss": 14.943763494491577,
    "value_loss": 0.6525646150112152,
    "entropy": 1.1811456084251404,
    "total_loss": 15.123869866132736
  },
  {
    "episode": 34,
    "avg_reward_per_step": -0.4194610083081688,
    "episode_length": 3000,
    "policy_loss": 5.9680434465408325,
    "value_loss": 0.5420423001050949,
    "entropy": 1.1934641301631927,
    "total_loss": 6.03270009458065
  },
  {
    "episode": 35,
    "avg_reward_per_step": 14.296851579069296,
    "episode_length": 1390,
    "policy_loss": -244.64072799682617,
    "value_loss": 0.5115974247455597,
    "entropy": 1.1660694777965546,
    "total_loss": -244.59555836319925
  },
  {
    "episode": 36,
    "avg_reward_per_step": -0.1059104835799773,
    "episode_length": 3000,
    "policy_loss": 0.44475214183330536,
    "value_loss": 0.5014625787734985,
    "entropy": 1.1327116191387177,
    "total_loss": 0.49313007295131683
  },
  {
    "episode": 37,
    "avg_reward_per_step": 7.914091126851125,
    "episode_length": 2230,
    "policy_loss": -134.31066131591797,
    "value_loss": 0.5056057423353195,
    "entropy": 1.1249383687973022,
    "total_loss": -134.25503092110156
  },
  {
    "episode": 38,
    "avg_reward_per_step": 17.634751711259288,
    "episode_length": 1085,
    "policy_loss": -300.94288635253906,
    "value_loss": 0.51380755007267,
    "entropy": 1.1717680394649506,
    "total_loss": -300.89778601825236
  },
  {
    "episode": 39,
    "avg_reward_per_step": 6.071019953848813,
    "episode_length": 2883,
    "policy_loss": -105.35720634460449,
    "value_loss": 0.5042682737112045,
    "entropy": 1.1746695637702942,
    "total_loss": -105.3228058964014
  },
  {
    "episode": 40,
    "avg_reward_per_step": -1.0041006801029064,
    "episode_length": 3000,
    "policy_loss": 15.542397022247314,
    "value_loss": 0.7602178901433945,
    "entropy": 1.2201864123344421,
    "total_loss": 15.814540347456932
  },
  {
    "episode": 41,
    "avg_reward_per_step": -0.5800641902997388,
    "episode_length": 3000,
    "policy_loss": 8.424295902252197,
    "value_loss": 0.5906661152839661,
    "entropy": 1.2583755850791931,
    "total_loss": 8.511611783504486
  },
  {
    "episode": 42,
    "avg_reward_per_step": 7.084870276040413,
    "episode_length": 2594,
    "policy_loss": -120.8011589050293,
    "value_loss": 0.5052616745233536,
    "entropy": 1.2644120454788208,
    "total_loss": -120.80166204869747
  },
  {
    "episode": 43,
    "avg_reward_per_step": 226.91653294997576,
    "episode_length": 89,
    "policy_loss": -3873.0690307617188,
    "value_loss": 0.7831458002328873,
    "entropy": 1.0318039953708649,
    "total_loss": -3872.6986065596343
  },
  {
    "episode": 44,
    "avg_reward_per_step": -1.2653795918833075,
    "episode_length": 3000,
    "policy_loss": 19.77800989151001,
    "value_loss": 0.7493578344583511,
    "entropy": 1.2189562320709229,
    "total_loss": 20.03978523313999
  },
  {
    "episode": 45,
    "avg_reward_per_step": -0.8354911427567405,
    "episode_length": 3000,
    "policy_loss": 12.34140920639038,
    "value_loss": 0.7301363945007324,
    "entropy": 1.2605873942375183,
    "total_loss": 12.567310643196105
  },
  {
    "episode": 46,
    "avg_reward_per_step": 12.623107760080492,
    "episode_length": 1468,
    "policy_loss": -214.77312850952148,
    "value_loss": 0.5094412267208099,
    "entropy": 1.13682359457016,
    "total_loss": -214.71841672062874
  },
  {
    "episode": 47,
    "avg_reward_per_step": 9.726543960989039,
    "episode_length": 1875,
    "policy_loss": -167.14025497436523,
    "value_loss": 0.5071390122175217,
    "entropy": 1.126306414604187,
    "total_loss": -167.0836385279894
  },
  {
    "episode": 48,
    "avg_reward_per_step": 20.669661496766928,
    "episode_length": 935,
    "policy_loss": -358.56563568115234,
    "value_loss": 0.5162900686264038,
    "entropy": 1.2107174694538116,
    "total_loss": -358.53363260030744
  },
  {
    "episode": 49,
    "avg_reward_per_step": 15.09422585705795,
    "episode_length": 1239,
    "policy_loss": -258.73841094970703,
    "value_loss": 0.511429637670517,
    "entropy": 1.0657233893871307,
    "total_loss": -258.6532706677914
  },
  {
    "episode": 50,
    "avg_reward_per_step": 19.40904840813242,
    "episode_length": 986,
    "policy_loss": -330.01000213623047,
    "value_loss": 0.5149915814399719,
    "entropy": 1.006241351366043,
    "total_loss": -329.8975070953369
  },
  {
    "episode": 51,
    "avg_reward_per_step": 12.000550946174304,
    "episode_length": 1555,
    "policy_loss": -204.92746353149414,
    "value_loss": 0.5089704841375351,
    "entropy": 0.9263457208871841,
    "total_loss": -204.78903133571148
  },
  {
    "episode": 52,
    "avg_reward_per_step": -1.3429573610623236,
    "episode_length": 3000,
    "policy_loss": 20.623961925506592,
    "value_loss": 0.5609471201896667,
    "entropy": 0.8747308999300003,
    "total_loss": 20.83501668572426
  },
  {
    "episode": 53,
    "avg_reward_per_step": -1.1303914594378546,
    "episode_length": 3000,
    "policy_loss": 17.03593349456787,
    "value_loss": 0.5457430481910706,
    "entropy": 0.9049044549465179,
    "total_loss": 17.219714760780334
  },
  {
    "episode": 54,
    "avg_reward_per_step": -0.9510674576109469,
    "episode_length": 3000,
    "policy_loss": 13.937422037124634,
    "value_loss": 0.5280570685863495,
    "entropy": 0.83445805311203,
    "total_loss": 14.131695884466172
  },
  {
    "episode": 55,
    "avg_reward_per_step": -0.964074520311415,
    "episode_length": 3000,
    "policy_loss": 14.116120100021362,
    "value_loss": 0.5278640240430832,
    "entropy": 0.8051976263523102,
    "total_loss": 14.32190507352352
  },
  {
    "episode": 56,
    "avg_reward_per_step": -1.0908803651143995,
    "episode_length": 3000,
    "policy_loss": 16.19315195083618,
    "value_loss": 0.5435105711221695,
    "entropy": 0.8207584917545319,
    "total_loss": 16.40835912525654
  },
  {
    "episode": 57,
    "avg_reward_per_step": 6.168868235390339,
    "episode_length": 2819,
    "policy_loss": -106.22062873840332,
    "value_loss": 0.5042108446359634,
    "entropy": 0.8033487945795059,
    "total_loss": -106.03775741159916
  },
  {
    "episode": 58,
    "avg_reward_per_step": -1.333669469361115,
    "episode_length": 3000,
    "policy_loss": 20.15859889984131,
    "value_loss": 0.557839885354042,
    "entropy": 0.8110245913267136,
    "total_loss": 20.392028948664667
  },
  {
    "episode": 59,
    "avg_reward_per_step": 18.33546523265769,
    "episode_length": 1043,
    "policy_loss": -315.85376739501953,
    "value_loss": 0.5142060667276382,
    "entropy": 0.8570656329393387,
    "total_loss": -315.68238758146765
  },
  {
    "episode": 60,
    "avg_reward_per_step": -1.2786442116554333,
    "episode_length": 3000,
    "policy_loss": 18.817330837249756,
    "value_loss": 0.5575985610485077,
    "entropy": 0.946413516998291,
    "total_loss": 18.996363991498946
  },
  {
    "episode": 61,
    "avg_reward_per_step": 14.70992463869195,
    "episode_length": 1280,
    "policy_loss": -255.16299438476562,
    "value_loss": 0.5112385898828506,
    "entropy": 0.887043297290802,
    "total_loss": -255.0065731137991
  },
  {
    "episode": 62,
    "avg_reward_per_step": 12.466415338340939,
    "episode_length": 1481,
    "policy_loss": -220.4820213317871,
    "value_loss": 0.5092163383960724,
    "entropy": 1.1042627394199371,
    "total_loss": -220.41451008915902
  },
  {
    "episode": 63,
    "avg_reward_per_step": 7.341235964590035,
    "episode_length": 2468,
    "policy_loss": -128.26408004760742,
    "value_loss": 0.5053699463605881,
    "entropy": 1.1522276997566223,
    "total_loss": -128.21960118114947
  },
  {
    "episode": 64,
    "avg_reward_per_step": 7.729303844023341,
    "episode_length": 2378,
    "policy_loss": -133.8486328125,
    "value_loss": 0.5057791322469711,
    "entropy": 1.0551978051662445,
    "total_loss": -133.76493280231952
  },
  {
    "episode": 65,
    "avg_reward_per_step": -0.8665510887210223,
    "episode_length": 3000,
    "policy_loss": 12.003100872039795,
    "value_loss": 0.7777609378099442,
    "entropy": 1.02186918258667,
    "total_loss": 12.372114136815071
  },
  {
    "episode": 66,
    "avg_reward_per_step": -0.6602726072544406,
    "episode_length": 3000,
    "policy_loss": 8.557522296905518,
    "value_loss": 0.8017077744007111,
    "entropy": 1.0144624412059784,
    "total_loss": 8.953445094823838
  },
  {
    "episode": 67,
    "avg_reward_per_step": 13.944187627445142,
    "episode_length": 1363,
    "policy_loss": -238.82048797607422,
    "value_loss": 0.5109528750181198,
    "entropy": 0.9272717386484146,
    "total_loss": -238.68044379651548
  },
  {
    "episode": 68,
    "avg_reward_per_step": 8.259394649670734,
    "episode_length": 2222,
    "policy_loss": -145.18007278442383,
    "value_loss": 0.5063169598579407,
    "entropy": 0.9559002071619034,
    "total_loss": -145.05611590743064
  },
  {
    "episode": 69,
    "avg_reward_per_step": 27.24621756358329,
    "episode_length": 724,
    "policy_loss": -489.68248748779297,
    "value_loss": 0.5224057286977768,
    "entropy": 1.0165257453918457,
    "total_loss": -489.56669205725194
  },
  {
    "episode": 70,
    "avg_reward_per_step": 15.898356217532283,
    "episode_length": 1197,
    "policy_loss": -277.3712692260742,
    "value_loss": 0.512527585029602,
    "entropy": 1.029733031988144,
    "total_loss": -277.27063485383985
  },
  {
    "episode": 71,
    "avg_reward_per_step": 15.021561128102414,
    "episode_length": 1274,
    "policy_loss": -257.9800338745117,
    "value_loss": 0.5117247104644775,
    "entropy": 1.0487278997898102,
    "total_loss": -257.8878003239632
  },
  {
    "episode": 72,
    "avg_reward_per_step": 29.134536095818003,
    "episode_length": 672,
    "policy_loss": -514.8874588012695,
    "value_loss": 0.5235721617937088,
    "entropy": 0.9326820820569992,
    "total_loss": -514.7369594722986
  },
  {
    "episode": 73,
    "avg_reward_per_step": 69.21981753857193,
    "episode_length": 288,
    "policy_loss": -1202.7898864746094,
    "value_loss": 0.5618744790554047,
    "entropy": 0.7494826167821884,
    "total_loss": -1202.527805042267
  },
  {
    "episode": 74,
    "avg_reward_per_step": 53.25286771448006,
    "episode_length": 375,
    "policy_loss": -932.0627746582031,
    "value_loss": 0.5460289120674133,
    "entropy": 0.6910301446914673,
    "total_loss": -931.7931578040123
  },
  {
    "episode": 75,
    "avg_reward_per_step": 65.37181314425646,
    "episode_length": 304,
    "policy_loss": -1125.3741760253906,
    "value_loss": 0.5575452148914337,
    "entropy": 0.6016411036252975,
    "total_loss": -1125.0572872519492
  },
  {
    "episode": 76,
    "avg_reward_per_step": 47.119768957669734,
    "episode_length": 421,
    "policy_loss": -807.4569244384766,
    "value_loss": 0.539953276515007,
    "entropy": 0.50239197909832,
    "total_loss": -807.1179279536009
  },
  {
    "episode": 77,
    "avg_reward_per_step": 47.10110652506698,
    "episode_length": 419,
    "policy_loss": -800.2588500976562,
    "value_loss": 0.5398090332746506,
    "entropy": 0.4396168738603592,
    "total_loss": -799.8948878139257
  },
  {
    "episode": 78,
    "avg_reward_per_step": 25.889874783620336,
    "episode_length": 745,
    "policy_loss": -440.2885284423828,
    "value_loss": 0.5206060111522675,
    "entropy": 0.5022818520665169,
    "total_loss": -439.96883517205714
  },
  {
    "episode": 79,
    "avg_reward_per_step": 63.51052279874613,
    "episode_length": 314,
    "policy_loss": -1074.4477844238281,
    "value_loss": 0.5558974146842957,
    "entropy": 0.46075108647346497,
    "total_loss": -1074.0761874437333
  },
  {
    "episode": 80,
    "avg_reward_per_step": 37.101025697846424,
    "episode_length": 528,
    "policy_loss": -634.7953186035156,
    "value_loss": 0.530538335442543,
    "entropy": 0.39854222536087036,
    "total_loss": -634.4241971582175
  },
  {
    "episode": 81,
    "avg_reward_per_step": 106.20329664991063,
    "episode_length": 189,
    "policy_loss": -1805.5277099609375,
    "value_loss": 0.6018373966217041,
    "entropy": 0.3604762926697731,
    "total_loss": -1805.0700630813838
  },
  {
    "episode": 82,
    "avg_reward_per_step": 64.51201660663004,
    "episode_length": 309,
    "policy_loss": -1102.0872192382812,
    "value_loss": 0.5568109154701233,
    "entropy": 0.4036441594362259,
    "total_loss": -1101.6918659865855
  },
  {
    "episode": 83,
    "avg_reward_per_step": 48.88786697188527,
    "episode_length": 406,
    "policy_loss": -854.3120880126953,
    "value_loss": 0.5416949987411499,
    "entropy": 0.3627910688519478,
    "total_loss": -853.9155094414949
  },
  {
    "episode": 84,
    "avg_reward_per_step": 39.68677663888941,
    "episode_length": 493,
    "policy_loss": -679.3881530761719,
    "value_loss": 0.5327767580747604,
    "entropy": 0.4023524299263954,
    "total_loss": -679.0163172900677
  },
  {
    "episode": 85,
    "avg_reward_per_step": 73.58102514223658,
    "episode_length": 271,
    "policy_loss": -1249.76953125,
    "value_loss": 0.5659484267234802,
    "entropy": 0.3906330242753029,
    "total_loss": -1249.3598360329865
  },
  {
    "episode": 86,
    "avg_reward_per_step": 41.18422074970733,
    "episode_length": 477,
    "policy_loss": -689.7391204833984,
    "value_loss": 0.5342921018600464,
    "entropy": 0.3389348238706589,
    "total_loss": -689.3404023110867
  },
  {
    "episode": 87,
    "avg_reward_per_step": 106.9288113947823,
    "episode_length": 188,
    "policy_loss": -1832.1565551757812,
    "value_loss": 0.6032201945781708,
    "entropy": 0.3533298969268799,
    "total_loss": -1831.6946669399738
  },
  {
    "episode": 88,
    "avg_reward_per_step": 64.79926301635946,
    "episode_length": 308,
    "policy_loss": -1107.906982421875,
    "value_loss": 0.5571147203445435,
    "entropy": 0.36080120503902435,
    "total_loss": -1107.4941881835462
  },
  {
    "episode": 89,
    "avg_reward_per_step": 84.93615899175566,
    "episode_length": 236,
    "policy_loss": -1470.4762268066406,
    "value_loss": 0.5785160660743713,
    "entropy": 0.29703401774168015,
    "total_loss": -1470.0165243476629
  },
  {
    "episode": 90,
    "avg_reward_per_step": 82.10385539047941,
    "episode_length": 243,
    "policy_loss": -1396.9122619628906,
    "value_loss": 0.5748458951711655,
    "entropy": 0.29809030145406723,
    "total_loss": -1396.4566521883012
  },
  {
    "episode": 91,
    "avg_reward_per_step": 46.53799410375197,
    "episode_length": 424,
    "policy_loss": -806.0440521240234,
    "value_loss": 0.5393956899642944,
    "entropy": 0.2660200521349907,
    "total_loss": -805.6110644549132
  },
  {
    "episode": 92,
    "avg_reward_per_step": 113.35906010859797,
    "episode_length": 178,
    "policy_loss": -1915.7235412597656,
    "value_loss": 0.6111239641904831,
    "entropy": 0.26757125556468964,
    "total_loss": -1915.219445797801
  },
  {
    "episode": 93,
    "avg_reward_per_step": 78.13631490606859,
    "episode_length": 255,
    "policy_loss": -1340.0512390136719,
    "value_loss": 0.570769190788269,
    "entropy": 0.2886503264307976,
    "total_loss": -1339.5959299534559
  },
  {
    "episode": 94,
    "avg_reward_per_step": 137.03203466162583,
    "episode_length": 147,
    "policy_loss": -2325.9061279296875,
    "value_loss": 0.640781357884407,
    "entropy": 0.27086811512708664,
    "total_loss": -2325.373693817854
  },
  {
    "episode": 95,
    "avg_reward_per_step": 136.36464530380508,
    "episode_length": 148,
    "policy_loss": -2312.1968994140625,
    "value_loss": 0.6399069726467133,
    "entropy": 0.26027006655931473,
    "total_loss": -2311.6611004680394
  },
  {
    "episode": 96,
    "avg_reward_per_step": 33.506079675987394,
    "episode_length": 584,
    "policy_loss": -565.6911773681641,
    "value_loss": 0.5275897085666656,
    "entropy": 0.20855876058340073,
    "total_loss": -565.2470111638307
  },
  {
    "episode": 97,
    "avg_reward_per_step": 45.28756631576617,
    "episode_length": 436,
    "policy_loss": -764.7728729248047,
    "value_loss": 0.5383279919624329,
    "entropy": 0.190402552485466,
    "total_loss": -764.3107059538364
  },
  {
    "episode": 98,
    "avg_reward_per_step": 42.00088654778702,
    "episode_length": 474,
    "policy_loss": -720.41015625,
    "value_loss": 0.5354746133089066,
    "entropy": 0.21372009813785553,
    "total_loss": -719.9601696759462
  },
  {
    "episode": 99,
    "avg_reward_per_step": 136.68995003828243,
    "episode_length": 147,
    "policy_loss": -2312.0167236328125,
    "value_loss": 0.6400358825922012,
    "entropy": 0.23898163437843323,
    "total_loss": -2311.4722804039716
  },
  {
    "episode": 100,
    "avg_reward_per_step": 120.18541093798828,
    "episode_length": 167,
    "policy_loss": -2029.199951171875,
    "value_loss": 0.6187457889318466,
    "entropy": 0.19256331399083138,
    "total_loss": -2028.6582307085396
  },
  {
    "episode": 101,
    "avg_reward_per_step": 59.98332960759695,
    "episode_length": 331,
    "policy_loss": -1021.7178802490234,
    "value_loss": 0.5523287057876587,
    "entropy": 0.2156055048108101,
    "total_loss": -1021.2517937451601
  },
  {
    "episode": 102,
    "avg_reward_per_step": 122.63886563787942,
    "episode_length": 164,
    "policy_loss": -2073.7651977539062,
    "value_loss": 0.622027263045311,
    "entropy": 0.18905530497431755,
    "total_loss": -2073.218792612851
  },
  {
    "episode": 103,
    "avg_reward_per_step": 76.66600586763964,
    "episode_length": 260,
    "policy_loss": -1305.906494140625,
    "value_loss": 0.5691434592008591,
    "entropy": 0.18322008848190308,
    "total_loss": -1305.410638716817
  },
  {
    "episode": 104,
    "avg_reward_per_step": 115.00978463517164,
    "episode_length": 174,
    "policy_loss": -1948.8332214355469,
    "value_loss": 0.6120750606060028,
    "entropy": 0.19377127289772034,
    "total_loss": -1948.2986548841
  },
  {
    "episode": 105,
    "avg_reward_per_step": 74.91224603407854,
    "episode_length": 267,
    "policy_loss": -1266.8186645507812,
    "value_loss": 0.5676112920045853,
    "entropy": 0.17162107676267624,
    "total_loss": -1266.3197016894817
  },
  {
    "episode": 106,
    "avg_reward_per_step": 72.60995161368943,
    "episode_length": 274,
    "policy_loss": -1226.7826232910156,
    "value_loss": 0.5649194419384003,
    "entropy": 0.1368563510477543,
    "total_loss": -1226.2724463894963
  },
  {
    "episode": 107,
    "avg_reward_per_step": 32.94309840240935,
    "episode_length": 596,
    "policy_loss": -559.2823486328125,
    "value_loss": 0.5271848887205124,
    "entropy": 0.13884297013282776,
    "total_loss": -558.8107009321451
  },
  {
    "episode": 108,
    "avg_reward_per_step": 103.5587348302305,
    "episode_length": 194,
    "policy_loss": -1750.6627807617188,
    "value_loss": 0.5992471277713776,
    "entropy": 0.16678516566753387,
    "total_loss": -1750.1302477002143
  },
  {
    "episode": 109,
    "avg_reward_per_step": 65.74246693310876,
    "episode_length": 302,
    "policy_loss": -1111.6781616210938,
    "value_loss": 0.5579994171857834,
    "entropy": 0.16852841153740883,
    "total_loss": -1111.187573568523
  },
  {
    "episode": 110,
    "avg_reward_per_step": 67.09177681250786,
    "episode_length": 297,
    "policy_loss": -1134.8732604980469,
    "value_loss": 0.5595531314611435,
    "entropy": 0.1684112399816513,
    "total_loss": -1134.3810718625784
  },
  {
    "episode": 111,
    "avg_reward_per_step": 43.657367944686925,
    "episode_length": 452,
    "policy_loss": -739.2203369140625,
    "value_loss": 0.5368548929691315,
    "entropy": 0.13086584210395813,
    "total_loss": -738.7358283579349
  },
  {
    "episode": 112,
    "avg_reward_per_step": 55.360185911566504,
    "episode_length": 358,
    "policy_loss": -936.7141418457031,
    "value_loss": 0.5478406548500061,
    "entropy": 0.1849673017859459,
    "total_loss": -936.2402881115675
  },
  {
    "episode": 113,
    "avg_reward_per_step": 107.59957690881144,
    "episode_length": 186,
    "policy_loss": -1816.4742431640625,
    "value_loss": 0.6034763306379318,
    "entropy": 0.1524059884250164,
    "total_loss": -1815.9317292287947
  },
  {
    "episode": 114,
    "avg_reward_per_step": -0.46786984015855354,
    "episode_length": 3000,
    "policy_loss": 5.108564853668213,
    "value_loss": 0.6139853596687317,
    "entropy": 0.012049442855641246,
    "total_loss": 5.717730436194688
  },
  {
    "episode": 115,
    "avg_reward_per_step": 9.698959580344257,
    "episode_length": 1971,
    "policy_loss": -166.26604461669922,
    "value_loss": 0.5076598823070526,
    "entropy": 0.02189414342865348,
    "total_loss": -165.76714239176363
  },
  {
    "episode": 116,
    "avg_reward_per_step": 57.13674003980687,
    "episode_length": 347,
    "policy_loss": -965.9204559326172,
    "value_loss": 0.5496116280555725,
    "entropy": 0.1347530297935009,
    "total_loss": -965.424745516479
  },
  {
    "episode": 117,
    "avg_reward_per_step": 38.661414912165014,
    "episode_length": 507,
    "policy_loss": -654.5803527832031,
    "value_loss": 0.5322315394878387,
    "entropy": 0.14184924215078354,
    "total_loss": -654.1048609405756
  },
  {
    "episode": 118,
    "avg_reward_per_step": -0.4651308774021428,
    "episode_length": 3000,
    "policy_loss": 4.334742426872253,
    "value_loss": 0.5568595975637436,
    "entropy": 0.013333463342860341,
    "total_loss": 4.886268639098853
  },
  {
    "episode": 119,
    "avg_reward_per_step": 107.41482106774103,
    "episode_length": 187,
    "policy_loss": -1828.6405639648438,
    "value_loss": 0.604236051440239,
    "entropy": 0.1506163254380226,
    "total_loss": -1828.0965744435787
  },
  {
    "episode": 120,
    "avg_reward_per_step": 40.93890395639299,
    "episode_length": 486,
    "policy_loss": -698.4154510498047,
    "value_loss": 0.5346163958311081,
    "entropy": 0.05467312503606081,
    "total_loss": -697.902703903988
  },
  {
    "episode": 121,
    "avg_reward_per_step": 11.65812147799354,
    "episode_length": 1633,
    "policy_loss": -198.89911270141602,
    "value_loss": 0.5090488493442535,
    "entropy": 0.04776071757078171,
    "total_loss": -198.40916813910007
  },
  {
    "episode": 122,
    "avg_reward_per_step": 85.95041817070539,
    "episode_length": 233,
    "policy_loss": -1488.9291381835938,
    "value_loss": 0.5797452181577682,
    "entropy": 0.19133620709180832,
    "total_loss": -1488.4259274482727
  },
  {
    "episode": 123,
    "avg_reward_per_step": 87.64811569833246,
    "episode_length": 228,
    "policy_loss": -1478.4070739746094,
    "value_loss": 0.5809374153614044,
    "entropy": 0.11807633377611637,
    "total_loss": -1477.8733670927584
  },
  {
    "episode": 124,
    "avg_reward_per_step": 55.86554765302413,
    "episode_length": 354,
    "policy_loss": -958.6706085205078,
    "value_loss": 0.5484193414449692,
    "entropy": 0.16958045214414597,
    "total_loss": -958.1900213599205
  },
  {
    "episode": 125,
    "avg_reward_per_step": 106.47310750592297,
    "episode_length": 188,
    "policy_loss": -1797.4984741210938,
    "value_loss": 0.6023140996694565,
    "entropy": 0.17374784499406815,
    "total_loss": -1796.9656591594219
  },
  {
    "episode": 126,
    "avg_reward_per_step": 110.63902980343408,
    "episode_length": 181,
    "policy_loss": -1873.5816650390625,
    "value_loss": 0.6072367876768112,
    "entropy": 0.15848908945918083,
    "total_loss": -1873.0378238871695
  },
  {
    "episode": 127,
    "avg_reward_per_step": 115.53745296146148,
    "episode_length": 173,
    "policy_loss": -1952.017822265625,
    "value_loss": 0.6128173917531967,
    "entropy": 0.13073308765888214,
    "total_loss": -1951.4572981089354
  },
  {
    "episode": 128,
    "avg_reward_per_step": 75.34762672484324,
    "episode_length": 264,
    "policy_loss": -1275.8063049316406,
    "value_loss": 0.5679238140583038,
    "entropy": 0.13610222563147545,
    "total_loss": -1275.292822007835
  },
  {
    "episode": 129,
    "avg_reward_per_step": 97.02080601808898,
    "episode_length": 207,
    "policy_loss": -1663.3538513183594,
    "value_loss": 0.5915601402521133,
    "entropy": 0.12004903145134449,
    "total_loss": -1662.8103107906877
  },
  {
    "episode": 130,
    "avg_reward_per_step": 51.824768503410276,
    "episode_length": 386,
    "policy_loss": -876.8574523925781,
    "value_loss": 0.5448161363601685,
    "entropy": 0.08272299356758595,
    "total_loss": -876.345725453645
  },
  {
    "episode": 131,
    "avg_reward_per_step": 74.00483674750626,
    "episode_length": 272,
    "policy_loss": -1271.0311279296875,
    "value_loss": 0.566981166601181,
    "entropy": 0.12217233330011368,
    "total_loss": -1270.5130156964065
  },
  {
    "episode": 132,
    "avg_reward_per_step": 55.58324572963734,
    "episode_length": 359,
    "policy_loss": -939.1717529296875,
    "value_loss": 0.5486895442008972,
    "entropy": 0.11231604591012001,
    "total_loss": -938.6679898038507
  },
  {
    "episode": 133,
    "avg_reward_per_step": 108.42641091497235,
    "episode_length": 185,
    "policy_loss": -1870.1085510253906,
    "value_loss": 0.6047015488147736,
    "entropy": 0.11440270580351353,
    "total_loss": -1869.5496105588973
  },
  {
    "episode": 134,
    "avg_reward_per_step": 62.99928755821688,
    "episode_length": 318,
    "policy_loss": -1063.5812072753906,
    "value_loss": 0.5556993335485458,
    "entropy": 0.10814598947763443,
    "total_loss": -1063.0687663376332
  },
  {
    "episode": 135,
    "avg_reward_per_step": 58.52229261040554,
    "episode_length": 339,
    "policy_loss": -991.0396118164062,
    "value_loss": 0.5507950484752655,
    "entropy": 0.12945448234677315,
    "total_loss": -990.5405985608697
  },
  {
    "episode": 136,
    "avg_reward_per_step": 111.06118826641135,
    "episode_length": 180,
    "policy_loss": -1879.4598693847656,
    "value_loss": 0.6074102520942688,
    "entropy": 0.12507435120642185,
    "total_loss": -1878.902488873154
  },
  {
    "episode": 137,
    "avg_reward_per_step": 117.86360542320661,
    "episode_length": 170,
    "policy_loss": -2002.8587341308594,
    "value_loss": 0.6157177835702896,
    "entropy": 0.12330278195440769,
    "total_loss": -2002.292337460071
  },
  {
    "episode": 138,
    "avg_reward_per_step": 117.14625838726984,
    "episode_length": 171,
    "policy_loss": -1991.8126831054688,
    "value_loss": 0.6148650348186493,
    "entropy": 0.10868945717811584,
    "total_loss": -1991.2412938535213
  },
  {
    "episode": 139,
    "avg_reward_per_step": 74.71579587416369,
    "episode_length": 269,
    "policy_loss": -1263.8965759277344,
    "value_loss": 0.5676452070474625,
    "entropy": 0.12301020324230194,
    "total_loss": -1263.3781348019838
  },
  {
    "episode": 140,
    "avg_reward_per_step": 81.55907968120175,
    "episode_length": 246,
    "policy_loss": -1384.0665893554688,
    "value_loss": 0.5746907293796539,
    "entropy": 0.09975168853998184,
    "total_loss": -1383.531799301505
  },
  {
    "episode": 141,
    "avg_reward_per_step": 58.89645836852544,
    "episode_length": 338,
    "policy_loss": -995.0042266845703,
    "value_loss": 0.5515541583299637,
    "entropy": 0.1448114737868309,
    "total_loss": -994.5105971157551
  },
  {
    "episode": 142,
    "avg_reward_per_step": 25.491908469973254,
    "episode_length": 768,
    "policy_loss": -431.9848937988281,
    "value_loss": 0.5208984315395355,
    "entropy": 0.11863431893289089,
    "total_loss": -431.51144909486175
  },
  {
    "episode": 143,
    "avg_reward_per_step": 73.30911978098037,
    "episode_length": 273,
    "policy_loss": -1240.3265075683594,
    "value_loss": 0.5661032348871231,
    "entropy": 0.1554345116019249,
    "total_loss": -1239.822578138113
  },
  {
    "episode": 144,
    "avg_reward_per_step": 73.06865674183543,
    "episode_length": 274,
    "policy_loss": -1244.2342529296875,
    "value_loss": 0.5659755170345306,
    "entropy": 0.15613633021712303,
    "total_loss": -1243.7307319447398
  },
  {
    "episode": 145,
    "avg_reward_per_step": 70.8475374010838,
    "episode_length": 282,
    "policy_loss": -1202.5624694824219,
    "value_loss": 0.5635833740234375,
    "entropy": 0.1474718227982521,
    "total_loss": -1202.0578748375178
  },
  {
    "episode": 146,
    "avg_reward_per_step": 24.41130718758923,
    "episode_length": 799,
    "policy_loss": -418.5474319458008,
    "value_loss": 0.5198613554239273,
    "entropy": 0.11135300435125828,
    "total_loss": -418.07211179211737
  },
  {
    "episode": 147,
    "avg_reward_per_step": 106.55378522656937,
    "episode_length": 188,
    "policy_loss": -1809.9615783691406,
    "value_loss": 0.6024607419967651,
    "entropy": 0.11782517656683922,
    "total_loss": -1809.4062476977706
  },
  {
    "episode": 148,
    "avg_reward_per_step": 54.42292634002409,
    "episode_length": 364,
    "policy_loss": -919.66015625,
    "value_loss": 0.5470194518566132,
    "entropy": 0.11659578792750835,
    "total_loss": -919.1597751133144
  },
  {
    "episode": 149,
    "avg_reward_per_step": 118.57241374848083,
    "episode_length": 169,
    "policy_loss": -2004.4325256347656,
    "value_loss": 0.6165814995765686,
    "entropy": 0.11119594424962997,
    "total_loss": -2003.8604225128888
  },
  {
    "episode": 150,
    "avg_reward_per_step": 117.1156009314426,
    "episode_length": 171,
    "policy_loss": -1978.3302307128906,
    "value_loss": 0.6147218346595764,
    "entropy": 0.10181809403002262,
    "total_loss": -1977.756236115843
  },
  {
    "episode": 151,
    "avg_reward_per_step": 119.57892579616225,
    "episode_length": 168,
    "policy_loss": -2021.8589477539062,
    "value_loss": 0.6182200610637665,
    "entropy": 0.10525773465633392,
    "total_loss": -2021.282830786705
  },
  {
    "episode": 152,
    "avg_reward_per_step": 117.17544097988592,
    "episode_length": 171,
    "policy_loss": -1981.2367248535156,
    "value_loss": 0.6150048971176147,
    "entropy": 0.10792954452335835,
    "total_loss": -1980.6648917742073
  },
  {
    "episode": 153,
    "avg_reward_per_step": 45.33616290986983,
    "episode_length": 437,
    "policy_loss": -766.6693725585938,
    "value_loss": 0.5385446101427078,
    "entropy": 0.11073172651231289,
    "total_loss": -766.175120639056
  },
  {
    "episode": 154,
    "avg_reward_per_step": 98.61895051793022,
    "episode_length": 203,
    "policy_loss": -1664.3428344726562,
    "value_loss": 0.5930957794189453,
    "entropy": 0.07933816313743591,
    "total_loss": -1663.7814739584924
  },
  {
    "episode": 155,
    "avg_reward_per_step": 78.23692274236518,
    "episode_length": 255,
    "policy_loss": -1323.0223083496094,
    "value_loss": 0.5710158050060272,
    "entropy": 0.12050518579781055,
    "total_loss": -1322.4994946189224
  },
  {
    "episode": 156,
    "avg_reward_per_step": 97.21253063116137,
    "episode_length": 206,
    "policy_loss": -1652.7109680175781,
    "value_loss": 0.5915022492408752,
    "entropy": 0.08295348472893238,
    "total_loss": -1652.1526471622287
  },
  {
    "episode": 157,
    "avg_reward_per_step": 81.68631292856178,
    "episode_length": 245,
    "policy_loss": -1379.3974914550781,
    "value_loss": 0.574737012386322,
    "entropy": 0.07883262820541859,
    "total_loss": -1378.854287493974
  },
  {
    "episode": 158,
    "avg_reward_per_step": 130.00404630364585,
    "episode_length": 155,
    "policy_loss": -2193.7362670898438,
    "value_loss": 0.6315122246742249,
    "entropy": 0.07800108194351196,
    "total_loss": -2193.135955297947
  },
  {
    "episode": 159,
    "avg_reward_per_step": 120.5036179308912,
    "episode_length": 167,
    "policy_loss": -2044.0161437988281,
    "value_loss": 0.619480699300766,
    "entropy": 0.13448373973369598,
    "total_loss": -2043.4504565954207
  },
  {
    "episode": 160,
    "avg_reward_per_step": 117.23032432474476,
    "episode_length": 171,
    "policy_loss": -1994.2633972167969,
    "value_loss": 0.6149796396493912,
    "entropy": 0.09240751340985298,
    "total_loss": -1993.6853805825115
  },
  {
    "episode": 161,
    "avg_reward_per_step": 117.43776950428891,
    "episode_length": 171,
    "policy_loss": -1994.9480590820312,
    "value_loss": 0.6154255867004395,
    "entropy": 0.10032911784946918,
    "total_loss": -1994.3727651424706
  },
  {
    "episode": 162,
    "avg_reward_per_step": 107.15217133614883,
    "episode_length": 187,
    "policy_loss": -1811.1061096191406,
    "value_loss": 0.6030565202236176,
    "entropy": 0.08970279805362225,
    "total_loss": -1810.5389342181384
  },
  {
    "episode": 163,
    "avg_reward_per_step": 53.228907557661366,
    "episode_length": 372,
    "policy_loss": -900.3284454345703,
    "value_loss": 0.5458972901105881,
    "entropy": 0.09126797877252102,
    "total_loss": -899.8190553359688
  },
  {
    "episode": 164,
    "avg_reward_per_step": 58.70734780161382,
    "episode_length": 339,
    "policy_loss": -995.9458618164062,
    "value_loss": 0.5512911677360535,
    "entropy": 0.1020971778780222,
    "total_loss": -995.4354095198214
  },
  {
    "episode": 165,
    "avg_reward_per_step": 33.69273644850094,
    "episode_length": 582,
    "policy_loss": -583.7945709228516,
    "value_loss": 0.5278957039117813,
    "entropy": 0.10328816622495651,
    "total_loss": -583.3079904854297
  },
  {
    "episode": 166,
    "avg_reward_per_step": 78.25858654162693,
    "episode_length": 255,
    "policy_loss": -1333.250732421875,
    "value_loss": 0.5710292607545853,
    "entropy": 0.10219582170248032,
    "total_loss": -1332.7205814898014
  },
  {
    "episode": 167,
    "avg_reward_per_step": 73.310520623818,
    "episode_length": 272,
    "policy_loss": -1241.4169006347656,
    "value_loss": 0.5658937096595764,
    "entropy": 0.09308040700852871,
    "total_loss": -1240.8882390879094
  },
  {
    "episode": 168,
    "avg_reward_per_step": 102.1956629549349,
    "episode_length": 196,
    "policy_loss": -1726.3401489257812,
    "value_loss": 0.5973830819129944,
    "entropy": 0.12368946708738804,
    "total_loss": -1725.7922416307033
  },
  {
    "episode": 169,
    "avg_reward_per_step": 86.65469722927598,
    "episode_length": 231,
    "policy_loss": -1487.7153625488281,
    "value_loss": 0.580189511179924,
    "entropy": 0.15819061174988747,
    "total_loss": -1487.198449282348
  },
  {
    "episode": 170,
    "avg_reward_per_step": 46.28322844326207,
    "episode_length": 427,
    "policy_loss": -784.1410980224609,
    "value_loss": 0.5394280850887299,
    "entropy": 0.11838351562619209,
    "total_loss": -783.6490233436227
  },
  {
    "episode": 171,
    "avg_reward_per_step": 41.027321129037,
    "episode_length": 481,
    "policy_loss": -694.4217987060547,
    "value_loss": 0.5345336347818375,
    "entropy": 0.07910030521452427,
    "total_loss": -693.9189051933587
  },
  {
    "episode": 172,
    "avg_reward_per_step": 80.83053686587928,
    "episode_length": 247,
    "policy_loss": -1365.6819763183594,
    "value_loss": 0.5737173110246658,
    "entropy": 0.09179881028831005,
    "total_loss": -1365.14497853145
  },
  {
    "episode": 173,
    "avg_reward_per_step": 77.32875217591487,
    "episode_length": 258,
    "policy_loss": -1306.1841430664062,
    "value_loss": 0.5700452923774719,
    "entropy": 0.09535986557602882,
    "total_loss": -1305.652241720259
  },
  {
    "episode": 174,
    "avg_reward_per_step": 58.9748324456079,
    "episode_length": 335,
    "policy_loss": -996.8978729248047,
    "value_loss": 0.5511870086193085,
    "entropy": 0.08392513170838356,
    "total_loss": -996.3802559688687
  },
  {
    "episode": 175,
    "avg_reward_per_step": 79.35581187505689,
    "episode_length": 251,
    "policy_loss": -1354.4380798339844,
    "value_loss": 0.5720591843128204,
    "entropy": 0.0923397671431303,
    "total_loss": -1353.9029565565288
  },
  {
    "episode": 176,
    "avg_reward_per_step": 57.34655140263283,
    "episode_length": 346,
    "policy_loss": -968.9817810058594,
    "value_loss": 0.5498171448707581,
    "entropy": 0.09002594090998173,
    "total_loss": -968.4679742373526
  },
  {
    "episode": 177,
    "avg_reward_per_step": 84.24966134881483,
    "episode_length": 237,
    "policy_loss": -1430.8147277832031,
    "value_loss": 0.5773079544305801,
    "entropy": 0.09405486285686493,
    "total_loss": -1430.2750417739153
  },
  {
    "episode": 178,
    "avg_reward_per_step": 71.9994635564154,
    "episode_length": 276,
    "policy_loss": -1217.4462585449219,
    "value_loss": 0.5642970502376556,
    "entropy": 0.10119061917066574,
    "total_loss": -1216.9224377423525
  },
  {
    "episode": 179,
    "avg_reward_per_step": 134.65192258486138,
    "episode_length": 149,
    "policy_loss": -2280.7586059570312,
    "value_loss": 0.6375057995319366,
    "entropy": 0.11531603336334229,
    "total_loss": -2280.167226570845
  },
  {
    "episode": 180,
    "avg_reward_per_step": 49.018860252648246,
    "episode_length": 403,
    "policy_loss": -829.7290649414062,
    "value_loss": 0.5418425053358078,
    "entropy": 0.08437841385602951,
    "total_loss": -829.2209738016129
  },
  {
    "episode": 181,
    "avg_reward_per_step": 72.5023719829066,
    "episode_length": 274,
    "policy_loss": -1229.788330078125,
    "value_loss": 0.5647682994604111,
    "entropy": 0.0966903530061245,
    "total_loss": -1229.262237919867
  },
  {
    "episode": 182,
    "avg_reward_per_step": 60.66189249103479,
    "episode_length": 328,
    "policy_loss": -1026.00341796875,
    "value_loss": 0.5531274825334549,
    "entropy": 0.08813264220952988,
    "total_loss": -1025.4855435431004
  },
  {
    "episode": 183,
    "avg_reward_per_step": 35.08316727684031,
    "episode_length": 556,
    "policy_loss": -594.3241424560547,
    "value_loss": 0.528950959444046,
    "entropy": 0.1015553455799818,
    "total_loss": -593.8358136348427
  },
  {
    "episode": 184,
    "avg_reward_per_step": 74.9401595016781,
    "episode_length": 267,
    "policy_loss": -1275.4341735839844,
    "value_loss": 0.5677933394908905,
    "entropy": 0.08792978897690773,
    "total_loss": -1274.9015521600843
  },
  {
    "episode": 185,
    "avg_reward_per_step": 73.51502400680528,
    "episode_length": 271,
    "policy_loss": -1241.9295043945312,
    "value_loss": 0.5660160332918167,
    "entropy": 0.10222124494612217,
    "total_loss": -1241.4043768592178
  },
  {
    "episode": 186,
    "avg_reward_per_step": 106.44392375587032,
    "episode_length": 188,
    "policy_loss": -1797.9407653808594,
    "value_loss": 0.6021282523870468,
    "entropy": 0.07234448008239269,
    "total_loss": -1797.3675749205054
  },
  {
    "episode": 187,
    "avg_reward_per_step": 117.39074945052509,
    "episode_length": 171,
    "policy_loss": -1982.3904113769531,
    "value_loss": 0.6153369843959808,
    "entropy": 0.08521114848554134,
    "total_loss": -1981.8091588519515
  },
  {
    "episode": 188,
    "avg_reward_per_step": 73.90904551920957,
    "episode_length": 270,
    "policy_loss": -1253.9002075195312,
    "value_loss": 0.5665042698383331,
    "entropy": 0.09909248724579811,
    "total_loss": -1253.3733402445912
  },
  {
    "episode": 189,
    "avg_reward_per_step": 84.48146163751696,
    "episode_length": 236,
    "policy_loss": -1427.1029663085938,
    "value_loss": 0.577398270368576,
    "entropy": 0.09156106598675251,
    "total_loss": -1426.5621924646198
  },
  {
    "episode": 190,
    "avg_reward_per_step": 117.33889128217665,
    "episode_length": 171,
    "policy_loss": -1980.4345397949219,
    "value_loss": 0.6151849925518036,
    "entropy": 0.08211667463183403,
    "total_loss": -1979.8522014722228
  },
  {
    "episode": 191,
    "avg_reward_per_step": 60.24276482678754,
    "episode_length": 329,
    "policy_loss": -1018.7041625976562,
    "value_loss": 0.5525694191455841,
    "entropy": 0.09889126569032669,
    "total_loss": -1018.1911496847868
  },
  {
    "episode": 192,
    "avg_reward_per_step": 77.7328898094026,
    "episode_length": 257,
    "policy_loss": -1313.3975830078125,
    "value_loss": 0.5705285519361496,
    "entropy": 0.10247006453573704,
    "total_loss": -1312.8680424816907
  },
  {
    "episode": 193,
    "avg_reward_per_step": 105.90169367781388,
    "episode_length": 189,
    "policy_loss": -1791.3038940429688,
    "value_loss": 0.6015011221170425,
    "entropy": 0.09564905054867268,
    "total_loss": -1790.740652541071
  },
  {
    "episode": 194,
    "avg_reward_per_step": 115.88217374799902,
    "episode_length": 173,
    "policy_loss": -1956.1463623046875,
    "value_loss": 0.6133941859006882,
    "entropy": 0.09008437767624855,
    "total_loss": -1955.5690018698574
  },
  {
    "episode": 195,
    "avg_reward_per_step": 110.63908208624896,
    "episode_length": 181,
    "policy_loss": -1872.742431640625,
    "value_loss": 0.606949970126152,
    "entropy": 0.10032865405082703,
    "total_loss": -1872.1756131321192
  },
  {
    "episode": 196,
    "avg_reward_per_step": 115.8961674742269,
    "episode_length": 173,
    "policy_loss": -1965.2923278808594,
    "value_loss": 0.6135400831699371,
    "entropy": 0.07375889644026756,
    "total_loss": -1964.7082913562656
  },
  {
    "episode": 197,
    "avg_reward_per_step": 115.88593330921888,
    "episode_length": 173,
    "policy_loss": -1956.8339538574219,
    "value_loss": 0.6133227944374084,
    "entropy": 0.08949233591556549,
    "total_loss": -1956.2564279973508
  },
  {
    "episode": 198,
    "avg_reward_per_step": 116.98362176741456,
    "episode_length": 171,
    "policy_loss": -1973.9108581542969,
    "value_loss": 0.6143991649150848,
    "entropy": 0.07959060929715633,
    "total_loss": -1973.3282952331006
  },
  {
    "episode": 199,
    "avg_reward_per_step": 77.34663071029235,
    "episode_length": 258,
    "policy_loss": -1313.0530090332031,
    "value_loss": 0.5701032131910324,
    "entropy": 0.08248725533485413,
    "total_loss": -1312.515900722146
  },
  {
    "episode": 200,
    "avg_reward_per_step": 36.92114906027947,
    "episode_length": 531,
    "policy_loss": -625.1873626708984,
    "value_loss": 0.5306901931762695,
    "entropy": 0.08506156876683235,
    "total_loss": -624.6906971052289
  },
  {
    "episode": 201,
    "avg_reward_per_step": 113.77074474551165,
    "episode_length": 176,
    "policy_loss": -1927.05615234375,
    "value_loss": 0.6108607649803162,
    "entropy": 0.09813917800784111,
    "total_loss": -1926.4845472499728
  },
  {
    "episode": 202,
    "avg_reward_per_step": -0.5166589177987285,
    "episode_length": 3000,
    "policy_loss": 6.145029544830322,
    "value_loss": 0.5752397328615189,
    "entropy": 0.00995620246976614,
    "total_loss": 6.716286796703935
  },
  {
    "episode": 203,
    "avg_reward_per_step": 14.852834868895558,
    "episode_length": 1262,
    "policy_loss": -253.99975204467773,
    "value_loss": 0.5115587562322617,
    "entropy": 0.0885420423001051,
    "total_loss": -253.52361010536552
  },
  {
    "episode": 204,
    "avg_reward_per_step": 21.52739115272577,
    "episode_length": 906,
    "policy_loss": -365.8479309082031,
    "value_loss": 0.5176019668579102,
    "entropy": 0.0367983877658844,
    "total_loss": -365.3450482964516
  },
  {
    "episode": 205,
    "avg_reward_per_step": 102.17905490952532,
    "episode_length": 196,
    "policy_loss": -1731.4515686035156,
    "value_loss": 0.5974159091711044,
    "entropy": 0.07380731962621212,
    "total_loss": -1730.883675622195
  },
  {
    "episode": 206,
    "avg_reward_per_step": 15.856922669219092,
    "episode_length": 1176,
    "policy_loss": -270.80191802978516,
    "value_loss": 0.5122888684272766,
    "entropy": 0.08271543495357037,
    "total_loss": -270.3227153353393
  },
  {
    "episode": 207,
    "avg_reward_per_step": -0.5035610371301932,
    "episode_length": 3000,
    "policy_loss": 5.0914576053619385,
    "value_loss": 122.39020347595215,
    "entropy": 0.0014211486850399524,
    "total_loss": 127.48109262184008
  },
  {
    "episode": 208,
    "avg_reward_per_step": 11.02307378682067,
    "episode_length": 1694,
    "policy_loss": -189.7314338684082,
    "value_loss": 0.5085600465536118,
    "entropy": 0.04884275421500206,
    "total_loss": -189.2424109235406
  },
  {
    "episode": 209,
    "avg_reward_per_step": 46.33516875186247,
    "episode_length": 424,
    "policy_loss": -785.477294921875,
    "value_loss": 0.5392633229494095,
    "entropy": 0.0846710205078125,
    "total_loss": -784.9719000071287
  },
  {
    "episode": 210,
    "avg_reward_per_step": 37.8768609517167,
    "episode_length": 517,
    "policy_loss": -643.0489959716797,
    "value_loss": 0.5316246002912521,
    "entropy": 0.09844853356480598,
    "total_loss": -642.5567507848143
  },
  {
    "episode": 211,
    "avg_reward_per_step": 89.96721855558748,
    "episode_length": 222,
    "policy_loss": -1529.3019104003906,
    "value_loss": 0.5837583690881729,
    "entropy": 0.13269685953855515,
    "total_loss": -1528.7712307751178
  },
  {
    "episode": 212,
    "avg_reward_per_step": 67.75253532839642,
    "episode_length": 294,
    "policy_loss": -1163.2725830078125,
    "value_loss": 0.5604062229394913,
    "entropy": 0.11328583210706711,
    "total_loss": -1162.7574911177157
  },
  {
    "episode": 213,
    "avg_reward_per_step": 71.30638432064981,
    "episode_length": 278,
    "policy_loss": -1203.6553955078125,
    "value_loss": 0.5635403245687485,
    "entropy": 0.10379892215132713,
    "total_loss": -1203.1333747521044
  },
  {
    "episode": 214,
    "avg_reward_per_step": 105.86711354689922,
    "episode_length": 189,
    "policy_loss": -1799.6123657226562,
    "value_loss": 0.6015969514846802,
    "entropy": 0.11283840797841549,
    "total_loss": -1799.055904134363
  },
  {
    "episode": 215,
    "avg_reward_per_step": 114.21643617181309,
    "episode_length": 175,
    "policy_loss": -1954.6668395996094,
    "value_loss": 0.6113144755363464,
    "entropy": 0.08743241615593433,
    "total_loss": -1954.0904980905354
  },
  {
    "episode": 216,
    "avg_reward_per_step": -0.45926946986768774,
    "episode_length": 3000,
    "policy_loss": 2.0194262266159058,
    "value_loss": 0.4816429242491722,
    "entropy": 0.008653852390125394,
    "total_loss": 2.4976076099090276
  },
  {
    "episode": 217,
    "avg_reward_per_step": -0.47416671984042796,
    "episode_length": 3000,
    "policy_loss": 2.299175798892975,
    "value_loss": 0.477102130651474,
    "entropy": 0.005099181202240288,
    "total_loss": 2.7742382570635526
  },
  {
    "episode": 218,
    "avg_reward_per_step": -0.4710412972488733,
    "episode_length": 3000,
    "policy_loss": 2.156441390514374,
    "value_loss": 0.4790608808398247,
    "entropy": 0.006484684883616865,
    "total_loss": 2.632908397400752
  },
  {
    "episode": 219,
    "avg_reward_per_step": 7.573824928489468,
    "episode_length": 2468,
    "policy_loss": -133.5540428161621,
    "value_loss": 0.5056248009204865,
    "entropy": 0.01997627504169941,
    "total_loss": -133.0564085252583
  },
  {
    "episode": 220,
    "avg_reward_per_step": -0.47916024666450124,
    "episode_length": 3000,
    "policy_loss": 2.09509414434433,
    "value_loss": 0.4700930565595627,
    "entropy": 0.006789423059672117,
    "total_loss": 2.5624714316800237
  },
  {
    "episode": 221,
    "avg_reward_per_step": -0.4827015844311738,
    "episode_length": 3000,
    "policy_loss": 2.17357861995697,
    "value_loss": 0.4719751328229904,
    "entropy": 0.007258082274347544,
    "total_loss": 2.6426505198702217
  },
  {
    "episode": 222,
    "avg_reward_per_step": 6.303550877020835,
    "episode_length": 2964,
    "policy_loss": -111.93865585327148,
    "value_loss": 0.5047475844621658,
    "entropy": 0.016758971847593784,
    "total_loss": -111.44061185754836
  },
  {
    "episode": 223,
    "avg_reward_per_step": 14.285477535472628,
    "episode_length": 1370,
    "policy_loss": -247.72061920166016,
    "value_loss": 0.5113640427589417,
    "entropy": 0.019783640280365944,
    "total_loss": -247.21716861501335
  },
  {
    "episode": 224,
    "avg_reward_per_step": 120.31337082914472,
    "episode_length": 167,
    "policy_loss": -2035.8627014160156,
    "value_loss": 0.6195439100265503,
    "entropy": 0.08647476509213448,
    "total_loss": -2035.277747412026
  },
  {
    "episode": 225,
    "avg_reward_per_step": -0.4645603154031115,
    "episode_length": 3000,
    "policy_loss": 1.5384656488895416,
    "value_loss": 0.45229651033878326,
    "entropy": 0.006307349889539182,
    "total_loss": 1.9882392192725091
  },
  {
    "episode": 226,
    "avg_reward_per_step": 7.32778911272331,
    "episode_length": 2568,
    "policy_loss": -129.44720458984375,
    "value_loss": 0.5055198222398758,
    "entropy": 0.012049215147271752,
    "total_loss": -128.94650445366278
  },
  {
    "episode": 227,
    "avg_reward_per_step": 51.17419416703689,
    "episode_length": 388,
    "policy_loss": -877.3274841308594,
    "value_loss": 0.5443855226039886,
    "entropy": 0.0848603080958128,
    "total_loss": -876.8170427314938
  },
  {
    "episode": 228,
    "avg_reward_per_step": 75.9624061815687,
    "episode_length": 262,
    "policy_loss": -1286.164306640625,
    "value_loss": 0.5688222646713257,
    "entropy": 0.07662783563137054,
    "total_loss": -1285.6261355102063
  },
  {
    "episode": 229,
    "avg_reward_per_step": 109.31031213865488,
    "episode_length": 183,
    "policy_loss": -1854.5870666503906,
    "value_loss": 0.6057905554771423,
    "entropy": 0.10414709523320198,
    "total_loss": -1854.0229349330068
  },
  {
    "episode": 230,
    "avg_reward_per_step": 112.34984473396153,
    "episode_length": 178,
    "policy_loss": -1899.6333312988281,
    "value_loss": 0.609265923500061,
    "entropy": 0.09889205172657967,
    "total_loss": -1899.0636221960187
  },
  {
    "episode": 231,
    "avg_reward_per_step": 113.15975471979725,
    "episode_length": 177,
    "policy_loss": -1912.3973388671875,
    "value_loss": 0.6103672236204147,
    "entropy": 0.09657585248351097,
    "total_loss": -1911.8256019845605
  },
  {
    "episode": 232,
    "avg_reward_per_step": 10.28790753462579,
    "episode_length": 1845,
    "policy_loss": -178.85046005249023,
    "value_loss": 0.5082073956727982,
    "entropy": 0.022726325783878565,
    "total_loss": -178.351343187131
  },
  {
    "episode": 233,
    "avg_reward_per_step": 114.22667078767071,
    "episode_length": 175,
    "policy_loss": -1931.8284301757812,
    "value_loss": 0.6113944500684738,
    "entropy": 0.08657297864556313,
    "total_loss": -1931.251664917171
  },
  {
    "episode": 234,
    "avg_reward_per_step": 107.16721386893678,
    "episode_length": 187,
    "policy_loss": -1811.6083068847656,
    "value_loss": 0.6036126911640167,
    "entropy": 0.08763213641941547,
    "total_loss": -1811.0397470481694
  },
  {
    "episode": 235,
    "avg_reward_per_step": 96.28398713671558,
    "episode_length": 208,
    "policy_loss": -1622.5092468261719,
    "value_loss": 0.5902951210737228,
    "entropy": 0.0625866586342454,
    "total_loss": -1621.9439863685518
  },
  {
    "episode": 236,
    "avg_reward_per_step": 114.89288419560971,
    "episode_length": 174,
    "policy_loss": -1942.1361389160156,
    "value_loss": 0.6122356653213501,
    "entropy": 0.07535145431756973,
    "total_loss": -1941.5540438324213
  },
  {
    "episode": 237,
    "avg_reward_per_step": 115.80983216922212,
    "episode_length": 173,
    "policy_loss": -1959.4384460449219,
    "value_loss": 0.6135789155960083,
    "entropy": 0.07646848820149899,
    "total_loss": -1958.8554545246066
  },
  {
    "episode": 238,
    "avg_reward_per_step": 116.23962743544533,
    "episode_length": 172,
    "policy_loss": -1963.8058166503906,
    "value_loss": 0.6138087958097458,
    "entropy": 0.06925776600837708,
    "total_loss": -1963.2197109609842
  },
  {
    "episode": 239,
    "avg_reward_per_step": 107.71116021935771,
    "episode_length": 186,
    "policy_loss": -1821.3359069824219,
    "value_loss": 0.6039762645959854,
    "entropy": 0.06532267294824123,
    "total_loss": -1820.758059787005
  },
  {
    "episode": 240,
    "avg_reward_per_step": 118.60355438928535,
    "episode_length": 169,
    "policy_loss": -2004.6935729980469,
    "value_loss": 0.6169289350509644,
    "entropy": 0.060773177072405815,
    "total_loss": -2004.100953333825
  },
  {
    "episode": 241,
    "avg_reward_per_step": 114.9216477807525,
    "episode_length": 174,
    "policy_loss": -1942.6316223144531,
    "value_loss": 0.6123540103435516,
    "entropy": 0.061149938963353634,
    "total_loss": -1942.043728279695
  },
  {
    "episode": 242,
    "avg_reward_per_step": 116.35349062903356,
    "episode_length": 172,
    "policy_loss": -1965.7537841796875,
    "value_loss": 0.6140641570091248,
    "entropy": 0.07724609971046448,
    "total_loss": -1965.1706184625625
  },
  {
    "episode": 243,
    "avg_reward_per_step": 57.04356872473423,
    "episode_length": 349,
    "policy_loss": -966.7064361572266,
    "value_loss": 0.5500975549221039,
    "entropy": 0.0901936162263155,
    "total_loss": -966.1924160487949
  },
  {
    "episode": 244,
    "avg_reward_per_step": 63.1482008346093,
    "episode_length": 314,
    "policy_loss": -1069.3204040527344,
    "value_loss": 0.5557467043399811,
    "entropy": 0.07352071069180965,
    "total_loss": -1068.7940656326712
  },
  {
    "episode": 245,
    "avg_reward_per_step": 117.87688675724547,
    "episode_length": 170,
    "policy_loss": -1991.6622619628906,
    "value_loss": 0.6161414384841919,
    "entropy": 0.06527030281722546,
    "total_loss": -1991.0722286455334
  },
  {
    "episode": 246,
    "avg_reward_per_step": 105.17687837775685,
    "episode_length": 190,
    "policy_loss": -1780.52392578125,
    "value_loss": 0.6008907705545425,
    "entropy": 0.07923857867717743,
    "total_loss": -1779.9547304421662
  },
  {
    "episode": 247,
    "avg_reward_per_step": 103.81791511563539,
    "episode_length": 193,
    "policy_loss": -1757.4499206542969,
    "value_loss": 0.5996317118406296,
    "entropy": 0.06886586360633373,
    "total_loss": -1756.8778352878987
  },
  {
    "episode": 248,
    "avg_reward_per_step": 31.759756815795424,
    "episode_length": 613,
    "policy_loss": -542.4553985595703,
    "value_loss": 0.5263299942016602,
    "entropy": 0.08353111520409584,
    "total_loss": -541.9624810114503
  },
  {
    "episode": 249,
    "avg_reward_per_step": 105.8974640895203,
    "episode_length": 189,
    "policy_loss": -1807.3580017089844,
    "value_loss": 0.6018469929695129,
    "entropy": 0.08652702905237675,
    "total_loss": -1806.7907655276358
  },
  {
    "episode": 250,
    "avg_reward_per_step": 30.524991856150816,
    "episode_length": 639,
    "policy_loss": -520.5258026123047,
    "value_loss": 0.5252576470375061,
    "entropy": 0.07924961671233177,
    "total_loss": -520.0322448119521
  },
  {
    "episode": 251,
    "avg_reward_per_step": 107.540323361906,
    "episode_length": 186,
    "policy_loss": -1827.093017578125,
    "value_loss": 0.6036792993545532,
    "entropy": 0.0691584125161171,
    "total_loss": -1826.517001643777
  },
  {
    "episode": 252,
    "avg_reward_per_step": 104.74261612284342,
    "episode_length": 191,
    "policy_loss": -1776.8829650878906,
    "value_loss": 0.600595235824585,
    "entropy": 0.07870066724717617,
    "total_loss": -1776.3138501189649
  },
  {
    "episode": 253,
    "avg_reward_per_step": 118.45532142271418,
    "episode_length": 169,
    "policy_loss": -1998.8969116210938,
    "value_loss": 0.6166218519210815,
    "entropy": 0.0569097138941288,
    "total_loss": -1998.3030536547303
  },
  {
    "episode": 254,
    "avg_reward_per_step": -0.47213633955388506,
    "episode_length": 3000,
    "policy_loss": 1.8466270565986633,
    "value_loss": 0.42789609730243683,
    "entropy": 0.004266523872502148,
    "total_loss": 2.272816544352099
  },
  {
    "episode": 255,
    "avg_reward_per_step": 11.262042407416631,
    "episode_length": 1708,
    "policy_loss": -195.29496383666992,
    "value_loss": 0.5088546425104141,
    "entropy": 0.013569812290370464,
    "total_loss": -194.79153711907566
  },
  {
    "episode": 256,
    "avg_reward_per_step": 32.749072377823516,
    "episode_length": 594,
    "policy_loss": -556.7246246337891,
    "value_loss": 0.527202919125557,
    "entropy": 0.08681631833314896,
    "total_loss": -556.2321482419968
  },
  {
    "episode": 257,
    "avg_reward_per_step": 117.70101888828084,
    "episode_length": 170,
    "policy_loss": -1991.1576843261719,
    "value_loss": 0.6156509965658188,
    "entropy": 0.058001975528895855,
    "total_loss": -1990.5652341198177
  },
  {
    "episode": 258,
    "avg_reward_per_step": -0.4683171454984925,
    "episode_length": 3000,
    "policy_loss": 1.6365736424922943,
    "value_loss": 0.4085226505994797,
    "entropy": 0.003467692411504686,
    "total_loss": 2.043709216127172
  },
  {
    "episode": 259,
    "avg_reward_per_step": -0.5035610371301932,
    "episode_length": 3000,
    "policy_loss": 2.6400634050369263,
    "value_loss": 61.7927770614624,
    "entropy": 0.001728374365484342,
    "total_loss": 64.43214911675314
  },
  {
    "episode": 260,
    "avg_reward_per_step": -0.5034835688149861,
    "episode_length": 3000,
    "policy_loss": 2.0324273109436035,
    "value_loss": 43.77077674865723,
    "entropy": 0.0013099942298140377,
    "total_loss": 45.8026800619089
  },
  {
    "episode": 261,
    "avg_reward_per_step": -0.5034835688149861,
    "episode_length": 3000,
    "policy_loss": 1.3576704859733582,
    "value_loss": 23.585190296173096,
    "entropy": 0.001314377412199974,
    "total_loss": 24.942335031181575
  },
  {
    "episode": 262,
    "avg_reward_per_step": -0.5034835688149861,
    "episode_length": 3000,
    "policy_loss": 0.8545612245798111,
    "value_loss": 9.578285455703735,
    "entropy": 0.001463969238102436,
    "total_loss": 10.432261092588305
  },
  {
    "episode": 263,
    "avg_reward_per_step": 12.867352280986793,
    "episode_length": 1472,
    "policy_loss": -223.89524459838867,
    "value_loss": 0.5100435018539429,
    "entropy": 0.036108613945543766,
    "total_loss": -223.39964454211295
  },
  {
    "episode": 264,
    "avg_reward_per_step": 116.33371929993983,
    "episode_length": 172,
    "policy_loss": -1969.5734558105469,
    "value_loss": 0.6143390387296677,
    "entropy": 0.08065548725426197,
    "total_loss": -1968.991378966719
  },
  {
    "episode": 265,
    "avg_reward_per_step": 46.67881489368597,
    "episode_length": 422,
    "policy_loss": -794.21923828125,
    "value_loss": 0.5400138944387436,
    "entropy": 0.07773524522781372,
    "total_loss": -793.7103184849024
  },
  {
    "episode": 266,
    "avg_reward_per_step": 113.52462312403732,
    "episode_length": 176,
    "policy_loss": -1921.8270263671875,
    "value_loss": 0.6106779128313065,
    "entropy": 0.07102766260504723,
    "total_loss": -1921.2447595193983
  },
  {
    "episode": 267,
    "avg_reward_per_step": 104.84444935489677,
    "episode_length": 191,
    "policy_loss": -1778.7569885253906,
    "value_loss": 0.6009325236082077,
    "entropy": 0.06821833364665508,
    "total_loss": -1778.183343335241
  },
  {
    "episode": 268,
    "avg_reward_per_step": 105.43060617015665,
    "episode_length": 190,
    "policy_loss": -1783.6818237304688,
    "value_loss": 0.6015946418046951,
    "entropy": 0.07439571619033813,
    "total_loss": -1783.1099873751402
  },
  {
    "episode": 269,
    "avg_reward_per_step": -0.4838865592345613,
    "episode_length": 3000,
    "policy_loss": 0.1446915604174137,
    "value_loss": 0.4162720814347267,
    "entropy": 0.003513881703838706,
    "total_loss": 0.5595580891706049
  },
  {
    "episode": 270,
    "avg_reward_per_step": -0.5035610371301932,
    "episode_length": 3000,
    "policy_loss": 0.27603699266910553,
    "value_loss": 1.4568298161029816,
    "entropy": 0.004212143132463098,
    "total_loss": 1.7311819515191018
  },
  {
    "episode": 271,
    "avg_reward_per_step": 9.256366709575019,
    "episode_length": 2066,
    "policy_loss": -164.07432174682617,
    "value_loss": 0.5069710165262222,
    "entropy": 0.00938373408280313,
    "total_loss": -163.57110422393308
  },
  {
    "episode": 272,
    "avg_reward_per_step": 113.88654642603034,
    "episode_length": 176,
    "policy_loss": -1926.6763610839844,
    "value_loss": 0.6114129573106766,
    "entropy": 0.06576302088797092,
    "total_loss": -1926.0912533350288
  },
  {
    "episode": 273,
    "avg_reward_per_step": 106.58048249086578,
    "episode_length": 188,
    "policy_loss": -1804.2012023925781,
    "value_loss": 0.6029038429260254,
    "entropy": 0.06506985239684582,
    "total_loss": -1803.6243264906109
  },
  {
    "episode": 274,
    "avg_reward_per_step": 76.36596097309892,
    "episode_length": 261,
    "policy_loss": -1295.2046508789062,
    "value_loss": 0.5694628953933716,
    "entropy": 0.08019126765429974,
    "total_loss": -1294.6672644905746
  },
  {
    "episode": 275,
    "avg_reward_per_step": 115.19312289284977,
    "episode_length": 174,
    "policy_loss": -1948.2476501464844,
    "value_loss": 0.6130310893058777,
    "entropy": 0.06737589091062546,
    "total_loss": -1947.6615694135428
  },
  {
    "episode": 276,
    "avg_reward_per_step": 117.16977816107361,
    "episode_length": 171,
    "policy_loss": -1982.4876403808594,
    "value_loss": 0.6153401881456375,
    "entropy": 0.06378137692809105,
    "total_loss": -1981.897812743485
  },
  {
    "episode": 277,
    "avg_reward_per_step": 117.0440439737137,
    "episode_length": 171,
    "policy_loss": -1980.1766357421875,
    "value_loss": 0.6150939911603928,
    "entropy": 0.07352200895547867,
    "total_loss": -1979.5909505546092
  },
  {
    "episode": 278,
    "avg_reward_per_step": 107.15085473420919,
    "episode_length": 187,
    "policy_loss": -1813.5238952636719,
    "value_loss": 0.6035057902336121,
    "entropy": 0.060696966014802456,
    "total_loss": -1812.944668259844
  },
  {
    "episode": 279,
    "avg_reward_per_step": 107.66256544458864,
    "episode_length": 186,
    "policy_loss": -1828.6218566894531,
    "value_loss": 0.6040118187665939,
    "entropy": 0.06592164933681488,
    "total_loss": -1828.0442135304213
  },
  {
    "episode": 280,
    "avg_reward_per_step": 118.02780132746888,
    "episode_length": 170,
    "policy_loss": -1995.845703125,
    "value_loss": 0.616590678691864,
    "entropy": 0.0640818439424038,
    "total_loss": -1995.254745183885
  },
  {
    "episode": 281,
    "avg_reward_per_step": 117.16941394174256,
    "episode_length": 171,
    "policy_loss": -1982.1121520996094,
    "value_loss": 0.6153354495763779,
    "entropy": 0.06475302577018738,
    "total_loss": -1981.5227178603411
  },
  {
    "episode": 282,
    "avg_reward_per_step": 116.37660683088286,
    "episode_length": 172,
    "policy_loss": -1970.0573120117188,
    "value_loss": 0.6142881214618683,
    "entropy": 0.06479558534920216,
    "total_loss": -1969.4689421243966
  },
  {
    "episode": 283,
    "avg_reward_per_step": -0.899076968615891,
    "episode_length": 3000,
    "policy_loss": 7.63149356842041,
    "value_loss": 0.4735846146941185,
    "entropy": 0.03690350707620382,
    "total_loss": 8.090316780284047
  },
  {
    "episode": 284,
    "avg_reward_per_step": -0.5035610371299066,
    "episode_length": 3000,
    "policy_loss": 0.08386795409023762,
    "value_loss": 1.105492740869522,
    "entropy": 0.005951672559604049,
    "total_loss": 1.186980025935918
  },
  {
    "episode": 285,
    "avg_reward_per_step": 8.549413013712964,
    "episode_length": 2222,
    "policy_loss": -152.37231826782227,
    "value_loss": 0.506368950009346,
    "entropy": 0.012662744149565697,
    "total_loss": -151.87101441547276
  },
  {
    "episode": 286,
    "avg_reward_per_step": 21.662899991367993,
    "episode_length": 887,
    "policy_loss": -372.1183776855469,
    "value_loss": 0.51777084171772,
    "entropy": 0.07804123871028423,
    "total_loss": -371.63182333931326
  },
  {
    "episode": 287,
    "avg_reward_per_step": 118.55631525347414,
    "episode_length": 169,
    "policy_loss": -2005.199462890625,
    "value_loss": 0.6169804930686951,
    "entropy": 0.10117728635668755,
    "total_loss": -2004.622953312099
  },
  {
    "episode": 288,
    "avg_reward_per_step": 107.09769650888188,
    "episode_length": 187,
    "policy_loss": -1813.2182922363281,
    "value_loss": 0.6034620702266693,
    "entropy": 0.07146604359149933,
    "total_loss": -1812.643416583538
  },
  {
    "episode": 289,
    "avg_reward_per_step": -0.4805319508048951,
    "episode_length": 3000,
    "policy_loss": -0.3160117194056511,
    "value_loss": 0.3758793994784355,
    "entropy": 0.004323730478063226,
    "total_loss": 0.05813818788155913
  },
  {
    "episode": 290,
    "avg_reward_per_step": -0.4741606810427702,
    "episode_length": 3000,
    "policy_loss": -0.3972599506378174,
    "value_loss": 0.36989252269268036,
    "entropy": 0.00707245129160583,
    "total_loss": -0.030196408461779355
  },
  {
    "episode": 291,
    "avg_reward_per_step": -0.47286353268672854,
    "episode_length": 3000,
    "policy_loss": -0.4179830104112625,
    "value_loss": 0.37641896307468414,
    "entropy": 0.0034480575704947114,
    "total_loss": -0.042943270364776256
  },
  {
    "episode": 292,
    "avg_reward_per_step": -0.47918487587120184,
    "episode_length": 3000,
    "policy_loss": -0.30594272911548615,
    "value_loss": 0.36897460371255875,
    "entropy": 0.011036301264539361,
    "total_loss": 0.05861735409125686
  },
  {
    "episode": 293,
    "avg_reward_per_step": -0.4737513521429905,
    "episode_length": 3000,
    "policy_loss": -0.39706581085920334,
    "value_loss": 0.36043184250593185,
    "entropy": 0.005978396162390709,
    "total_loss": -0.03902532681822777
  },
  {
    "episode": 294,
    "avg_reward_per_step": 39.42477136238805,
    "episode_length": 504,
    "policy_loss": -672.2765045166016,
    "value_loss": 0.533028855919838,
    "entropy": 0.04602886363863945,
    "total_loss": -671.7618872061372
  },
  {
    "episode": 295,
    "avg_reward_per_step": -0.46500582184190353,
    "episode_length": 3000,
    "policy_loss": -0.5291929990053177,
    "value_loss": 0.35039808601140976,
    "entropy": 0.004665712243877351,
    "total_loss": -0.18066119789145887
  },
  {
    "episode": 296,
    "avg_reward_per_step": -0.47181468310027974,
    "episode_length": 3000,
    "policy_loss": -0.42141127586364746,
    "value_loss": 0.36801302433013916,
    "entropy": 0.003342839307151735,
    "total_loss": -0.05473538725636899
  },
  {
    "episode": 297,
    "avg_reward_per_step": -0.4743705999490056,
    "episode_length": 3000,
    "policy_loss": -0.3538069725036621,
    "value_loss": 0.36459534615278244,
    "entropy": 0.004593729390762746,
    "total_loss": 0.008950881892815232
  },
  {
    "episode": 298,
    "avg_reward_per_step": -0.469855235831235,
    "episode_length": 3000,
    "policy_loss": -0.4151391386985779,
    "value_loss": 0.3527398630976677,
    "entropy": 0.00910504860803485,
    "total_loss": -0.06604129504412412
  },
  {
    "episode": 299,
    "avg_reward_per_step": -0.46997233630367313,
    "episode_length": 3000,
    "policy_loss": -0.407661572098732,
    "value_loss": 0.3475523218512535,
    "entropy": 0.004099871497601271,
    "total_loss": -0.06174919884651899
  },
  {
    "episode": 300,
    "avg_reward_per_step": -0.4763370443976579,
    "episode_length": 3000,
    "policy_loss": -0.28335951268672943,
    "value_loss": 0.3462482988834381,
    "entropy": 0.005819660145789385,
    "total_loss": 0.060560922138392925
  }
]