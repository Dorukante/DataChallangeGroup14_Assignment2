[
  {
    "episode": 1,
    "avg_reward_per_step": 36.56533826983304,
    "episode_length": 512,
    "policy_loss": -628.254638671875,
    "value_loss": 0.5286757051944733,
    "entropy": 1.3803499341011047,
    "total_loss": -628.278102940321
  },
  {
    "episode": 2,
    "avg_reward_per_step": 22.048738886618267,
    "episode_length": 798,
    "policy_loss": -380.43909454345703,
    "value_loss": 0.5157639533281326,
    "entropy": 1.3712184429168701,
    "total_loss": -380.47181796729564
  },
  {
    "episode": 3,
    "avg_reward_per_step": 10.105811406191641,
    "episode_length": 1644,
    "policy_loss": -171.65871810913086,
    "value_loss": 0.5066388249397278,
    "entropy": 1.3586333096027374,
    "total_loss": -171.69553260803224
  },
  {
    "episode": 4,
    "avg_reward_per_step": 34.68763245009287,
    "episode_length": 547,
    "policy_loss": -587.6468200683594,
    "value_loss": 0.5275789052248001,
    "entropy": 1.339886873960495,
    "total_loss": -587.6551959127188
  },
  {
    "episode": 5,
    "avg_reward_per_step": 16.11452797983014,
    "episode_length": 1043,
    "policy_loss": -275.27931213378906,
    "value_loss": 0.5108425170183182,
    "entropy": 1.3161091804504395,
    "total_loss": -275.2949132889509
  },
  {
    "episode": 6,
    "avg_reward_per_step": 18.44844582372566,
    "episode_length": 959,
    "policy_loss": -311.5680618286133,
    "value_loss": 0.5131961405277252,
    "entropy": 1.2921631038188934,
    "total_loss": -311.5717309296131
  },
  {
    "episode": 7,
    "avg_reward_per_step": 59.76278120434625,
    "episode_length": 323,
    "policy_loss": -1008.4848022460938,
    "value_loss": 0.5504277348518372,
    "entropy": 1.2729111909866333,
    "total_loss": -1008.4435389876365
  },
  {
    "episode": 8,
    "avg_reward_per_step": 56.83763527834033,
    "episode_length": 330,
    "policy_loss": -969.6665496826172,
    "value_loss": 0.5460694879293442,
    "entropy": 1.2450076043605804,
    "total_loss": -969.6184832364321
  },
  {
    "episode": 9,
    "avg_reward_per_step": 13.059179636367011,
    "episode_length": 1132,
    "policy_loss": -219.7420883178711,
    "value_loss": 0.5075386613607407,
    "entropy": 1.1910912692546844,
    "total_loss": -219.71098616421222
  },
  {
    "episode": 10,
    "avg_reward_per_step": 42.97740164164989,
    "episode_length": 400,
    "policy_loss": -724.5955352783203,
    "value_loss": 0.5307333469390869,
    "entropy": 1.1405741274356842,
    "total_loss": -724.5210315823555
  },
  {
    "episode": 11,
    "avg_reward_per_step": 48.195729884161636,
    "episode_length": 381,
    "policy_loss": -818.9954833984375,
    "value_loss": 0.5375382453203201,
    "entropy": 1.122118592262268,
    "total_loss": -818.9067925900221
  },
  {
    "episode": 12,
    "avg_reward_per_step": 19.03074387850921,
    "episode_length": 819,
    "policy_loss": -321.1981964111328,
    "value_loss": 0.5117454677820206,
    "entropy": 1.1586522459983826,
    "total_loss": -321.14991184175017
  },
  {
    "episode": 13,
    "avg_reward_per_step": 21.677892193595106,
    "episode_length": 760,
    "policy_loss": -363.7152557373047,
    "value_loss": 0.5143946409225464,
    "entropy": 1.2068032026290894,
    "total_loss": -363.68358237743377
  },
  {
    "episode": 14,
    "avg_reward_per_step": 5.651823312572228,
    "episode_length": 1849,
    "policy_loss": -95.52157211303711,
    "value_loss": 0.50210902094841,
    "entropy": 1.2081747949123383,
    "total_loss": -95.50273301005363
  },
  {
    "episode": 15,
    "avg_reward_per_step": 47.22607335713692,
    "episode_length": 382,
    "policy_loss": -798.3743286132812,
    "value_loss": 0.5362209975719452,
    "entropy": 1.2158781290054321,
    "total_loss": -798.3244588673115
  },
  {
    "episode": 16,
    "avg_reward_per_step": 26.081065023938418,
    "episode_length": 665,
    "policy_loss": -439.12530517578125,
    "value_loss": 0.5183404088020325,
    "entropy": 1.2027234435081482,
    "total_loss": -439.08805414438245
  },
  {
    "episode": 17,
    "avg_reward_per_step": 75.03446106683106,
    "episode_length": 255,
    "policy_loss": -1264.2442626953125,
    "value_loss": 0.5646871626377106,
    "entropy": 1.1956731081008911,
    "total_loss": -1264.1578447759152
  },
  {
    "episode": 18,
    "avg_reward_per_step": 46.05834619730771,
    "episode_length": 394,
    "policy_loss": -778.1690673828125,
    "value_loss": 0.5354879200458527,
    "entropy": 1.1895701885223389,
    "total_loss": -778.1094075381756
  },
  {
    "episode": 19,
    "avg_reward_per_step": 3.8757680216912243,
    "episode_length": 2316,
    "policy_loss": -65.66008377075195,
    "value_loss": 0.5011464655399323,
    "entropy": 1.1865403950214386,
    "total_loss": -65.6335534632206
  },
  {
    "episode": 20,
    "avg_reward_per_step": 91.66205759597266,
    "episode_length": 211,
    "policy_loss": -1575.2571716308594,
    "value_loss": 0.5821471810340881,
    "entropy": 1.1801942884922028,
    "total_loss": -1575.1471021652221
  },
  {
    "episode": 21,
    "avg_reward_per_step": 40.10816053416791,
    "episode_length": 474,
    "policy_loss": -686.2341613769531,
    "value_loss": 0.5320138335227966,
    "entropy": 1.1709349155426025,
    "total_loss": -686.1705215096474
  },
  {
    "episode": 22,
    "avg_reward_per_step": 24.74373996943313,
    "episode_length": 729,
    "policy_loss": -418.5696258544922,
    "value_loss": 0.5181064903736115,
    "entropy": 1.127579241991043,
    "total_loss": -418.502551060915
  },
  {
    "episode": 23,
    "avg_reward_per_step": 19.471277361109056,
    "episode_length": 914,
    "policy_loss": -327.37410736083984,
    "value_loss": 0.5138821750879288,
    "entropy": 1.0848141312599182,
    "total_loss": -327.29415083825586
  },
  {
    "episode": 24,
    "avg_reward_per_step": -1.8821677566018955,
    "episode_length": 3000,
    "policy_loss": 32.365647315979004,
    "value_loss": 1.3448899686336517,
    "entropy": 1.0721778571605682,
    "total_loss": 33.28166614174843
  },
  {
    "episode": 25,
    "avg_reward_per_step": 31.829176652071133,
    "episode_length": 599,
    "policy_loss": -534.7475433349609,
    "value_loss": 0.5250146389007568,
    "entropy": 1.0279043912887573,
    "total_loss": -534.6336904525757
  },
  {
    "episode": 26,
    "avg_reward_per_step": 15.33609041666754,
    "episode_length": 1178,
    "policy_loss": -257.91886138916016,
    "value_loss": 0.5110642910003662,
    "entropy": 1.048884928226471,
    "total_loss": -257.8273510694504
  },
  {
    "episode": 27,
    "avg_reward_per_step": 22.697459715538653,
    "episode_length": 805,
    "policy_loss": -383.33094787597656,
    "value_loss": 0.516817569732666,
    "entropy": 1.0453383922576904,
    "total_loss": -383.23226566314696
  },
  {
    "episode": 28,
    "avg_reward_per_step": 11.213657210461347,
    "episode_length": 1535,
    "policy_loss": -188.66642379760742,
    "value_loss": 0.5075833946466446,
    "entropy": 1.0634425282478333,
    "total_loss": -188.5842174142599
  },
  {
    "episode": 29,
    "avg_reward_per_step": 58.13093373586558,
    "episode_length": 332,
    "policy_loss": -993.4494781494141,
    "value_loss": 0.5487847328186035,
    "entropy": 1.0487505495548248,
    "total_loss": -993.3201936364173
  },
  {
    "episode": 30,
    "avg_reward_per_step": 27.515816143957846,
    "episode_length": 677,
    "policy_loss": -462.8273010253906,
    "value_loss": 0.5210175812244415,
    "entropy": 1.0368890166282654,
    "total_loss": -462.72103905081747
  },
  {
    "episode": 31,
    "avg_reward_per_step": 23.079896862291324,
    "episode_length": 750,
    "policy_loss": -387.7932434082031,
    "value_loss": 0.5160809755325317,
    "entropy": 1.0155307054519653,
    "total_loss": -387.68337471485137
  },
  {
    "episode": 32,
    "avg_reward_per_step": 105.96074815934551,
    "episode_length": 186,
    "policy_loss": -1801.4752197265625,
    "value_loss": 0.5994568765163422,
    "entropy": 0.966585323214531,
    "total_loss": -1801.262396979332
  },
  {
    "episode": 33,
    "avg_reward_per_step": 179.23100129010345,
    "episode_length": 110,
    "policy_loss": -3048.2141723632812,
    "value_loss": 0.6963109374046326,
    "entropy": 0.8853074908256531,
    "total_loss": -3047.871984422207
  },
  {
    "episode": 34,
    "avg_reward_per_step": 0.43080798009465204,
    "episode_length": 2285,
    "policy_loss": -5.816655158996582,
    "value_loss": 0.4997679069638252,
    "entropy": 0.7674505263566971,
    "total_loss": -5.6238674625754355
  },
  {
    "episode": 35,
    "avg_reward_per_step": -10.46745602698658,
    "episode_length": 3000,
    "policy_loss": 176.60962677001953,
    "value_loss": 3.884188652038574,
    "entropy": 0.67080058157444,
    "total_loss": 180.22549518942833
  },
  {
    "episode": 36,
    "avg_reward_per_step": 151.13578197145705,
    "episode_length": 127,
    "policy_loss": -2570.0590209960938,
    "value_loss": 0.6516922414302826,
    "entropy": 0.6261370033025742,
    "total_loss": -2569.6577835559847
  },
  {
    "episode": 37,
    "avg_reward_per_step": 128.6590988639094,
    "episode_length": 149,
    "policy_loss": -2181.1829833984375,
    "value_loss": 0.6227668076753616,
    "entropy": 0.711119070649147,
    "total_loss": -2180.844664219022
  },
  {
    "episode": 38,
    "avg_reward_per_step": 2.0214652766346757,
    "episode_length": 2047,
    "policy_loss": -33.7312126159668,
    "value_loss": 0.5000673830509186,
    "entropy": 0.7180835008621216,
    "total_loss": -33.518378633260724
  },
  {
    "episode": 39,
    "avg_reward_per_step": 7.116117989093582,
    "episode_length": 1381,
    "policy_loss": -120.22850799560547,
    "value_loss": 0.5024661123752594,
    "entropy": 0.7183501571416855,
    "total_loss": -120.01338194608688
  },
  {
    "episode": 40,
    "avg_reward_per_step": 14.219135524050433,
    "episode_length": 923,
    "policy_loss": -239.97027206420898,
    "value_loss": 0.5071121901273727,
    "entropy": 0.7264363169670105,
    "total_loss": -239.7537344008684
  },
  {
    "episode": 41,
    "avg_reward_per_step": 181.0344699690341,
    "episode_length": 110,
    "policy_loss": -3069.6648559570312,
    "value_loss": 0.7014473974704742,
    "entropy": 0.7819884568452835,
    "total_loss": -3069.2762039422987
  },
  {
    "episode": 42,
    "avg_reward_per_step": 24.718737622037658,
    "episode_length": 644,
    "policy_loss": -416.5083236694336,
    "value_loss": 0.5158351957798004,
    "entropy": 0.8204593509435654,
    "total_loss": -416.3206722140312
  },
  {
    "episode": 43,
    "avg_reward_per_step": 69.01978961828672,
    "episode_length": 277,
    "policy_loss": -1161.2292785644531,
    "value_loss": 0.5583124607801437,
    "entropy": 0.8539471179246902,
    "total_loss": -1161.0125449508428
  },
  {
    "episode": 44,
    "avg_reward_per_step": 68.97186431020724,
    "episode_length": 277,
    "policy_loss": -1166.4458618164062,
    "value_loss": 0.5581251829862595,
    "entropy": 0.8624556809663773,
    "total_loss": -1166.2327189058065
  },
  {
    "episode": 45,
    "avg_reward_per_step": 134.3501371306478,
    "episode_length": 146,
    "policy_loss": -2311.8351440429688,
    "value_loss": 0.6326226890087128,
    "entropy": 0.8033341765403748,
    "total_loss": -2311.5238550245763
  },
  {
    "episode": 46,
    "avg_reward_per_step": 0.48757388744849717,
    "episode_length": 2164,
    "policy_loss": -6.228802561759949,
    "value_loss": 0.4997849017381668,
    "entropy": 0.6811496168375015,
    "total_loss": -6.001477506756783
  },
  {
    "episode": 47,
    "avg_reward_per_step": -10.387421282447967,
    "episode_length": 3000,
    "policy_loss": 175.06364822387695,
    "value_loss": 2.770792841911316,
    "entropy": 0.6215952336788177,
    "total_loss": 177.58580297231674
  },
  {
    "episode": 48,
    "avg_reward_per_step": -11.808130653595134,
    "episode_length": 3000,
    "policy_loss": 198.80107879638672,
    "value_loss": 3.6501415371894836,
    "entropy": 0.5684491097927094,
    "total_loss": 202.2238406896591
  },
  {
    "episode": 49,
    "avg_reward_per_step": -12.104672120768768,
    "episode_length": 3000,
    "policy_loss": 203.52529907226562,
    "value_loss": 3.875638484954834,
    "entropy": 0.5423254370689392,
    "total_loss": 207.18400738239288
  },
  {
    "episode": 50,
    "avg_reward_per_step": 59.001656755070016,
    "episode_length": 306,
    "policy_loss": -993.8700561523438,
    "value_loss": 0.5462564080953598,
    "entropy": 0.4850170910358429,
    "total_loss": -993.5178065806628
  },
  {
    "episode": 51,
    "avg_reward_per_step": -12.73341307260043,
    "episode_length": 3000,
    "policy_loss": 213.67348098754883,
    "value_loss": 3.6439499855041504,
    "entropy": 0.5015862286090851,
    "total_loss": 217.11679648160936
  },
  {
    "episode": 52,
    "avg_reward_per_step": -11.155651128868534,
    "episode_length": 3000,
    "policy_loss": 187.01987838745117,
    "value_loss": 2.021065831184387,
    "entropy": 0.5070579200983047,
    "total_loss": 188.83812105059624
  },
  {
    "episode": 53,
    "avg_reward_per_step": -12.777025700466703,
    "episode_length": 3000,
    "policy_loss": 214.00630950927734,
    "value_loss": 3.8272505402565002,
    "entropy": 0.4867173284292221,
    "total_loss": 217.63887311816217
  },
  {
    "episode": 54,
    "avg_reward_per_step": -2.5687700452161617,
    "episode_length": 2081,
    "policy_loss": 41.97683525085449,
    "value_loss": 0.500267431139946,
    "entropy": 0.46105659008026123,
    "total_loss": 42.292680045962335
  },
  {
    "episode": 55,
    "avg_reward_per_step": -9.546909054057211,
    "episode_length": 3000,
    "policy_loss": 159.30291366577148,
    "value_loss": 1.543775498867035,
    "entropy": 0.5203420370817184,
    "total_loss": 160.63855234980582
  },
  {
    "episode": 56,
    "avg_reward_per_step": 78.98094960393331,
    "episode_length": 228,
    "policy_loss": -1336.3965759277344,
    "value_loss": 0.5638325214385986,
    "entropy": 0.45296070724725723,
    "total_loss": -1336.0139276891946
  },
  {
    "episode": 57,
    "avg_reward_per_step": -12.97253753071922,
    "episode_length": 3000,
    "policy_loss": 216.90013885498047,
    "value_loss": 3.8019816875457764,
    "entropy": 0.4916752949357033,
    "total_loss": 220.50545042455195
  },
  {
    "episode": 58,
    "avg_reward_per_step": -0.9300954118303504,
    "episode_length": 2008,
    "policy_loss": 13.794783353805542,
    "value_loss": 0.4998134821653366,
    "entropy": 0.5550046861171722,
    "total_loss": 14.07259496152401
  },
  {
    "episode": 59,
    "avg_reward_per_step": -11.321733088623784,
    "episode_length": 3000,
    "policy_loss": 188.61687469482422,
    "value_loss": 2.671310603618622,
    "entropy": 0.6021156758069992,
    "total_loss": 191.04733902812004
  },
  {
    "episode": 60,
    "avg_reward_per_step": -8.89736898195546,
    "episode_length": 3000,
    "policy_loss": 148.22016525268555,
    "value_loss": 1.708661139011383,
    "entropy": 0.6579599380493164,
    "total_loss": 149.6656424164772
  },
  {
    "episode": 61,
    "avg_reward_per_step": -9.429546302139117,
    "episode_length": 3000,
    "policy_loss": 156.7658920288086,
    "value_loss": 2.1985220909118652,
    "entropy": 0.651489332318306,
    "total_loss": 158.70381838679313
  },
  {
    "episode": 62,
    "avg_reward_per_step": 6.836278414960768,
    "episode_length": 1074,
    "policy_loss": -117.51203727722168,
    "value_loss": 0.5016642063856125,
    "entropy": 0.605304092168808,
    "total_loss": -117.25249470770359
  },
  {
    "episode": 63,
    "avg_reward_per_step": -11.400959927322447,
    "episode_length": 3000,
    "policy_loss": 189.62612915039062,
    "value_loss": 3.089673340320587,
    "entropy": 0.6442310810089111,
    "total_loss": 192.45811005830765
  },
  {
    "episode": 64,
    "avg_reward_per_step": -2.3225847004149887,
    "episode_length": 2437,
    "policy_loss": 36.8247709274292,
    "value_loss": 0.5002573430538177,
    "entropy": 0.6773446202278137,
    "total_loss": 37.054090422391894
  },
  {
    "episode": 65,
    "avg_reward_per_step": -10.337564890923764,
    "episode_length": 3000,
    "policy_loss": 171.5154571533203,
    "value_loss": 3.024838864803314,
    "entropy": 0.7056884169578552,
    "total_loss": 174.25802065134047
  },
  {
    "episode": 66,
    "avg_reward_per_step": -9.980227106753874,
    "episode_length": 3000,
    "policy_loss": 165.45823287963867,
    "value_loss": 3.1043172478675842,
    "entropy": 0.7232658416032791,
    "total_loss": 168.27324379086494
  },
  {
    "episode": 67,
    "avg_reward_per_step": 8.266717732575769,
    "episode_length": 1235,
    "policy_loss": -143.02793884277344,
    "value_loss": 0.5032098740339279,
    "entropy": 0.7305988520383835,
    "total_loss": -142.81696850955487
  },
  {
    "episode": 68,
    "avg_reward_per_step": 122.0275360726619,
    "episode_length": 160,
    "policy_loss": -2068.4260864257812,
    "value_loss": 0.617048591375351,
    "entropy": 0.7430592328310013,
    "total_loss": -2068.106261527538
  },
  {
    "episode": 69,
    "avg_reward_per_step": 5.377286094039274,
    "episode_length": 1422,
    "policy_loss": -94.11630439758301,
    "value_loss": 0.5014393180608749,
    "entropy": 0.8246084749698639,
    "total_loss": -93.94470846951008
  },
  {
    "episode": 70,
    "avg_reward_per_step": 25.054061847561613,
    "episode_length": 597,
    "policy_loss": -429.5121841430664,
    "value_loss": 0.5150760263204575,
    "entropy": 0.8478092402219772,
    "total_loss": -429.33623181283474
  },
  {
    "episode": 71,
    "avg_reward_per_step": 0.45955521843517894,
    "episode_length": 2230,
    "policy_loss": -12.399816513061523,
    "value_loss": 0.49981962889432907,
    "entropy": 0.9301835745573044,
    "total_loss": -12.272070313990117
  },
  {
    "episode": 72,
    "avg_reward_per_step": 22.496540144293544,
    "episode_length": 725,
    "policy_loss": -381.11570739746094,
    "value_loss": 0.5150792598724365,
    "entropy": 1.0077342242002487,
    "total_loss": -381.0037218272686
  },
  {
    "episode": 73,
    "avg_reward_per_step": 142.74621868669755,
    "episode_length": 137,
    "policy_loss": -2434.5032958984375,
    "value_loss": 0.6438425779342651,
    "entropy": 1.005516603589058,
    "total_loss": -2434.2616599619387
  },
  {
    "episode": 74,
    "avg_reward_per_step": 52.80064568198985,
    "episode_length": 354,
    "policy_loss": -892.4641723632812,
    "value_loss": 0.5427073389291763,
    "entropy": 1.0708994567394257,
    "total_loss": -892.3498248070479
  },
  {
    "episode": 75,
    "avg_reward_per_step": 4.648124944130086,
    "episode_length": 2372,
    "policy_loss": -80.14019012451172,
    "value_loss": 0.502024456858635,
    "entropy": 1.1168099343776703,
    "total_loss": -80.08488964140415
  },
  {
    "episode": 76,
    "avg_reward_per_step": 37.95180363882538,
    "episode_length": 490,
    "policy_loss": -642.7846527099609,
    "value_loss": 0.5298290699720383,
    "entropy": 1.1268606185913086,
    "total_loss": -642.7055678874254
  },
  {
    "episode": 77,
    "avg_reward_per_step": 24.83554355484185,
    "episode_length": 693,
    "policy_loss": -422.80503845214844,
    "value_loss": 0.5176302939653397,
    "entropy": 1.0993572175502777,
    "total_loss": -422.7271510452032
  },
  {
    "episode": 78,
    "avg_reward_per_step": 12.916130635653223,
    "episode_length": 1237,
    "policy_loss": -220.24871063232422,
    "value_loss": 0.5084093362092972,
    "entropy": 1.0928539037704468,
    "total_loss": -220.1774428576231
  },
  {
    "episode": 79,
    "avg_reward_per_step": 78.2070433563551,
    "episode_length": 248,
    "policy_loss": -1330.6123352050781,
    "value_loss": 0.5692020654678345,
    "entropy": 1.0233864784240723,
    "total_loss": -1330.45248773098
  },
  {
    "episode": 80,
    "avg_reward_per_step": 39.908968429415,
    "episode_length": 461,
    "policy_loss": -680.8332977294922,
    "value_loss": 0.5310662090778351,
    "entropy": 0.9721113443374634,
    "total_loss": -680.6910760581493
  },
  {
    "episode": 81,
    "avg_reward_per_step": 15.100922424961112,
    "episode_length": 1000,
    "policy_loss": -258.5101852416992,
    "value_loss": 0.5091509819030762,
    "entropy": 0.9369380176067352,
    "total_loss": -258.37580946683886
  },
  {
    "episode": 82,
    "avg_reward_per_step": 35.696922015781695,
    "episode_length": 504,
    "policy_loss": -603.9093170166016,
    "value_loss": 0.5271609276533127,
    "entropy": 0.9063732177019119,
    "total_loss": -603.7447053760291
  },
  {
    "episode": 83,
    "avg_reward_per_step": 89.88240258648561,
    "episode_length": 214,
    "policy_loss": -1536.4531860351562,
    "value_loss": 0.5800759196281433,
    "entropy": 0.8655267953872681,
    "total_loss": -1536.219320833683
  },
  {
    "episode": 84,
    "avg_reward_per_step": 6.132375440898068,
    "episode_length": 2062,
    "policy_loss": -109.18341827392578,
    "value_loss": 0.5031133741140366,
    "entropy": 0.8974388092756271,
    "total_loss": -109.039280423522
  },
  {
    "episode": 85,
    "avg_reward_per_step": 92.38948481786294,
    "episode_length": 213,
    "policy_loss": -1558.7969360351562,
    "value_loss": 0.5847000181674957,
    "entropy": 0.8750320971012115,
    "total_loss": -1558.5622488558292
  },
  {
    "episode": 86,
    "avg_reward_per_step": 44.67444288995518,
    "episode_length": 418,
    "policy_loss": -757.6247253417969,
    "value_loss": 0.5356468707323074,
    "entropy": 0.8424628376960754,
    "total_loss": -757.426063606143
  },
  {
    "episode": 87,
    "avg_reward_per_step": 13.590878082556111,
    "episode_length": 1251,
    "policy_loss": -231.91864776611328,
    "value_loss": 0.5095712244510651,
    "entropy": 0.8394116908311844,
    "total_loss": -231.7448412179947
  },
  {
    "episode": 88,
    "avg_reward_per_step": 74.9127286513316,
    "episode_length": 257,
    "policy_loss": -1275.5767822265625,
    "value_loss": 0.5650516450405121,
    "entropy": 0.7931193709373474,
    "total_loss": -1275.328978329897
  },
  {
    "episode": 89,
    "avg_reward_per_step": 40.74619499908028,
    "episode_length": 465,
    "policy_loss": -692.5588531494141,
    "value_loss": 0.5330332815647125,
    "entropy": 0.7730399966239929,
    "total_loss": -692.335035866499
  },
  {
    "episode": 90,
    "avg_reward_per_step": 57.041485626480465,
    "episode_length": 340,
    "policy_loss": -968.2971801757812,
    "value_loss": 0.5482731759548187,
    "entropy": 0.7421477884054184,
    "total_loss": -968.0457661151886
  },
  {
    "episode": 91,
    "avg_reward_per_step": 105.37130694374615,
    "episode_length": 185,
    "policy_loss": -1784.0417785644531,
    "value_loss": 0.5985393524169922,
    "entropy": 0.7497562170028687,
    "total_loss": -1783.7431416988372
  },
  {
    "episode": 92,
    "avg_reward_per_step": 45.70532648805248,
    "episode_length": 424,
    "policy_loss": -775.0408935546875,
    "value_loss": 0.5380179584026337,
    "entropy": 0.6632079780101776,
    "total_loss": -774.7681587874889
  },
  {
    "episode": 93,
    "avg_reward_per_step": 28.20646397742856,
    "episode_length": 680,
    "policy_loss": -477.4590072631836,
    "value_loss": 0.522608682513237,
    "entropy": 0.6009815484285355,
    "total_loss": -477.17679120004175
  },
  {
    "episode": 94,
    "avg_reward_per_step": 11.25257328925205,
    "episode_length": 1615,
    "policy_loss": -191.96831130981445,
    "value_loss": 0.5084412693977356,
    "entropy": 0.5247166901826859,
    "total_loss": -191.6697567164898
  },
  {
    "episode": 95,
    "avg_reward_per_step": 34.76897984269204,
    "episode_length": 558,
    "policy_loss": -592.0987701416016,
    "value_loss": 0.5284829586744308,
    "entropy": 0.5536643266677856,
    "total_loss": -591.7917529135942
  },
  {
    "episode": 96,
    "avg_reward_per_step": -1.0176168960528633,
    "episode_length": 3000,
    "policy_loss": 14.715062379837036,
    "value_loss": 1.0324100255966187,
    "entropy": 0.5604468882083893,
    "total_loss": 15.523293650150299
  },
  {
    "episode": 97,
    "avg_reward_per_step": 6.932403188368733,
    "episode_length": 2427,
    "policy_loss": -120.19261360168457,
    "value_loss": 0.5048971176147461,
    "entropy": 0.5608582645654678,
    "total_loss": -119.912059789896
  },
  {
    "episode": 98,
    "avg_reward_per_step": 20.083189381849436,
    "episode_length": 902,
    "policy_loss": -341.04803466796875,
    "value_loss": 0.515069991350174,
    "entropy": 0.6953106075525284,
    "total_loss": -340.8110889196396
  },
  {
    "episode": 99,
    "avg_reward_per_step": 103.47301760639154,
    "episode_length": 192,
    "policy_loss": -1759.1036682128906,
    "value_loss": 0.5979716032743454,
    "entropy": 0.6876156777143478,
    "total_loss": -1758.780742880702
  },
  {
    "episode": 100,
    "avg_reward_per_step": 55.70096747765788,
    "episode_length": 347,
    "policy_loss": -942.4080657958984,
    "value_loss": 0.5471365302801132,
    "entropy": 0.6541908234357834,
    "total_loss": -942.1226055949926
  },
  {
    "episode": 101,
    "avg_reward_per_step": 220.17649989891368,
    "episode_length": 91,
    "policy_loss": -3758.6994018554688,
    "value_loss": 0.768901526927948,
    "entropy": 0.6754661500453949,
    "total_loss": -3758.200686788559
  },
  {
    "episode": 102,
    "avg_reward_per_step": 240.8637133279644,
    "episode_length": 83,
    "policy_loss": -4096.69287109375,
    "value_loss": 0.8073510229587555,
    "entropy": 0.6770287305116653,
    "total_loss": -4096.156331562996
  },
  {
    "episode": 103,
    "avg_reward_per_step": 243.8615987303069,
    "episode_length": 82,
    "policy_loss": -4117.8375244140625,
    "value_loss": 0.8134634494781494,
    "entropy": 0.6517525762319565,
    "total_loss": -4117.284761995077
  },
  {
    "episode": 104,
    "avg_reward_per_step": -11.678151767588332,
    "episode_length": 3000,
    "policy_loss": 193.22820281982422,
    "value_loss": 3.0511797070503235,
    "entropy": 0.46759549528360367,
    "total_loss": 196.0923443287611
  },
  {
    "episode": 105,
    "avg_reward_per_step": -12.369993441492552,
    "episode_length": 3000,
    "policy_loss": 204.9495964050293,
    "value_loss": 3.392044186592102,
    "entropy": 0.4794149696826935,
    "total_loss": 208.14987460374832
  },
  {
    "episode": 106,
    "avg_reward_per_step": -12.707210609778235,
    "episode_length": 3000,
    "policy_loss": 210.1830825805664,
    "value_loss": 3.5247857570648193,
    "entropy": 0.4542016386985779,
    "total_loss": 213.5261876821518
  },
  {
    "episode": 107,
    "avg_reward_per_step": -12.39294229718109,
    "episode_length": 3000,
    "policy_loss": 204.83668899536133,
    "value_loss": 3.121631681919098,
    "entropy": 0.4526483491063118,
    "total_loss": 207.7772613376379
  },
  {
    "episode": 108,
    "avg_reward_per_step": -14.119121360590047,
    "episode_length": 3000,
    "policy_loss": 233.4672088623047,
    "value_loss": 3.686355233192444,
    "entropy": 0.35958971083164215,
    "total_loss": 237.0097282111645
  },
  {
    "episode": 109,
    "avg_reward_per_step": -12.45613477810647,
    "episode_length": 3000,
    "policy_loss": 205.0350685119629,
    "value_loss": 3.2437559366226196,
    "entropy": 0.4509323909878731,
    "total_loss": 208.09845149219035
  },
  {
    "episode": 110,
    "avg_reward_per_step": -12.62220935090224,
    "episode_length": 3000,
    "policy_loss": 207.83519744873047,
    "value_loss": 3.049661338329315,
    "entropy": 0.45566508919000626,
    "total_loss": 210.70259275138378
  },
  {
    "episode": 111,
    "avg_reward_per_step": 61.69658258968851,
    "episode_length": 298,
    "policy_loss": -1045.1932373046875,
    "value_loss": 0.5501357316970825,
    "entropy": 0.3691970780491829,
    "total_loss": -1044.7907804042102
  },
  {
    "episode": 112,
    "avg_reward_per_step": -12.635834982831737,
    "episode_length": 3000,
    "policy_loss": 207.51056671142578,
    "value_loss": 3.7335986495018005,
    "entropy": 0.47328315675258636,
    "total_loss": 211.05485209822655
  },
  {
    "episode": 113,
    "avg_reward_per_step": -12.711823810326141,
    "episode_length": 3000,
    "policy_loss": 208.7119026184082,
    "value_loss": 3.453651785850525,
    "entropy": 0.46390528976917267,
    "total_loss": 211.97999228835107
  },
  {
    "episode": 114,
    "avg_reward_per_step": -12.760969216461916,
    "episode_length": 3000,
    "policy_loss": 209.11931991577148,
    "value_loss": 3.291419804096222,
    "entropy": 0.43046828359365463,
    "total_loss": 212.23855240643024
  },
  {
    "episode": 115,
    "avg_reward_per_step": -11.726240449177423,
    "episode_length": 3000,
    "policy_loss": 191.4450912475586,
    "value_loss": 2.6332043409347534,
    "entropy": 0.47645294666290283,
    "total_loss": 193.8877144098282
  },
  {
    "episode": 116,
    "avg_reward_per_step": 45.15103276936241,
    "episode_length": 357,
    "policy_loss": -778.611328125,
    "value_loss": 0.5308658182621002,
    "entropy": 0.4741237536072731,
    "total_loss": -778.2701118081808
  },
  {
    "episode": 117,
    "avg_reward_per_step": 10.333389639875996,
    "episode_length": 975,
    "policy_loss": -182.61326217651367,
    "value_loss": 0.5040910691022873,
    "entropy": 0.5814446806907654,
    "total_loss": -182.34174897968768
  },
  {
    "episode": 118,
    "avg_reward_per_step": 92.39673639439494,
    "episode_length": 203,
    "policy_loss": -1578.3727722167969,
    "value_loss": 0.5811157822608948,
    "entropy": 0.6172264665365219,
    "total_loss": -1578.0385470211506
  },
  {
    "episode": 119,
    "avg_reward_per_step": 5.3183943945015875,
    "episode_length": 1545,
    "policy_loss": -99.99826240539551,
    "value_loss": 0.5017685741186142,
    "entropy": 0.6231647729873657,
    "total_loss": -99.74575974047184
  },
  {
    "episode": 120,
    "avg_reward_per_step": 20.450499125908646,
    "episode_length": 745,
    "policy_loss": -352.5817108154297,
    "value_loss": 0.5130167007446289,
    "entropy": 0.6987605392932892,
    "total_loss": -352.3481983304024
  },
  {
    "episode": 121,
    "avg_reward_per_step": 101.21248368605296,
    "episode_length": 193,
    "policy_loss": -1718.3471984863281,
    "value_loss": 0.5942669212818146,
    "entropy": 0.706492230296135,
    "total_loss": -1718.0355284571647
  },
  {
    "episode": 122,
    "avg_reward_per_step": 11.428370108208622,
    "episode_length": 1258,
    "policy_loss": -201.48548126220703,
    "value_loss": 0.5069936066865921,
    "entropy": 0.735156312584877,
    "total_loss": -201.2725501805544
  },
  {
    "episode": 123,
    "avg_reward_per_step": 23.18213401445531,
    "episode_length": 750,
    "policy_loss": -399.61622619628906,
    "value_loss": 0.517053097486496,
    "entropy": 0.7269531637430191,
    "total_loss": -399.3899543642998
  },
  {
    "episode": 124,
    "avg_reward_per_step": 30.902568124765097,
    "episode_length": 593,
    "policy_loss": -531.9647827148438,
    "value_loss": 0.5241397470235825,
    "entropy": 0.7323561310768127,
    "total_loss": -531.7335854202508
  },
  {
    "episode": 125,
    "avg_reward_per_step": 16.586828395288066,
    "episode_length": 1062,
    "policy_loss": -284.61888885498047,
    "value_loss": 0.5124756097793579,
    "entropy": 0.6792992502450943,
    "total_loss": -284.37813294529917
  },
  {
    "episode": 126,
    "avg_reward_per_step": 44.221732600075775,
    "episode_length": 426,
    "policy_loss": -759.9730834960938,
    "value_loss": 0.5361702889204025,
    "entropy": 0.6875839531421661,
    "total_loss": -759.7119467884302
  },
  {
    "episode": 127,
    "avg_reward_per_step": 23.023256619693047,
    "episode_length": 785,
    "policy_loss": -393.0948486328125,
    "value_loss": 0.5176376402378082,
    "entropy": 0.7054207772016525,
    "total_loss": -392.85937930345534
  },
  {
    "episode": 128,
    "avg_reward_per_step": 47.927781178698346,
    "episode_length": 398,
    "policy_loss": -813.5401458740234,
    "value_loss": 0.5398732721805573,
    "entropy": 0.7056198269128799,
    "total_loss": -813.282520532608
  },
  {
    "episode": 129,
    "avg_reward_per_step": 52.640366802329034,
    "episode_length": 367,
    "policy_loss": -898.2920074462891,
    "value_loss": 0.5446032583713531,
    "entropy": 0.6992092281579971,
    "total_loss": -898.027087879181
  },
  {
    "episode": 130,
    "avg_reward_per_step": 123.04705510499593,
    "episode_length": 160,
    "policy_loss": -2106.6454467773438,
    "value_loss": 0.6203464567661285,
    "entropy": 0.6887523084878922,
    "total_loss": -2106.300601243973
  },
  {
    "episode": 131,
    "avg_reward_per_step": 119.3051819682379,
    "episode_length": 165,
    "policy_loss": -2026.2769775390625,
    "value_loss": 0.6161584407091141,
    "entropy": 0.6862428039312363,
    "total_loss": -2025.9353162199259
  },
  {
    "episode": 132,
    "avg_reward_per_step": 33.9846936260964,
    "episode_length": 488,
    "policy_loss": -578.54443359375,
    "value_loss": 0.5235301703214645,
    "entropy": 0.6226911842823029,
    "total_loss": -578.2699798971414
  },
  {
    "episode": 133,
    "avg_reward_per_step": 96.92382472137243,
    "episode_length": 199,
    "policy_loss": -1644.9304809570312,
    "value_loss": 0.5877802819013596,
    "entropy": 0.6700263917446136,
    "total_loss": -1644.6107112318277
  },
  {
    "episode": 134,
    "avg_reward_per_step": -10.891266500231337,
    "episode_length": 3000,
    "policy_loss": 176.62908554077148,
    "value_loss": 3.6170576214790344,
    "entropy": 0.5447080731391907,
    "total_loss": 180.02825993299484
  },
  {
    "episode": 135,
    "avg_reward_per_step": -1.3313548950098206,
    "episode_length": 2285,
    "policy_loss": 15.217703104019165,
    "value_loss": 0.4999605864286423,
    "entropy": 0.5200426578521729,
    "total_loss": 15.509646627306939
  },
  {
    "episode": 136,
    "avg_reward_per_step": -11.718099085337101,
    "episode_length": 3000,
    "policy_loss": 190.15281677246094,
    "value_loss": 3.4089295864105225,
    "entropy": 0.5230788737535477,
    "total_loss": 193.35251480937004
  },
  {
    "episode": 137,
    "avg_reward_per_step": 72.35860026651304,
    "episode_length": 253,
    "policy_loss": -1228.161865234375,
    "value_loss": 0.5596650987863541,
    "entropy": 0.42197228968143463,
    "total_loss": -1227.7709890514611
  },
  {
    "episode": 138,
    "avg_reward_per_step": 4.813135325102358,
    "episode_length": 1305,
    "policy_loss": -90.8829288482666,
    "value_loss": 0.5011719763278961,
    "entropy": 0.5378903150558472,
    "total_loss": -90.59691299796104
  },
  {
    "episode": 139,
    "avg_reward_per_step": -10.492035691294753,
    "episode_length": 3000,
    "policy_loss": 168.90067672729492,
    "value_loss": 2.9736234545707703,
    "entropy": 0.5751456916332245,
    "total_loss": 171.6442419052124
  },
  {
    "episode": 140,
    "avg_reward_per_step": -9.313780921623355,
    "episode_length": 3000,
    "policy_loss": 148.88229370117188,
    "value_loss": 2.246771275997162,
    "entropy": 0.6116546392440796,
    "total_loss": 150.8844031214714
  },
  {
    "episode": 141,
    "avg_reward_per_step": 3.498925923254501,
    "episode_length": 1598,
    "policy_loss": -66.93229293823242,
    "value_loss": 0.500817596912384,
    "entropy": 0.6188188195228577,
    "total_loss": -66.67900286912918
  },
  {
    "episode": 142,
    "avg_reward_per_step": 144.03457605980438,
    "episode_length": 133,
    "policy_loss": -2443.7150268554688,
    "value_loss": 0.6429096460342407,
    "entropy": 0.5760502070188522,
    "total_loss": -2443.302537292242
  },
  {
    "episode": 143,
    "avg_reward_per_step": 9.861021402716379,
    "episode_length": 1031,
    "policy_loss": -175.78913116455078,
    "value_loss": 0.5041516274213791,
    "entropy": 0.5489687323570251,
    "total_loss": -175.50456703007222
  },
  {
    "episode": 144,
    "avg_reward_per_step": 7.325313848400846,
    "episode_length": 1167,
    "policy_loss": -132.44603729248047,
    "value_loss": 0.5026154667139053,
    "entropy": 0.557047575712204,
    "total_loss": -132.16624085605145
  },
  {
    "episode": 145,
    "avg_reward_per_step": -11.17375622491251,
    "episode_length": 3000,
    "policy_loss": 179.27046585083008,
    "value_loss": 3.1573978662490845,
    "entropy": 0.542006328701973,
    "total_loss": 182.21106118559837
  },
  {
    "episode": 146,
    "avg_reward_per_step": 23.6161068654419,
    "episode_length": 616,
    "policy_loss": -407.8177947998047,
    "value_loss": 0.5142892748117447,
    "entropy": 0.5749221295118332,
    "total_loss": -407.5334743767977
  },
  {
    "episode": 147,
    "avg_reward_per_step": 15.74894677685147,
    "episode_length": 811,
    "policy_loss": -277.52801513671875,
    "value_loss": 0.5082653313875198,
    "entropy": 0.6201428920030594,
    "total_loss": -277.26780696213245
  },
  {
    "episode": 148,
    "avg_reward_per_step": 195.23391538468798,
    "episode_length": 102,
    "policy_loss": -3307.6489868164062,
    "value_loss": 0.7255979478359222,
    "entropy": 0.746229961514473,
    "total_loss": -3307.221880853176
  },
  {
    "episode": 149,
    "avg_reward_per_step": 0.2097504217148253,
    "episode_length": 2243,
    "policy_loss": -12.754592895507812,
    "value_loss": 0.49988481402397156,
    "entropy": 0.6059936881065369,
    "total_loss": -12.497105556726456
  },
  {
    "episode": 150,
    "avg_reward_per_step": -11.037649673792766,
    "episode_length": 3000,
    "policy_loss": 176.66921615600586,
    "value_loss": 2.9508151412010193,
    "entropy": 0.5453516244888306,
    "total_loss": 179.40189064741134
  },
  {
    "episode": 151,
    "avg_reward_per_step": -9.862737302274521,
    "episode_length": 3000,
    "policy_loss": 156.7289924621582,
    "value_loss": 2.6876155138015747,
    "entropy": 0.5917357951402664,
    "total_loss": 159.17991365790368
  },
  {
    "episode": 152,
    "avg_reward_per_step": -10.96884586561262,
    "episode_length": 3000,
    "policy_loss": 175.02907943725586,
    "value_loss": 2.738039493560791,
    "entropy": 0.5512357205152512,
    "total_loss": 177.54662464261054
  },
  {
    "episode": 153,
    "avg_reward_per_step": -11.078482731459449,
    "episode_length": 3000,
    "policy_loss": 176.47861099243164,
    "value_loss": 2.9266337752342224,
    "entropy": 0.552124097943306,
    "total_loss": 179.18439512848855
  },
  {
    "episode": 154,
    "avg_reward_per_step": -10.406162778571714,
    "episode_length": 3000,
    "policy_loss": 165.00785064697266,
    "value_loss": 2.7673794627189636,
    "entropy": 0.6000516265630722,
    "total_loss": 167.53520945906638
  },
  {
    "episode": 155,
    "avg_reward_per_step": -10.77314961798683,
    "episode_length": 3000,
    "policy_loss": 170.40657806396484,
    "value_loss": 3.1005207896232605,
    "entropy": 0.5450715869665146,
    "total_loss": 173.2890702188015
  },
  {
    "episode": 156,
    "avg_reward_per_step": -10.877886803540488,
    "episode_length": 3000,
    "policy_loss": 171.82987594604492,
    "value_loss": 3.072736978530884,
    "entropy": 0.5685992240905762,
    "total_loss": 174.67517323493956
  },
  {
    "episode": 157,
    "avg_reward_per_step": 139.09758453276737,
    "episode_length": 143,
    "policy_loss": -2389.291015625,
    "value_loss": 0.6428271681070328,
    "entropy": 0.6347805708646774,
    "total_loss": -2388.902100685239
  },
  {
    "episode": 158,
    "avg_reward_per_step": -11.89297928227248,
    "episode_length": 3000,
    "policy_loss": 189.04025268554688,
    "value_loss": 3.4378875494003296,
    "entropy": 0.4658931791782379,
    "total_loss": 192.29178296327592
  },
  {
    "episode": 159,
    "avg_reward_per_step": 58.35037800300115,
    "episode_length": 309,
    "policy_loss": -995.1722106933594,
    "value_loss": 0.5468623787164688,
    "entropy": 0.32209527492523193,
    "total_loss": -994.754186424613
  },
  {
    "episode": 160,
    "avg_reward_per_step": -10.640236208590375,
    "episode_length": 3000,
    "policy_loss": 166.75205993652344,
    "value_loss": 1.8881763517856598,
    "entropy": 0.4425995647907257,
    "total_loss": 168.4631964623928
  },
  {
    "episode": 161,
    "avg_reward_per_step": -13.554960892445724,
    "episode_length": 3000,
    "policy_loss": 215.1200408935547,
    "value_loss": 3.34136301279068,
    "entropy": 0.3901020959019661,
    "total_loss": 218.3053630679846
  },
  {
    "episode": 162,
    "avg_reward_per_step": -12.791991751995367,
    "episode_length": 3000,
    "policy_loss": 201.9537582397461,
    "value_loss": 2.999086320400238,
    "entropy": 0.3955880254507065,
    "total_loss": 204.79460934996604
  },
  {
    "episode": 163,
    "avg_reward_per_step": -13.020740507791876,
    "episode_length": 3000,
    "policy_loss": 205.24663925170898,
    "value_loss": 3.003614068031311,
    "entropy": 0.3900812193751335,
    "total_loss": 208.09422083199024
  },
  {
    "episode": 164,
    "avg_reward_per_step": -13.406413275412806,
    "episode_length": 3000,
    "policy_loss": 211.20523071289062,
    "value_loss": 3.1669440269470215,
    "entropy": 0.39241956919431686,
    "total_loss": 214.2152069121599
  },
  {
    "episode": 165,
    "avg_reward_per_step": -12.656716752235079,
    "episode_length": 3000,
    "policy_loss": 198.52312088012695,
    "value_loss": 2.8913705945014954,
    "entropy": 0.39480186253786087,
    "total_loss": 201.25657072961332
  },
  {
    "episode": 166,
    "avg_reward_per_step": -12.746187455645527,
    "episode_length": 3000,
    "policy_loss": 199.21928024291992,
    "value_loss": 2.964617669582367,
    "entropy": 0.4045640006661415,
    "total_loss": 202.02207231223582
  },
  {
    "episode": 167,
    "avg_reward_per_step": -12.401229305801355,
    "episode_length": 3000,
    "policy_loss": 193.2177505493164,
    "value_loss": 3.1079888939857483,
    "entropy": 0.4146121218800545,
    "total_loss": 196.15989459455014
  },
  {
    "episode": 168,
    "avg_reward_per_step": -12.381329820339142,
    "episode_length": 3000,
    "policy_loss": 192.12050247192383,
    "value_loss": 2.9444152116775513,
    "entropy": 0.41103609651327133,
    "total_loss": 194.90050324499606
  },
  {
    "episode": 169,
    "avg_reward_per_step": -12.24459186967375,
    "episode_length": 3000,
    "policy_loss": 189.55932998657227,
    "value_loss": 2.8234631419181824,
    "entropy": 0.424218013882637,
    "total_loss": 192.2131059229374
  },
  {
    "episode": 170,
    "avg_reward_per_step": -12.693583162484273,
    "episode_length": 3000,
    "policy_loss": 196.3700714111328,
    "value_loss": 3.031318783760071,
    "entropy": 0.42011774331331253,
    "total_loss": 199.23334309756757
  },
  {
    "episode": 171,
    "avg_reward_per_step": -12.72775053418275,
    "episode_length": 3000,
    "policy_loss": 196.38458633422852,
    "value_loss": 2.8631492257118225,
    "entropy": 0.4338213726878166,
    "total_loss": 199.07420701086522
  },
  {
    "episode": 172,
    "avg_reward_per_step": -12.681273578120953,
    "episode_length": 3000,
    "policy_loss": 195.31884384155273,
    "value_loss": 3.0733249187469482,
    "entropy": 0.44250519573688507,
    "total_loss": 198.21516668200493
  },
  {
    "episode": 173,
    "avg_reward_per_step": 90.84311635958544,
    "episode_length": 203,
    "policy_loss": -1567.7937316894531,
    "value_loss": 0.5794020295143127,
    "entropy": 0.42090146243572235,
    "total_loss": -1567.3826902449132
  },
  {
    "episode": 174,
    "avg_reward_per_step": -4.588153218604856,
    "episode_length": 2847,
    "policy_loss": 56.951260566711426,
    "value_loss": 0.5012181848287582,
    "entropy": 0.500476248562336,
    "total_loss": 57.25228825211525
  },
  {
    "episode": 175,
    "avg_reward_per_step": 3.307779562352219,
    "episode_length": 1588,
    "policy_loss": -78.11460304260254,
    "value_loss": 0.5012226104736328,
    "entropy": 0.5671149641275406,
    "total_loss": -77.84022641777992
  },
  {
    "episode": 176,
    "avg_reward_per_step": -10.649367586307553,
    "episode_length": 3000,
    "policy_loss": 159.16551971435547,
    "value_loss": 2.5379384756088257,
    "entropy": 0.559474304318428,
    "total_loss": 161.47966846823692
  },
  {
    "episode": 177,
    "avg_reward_per_step": 11.40951497738751,
    "episode_length": 983,
    "policy_loss": -215.39728927612305,
    "value_loss": 0.5061036944389343,
    "entropy": 0.591205820441246,
    "total_loss": -215.1276679098606
  },
  {
    "episode": 178,
    "avg_reward_per_step": 70.70024469356515,
    "episode_length": 268,
    "policy_loss": -1224.7936401367188,
    "value_loss": 0.5623277127742767,
    "entropy": 0.6855469197034836,
    "total_loss": -1224.5055311918259
  },
  {
    "episode": 179,
    "avg_reward_per_step": 169.99468437265585,
    "episode_length": 113,
    "policy_loss": -2934.0372314453125,
    "value_loss": 0.680595651268959,
    "entropy": 0.5767735689878464,
    "total_loss": -2933.5873452216388
  },
  {
    "episode": 180,
    "avg_reward_per_step": 72.55851732833902,
    "episode_length": 258,
    "policy_loss": -1253.7092590332031,
    "value_loss": 0.5635720044374466,
    "entropy": 0.5293243676424026,
    "total_loss": -1253.3574167758227
  },
  {
    "episode": 181,
    "avg_reward_per_step": -12.171897735374298,
    "episode_length": 3000,
    "policy_loss": 184.60776901245117,
    "value_loss": 2.7128483653068542,
    "entropy": 0.3930957242846489,
    "total_loss": 187.16337908804417
  },
  {
    "episode": 182,
    "avg_reward_per_step": -11.62439597287762,
    "episode_length": 3000,
    "policy_loss": 175.48627853393555,
    "value_loss": 1.6768566071987152,
    "entropy": 0.3820757195353508,
    "total_loss": 177.01030485332012
  },
  {
    "episode": 183,
    "avg_reward_per_step": -13.28725252023715,
    "episode_length": 3000,
    "policy_loss": 202.3706398010254,
    "value_loss": 2.8333077430725098,
    "entropy": 0.30414769798517227,
    "total_loss": 205.08228846490383
  },
  {
    "episode": 184,
    "avg_reward_per_step": -14.421658977155786,
    "episode_length": 3000,
    "policy_loss": 221.27958297729492,
    "value_loss": 3.0062729716300964,
    "entropy": 0.2778792157769203,
    "total_loss": 224.17470426261426
  },
  {
    "episode": 185,
    "avg_reward_per_step": 16.892617881527887,
    "episode_length": 836,
    "policy_loss": -308.4530563354492,
    "value_loss": 0.511175200343132,
    "entropy": 0.19483930990099907,
    "total_loss": -308.0198168590665
  },
  {
    "episode": 186,
    "avg_reward_per_step": -13.950931359829665,
    "episode_length": 3000,
    "policy_loss": 212.47006225585938,
    "value_loss": 2.7935526967048645,
    "entropy": 0.2685718461871147,
    "total_loss": 215.1561862140894
  },
  {
    "episode": 187,
    "avg_reward_per_step": -14.217281962278681,
    "episode_length": 3000,
    "policy_loss": 216.713623046875,
    "value_loss": 3.1343101859092712,
    "entropy": 0.2646358609199524,
    "total_loss": 219.7420788884163
  },
  {
    "episode": 188,
    "avg_reward_per_step": 31.33751349127817,
    "episode_length": 486,
    "policy_loss": -554.6456451416016,
    "value_loss": 0.5214097946882248,
    "entropy": 0.22687828913331032,
    "total_loss": -554.2149866625666
  },
  {
    "episode": 189,
    "avg_reward_per_step": 35.80374309815739,
    "episode_length": 458,
    "policy_loss": -633.7576751708984,
    "value_loss": 0.5264422595500946,
    "entropy": 0.193991307169199,
    "total_loss": -633.308829434216
  },
  {
    "episode": 190,
    "avg_reward_per_step": -14.03913099220333,
    "episode_length": 3000,
    "policy_loss": 212.6106071472168,
    "value_loss": 3.0688416957855225,
    "entropy": 0.30036596953868866,
    "total_loss": 215.55930245518684
  },
  {
    "episode": 191,
    "avg_reward_per_step": -13.092132699144575,
    "episode_length": 3000,
    "policy_loss": 196.34990692138672,
    "value_loss": 2.638186514377594,
    "entropy": 0.3462117612361908,
    "total_loss": 198.84960873126983
  },
  {
    "episode": 192,
    "avg_reward_per_step": -13.539969453636555,
    "episode_length": 3000,
    "policy_loss": 203.94873046875,
    "value_loss": 2.7059447169303894,
    "entropy": 0.36547550559043884,
    "total_loss": 206.50848498344422
  },
  {
    "episode": 193,
    "avg_reward_per_step": -13.126012892485322,
    "episode_length": 3000,
    "policy_loss": 196.17030334472656,
    "value_loss": 2.9061537981033325,
    "entropy": 0.3802868202328682,
    "total_loss": 198.92434241473674
  },
  {
    "episode": 194,
    "avg_reward_per_step": -12.791055154363438,
    "episode_length": 3000,
    "policy_loss": 190.38812255859375,
    "value_loss": 2.918063223361969,
    "entropy": 0.38824881613254547,
    "total_loss": 193.1508862555027
  },
  {
    "episode": 195,
    "avg_reward_per_step": -11.581080139957427,
    "episode_length": 3000,
    "policy_loss": 169.6281509399414,
    "value_loss": 2.303041994571686,
    "entropy": 0.4139532446861267,
    "total_loss": 171.76561163663865
  },
  {
    "episode": 196,
    "avg_reward_per_step": 131.32524941695246,
    "episode_length": 151,
    "policy_loss": -2267.2582397460938,
    "value_loss": 0.634763702750206,
    "entropy": 0.5726400315761566,
    "total_loss": -2266.852532055974
  },
  {
    "episode": 197,
    "avg_reward_per_step": -11.487621631957088,
    "episode_length": 3000,
    "policy_loss": 166.7497787475586,
    "value_loss": 2.4822673201560974,
    "entropy": 0.4617813155055046,
    "total_loss": 169.0473335415125
  },
  {
    "episode": 198,
    "avg_reward_per_step": 7.141321378886971,
    "episode_length": 1197,
    "policy_loss": -148.78081512451172,
    "value_loss": 0.5036834478378296,
    "entropy": 0.49593984335660934,
    "total_loss": -148.47550761401652
  },
  {
    "episode": 199,
    "avg_reward_per_step": -11.416426360376223,
    "episode_length": 3000,
    "policy_loss": 164.57608795166016,
    "value_loss": 2.632232129573822,
    "entropy": 0.4915429577231407,
    "total_loss": 167.01170289814473
  },
  {
    "episode": 200,
    "avg_reward_per_step": -11.142971442629282,
    "episode_length": 3000,
    "policy_loss": 159.85774993896484,
    "value_loss": 2.421187162399292,
    "entropy": 0.5017512738704681,
    "total_loss": 162.07823659181594
  },
  {
    "episode": 201,
    "avg_reward_per_step": 213.4176935973994,
    "episode_length": 93,
    "policy_loss": -3714.7290649414062,
    "value_loss": 0.7578587979078293,
    "entropy": 0.5855664163827896,
    "total_loss": -3714.2054327100514
  },
  {
    "episode": 202,
    "avg_reward_per_step": 150.9646797622321,
    "episode_length": 130,
    "policy_loss": -2601.9463500976562,
    "value_loss": 0.6586982160806656,
    "entropy": 0.6553757041692734,
    "total_loss": -2601.5498021632434
  },
  {
    "episode": 203,
    "avg_reward_per_step": 26.7715595321275,
    "episode_length": 639,
    "policy_loss": -484.4751434326172,
    "value_loss": 0.5218414813280106,
    "entropy": 0.6974760591983795,
    "total_loss": -484.23229237496855
  },
  {
    "episode": 204,
    "avg_reward_per_step": 20.774025674604427,
    "episode_length": 803,
    "policy_loss": -383.37940216064453,
    "value_loss": 0.5169479548931122,
    "entropy": 0.7026977986097336,
    "total_loss": -383.14353332519534
  },
  {
    "episode": 205,
    "avg_reward_per_step": 138.84059791120777,
    "episode_length": 141,
    "policy_loss": -2389.4298095703125,
    "value_loss": 0.6432427763938904,
    "entropy": 0.6971809715032578,
    "total_loss": -2389.06543918252
  },
  {
    "episode": 206,
    "avg_reward_per_step": 117.06929796635742,
    "episode_length": 169,
    "policy_loss": -2022.837646484375,
    "value_loss": 0.6176182627677917,
    "entropy": 0.7134225815534592,
    "total_loss": -2022.5053972542287
  },
  {
    "episode": 207,
    "avg_reward_per_step": 86.9916798503266,
    "episode_length": 225,
    "policy_loss": -1504.1902770996094,
    "value_loss": 0.5816341936588287,
    "entropy": 0.7031202167272568,
    "total_loss": -1503.8898909926415
  },
  {
    "episode": 208,
    "avg_reward_per_step": 163.68486039874242,
    "episode_length": 122,
    "policy_loss": -2846.7623291015625,
    "value_loss": 0.6801215559244156,
    "entropy": 0.6853454858064651,
    "total_loss": -2846.3563457399605
  },
  {
    "episode": 209,
    "avg_reward_per_step": 143.73840215095075,
    "episode_length": 138,
    "policy_loss": -2486.3627319335938,
    "value_loss": 0.6517749428749084,
    "entropy": 0.6261802017688751,
    "total_loss": -2485.961429071426
  },
  {
    "episode": 210,
    "avg_reward_per_step": 16.90641483133353,
    "episode_length": 951,
    "policy_loss": -309.9924087524414,
    "value_loss": 0.5138138383626938,
    "entropy": 0.6765480786561966,
    "total_loss": -309.7492141455412
  },
  {
    "episode": 211,
    "avg_reward_per_step": 146.56227657882022,
    "episode_length": 136,
    "policy_loss": -2518.04931640625,
    "value_loss": 0.6559392511844635,
    "entropy": 0.6812767386436462,
    "total_loss": -2517.665887850523
  },
  {
    "episode": 212,
    "avg_reward_per_step": 183.09236567129386,
    "episode_length": 109,
    "policy_loss": -3155.8872680664062,
    "value_loss": 0.7103093862533569,
    "entropy": 0.6357422471046448,
    "total_loss": -3155.4312555789948
  },
  {
    "episode": 213,
    "avg_reward_per_step": 79.34759563960459,
    "episode_length": 250,
    "policy_loss": -1374.6612243652344,
    "value_loss": 0.5754057019948959,
    "entropy": 0.6115272790193558,
    "total_loss": -1374.3304295748471
  },
  {
    "episode": 214,
    "avg_reward_per_step": 63.79207209102892,
    "episode_length": 310,
    "policy_loss": -1115.1943054199219,
    "value_loss": 0.5593157112598419,
    "entropy": 0.6489534229040146,
    "total_loss": -1114.8945710778237
  },
  {
    "episode": 215,
    "avg_reward_per_step": 19.535097196759274,
    "episode_length": 935,
    "policy_loss": -358.7823486328125,
    "value_loss": 0.5178200006484985,
    "entropy": 0.6210519075393677,
    "total_loss": -358.51294939517976
  },
  {
    "episode": 216,
    "avg_reward_per_step": 94.0690906525064,
    "episode_length": 212,
    "policy_loss": -1653.0706481933594,
    "value_loss": 0.5918100774288177,
    "entropy": 0.5526772886514664,
    "total_loss": -1652.6999090313911
  },
  {
    "episode": 217,
    "avg_reward_per_step": 85.65932604679426,
    "episode_length": 232,
    "policy_loss": -1472.4465637207031,
    "value_loss": 0.5822805911302567,
    "entropy": 0.6288488954305649,
    "total_loss": -1472.115822687745
  },
  {
    "episode": 218,
    "avg_reward_per_step": 226.90301197871287,
    "episode_length": 88,
    "policy_loss": -3886.4300537109375,
    "value_loss": 0.7859757095575333,
    "entropy": 0.6035365611314774,
    "total_loss": -3885.8854926258327
  },
  {
    "episode": 219,
    "avg_reward_per_step": 52.055623257859736,
    "episode_length": 372,
    "policy_loss": -924.5846862792969,
    "value_loss": 0.546983003616333,
    "entropy": 0.6103968769311905,
    "total_loss": -924.281862026453
  },
  {
    "episode": 220,
    "avg_reward_per_step": 208.75326983608977,
    "episode_length": 96,
    "policy_loss": -3571.4893798828125,
    "value_loss": 0.752951055765152,
    "entropy": 0.5794405043125153,
    "total_loss": -3570.9682050287724
  },
  {
    "episode": 221,
    "avg_reward_per_step": 17.54209662169166,
    "episode_length": 783,
    "policy_loss": -326.7465591430664,
    "value_loss": 0.5122694075107574,
    "entropy": 0.5167413204908371,
    "total_loss": -326.440986263752
  },
  {
    "episode": 222,
    "avg_reward_per_step": 11.316343702461168,
    "episode_length": 1001,
    "policy_loss": -224.7757797241211,
    "value_loss": 0.5070137977600098,
    "entropy": 0.46921734511852264,
    "total_loss": -224.4564528644085
  },
  {
    "episode": 223,
    "avg_reward_per_step": -11.039451639012587,
    "episode_length": 3000,
    "policy_loss": 157.00511932373047,
    "value_loss": 1.8015691637992859,
    "entropy": 0.4231383576989174,
    "total_loss": 158.6374331444502
  },
  {
    "episode": 224,
    "avg_reward_per_step": -11.560289827243725,
    "episode_length": 3000,
    "policy_loss": 165.60405349731445,
    "value_loss": 1.9432582259178162,
    "entropy": 0.4023040160536766,
    "total_loss": 167.3863901168108
  },
  {
    "episode": 225,
    "avg_reward_per_step": -12.213048078346224,
    "episode_length": 3000,
    "policy_loss": 176.08624649047852,
    "value_loss": 2.1638166904449463,
    "entropy": 0.38114670664072037,
    "total_loss": 178.09760449826717
  },
  {
    "episode": 226,
    "avg_reward_per_step": 156.7780531362645,
    "episode_length": 124,
    "policy_loss": -2694.73291015625,
    "value_loss": 0.6660400778055191,
    "entropy": 0.4364389255642891,
    "total_loss": -2694.2414456486704
  },
  {
    "episode": 227,
    "avg_reward_per_step": 163.56952591471642,
    "episode_length": 119,
    "policy_loss": -2831.9578247070312,
    "value_loss": 0.675201341509819,
    "entropy": 0.4453365132212639,
    "total_loss": -2831.46075797081
  },
  {
    "episode": 228,
    "avg_reward_per_step": -12.83594259804471,
    "episode_length": 3000,
    "policy_loss": 185.56089782714844,
    "value_loss": 2.0579962134361267,
    "entropy": 0.3721105605363846,
    "total_loss": 187.47004981637002
  },
  {
    "episode": 229,
    "avg_reward_per_step": -12.170010650953206,
    "episode_length": 3000,
    "policy_loss": 174.1130142211914,
    "value_loss": 2.0127039551734924,
    "entropy": 0.37717387080192566,
    "total_loss": 175.97484862804413
  },
  {
    "episode": 230,
    "avg_reward_per_step": -12.050815951804536,
    "episode_length": 3000,
    "policy_loss": 171.81607818603516,
    "value_loss": 1.8344397842884064,
    "entropy": 0.3898608908057213,
    "total_loss": 173.49457361400127
  },
  {
    "episode": 231,
    "avg_reward_per_step": 187.36897318640692,
    "episode_length": 105,
    "policy_loss": -3221.8795776367188,
    "value_loss": 0.7134232372045517,
    "entropy": 0.48553112149238586,
    "total_loss": -3221.360366848111
  },
  {
    "episode": 232,
    "avg_reward_per_step": 186.77758304595804,
    "episode_length": 106,
    "policy_loss": -3199.8328247070312,
    "value_loss": 0.7131450772285461,
    "entropy": 0.4890277534723282,
    "total_loss": -3199.3152907311915
  },
  {
    "episode": 233,
    "avg_reward_per_step": 207.65143732278162,
    "episode_length": 95,
    "policy_loss": -3544.9412841796875,
    "value_loss": 0.7473333328962326,
    "entropy": 0.5180560350418091,
    "total_loss": -3544.401173260808
  },
  {
    "episode": 234,
    "avg_reward_per_step": 11.978561915135538,
    "episode_length": 964,
    "policy_loss": -236.220458984375,
    "value_loss": 0.5075910240411758,
    "entropy": 0.4500742554664612,
    "total_loss": -235.8928976625204
  },
  {
    "episode": 235,
    "avg_reward_per_step": 233.22553449310328,
    "episode_length": 85,
    "policy_loss": -4097.724182128906,
    "value_loss": 0.7948921173810959,
    "entropy": 0.5372046530246735,
    "total_loss": -4097.144171872735
  },
  {
    "episode": 236,
    "avg_reward_per_step": 193.04081408146507,
    "episode_length": 102,
    "policy_loss": -3356.3992309570312,
    "value_loss": 0.7231189608573914,
    "entropy": 0.44624871760606766,
    "total_loss": -3355.854611483216
  },
  {
    "episode": 237,
    "avg_reward_per_step": 121.69187517314579,
    "episode_length": 159,
    "policy_loss": -2113.498291015625,
    "value_loss": 0.6203246414661407,
    "entropy": 0.3831345736980438,
    "total_loss": -2113.031220203638
  },
  {
    "episode": 238,
    "avg_reward_per_step": 152.70968152167677,
    "episode_length": 127,
    "policy_loss": -2621.2046508789062,
    "value_loss": 0.6598415076732635,
    "entropy": 0.34184369444847107,
    "total_loss": -2620.681546849012
  },
  {
    "episode": 239,
    "avg_reward_per_step": 46.02046267779712,
    "episode_length": 386,
    "policy_loss": -818.5631408691406,
    "value_loss": 0.5378582626581192,
    "entropy": 0.25045204162597656,
    "total_loss": -818.1254634231329
  },
  {
    "episode": 240,
    "avg_reward_per_step": 97.20061727873372,
    "episode_length": 198,
    "policy_loss": -1693.2417907714844,
    "value_loss": 0.592057853937149,
    "entropy": 0.2949703484773636,
    "total_loss": -1692.7677210569382
  },
  {
    "episode": 241,
    "avg_reward_per_step": 87.7073936516471,
    "episode_length": 215,
    "policy_loss": -1539.50439453125,
    "value_loss": 0.579839438199997,
    "entropy": 0.3147429749369621,
    "total_loss": -1539.0504522830247
  },
  {
    "episode": 242,
    "avg_reward_per_step": -13.71378025545062,
    "episode_length": 3000,
    "policy_loss": 198.44947052001953,
    "value_loss": 2.2940614819526672,
    "entropy": 0.24342982470989227,
    "total_loss": 200.64616007208824
  },
  {
    "episode": 243,
    "avg_reward_per_step": -13.30066703174635,
    "episode_length": 3000,
    "policy_loss": 191.12229919433594,
    "value_loss": 2.1798747181892395,
    "entropy": 0.22859851270914078,
    "total_loss": 193.21073450744152
  },
  {
    "episode": 244,
    "avg_reward_per_step": 140.87195339940158,
    "episode_length": 140,
    "policy_loss": -2457.421875,
    "value_loss": 0.6468166708946228,
    "entropy": 0.37747639417648315,
    "total_loss": -2456.926048886776
  },
  {
    "episode": 245,
    "avg_reward_per_step": -13.466032871927148,
    "episode_length": 3000,
    "policy_loss": 193.79132461547852,
    "value_loss": 2.1501330137252808,
    "entropy": 0.2542148604989052,
    "total_loss": 195.83977168500422
  },
  {
    "episode": 246,
    "avg_reward_per_step": -13.34676740996647,
    "episode_length": 3000,
    "policy_loss": 191.49033737182617,
    "value_loss": 1.8797467052936554,
    "entropy": 0.2618395760655403,
    "total_loss": 193.2653482466936
  },
  {
    "episode": 247,
    "avg_reward_per_step": -14.19838521645854,
    "episode_length": 3000,
    "policy_loss": 205.6316375732422,
    "value_loss": 1.9962140619754791,
    "entropy": 0.25803395360708237,
    "total_loss": 207.52463805377482
  },
  {
    "episode": 248,
    "avg_reward_per_step": 120.43751248602779,
    "episode_length": 164,
    "policy_loss": -2088.3284301757812,
    "value_loss": 0.6212048530578613,
    "entropy": 0.36210743337869644,
    "total_loss": -2087.852068296075
  },
  {
    "episode": 249,
    "avg_reward_per_step": 181.95475785972943,
    "episode_length": 108,
    "policy_loss": -3142.2249145507812,
    "value_loss": 0.7051363736391068,
    "entropy": 0.36294829100370407,
    "total_loss": -3141.6649574935436
  },
  {
    "episode": 250,
    "avg_reward_per_step": 128.7490277911337,
    "episode_length": 154,
    "policy_loss": -2233.8696899414062,
    "value_loss": 0.6309598684310913,
    "entropy": 0.3749217092990875,
    "total_loss": -2233.388698756695
  },
  {
    "episode": 251,
    "avg_reward_per_step": -13.258814534553528,
    "episode_length": 3000,
    "policy_loss": 188.7699966430664,
    "value_loss": 1.9093358516693115,
    "entropy": 0.21452195942401886,
    "total_loss": 190.5935237109661
  },
  {
    "episode": 252,
    "avg_reward_per_step": 129.747291791236,
    "episode_length": 153,
    "policy_loss": -2259.5720825195312,
    "value_loss": 0.6329102218151093,
    "entropy": 0.30034324526786804,
    "total_loss": -2259.0593095958234
  },
  {
    "episode": 253,
    "avg_reward_per_step": 170.6399480581812,
    "episode_length": 115,
    "policy_loss": -2959.7343139648438,
    "value_loss": 0.6877811700105667,
    "entropy": 0.31933579593896866,
    "total_loss": -2959.1742671132088
  },
  {
    "episode": 254,
    "avg_reward_per_step": 83.91248429307656,
    "episode_length": 235,
    "policy_loss": -1456.0430297851562,
    "value_loss": 0.579252228140831,
    "entropy": 0.2316356860101223,
    "total_loss": -1455.5564318314196
  },
  {
    "episode": 255,
    "avg_reward_per_step": -14.236487162345023,
    "episode_length": 3000,
    "policy_loss": 204.99799728393555,
    "value_loss": 1.9241121411323547,
    "entropy": 0.16886870190501213,
    "total_loss": 206.85456194430589
  },
  {
    "episode": 256,
    "avg_reward_per_step": -14.701004844490415,
    "episode_length": 3000,
    "policy_loss": 213.07186126708984,
    "value_loss": 2.0824776887893677,
    "entropy": 0.20411889255046844,
    "total_loss": 215.07269139885904
  },
  {
    "episode": 257,
    "avg_reward_per_step": 123.91459315343813,
    "episode_length": 160,
    "policy_loss": -2153.6441040039062,
    "value_loss": 0.6256978958845139,
    "entropy": 0.23866818472743034,
    "total_loss": -2153.1138733819125
  },
  {
    "episode": 258,
    "avg_reward_per_step": -14.441212709633493,
    "episode_length": 3000,
    "policy_loss": 208.3869972229004,
    "value_loss": 1.9166251122951508,
    "entropy": 0.2397783100605011,
    "total_loss": 210.20771101117134
  },
  {
    "episode": 259,
    "avg_reward_per_step": 258.72578856345433,
    "episode_length": 77,
    "policy_loss": -4421.7003173828125,
    "value_loss": 0.8465250879526138,
    "entropy": 0.2876179367303848,
    "total_loss": -4420.968839469552
  },
  {
    "episode": 260,
    "avg_reward_per_step": -13.226564609946406,
    "episode_length": 3000,
    "policy_loss": 187.87549591064453,
    "value_loss": 1.8395881056785583,
    "entropy": 0.2566261440515518,
    "total_loss": 189.61243355870246
  },
  {
    "episode": 261,
    "avg_reward_per_step": -14.135708788187715,
    "episode_length": 3000,
    "policy_loss": 202.75788497924805,
    "value_loss": 1.9787562191486359,
    "entropy": 0.23649104312062263,
    "total_loss": 204.64204478114843
  },
  {
    "episode": 262,
    "avg_reward_per_step": 197.06189023890246,
    "episode_length": 101,
    "policy_loss": -3391.150634765625,
    "value_loss": 0.7310984134674072,
    "entropy": 0.2388611026108265,
    "total_loss": -3390.515080793202
  },
  {
    "episode": 263,
    "avg_reward_per_step": -11.555368195630118,
    "episode_length": 3000,
    "policy_loss": 158.93471145629883,
    "value_loss": 1.3924829959869385,
    "entropy": 0.2241198904812336,
    "total_loss": 160.23754649609327
  },
  {
    "episode": 264,
    "avg_reward_per_step": 246.05963735849713,
    "episode_length": 81,
    "policy_loss": -4217.528564453125,
    "value_loss": 0.8197884112596512,
    "entropy": 0.26310601085424423,
    "total_loss": -4216.814018446207
  },
  {
    "episode": 265,
    "avg_reward_per_step": 203.04486022607233,
    "episode_length": 98,
    "policy_loss": -3516.9713745117188,
    "value_loss": 0.7411221563816071,
    "entropy": 0.24176785349845886,
    "total_loss": -3516.3269594967364
  },
  {
    "episode": 266,
    "avg_reward_per_step": -13.85978895237251,
    "episode_length": 3000,
    "policy_loss": 196.89688873291016,
    "value_loss": 1.8598127365112305,
    "entropy": 0.17849893495440483,
    "total_loss": 198.68530189543964
  },
  {
    "episode": 267,
    "avg_reward_per_step": -13.111653384608147,
    "episode_length": 3000,
    "policy_loss": 183.8373680114746,
    "value_loss": 1.8853033185005188,
    "entropy": 0.15789497643709183,
    "total_loss": 185.6595133394003
  },
  {
    "episode": 268,
    "avg_reward_per_step": 142.97049666342272,
    "episode_length": 139,
    "policy_loss": -2487.0980834960938,
    "value_loss": 0.649952620267868,
    "entropy": 0.22085021808743477,
    "total_loss": -2486.5364709630608
  },
  {
    "episode": 269,
    "avg_reward_per_step": 89.67140257657287,
    "episode_length": 221,
    "policy_loss": -1565.4897766113281,
    "value_loss": 0.585227832198143,
    "entropy": 0.19472859799861908,
    "total_loss": -1564.9824402183294
  },
  {
    "episode": 270,
    "avg_reward_per_step": -12.99824835978849,
    "episode_length": 3000,
    "policy_loss": 181.0906524658203,
    "value_loss": 1.499865561723709,
    "entropy": 0.15018045529723167,
    "total_loss": 182.53044584542513
  },
  {
    "episode": 271,
    "avg_reward_per_step": -11.65753229038051,
    "episode_length": 3000,
    "policy_loss": 158.37481689453125,
    "value_loss": 1.2595761120319366,
    "entropy": 0.17265257611870766,
    "total_loss": 159.56533197611571
  },
  {
    "episode": 272,
    "avg_reward_per_step": -12.068186310692724,
    "episode_length": 3000,
    "policy_loss": 164.9406280517578,
    "value_loss": 1.4251510500907898,
    "entropy": 0.2058681808412075,
    "total_loss": 166.28343182951212
  },
  {
    "episode": 273,
    "avg_reward_per_step": 174.34238655968537,
    "episode_length": 114,
    "policy_loss": -3047.8307495117188,
    "value_loss": 0.6942404806613922,
    "entropy": 0.2312309369444847,
    "total_loss": -3047.2290014058353
  },
  {
    "episode": 274,
    "avg_reward_per_step": 160.46379205521262,
    "episode_length": 124,
    "policy_loss": -2777.271728515625,
    "value_loss": 0.6746902614831924,
    "entropy": 0.285583958029747,
    "total_loss": -2776.7112718373537
  },
  {
    "episode": 275,
    "avg_reward_per_step": -13.353450443179815,
    "episode_length": 3000,
    "policy_loss": 185.75453186035156,
    "value_loss": 1.7290169298648834,
    "entropy": 0.21009602770209312,
    "total_loss": 187.39951037913562
  },
  {
    "episode": 276,
    "avg_reward_per_step": -12.301134594194599,
    "episode_length": 3000,
    "policy_loss": 167.78682708740234,
    "value_loss": 1.6523879170417786,
    "entropy": 0.24956443160772324,
    "total_loss": 169.33938923180102
  },
  {
    "episode": 277,
    "avg_reward_per_step": 201.1965896828546,
    "episode_length": 99,
    "policy_loss": -3461.845947265625,
    "value_loss": 0.7387257665395737,
    "entropy": 0.30658622086048126,
    "total_loss": -3461.22985598743
  },
  {
    "episode": 278,
    "avg_reward_per_step": 34.82647095730964,
    "episode_length": 465,
    "policy_loss": -635.85498046875,
    "value_loss": 0.5265026837587357,
    "entropy": 0.3239433839917183,
    "total_loss": -635.458055138588
  },
  {
    "episode": 279,
    "avg_reward_per_step": 47.191883601717,
    "episode_length": 362,
    "policy_loss": -849.9713134765625,
    "value_loss": 0.5361841320991516,
    "entropy": 0.3272858336567879,
    "total_loss": -849.566043677926
  },
  {
    "episode": 280,
    "avg_reward_per_step": -11.220969471563198,
    "episode_length": 3000,
    "policy_loss": 148.66545486450195,
    "value_loss": 1.3448571264743805,
    "entropy": 0.33215710520744324,
    "total_loss": 149.87744914889336
  },
  {
    "episode": 281,
    "avg_reward_per_step": -11.890900544576342,
    "episode_length": 3000,
    "policy_loss": 159.62171936035156,
    "value_loss": 1.5097255408763885,
    "entropy": 0.30401643365621567,
    "total_loss": 161.00983832776546
  },
  {
    "episode": 282,
    "avg_reward_per_step": -11.76250179600459,
    "episode_length": 3000,
    "policy_loss": 157.1964225769043,
    "value_loss": 1.3822269439697266,
    "entropy": 0.3106076344847679,
    "total_loss": 158.4544064670801
  },
  {
    "episode": 283,
    "avg_reward_per_step": -11.246556949265193,
    "episode_length": 3000,
    "policy_loss": 147.9800148010254,
    "value_loss": 1.3175716400146484,
    "entropy": 0.3764849454164505,
    "total_loss": 149.14699246287347
  },
  {
    "episode": 284,
    "avg_reward_per_step": -11.847052174634072,
    "episode_length": 3000,
    "policy_loss": 157.75265884399414,
    "value_loss": 1.5214469730854034,
    "entropy": 0.31154103577136993,
    "total_loss": 159.149489402771
  },
  {
    "episode": 285,
    "avg_reward_per_step": -11.401989934830139,
    "episode_length": 3000,
    "policy_loss": 149.79570770263672,
    "value_loss": 1.3438590466976166,
    "entropy": 0.3168404772877693,
    "total_loss": 151.01283055841924
  },
  {
    "episode": 286,
    "avg_reward_per_step": -11.855932563955248,
    "episode_length": 3000,
    "policy_loss": 156.72549438476562,
    "value_loss": 1.4161110818386078,
    "entropy": 0.3340185880661011,
    "total_loss": 158.00799803137778
  },
  {
    "episode": 287,
    "avg_reward_per_step": -10.309968255548169,
    "episode_length": 3000,
    "policy_loss": 130.17996215820312,
    "value_loss": 1.123104989528656,
    "entropy": 0.3394772484898567,
    "total_loss": 131.16727624833584
  },
  {
    "episode": 288,
    "avg_reward_per_step": -12.089377958717638,
    "episode_length": 3000,
    "policy_loss": 159.34077835083008,
    "value_loss": 1.4529968202114105,
    "entropy": 0.33524780720472336,
    "total_loss": 160.6596760481596
  },
  {
    "episode": 289,
    "avg_reward_per_step": -10.00445756888724,
    "episode_length": 3000,
    "policy_loss": 124.11584281921387,
    "value_loss": 1.0969675481319427,
    "entropy": 0.3584784045815468,
    "total_loss": 125.0694190055132
  },
  {
    "episode": 290,
    "avg_reward_per_step": -12.344245551201329,
    "episode_length": 3000,
    "policy_loss": 162.6140251159668,
    "value_loss": 1.4283873736858368,
    "entropy": 0.30632368475198746,
    "total_loss": 163.91988301575185
  },
  {
    "episode": 291,
    "avg_reward_per_step": -10.82035650142955,
    "episode_length": 3000,
    "policy_loss": 136.3684539794922,
    "value_loss": 1.2307804822921753,
    "entropy": 0.35741571336984634,
    "total_loss": 137.45626817643642
  },
  {
    "episode": 292,
    "avg_reward_per_step": -10.955914798298434,
    "episode_length": 3000,
    "policy_loss": 138.0981559753418,
    "value_loss": 1.1707184612751007,
    "entropy": 0.31713005155324936,
    "total_loss": 139.1420224159956
  },
  {
    "episode": 293,
    "avg_reward_per_step": -11.383264952285215,
    "episode_length": 3000,
    "policy_loss": 144.5743064880371,
    "value_loss": 1.2663950622081757,
    "entropy": 0.3655870482325554,
    "total_loss": 145.69446673095226
  },
  {
    "episode": 294,
    "avg_reward_per_step": -10.494708459708953,
    "episode_length": 3000,
    "policy_loss": 129.10784912109375,
    "value_loss": 1.1222641468048096,
    "entropy": 0.3779245615005493,
    "total_loss": 130.07894344329833
  },
  {
    "episode": 295,
    "avg_reward_per_step": 111.41463585302317,
    "episode_length": 178,
    "policy_loss": -1947.3038940429688,
    "value_loss": 0.6114937365055084,
    "entropy": 0.42678532749414444,
    "total_loss": -1946.8631144374608
  },
  {
    "episode": 296,
    "avg_reward_per_step": -9.97592863589191,
    "episode_length": 3000,
    "policy_loss": 119.45883750915527,
    "value_loss": 1.0371368527412415,
    "entropy": 0.38862845301628113,
    "total_loss": 120.34052298069
  },
  {
    "episode": 297,
    "avg_reward_per_step": 41.80608141232881,
    "episode_length": 419,
    "policy_loss": -769.9033660888672,
    "value_loss": 0.5361614972352982,
    "entropy": 0.46390797942876816,
    "total_loss": -769.5527677834034
  },
  {
    "episode": 298,
    "avg_reward_per_step": 87.62535301083284,
    "episode_length": 216,
    "policy_loss": -1552.6348571777344,
    "value_loss": 0.5818519443273544,
    "entropy": 0.4656948670744896,
    "total_loss": -1552.2392831802367
  },
  {
    "episode": 299,
    "avg_reward_per_step": -8.156444805881202,
    "episode_length": 3000,
    "policy_loss": 88.01111602783203,
    "value_loss": 0.8843738287687302,
    "entropy": 0.4831445440649986,
    "total_loss": 88.70223203897476
  },
  {
    "episode": 300,
    "avg_reward_per_step": 93.81474276489648,
    "episode_length": 209,
    "policy_loss": -1652.59619140625,
    "value_loss": 0.5905693918466568,
    "entropy": 0.49747561663389206,
    "total_loss": -1652.2046122610568
  }
]