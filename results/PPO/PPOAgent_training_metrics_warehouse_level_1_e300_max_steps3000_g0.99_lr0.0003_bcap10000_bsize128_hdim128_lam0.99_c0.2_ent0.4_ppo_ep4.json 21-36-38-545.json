[
  {
    "episode": 1,
    "avg_reward_per_step": 63.961089421470234,
    "episode_length": 305,
    "policy_loss": -3249.65234375,
    "value_loss": 0.7258305102586746,
    "entropy": 1.377145916223526,
    "total_loss": -3249.477371606231
  },
  {
    "episode": 2,
    "avg_reward_per_step": 18.673470958842795,
    "episode_length": 933,
    "policy_loss": -956.0184020996094,
    "value_loss": 0.5444707572460175,
    "entropy": 1.3733149468898773,
    "total_loss": -956.0232573211193
  },
  {
    "episode": 3,
    "avg_reward_per_step": 7.409386617549721,
    "episode_length": 1867,
    "policy_loss": -377.71802520751953,
    "value_loss": 0.5131714642047882,
    "entropy": 1.3630594909191132,
    "total_loss": -377.75007753968237
  },
  {
    "episode": 4,
    "avg_reward_per_step": 25.141316349793467,
    "episode_length": 716,
    "policy_loss": -1282.1074523925781,
    "value_loss": 0.5647246539592743,
    "entropy": 1.3534615635871887,
    "total_loss": -1282.0841123640537
  },
  {
    "episode": 5,
    "avg_reward_per_step": 87.87000173702634,
    "episode_length": 224,
    "policy_loss": -4397.871337890625,
    "value_loss": 0.8684519082307816,
    "entropy": 1.340405434370041,
    "total_loss": -4397.539048156143
  },
  {
    "episode": 6,
    "avg_reward_per_step": 12.529798882417774,
    "episode_length": 1329,
    "policy_loss": -634.0845336914062,
    "value_loss": 0.5274135619401932,
    "entropy": 1.3339239656925201,
    "total_loss": -634.0906897157431
  },
  {
    "episode": 7,
    "avg_reward_per_step": 10.711074909541978,
    "episode_length": 1556,
    "policy_loss": -544.1127319335938,
    "value_loss": 0.5233517736196518,
    "entropy": 1.3330262005329132,
    "total_loss": -544.1225906401872
  },
  {
    "episode": 8,
    "avg_reward_per_step": 10.792185462833789,
    "episode_length": 1530,
    "policy_loss": -545.5538787841797,
    "value_loss": 0.5233510732650757,
    "entropy": 1.3333471715450287,
    "total_loss": -545.5638665795326
  },
  {
    "episode": 9,
    "avg_reward_per_step": 6.772150081610905,
    "episode_length": 2257,
    "policy_loss": -342.1646194458008,
    "value_loss": 0.5132454484701157,
    "entropy": 1.3359938561916351,
    "total_loss": -342.1857715398073
  },
  {
    "episode": 10,
    "avg_reward_per_step": -2.025431530544433,
    "episode_length": 3000,
    "policy_loss": 101.30073547363281,
    "value_loss": 3.74910706281662,
    "entropy": 1.3342812359333038,
    "total_loss": 104.51613004207611
  },
  {
    "episode": 11,
    "avg_reward_per_step": -2.030307143571328,
    "episode_length": 3000,
    "policy_loss": 100.49832344055176,
    "value_loss": 4.055531620979309,
    "entropy": 1.3326725959777832,
    "total_loss": 104.02078602313995
  },
  {
    "episode": 12,
    "avg_reward_per_step": 20.700119740944483,
    "episode_length": 891,
    "policy_loss": -1043.8710632324219,
    "value_loss": 0.5521866083145142,
    "entropy": 1.3324484527111053,
    "total_loss": -1043.8518560051918
  },
  {
    "episode": 13,
    "avg_reward_per_step": 7.543725410499926,
    "episode_length": 1997,
    "policy_loss": -381.4552764892578,
    "value_loss": 0.5145080089569092,
    "entropy": 1.3297136425971985,
    "total_loss": -381.47265393733977
  },
  {
    "episode": 14,
    "avg_reward_per_step": -1.9653763344174646,
    "episode_length": 3000,
    "policy_loss": 97.15711784362793,
    "value_loss": 5.035326957702637,
    "entropy": 1.3290184438228607,
    "total_loss": 101.66083742380142
  },
  {
    "episode": 15,
    "avg_reward_per_step": 24.33556351019645,
    "episode_length": 760,
    "policy_loss": -1231.2404174804688,
    "value_loss": 0.5631062984466553,
    "entropy": 1.328015148639679,
    "total_loss": -1231.208517241478
  },
  {
    "episode": 16,
    "avg_reward_per_step": 69.02417598187422,
    "episode_length": 285,
    "policy_loss": -3502.5797729492188,
    "value_loss": 0.7543829679489136,
    "entropy": 1.3263712227344513,
    "total_loss": -3502.3559384703635
  },
  {
    "episode": 17,
    "avg_reward_per_step": 11.507166115517874,
    "episode_length": 1487,
    "policy_loss": -590.389892578125,
    "value_loss": 0.525796040892601,
    "entropy": 1.3123576045036316,
    "total_loss": -590.3890395790338
  },
  {
    "episode": 18,
    "avg_reward_per_step": 4.092219140842595,
    "episode_length": 2893,
    "policy_loss": -209.02537155151367,
    "value_loss": 0.5060242116451263,
    "entropy": 1.277081936597824,
    "total_loss": -209.0301801145077
  },
  {
    "episode": 19,
    "avg_reward_per_step": 16.427869626880433,
    "episode_length": 1032,
    "policy_loss": -837.8917388916016,
    "value_loss": 0.5375083237886429,
    "entropy": 1.2386614978313446,
    "total_loss": -837.8496951669455
  },
  {
    "episode": 20,
    "avg_reward_per_step": -2.8953083131751476,
    "episode_length": 3000,
    "policy_loss": 143.50964736938477,
    "value_loss": 3.3182183504104614,
    "entropy": 1.2152603566646576,
    "total_loss": 146.34176157712938
  },
  {
    "episode": 21,
    "avg_reward_per_step": 106.41423585123516,
    "episode_length": 186,
    "policy_loss": -5315.04052734375,
    "value_loss": 1.0030462145805359,
    "entropy": 1.182960718870163,
    "total_loss": -5314.5106654167175
  },
  {
    "episode": 22,
    "avg_reward_per_step": 94.80303900998712,
    "episode_length": 207,
    "policy_loss": -4766.0584716796875,
    "value_loss": 0.9119642674922943,
    "entropy": 1.1127749383449554,
    "total_loss": -4765.591617387533
  },
  {
    "episode": 23,
    "avg_reward_per_step": 98.92916126172224,
    "episode_length": 197,
    "policy_loss": -4910.34375,
    "value_loss": 0.9395439028739929,
    "entropy": 1.023041307926178,
    "total_loss": -4909.8134226202965
  },
  {
    "episode": 24,
    "avg_reward_per_step": 24.217876486091004,
    "episode_length": 703,
    "policy_loss": -1223.9300537109375,
    "value_loss": 0.5575766265392303,
    "entropy": 1.0176213085651398,
    "total_loss": -1223.7795256078243
  },
  {
    "episode": 25,
    "avg_reward_per_step": 93.48909674853529,
    "episode_length": 208,
    "policy_loss": -4670.01123046875,
    "value_loss": 0.9029508084058762,
    "entropy": 0.9887852519750595,
    "total_loss": -4669.503793761134
  },
  {
    "episode": 26,
    "avg_reward_per_step": 22.604647626976416,
    "episode_length": 778,
    "policy_loss": -1147.6703186035156,
    "value_loss": 0.5558101534843445,
    "entropy": 0.9525845348834991,
    "total_loss": -1147.4955422639846
  },
  {
    "episode": 27,
    "avg_reward_per_step": 8.64701851847107,
    "episode_length": 1520,
    "policy_loss": -440.89871978759766,
    "value_loss": 0.5147329717874527,
    "entropy": 0.9223515391349792,
    "total_loss": -440.7529274314642
  },
  {
    "episode": 28,
    "avg_reward_per_step": 8.872630312072909,
    "episode_length": 1539,
    "policy_loss": -450.2405014038086,
    "value_loss": 0.5155863463878632,
    "entropy": 0.8899805992841721,
    "total_loss": -450.0809072971344
  },
  {
    "episode": 29,
    "avg_reward_per_step": 58.751273651184455,
    "episode_length": 320,
    "policy_loss": -2998.2263793945312,
    "value_loss": 0.6942314058542252,
    "entropy": 0.8607819378376007,
    "total_loss": -2997.8764607638122
  },
  {
    "episode": 30,
    "avg_reward_per_step": 12.919088062352875,
    "episode_length": 1116,
    "policy_loss": -661.3944091796875,
    "value_loss": 0.5251746028661728,
    "entropy": 0.8471783846616745,
    "total_loss": -661.208105930686
  },
  {
    "episode": 31,
    "avg_reward_per_step": 42.76005180320059,
    "episode_length": 422,
    "policy_loss": -2182.9913330078125,
    "value_loss": 0.6255441755056381,
    "entropy": 0.7996912598609924,
    "total_loss": -2182.685665336251
  },
  {
    "episode": 32,
    "avg_reward_per_step": 52.84273949854593,
    "episode_length": 343,
    "policy_loss": -2681.6234741210938,
    "value_loss": 0.6611091792583466,
    "entropy": 0.7760175913572311,
    "total_loss": -2681.2727719783784
  },
  {
    "episode": 33,
    "avg_reward_per_step": 166.7807627533488,
    "episode_length": 117,
    "policy_loss": -7676.1273193359375,
    "value_loss": 1.5766000151634216,
    "entropy": 0.7887673377990723,
    "total_loss": -7674.866226255894
  },
  {
    "episode": 34,
    "avg_reward_per_step": 50.201869184958895,
    "episode_length": 365,
    "policy_loss": -2542.6403198242188,
    "value_loss": 0.6545659601688385,
    "entropy": 0.8010782599449158,
    "total_loss": -2542.3061851680277
  },
  {
    "episode": 35,
    "avg_reward_per_step": 168.2045693037245,
    "episode_length": 117,
    "policy_loss": -7730.851806640625,
    "value_loss": 1.6094174087047577,
    "entropy": 0.797645628452301,
    "total_loss": -7729.561447483301
  },
  {
    "episode": 36,
    "avg_reward_per_step": 82.70022500062717,
    "episode_length": 224,
    "policy_loss": -4180.8980712890625,
    "value_loss": 0.8150213211774826,
    "entropy": 0.7478943318128586,
    "total_loss": -4180.38220770061
  },
  {
    "episode": 37,
    "avg_reward_per_step": 51.65800541651421,
    "episode_length": 349,
    "policy_loss": -2660.2724609375,
    "value_loss": 0.660513162612915,
    "entropy": 0.6922080516815186,
    "total_loss": -2659.8888309955596
  },
  {
    "episode": 38,
    "avg_reward_per_step": 14.550582775885594,
    "episode_length": 951,
    "policy_loss": -740.7420043945312,
    "value_loss": 0.5265371650457382,
    "entropy": 0.6748491376638412,
    "total_loss": -740.485406884551
  },
  {
    "episode": 39,
    "avg_reward_per_step": -11.151869291881946,
    "episode_length": 3000,
    "policy_loss": 551.13134765625,
    "value_loss": 7.885743618011475,
    "entropy": 0.5937772989273071,
    "total_loss": 558.7795803546906
  },
  {
    "episode": 40,
    "avg_reward_per_step": -12.6466522837081,
    "episode_length": 3000,
    "policy_loss": 628.5476531982422,
    "value_loss": 8.728021144866943,
    "entropy": 0.5265307128429413,
    "total_loss": 637.065062057972
  },
  {
    "episode": 41,
    "avg_reward_per_step": -12.447941674924923,
    "episode_length": 3000,
    "policy_loss": 616.0362548828125,
    "value_loss": 9.055849075317383,
    "entropy": 0.5197375267744064,
    "total_loss": 624.8842089474201
  },
  {
    "episode": 42,
    "avg_reward_per_step": 8.817374866168304,
    "episode_length": 1088,
    "policy_loss": -457.62699127197266,
    "value_loss": 0.5105503350496292,
    "entropy": 0.5436219722032547,
    "total_loss": -457.33388972580434
  },
  {
    "episode": 43,
    "avg_reward_per_step": -2.222374720234133,
    "episode_length": 1944,
    "policy_loss": 95.58529090881348,
    "value_loss": 0.5005922168493271,
    "entropy": 0.5236303508281708,
    "total_loss": 95.87643098533154
  },
  {
    "episode": 44,
    "avg_reward_per_step": -12.370165655027721,
    "episode_length": 3000,
    "policy_loss": 613.4253845214844,
    "value_loss": 10.924967765808105,
    "entropy": 0.549626037478447,
    "total_loss": 624.1305018723011
  },
  {
    "episode": 45,
    "avg_reward_per_step": -12.717033084065072,
    "episode_length": 3000,
    "policy_loss": 628.5341644287109,
    "value_loss": 8.502220869064331,
    "entropy": 0.5667371898889542,
    "total_loss": 636.8096904218197
  },
  {
    "episode": 46,
    "avg_reward_per_step": -11.98381755546615,
    "episode_length": 3000,
    "policy_loss": 594.0879211425781,
    "value_loss": 8.143165111541748,
    "entropy": 0.5858471989631653,
    "total_loss": 601.9967473745346
  },
  {
    "episode": 47,
    "avg_reward_per_step": -11.143451465703436,
    "episode_length": 3000,
    "policy_loss": 550.688720703125,
    "value_loss": 6.53085732460022,
    "entropy": 0.6107447296380997,
    "total_loss": 556.97528013587
  },
  {
    "episode": 48,
    "avg_reward_per_step": 18.89333173622044,
    "episode_length": 666,
    "policy_loss": -997.1082000732422,
    "value_loss": 0.5329651981592178,
    "entropy": 0.6018058210611343,
    "total_loss": -996.8159572035074
  },
  {
    "episode": 49,
    "avg_reward_per_step": -10.081829573101828,
    "episode_length": 3000,
    "policy_loss": 497.51721954345703,
    "value_loss": 5.10234797000885,
    "entropy": 0.728735938668251,
    "total_loss": 502.32807313799856
  },
  {
    "episode": 50,
    "avg_reward_per_step": 68.35684109724787,
    "episode_length": 277,
    "policy_loss": -3450.69775390625,
    "value_loss": 0.7493258714675903,
    "entropy": 0.7393475025892258,
    "total_loss": -3450.244167035818
  },
  {
    "episode": 51,
    "avg_reward_per_step": -7.183994732530034,
    "episode_length": 3000,
    "policy_loss": 352.70262145996094,
    "value_loss": 2.9862070083618164,
    "entropy": 0.7602694481611252,
    "total_loss": 355.3847206890583
  },
  {
    "episode": 52,
    "avg_reward_per_step": -8.481445349958248,
    "episode_length": 3000,
    "policy_loss": 415.5249710083008,
    "value_loss": 4.01631760597229,
    "entropy": 0.7063651829957962,
    "total_loss": 419.25874254107475
  },
  {
    "episode": 53,
    "avg_reward_per_step": 143.05823826902886,
    "episode_length": 135,
    "policy_loss": -6848.690673828125,
    "value_loss": 1.3129372298717499,
    "entropy": 0.7214845716953278,
    "total_loss": -6847.666330426931
  },
  {
    "episode": 54,
    "avg_reward_per_step": 30.065421628155992,
    "episode_length": 539,
    "policy_loss": -1549.4645385742188,
    "value_loss": 0.5710850059986115,
    "entropy": 0.7628035694360733,
    "total_loss": -1549.1985749959945
  },
  {
    "episode": 55,
    "avg_reward_per_step": 145.30675821142415,
    "episode_length": 134,
    "policy_loss": -6905.00048828125,
    "value_loss": 1.3444751501083374,
    "entropy": 0.7419402748346329,
    "total_loss": -6903.952789241075
  },
  {
    "episode": 56,
    "avg_reward_per_step": 24.594763073238326,
    "episode_length": 664,
    "policy_loss": -1261.6725769042969,
    "value_loss": 0.5590055137872696,
    "entropy": 0.7647982388734818,
    "total_loss": -1261.419490686059
  },
  {
    "episode": 57,
    "avg_reward_per_step": 69.37967126300903,
    "episode_length": 275,
    "policy_loss": -3507.9373168945312,
    "value_loss": 0.7562329918146133,
    "entropy": 0.7451091557741165,
    "total_loss": -3507.4791275650264
  },
  {
    "episode": 58,
    "avg_reward_per_step": 16.34790636632714,
    "episode_length": 936,
    "policy_loss": -830.0583648681641,
    "value_loss": 0.5336504131555557,
    "entropy": 0.7180230468511581,
    "total_loss": -829.811923673749
  },
  {
    "episode": 59,
    "avg_reward_per_step": 81.66023850526618,
    "episode_length": 236,
    "policy_loss": -4133.982666015625,
    "value_loss": 0.8181452304124832,
    "entropy": 0.7082296162843704,
    "total_loss": -4133.447812631726
  },
  {
    "episode": 60,
    "avg_reward_per_step": 34.886908383814614,
    "episode_length": 484,
    "policy_loss": -1807.4859313964844,
    "value_loss": 0.5897036492824554,
    "entropy": 0.7638318240642548,
    "total_loss": -1807.2017604768275
  },
  {
    "episode": 61,
    "avg_reward_per_step": 54.15306455084426,
    "episode_length": 347,
    "policy_loss": -2773.1293334960938,
    "value_loss": 0.6758833229541779,
    "entropy": 0.76705102622509,
    "total_loss": -2772.76027058363
  },
  {
    "episode": 62,
    "avg_reward_per_step": 219.27102683793095,
    "episode_length": 91,
    "policy_loss": -9328.360107421875,
    "value_loss": 2.3601200580596924,
    "entropy": 0.7943942844867706,
    "total_loss": -9326.31774507761
  },
  {
    "episode": 63,
    "avg_reward_per_step": 50.262325809646924,
    "episode_length": 374,
    "policy_loss": -2540.385986328125,
    "value_loss": 0.6594619154930115,
    "entropy": 0.770843043923378,
    "total_loss": -2540.0348616302012
  },
  {
    "episode": 64,
    "avg_reward_per_step": 83.51297190268242,
    "episode_length": 235,
    "policy_loss": -4197.426025390625,
    "value_loss": 0.8391871005296707,
    "entropy": 0.7647653520107269,
    "total_loss": -4196.892744430899
  },
  {
    "episode": 65,
    "avg_reward_per_step": 13.44280609084369,
    "episode_length": 1234,
    "policy_loss": -688.7204742431641,
    "value_loss": 0.5298843383789062,
    "entropy": 0.7614217102527618,
    "total_loss": -688.4951585888863
  },
  {
    "episode": 66,
    "avg_reward_per_step": 60.8502135272702,
    "episode_length": 311,
    "policy_loss": -3077.7088623046875,
    "value_loss": 0.7054770737886429,
    "entropy": 0.7333542704582214,
    "total_loss": -3077.296726939082
  },
  {
    "episode": 67,
    "avg_reward_per_step": 119.9107223664096,
    "episode_length": 164,
    "policy_loss": -5836.68603515625,
    "value_loss": 1.1113241612911224,
    "entropy": 0.742683932185173,
    "total_loss": -5835.871784567833
  },
  {
    "episode": 68,
    "avg_reward_per_step": 201.21658871382937,
    "episode_length": 98,
    "policy_loss": -8803.46728515625,
    "value_loss": 2.0503004789352417,
    "entropy": 0.7385142147541046,
    "total_loss": -8801.712390363216
  },
  {
    "episode": 69,
    "avg_reward_per_step": 139.92465300988127,
    "episode_length": 140,
    "policy_loss": -6670.9429931640625,
    "value_loss": 1.304909586906433,
    "entropy": 0.7489111721515656,
    "total_loss": -6669.937648046017
  },
  {
    "episode": 70,
    "avg_reward_per_step": 60.46040772924872,
    "episode_length": 320,
    "policy_loss": -3045.7774658203125,
    "value_loss": 0.704996794462204,
    "entropy": 0.7478472143411636,
    "total_loss": -3045.3716079115866
  },
  {
    "episode": 71,
    "avg_reward_per_step": 137.57119999084026,
    "episode_length": 145,
    "policy_loss": -6597.778564453125,
    "value_loss": 1.2895468175411224,
    "entropy": 0.7393796145915985,
    "total_loss": -6596.784769481421
  },
  {
    "episode": 72,
    "avg_reward_per_step": 11.528319626469504,
    "episode_length": 1396,
    "policy_loss": -593.2333984375,
    "value_loss": 0.5245967209339142,
    "entropy": 0.7439176440238953,
    "total_loss": -593.0063687741756
  },
  {
    "episode": 73,
    "avg_reward_per_step": 55.001727800485824,
    "episode_length": 345,
    "policy_loss": -2781.4486694335938,
    "value_loss": 0.6801330000162125,
    "entropy": 0.725677952170372,
    "total_loss": -2781.058807614446
  },
  {
    "episode": 74,
    "avg_reward_per_step": 53.65555027382731,
    "episode_length": 351,
    "policy_loss": -2723.1458740234375,
    "value_loss": 0.6714275777339935,
    "entropy": 0.7199445515871048,
    "total_loss": -2722.7624242663383
  },
  {
    "episode": 75,
    "avg_reward_per_step": 189.24038939387654,
    "episode_length": 104,
    "policy_loss": -8475.5263671875,
    "value_loss": 1.879824310541153,
    "entropy": 0.7145824134349823,
    "total_loss": -8473.932375842332
  },
  {
    "episode": 76,
    "avg_reward_per_step": 124.33336523980988,
    "episode_length": 158,
    "policy_loss": -6104.487060546875,
    "value_loss": 1.1522998809814453,
    "entropy": 0.7202962934970856,
    "total_loss": -6103.622879183293
  },
  {
    "episode": 77,
    "avg_reward_per_step": 52.47943046708462,
    "episode_length": 374,
    "policy_loss": -2632.7695922851562,
    "value_loss": 0.6725527942180634,
    "entropy": 0.6865504086017609,
    "total_loss": -2632.371659654379
  },
  {
    "episode": 78,
    "avg_reward_per_step": 10.193660358521281,
    "episode_length": 1585,
    "policy_loss": -519.7316589355469,
    "value_loss": 0.5217305272817612,
    "entropy": 0.7063886672258377,
    "total_loss": -519.4924838751555
  },
  {
    "episode": 79,
    "avg_reward_per_step": 9.895187865575009,
    "episode_length": 1588,
    "policy_loss": -505.7134323120117,
    "value_loss": 0.5206250697374344,
    "entropy": 0.7070152312517166,
    "total_loss": -505.47561333477495
  },
  {
    "episode": 80,
    "avg_reward_per_step": 7.161318423776717,
    "episode_length": 2090,
    "policy_loss": -367.5409622192383,
    "value_loss": 0.5140518993139267,
    "entropy": 0.6999926120042801,
    "total_loss": -367.30690736472604
  },
  {
    "episode": 81,
    "avg_reward_per_step": 63.00733781336269,
    "episode_length": 308,
    "policy_loss": -3198.4922485351562,
    "value_loss": 0.7215405851602554,
    "entropy": 0.6967433243989944,
    "total_loss": -3198.049405279756
  },
  {
    "episode": 82,
    "avg_reward_per_step": 93.507740054594,
    "episode_length": 211,
    "policy_loss": -4691.45068359375,
    "value_loss": 0.9067586064338684,
    "entropy": 0.7187860310077667,
    "total_loss": -4690.831439399719
  },
  {
    "episode": 83,
    "avg_reward_per_step": 218.02128338798053,
    "episode_length": 91,
    "policy_loss": -9275.254638671875,
    "value_loss": 2.31792414188385,
    "entropy": 0.7225270122289658,
    "total_loss": -9273.225725334883
  },
  {
    "episode": 84,
    "avg_reward_per_step": 44.64983764633699,
    "episode_length": 415,
    "policy_loss": -2270.954833984375,
    "value_loss": 0.6334030032157898,
    "entropy": 0.709573969244957,
    "total_loss": -2270.6052605688574
  },
  {
    "episode": 85,
    "avg_reward_per_step": 103.84942837861759,
    "episode_length": 189,
    "policy_loss": -5130.958984375,
    "value_loss": 0.9828427284955978,
    "entropy": 0.6919704377651215,
    "total_loss": -5130.25292982161
  },
  {
    "episode": 86,
    "avg_reward_per_step": 87.2424285777442,
    "episode_length": 218,
    "policy_loss": -4378.4693603515625,
    "value_loss": 0.854714646935463,
    "entropy": 0.6993756890296936,
    "total_loss": -4377.894395980239
  },
  {
    "episode": 87,
    "avg_reward_per_step": 46.55245377675244,
    "episode_length": 388,
    "policy_loss": -2378.5546875,
    "value_loss": 0.6380844116210938,
    "entropy": 0.7045056372880936,
    "total_loss": -2378.1984053432943
  },
  {
    "episode": 88,
    "avg_reward_per_step": 131.42247422653105,
    "episode_length": 148,
    "policy_loss": -6319.9599609375,
    "value_loss": 1.217322438955307,
    "entropy": 0.7087867259979248,
    "total_loss": -6319.026153188944
  },
  {
    "episode": 89,
    "avg_reward_per_step": 228.86016375784854,
    "episode_length": 87,
    "policy_loss": -9557.349853515625,
    "value_loss": 2.4960867166519165,
    "entropy": 0.7066996842622757,
    "total_loss": -9555.136446672677
  },
  {
    "episode": 90,
    "avg_reward_per_step": 140.69231141754517,
    "episode_length": 139,
    "policy_loss": -6684.0111083984375,
    "value_loss": 1.3122678697109222,
    "entropy": 0.708131268620491,
    "total_loss": -6682.982093036175
  },
  {
    "episode": 91,
    "avg_reward_per_step": 44.88618203323276,
    "episode_length": 419,
    "policy_loss": -2283.9591674804688,
    "value_loss": 0.635724350810051,
    "entropy": 0.7067583650350571,
    "total_loss": -2283.6061464756726
  },
  {
    "episode": 92,
    "avg_reward_per_step": 118.07675346392911,
    "episode_length": 166,
    "policy_loss": -5761.10986328125,
    "value_loss": 1.097032755613327,
    "entropy": 0.7005813121795654,
    "total_loss": -5760.293063050509
  },
  {
    "episode": 93,
    "avg_reward_per_step": 42.972946268334546,
    "episode_length": 427,
    "policy_loss": -2187.0120849609375,
    "value_loss": 0.6257831305265427,
    "entropy": 0.6935815960168839,
    "total_loss": -2186.663734468818
  },
  {
    "episode": 94,
    "avg_reward_per_step": 200.26931054800747,
    "episode_length": 99,
    "policy_loss": -8797.32373046875,
    "value_loss": 2.048551857471466,
    "entropy": 0.6908884942531586,
    "total_loss": -8795.55153400898
  },
  {
    "episode": 95,
    "avg_reward_per_step": 162.2890029670861,
    "episode_length": 122,
    "policy_loss": -7515.3870849609375,
    "value_loss": 1.550285428762436,
    "entropy": 0.6389562636613846,
    "total_loss": -7514.092382037639
  },
  {
    "episode": 96,
    "avg_reward_per_step": 80.05391782614106,
    "episode_length": 230,
    "policy_loss": -4047.3225708007812,
    "value_loss": 0.8081315755844116,
    "entropy": 0.6108749508857727,
    "total_loss": -4046.7587892055512
  },
  {
    "episode": 97,
    "avg_reward_per_step": 14.198440981162587,
    "episode_length": 909,
    "policy_loss": -732.8732452392578,
    "value_loss": 0.5246337205171585,
    "entropy": 0.5928219258785248,
    "total_loss": -732.5857402890921
  },
  {
    "episode": 98,
    "avg_reward_per_step": 6.6405361997993415,
    "episode_length": 1315,
    "policy_loss": -351.1265335083008,
    "value_loss": 0.5075941681861877,
    "entropy": 0.5948432832956314,
    "total_loss": -350.85687665343283
  },
  {
    "episode": 99,
    "avg_reward_per_step": 171.84748793066854,
    "episode_length": 115,
    "policy_loss": -7880.5164794921875,
    "value_loss": 1.6624197959899902,
    "entropy": 0.6167532503604889,
    "total_loss": -7879.100760996342
  },
  {
    "episode": 100,
    "avg_reward_per_step": 77.50511443336065,
    "episode_length": 244,
    "policy_loss": -3922.6820068359375,
    "value_loss": 0.7886786758899689,
    "entropy": 0.6441327184438705,
    "total_loss": -3922.150981247425
  },
  {
    "episode": 101,
    "avg_reward_per_step": 63.53482116150062,
    "episode_length": 300,
    "policy_loss": -3231.19287109375,
    "value_loss": 0.7191131412982941,
    "entropy": 0.667524591088295,
    "total_loss": -3230.740767788887
  },
  {
    "episode": 102,
    "avg_reward_per_step": 189.92699995146134,
    "episode_length": 105,
    "policy_loss": -8429.49609375,
    "value_loss": 1.9111073315143585,
    "entropy": 0.672132670879364,
    "total_loss": -8427.853839486837
  },
  {
    "episode": 103,
    "avg_reward_per_step": 95.88468004475425,
    "episode_length": 204,
    "policy_loss": -4787.2379150390625,
    "value_loss": 0.9235505312681198,
    "entropy": 0.6943743526935577,
    "total_loss": -4786.592114248871
  },
  {
    "episode": 104,
    "avg_reward_per_step": 50.12333524003284,
    "episode_length": 373,
    "policy_loss": -2536.4161987304688,
    "value_loss": 0.6531187295913696,
    "entropy": 0.6733595728874207,
    "total_loss": -2536.0324238300323
  },
  {
    "episode": 105,
    "avg_reward_per_step": 85.11480616853096,
    "episode_length": 234,
    "policy_loss": -4265.3289794921875,
    "value_loss": 0.8518271297216415,
    "entropy": 0.6072531044483185,
    "total_loss": -4264.720053604246
  },
  {
    "episode": 106,
    "avg_reward_per_step": 31.361176382136353,
    "episode_length": 596,
    "policy_loss": -1595.37109375,
    "value_loss": 0.5859418958425522,
    "entropy": 0.6390139907598495,
    "total_loss": -1595.0407574504613
  },
  {
    "episode": 107,
    "avg_reward_per_step": 74.75241060077396,
    "episode_length": 264,
    "policy_loss": -3768.7590942382812,
    "value_loss": 0.7881636172533035,
    "entropy": 0.5893666744232178,
    "total_loss": -3768.2066772907974
  },
  {
    "episode": 108,
    "avg_reward_per_step": 27.549556475716138,
    "episode_length": 652,
    "policy_loss": -1395.9212951660156,
    "value_loss": 0.5701624900102615,
    "entropy": 0.6290233731269836,
    "total_loss": -1395.6027420252562
  },
  {
    "episode": 109,
    "avg_reward_per_step": 66.66887304594309,
    "episode_length": 298,
    "policy_loss": -3387.0482177734375,
    "value_loss": 0.7426217496395111,
    "entropy": 0.5389939546585083,
    "total_loss": -3386.521193605661
  },
  {
    "episode": 110,
    "avg_reward_per_step": 40.59028590323626,
    "episode_length": 451,
    "policy_loss": -2072.8245849609375,
    "value_loss": 0.6139763742685318,
    "entropy": 0.5821792781352997,
    "total_loss": -2072.443480297923
  },
  {
    "episode": 111,
    "avg_reward_per_step": 59.35121027411936,
    "episode_length": 315,
    "policy_loss": -3007.7477416992188,
    "value_loss": 0.6933322101831436,
    "entropy": 0.5770651549100876,
    "total_loss": -3007.2852355509995
  },
  {
    "episode": 112,
    "avg_reward_per_step": 92.892161353407,
    "episode_length": 205,
    "policy_loss": -4643.7313232421875,
    "value_loss": 0.8826829344034195,
    "entropy": 0.5563498735427856,
    "total_loss": -4643.071180257201
  },
  {
    "episode": 113,
    "avg_reward_per_step": 96.02312312767323,
    "episode_length": 206,
    "policy_loss": -4815.500244140625,
    "value_loss": 0.9272930026054382,
    "entropy": 0.5207991749048233,
    "total_loss": -4814.781270807982
  },
  {
    "episode": 114,
    "avg_reward_per_step": 131.3572939295145,
    "episode_length": 151,
    "policy_loss": -6322.5712890625,
    "value_loss": 1.223718374967575,
    "entropy": 0.5546858906745911,
    "total_loss": -6321.569445043802
  },
  {
    "episode": 115,
    "avg_reward_per_step": 58.3373706007057,
    "episode_length": 308,
    "policy_loss": -2970.2168579101562,
    "value_loss": 0.6824187338352203,
    "entropy": 0.5877762734889984,
    "total_loss": -2969.769549685717
  },
  {
    "episode": 116,
    "avg_reward_per_step": 18.53100737940848,
    "episode_length": 787,
    "policy_loss": -947.4123229980469,
    "value_loss": 0.5366489887237549,
    "entropy": 0.5644635856151581,
    "total_loss": -947.1014594435692
  },
  {
    "episode": 117,
    "avg_reward_per_step": 93.56097639243212,
    "episode_length": 203,
    "policy_loss": -4710.9935302734375,
    "value_loss": 0.8893656432628632,
    "entropy": 0.5507483035326004,
    "total_loss": -4710.324463951588
  },
  {
    "episode": 118,
    "avg_reward_per_step": 23.234975377516946,
    "episode_length": 650,
    "policy_loss": -1199.3773803710938,
    "value_loss": 0.5504875630140305,
    "entropy": 0.5670878440141678,
    "total_loss": -1199.0537279456853
  },
  {
    "episode": 119,
    "avg_reward_per_step": 35.378270590878905,
    "episode_length": 473,
    "policy_loss": -1804.2837219238281,
    "value_loss": 0.5893068015575409,
    "entropy": 0.5641454011201859,
    "total_loss": -1803.9200732827187
  },
  {
    "episode": 120,
    "avg_reward_per_step": 86.06773843801066,
    "episode_length": 219,
    "policy_loss": -4338.9989013671875,
    "value_loss": 0.8364427387714386,
    "entropy": 0.581114336848259,
    "total_loss": -4338.394904363156
  },
  {
    "episode": 121,
    "avg_reward_per_step": 100.09585941372012,
    "episode_length": 191,
    "policy_loss": -5032.580810546875,
    "value_loss": 0.9364248067140579,
    "entropy": 0.6145811527967453,
    "total_loss": -5031.89021820128
  },
  {
    "episode": 122,
    "avg_reward_per_step": 106.9294269354711,
    "episode_length": 185,
    "policy_loss": -5293.8192138671875,
    "value_loss": 1.008664846420288,
    "entropy": 0.6336758881807327,
    "total_loss": -5293.064019376039
  },
  {
    "episode": 123,
    "avg_reward_per_step": 136.41148293629016,
    "episode_length": 145,
    "policy_loss": -6543.57177734375,
    "value_loss": 1.269837349653244,
    "entropy": 0.6725913882255554,
    "total_loss": -6542.570976549387
  },
  {
    "episode": 124,
    "avg_reward_per_step": 67.32778358093886,
    "episode_length": 292,
    "policy_loss": -3400.0584106445312,
    "value_loss": 0.7449664622545242,
    "entropy": 0.657635360956192,
    "total_loss": -3399.576498326659
  },
  {
    "episode": 125,
    "avg_reward_per_step": 18.103667328744596,
    "episode_length": 1013,
    "policy_loss": -920.49365234375,
    "value_loss": 0.5454462617635727,
    "entropy": 0.6212259382009506,
    "total_loss": -920.1966964572669
  },
  {
    "episode": 126,
    "avg_reward_per_step": 16.955169162472625,
    "episode_length": 1019,
    "policy_loss": -862.1556701660156,
    "value_loss": 0.5396279841661453,
    "entropy": 0.6113908737897873,
    "total_loss": -861.8605985313654
  },
  {
    "episode": 127,
    "avg_reward_per_step": 42.12779931943199,
    "episode_length": 465,
    "policy_loss": -2134.8233032226562,
    "value_loss": 0.6302206367254257,
    "entropy": 0.5124092698097229,
    "total_loss": -2134.398046293855
  },
  {
    "episode": 128,
    "avg_reward_per_step": 77.131127976941,
    "episode_length": 257,
    "policy_loss": -3874.2142333984375,
    "value_loss": 0.8018317818641663,
    "entropy": 0.5449423789978027,
    "total_loss": -3873.6303785681725
  },
  {
    "episode": 129,
    "avg_reward_per_step": 21.39051904359109,
    "episode_length": 878,
    "policy_loss": -1085.5078430175781,
    "value_loss": 0.5555853098630905,
    "entropy": 0.4944660812616348,
    "total_loss": -1085.1500441402197
  },
  {
    "episode": 130,
    "avg_reward_per_step": 28.10696645250516,
    "episode_length": 675,
    "policy_loss": -1426.0907287597656,
    "value_loss": 0.5772584229707718,
    "entropy": 0.5235630720853806,
    "total_loss": -1425.722895565629
  },
  {
    "episode": 131,
    "avg_reward_per_step": 10.772517481840117,
    "episode_length": 1655,
    "policy_loss": -549.3032836914062,
    "value_loss": 0.5252902209758759,
    "entropy": 0.48869136720895767,
    "total_loss": -548.973470017314
  },
  {
    "episode": 132,
    "avg_reward_per_step": 25.55650970818646,
    "episode_length": 748,
    "policy_loss": -1305.0539855957031,
    "value_loss": 0.5700481086969376,
    "entropy": 0.5502061992883682,
    "total_loss": -1304.7040199667215
  },
  {
    "episode": 133,
    "avg_reward_per_step": 57.89895265166482,
    "episode_length": 338,
    "policy_loss": -2921.5479125976562,
    "value_loss": 0.6966484189033508,
    "entropy": 0.5792315602302551,
    "total_loss": -2921.082956802845
  },
  {
    "episode": 134,
    "avg_reward_per_step": 81.97361928815924,
    "episode_length": 243,
    "policy_loss": -4111.5020751953125,
    "value_loss": 0.8326223790645599,
    "entropy": 0.4723321199417114,
    "total_loss": -4110.858385664224
  },
  {
    "episode": 135,
    "avg_reward_per_step": 85.31108854361123,
    "episode_length": 232,
    "policy_loss": -4309.518798828125,
    "value_loss": 0.8513014167547226,
    "entropy": 0.5510340332984924,
    "total_loss": -4308.88791102469
  },
  {
    "episode": 136,
    "avg_reward_per_step": 29.9767759078329,
    "episode_length": 587,
    "policy_loss": -1522.5712585449219,
    "value_loss": 0.5767591595649719,
    "entropy": 0.5914429426193237,
    "total_loss": -1522.2310765624047
  },
  {
    "episode": 137,
    "avg_reward_per_step": 160.83183733253762,
    "episode_length": 124,
    "policy_loss": -7487.0533447265625,
    "value_loss": 1.546953409910202,
    "entropy": 0.5752485990524292,
    "total_loss": -7485.736490756273
  },
  {
    "episode": 138,
    "avg_reward_per_step": 139.24493061128712,
    "episode_length": 141,
    "policy_loss": -6648.92822265625,
    "value_loss": 1.3013774454593658,
    "entropy": 0.5794733464717865,
    "total_loss": -6647.8586345493795
  },
  {
    "episode": 139,
    "avg_reward_per_step": 86.96079890505008,
    "episode_length": 224,
    "policy_loss": -4341.6864013671875,
    "value_loss": 0.8552912175655365,
    "entropy": 0.5905316174030304,
    "total_loss": -4341.0673227965835
  },
  {
    "episode": 140,
    "avg_reward_per_step": 52.17039705997019,
    "episode_length": 348,
    "policy_loss": -2673.8588256835938,
    "value_loss": 0.6575197279453278,
    "entropy": 0.5140179097652435,
    "total_loss": -2673.4069131195547
  },
  {
    "episode": 141,
    "avg_reward_per_step": 62.2940802034935,
    "episode_length": 298,
    "policy_loss": -3153.7685546875,
    "value_loss": 0.7037702053785324,
    "entropy": 0.5384439527988434,
    "total_loss": -3153.280162063241
  },
  {
    "episode": 142,
    "avg_reward_per_step": 23.985115802407254,
    "episode_length": 615,
    "policy_loss": -1225.5777282714844,
    "value_loss": 0.5501352995634079,
    "entropy": 0.5221473872661591,
    "total_loss": -1225.2364519268274
  },
  {
    "episode": 143,
    "avg_reward_per_step": 12.923567506991171,
    "episode_length": 899,
    "policy_loss": -663.7178344726562,
    "value_loss": 0.5196814090013504,
    "entropy": 0.46981920301914215,
    "total_loss": -663.3860807448625
  },
  {
    "episode": 144,
    "avg_reward_per_step": 18.316440344360633,
    "episode_length": 747,
    "policy_loss": -939.7366943359375,
    "value_loss": 0.5337899476289749,
    "entropy": 0.4609100818634033,
    "total_loss": -939.3872684210539
  },
  {
    "episode": 145,
    "avg_reward_per_step": 83.06449465615403,
    "episode_length": 229,
    "policy_loss": -4182.85498046875,
    "value_loss": 0.8339905440807343,
    "entropy": 0.4643492251634598,
    "total_loss": -4182.206729614734
  },
  {
    "episode": 146,
    "avg_reward_per_step": -11.300380726472444,
    "episode_length": 3000,
    "policy_loss": 561.6343688964844,
    "value_loss": 8.8600435256958,
    "entropy": 0.4506262019276619,
    "total_loss": 570.3141619414091
  },
  {
    "episode": 147,
    "avg_reward_per_step": -11.216629211002598,
    "episode_length": 3000,
    "policy_loss": 556.1106414794922,
    "value_loss": 6.099659204483032,
    "entropy": 0.415660060942173,
    "total_loss": 562.0440366595983
  },
  {
    "episode": 148,
    "avg_reward_per_step": -11.944880929543055,
    "episode_length": 3000,
    "policy_loss": 592.6077880859375,
    "value_loss": 7.008122801780701,
    "entropy": 0.40952157229185104,
    "total_loss": 599.4521022588015
  },
  {
    "episode": 149,
    "avg_reward_per_step": -12.439478790625786,
    "episode_length": 3000,
    "policy_loss": 613.8376007080078,
    "value_loss": 10.77968454360962,
    "entropy": 0.4011726975440979,
    "total_loss": 624.4568161725998
  },
  {
    "episode": 150,
    "avg_reward_per_step": -12.911096455212608,
    "episode_length": 3000,
    "policy_loss": 637.1002502441406,
    "value_loss": 6.713654041290283,
    "entropy": 0.3928838297724724,
    "total_loss": 643.6567507535219
  },
  {
    "episode": 151,
    "avg_reward_per_step": -12.339356344016085,
    "episode_length": 3000,
    "policy_loss": 610.441162109375,
    "value_loss": 7.170466899871826,
    "entropy": 0.39908576011657715,
    "total_loss": 617.4519947052001
  },
  {
    "episode": 152,
    "avg_reward_per_step": -12.390532629610037,
    "episode_length": 3000,
    "policy_loss": 607.1855163574219,
    "value_loss": 8.684590578079224,
    "entropy": 0.3922665938735008,
    "total_loss": 615.7132002979517
  },
  {
    "episode": 153,
    "avg_reward_per_step": -12.372359937648948,
    "episode_length": 3000,
    "policy_loss": 610.6251983642578,
    "value_loss": 7.467865467071533,
    "entropy": 0.3946727514266968,
    "total_loss": 617.9351947307587
  },
  {
    "episode": 154,
    "avg_reward_per_step": -12.540343312910048,
    "episode_length": 3000,
    "policy_loss": 616.8980865478516,
    "value_loss": 6.726405024528503,
    "entropy": 0.4007740020751953,
    "total_loss": 623.46418197155
  },
  {
    "episode": 155,
    "avg_reward_per_step": -12.261301741065884,
    "episode_length": 3000,
    "policy_loss": 598.9639587402344,
    "value_loss": 7.220270991325378,
    "entropy": 0.40836066752672195,
    "total_loss": 606.0208854645491
  },
  {
    "episode": 156,
    "avg_reward_per_step": -11.275796644526373,
    "episode_length": 3000,
    "policy_loss": 551.6089935302734,
    "value_loss": 7.457201361656189,
    "entropy": 0.40883245319128036,
    "total_loss": 558.9026619106531
  },
  {
    "episode": 157,
    "avg_reward_per_step": -12.544857462056555,
    "episode_length": 3000,
    "policy_loss": 609.8068695068359,
    "value_loss": 6.984843373298645,
    "entropy": 0.40544383227825165,
    "total_loss": 616.6295353472233
  },
  {
    "episode": 158,
    "avg_reward_per_step": -11.866389403699923,
    "episode_length": 3000,
    "policy_loss": 578.4163360595703,
    "value_loss": 5.868665337562561,
    "entropy": 0.4210156202316284,
    "total_loss": 584.1165951490402
  },
  {
    "episode": 159,
    "avg_reward_per_step": 1.7934104883417026,
    "episode_length": 1612,
    "policy_loss": -122.76256370544434,
    "value_loss": 0.500920757651329,
    "entropy": 0.42479801923036575,
    "total_loss": -122.43156215548515
  },
  {
    "episode": 160,
    "avg_reward_per_step": 455.42957033213094,
    "episode_length": 44,
    "policy_loss": -13604.642578125,
    "value_loss": 8.181763648986816,
    "entropy": 0.32919371873140335,
    "total_loss": -13596.592491963505
  },
  {
    "episode": 161,
    "avg_reward_per_step": -12.895964316855443,
    "episode_length": 3000,
    "policy_loss": 628.6639556884766,
    "value_loss": 7.3136420249938965,
    "entropy": 0.3251797780394554,
    "total_loss": 635.8475258022547
  },
  {
    "episode": 162,
    "avg_reward_per_step": -13.037547652625179,
    "episode_length": 3000,
    "policy_loss": 631.5241546630859,
    "value_loss": 6.320700287818909,
    "entropy": 0.26869626343250275,
    "total_loss": 637.7373764455318
  },
  {
    "episode": 163,
    "avg_reward_per_step": -14.757130412211474,
    "episode_length": 3000,
    "policy_loss": 720.6073913574219,
    "value_loss": 7.132017612457275,
    "entropy": 0.22832653671503067,
    "total_loss": 727.6480783551931
  },
  {
    "episode": 164,
    "avg_reward_per_step": 14.709974490924573,
    "episode_length": 846,
    "policy_loss": -762.5373840332031,
    "value_loss": 0.5252899825572968,
    "entropy": 0.12970239855349064,
    "total_loss": -762.0639750100672
  },
  {
    "episode": 165,
    "avg_reward_per_step": -15.008286671305118,
    "episode_length": 3000,
    "policy_loss": 727.6849670410156,
    "value_loss": 6.6918240785598755,
    "entropy": 0.1908443234860897,
    "total_loss": 734.300453390181
  },
  {
    "episode": 166,
    "avg_reward_per_step": 8.186477608664497,
    "episode_length": 1182,
    "policy_loss": -433.4290771484375,
    "value_loss": 0.5108723491430283,
    "entropy": 0.10910424031317234,
    "total_loss": -432.96184649541976
  },
  {
    "episode": 167,
    "avg_reward_per_step": 11.767335141084944,
    "episode_length": 1089,
    "policy_loss": -614.3844909667969,
    "value_loss": 0.5210441052913666,
    "entropy": 0.10885120183229446,
    "total_loss": -613.9069873422384
  },
  {
    "episode": 168,
    "avg_reward_per_step": 16.911415239155158,
    "episode_length": 707,
    "policy_loss": -877.1275787353516,
    "value_loss": 0.5278452783823013,
    "entropy": 0.11988599598407745,
    "total_loss": -876.6476878553628
  },
  {
    "episode": 169,
    "avg_reward_per_step": 7.654116030957424,
    "episode_length": 1074,
    "policy_loss": -409.81529998779297,
    "value_loss": 0.5085214972496033,
    "entropy": 0.1177813895046711,
    "total_loss": -409.3538910463452
  },
  {
    "episode": 170,
    "avg_reward_per_step": 4.4585811086666185,
    "episode_length": 1387,
    "policy_loss": -248.00807571411133,
    "value_loss": 0.5038527995347977,
    "entropy": 0.11985894665122032,
    "total_loss": -247.55216649323702
  },
  {
    "episode": 171,
    "avg_reward_per_step": -16.199463444833487,
    "episode_length": 3000,
    "policy_loss": 789.6991729736328,
    "value_loss": 7.582939505577087,
    "entropy": 0.16082533076405525,
    "total_loss": 797.2177823469043
  },
  {
    "episode": 172,
    "avg_reward_per_step": -15.127100122347445,
    "episode_length": 3000,
    "policy_loss": 737.1339721679688,
    "value_loss": 4.869672179222107,
    "entropy": 0.183920219540596,
    "total_loss": 741.9300762593746
  },
  {
    "episode": 173,
    "avg_reward_per_step": -15.080105547789788,
    "episode_length": 3000,
    "policy_loss": 734.1348876953125,
    "value_loss": 5.427310109138489,
    "entropy": 0.18765587732195854,
    "total_loss": 739.4871354535222
  },
  {
    "episode": 174,
    "avg_reward_per_step": -16.655637896398332,
    "episode_length": 3000,
    "policy_loss": 810.6197509765625,
    "value_loss": 7.545263767242432,
    "entropy": 0.20022745057940483,
    "total_loss": 818.0849237635732
  },
  {
    "episode": 175,
    "avg_reward_per_step": -14.399603482514538,
    "episode_length": 3000,
    "policy_loss": 698.9530944824219,
    "value_loss": 4.4203492403030396,
    "entropy": 0.20132290571928024,
    "total_loss": 703.2929145604372
  },
  {
    "episode": 176,
    "avg_reward_per_step": -15.53332779548188,
    "episode_length": 3000,
    "policy_loss": 751.2141876220703,
    "value_loss": 6.134074568748474,
    "entropy": 0.21140992641448975,
    "total_loss": 757.263698220253
  },
  {
    "episode": 177,
    "avg_reward_per_step": -16.367934625611046,
    "episode_length": 3000,
    "policy_loss": 789.0725555419922,
    "value_loss": 7.725300669670105,
    "entropy": 0.20191586017608643,
    "total_loss": 796.7170898675919
  },
  {
    "episode": 178,
    "avg_reward_per_step": 9.134919906719208,
    "episode_length": 938,
    "policy_loss": -491.1585464477539,
    "value_loss": 0.5108648836612701,
    "entropy": 0.14692767336964607,
    "total_loss": -490.7064526334405
  },
  {
    "episode": 179,
    "avg_reward_per_step": -15.726851719102589,
    "episode_length": 3000,
    "policy_loss": 760.7105407714844,
    "value_loss": 5.801402449607849,
    "entropy": 0.21649616584181786,
    "total_loss": 766.4253447547555
  },
  {
    "episode": 180,
    "avg_reward_per_step": 23.70873097994673,
    "episode_length": 582,
    "policy_loss": -1229.5977172851562,
    "value_loss": 0.5473291128873825,
    "entropy": 0.17901042103767395,
    "total_loss": -1229.1219923406838
  },
  {
    "episode": 181,
    "avg_reward_per_step": 18.854172083848294,
    "episode_length": 747,
    "policy_loss": -982.6232604980469,
    "value_loss": 0.5381311178207397,
    "entropy": 0.17129667103290558,
    "total_loss": -982.1536480486393
  },
  {
    "episode": 182,
    "avg_reward_per_step": -15.225095121445491,
    "episode_length": 3000,
    "policy_loss": 730.8994293212891,
    "value_loss": 6.96676778793335,
    "entropy": 0.22102836892008781,
    "total_loss": 737.7777857616544
  },
  {
    "episode": 183,
    "avg_reward_per_step": 313.33585122156853,
    "episode_length": 64,
    "policy_loss": -11498.25537109375,
    "value_loss": 4.220944404602051,
    "entropy": 0.18483209237456322,
    "total_loss": -11494.108359526097
  },
  {
    "episode": 184,
    "avg_reward_per_step": 99.4680855840535,
    "episode_length": 200,
    "policy_loss": -4957.8779296875,
    "value_loss": 0.9532158821821213,
    "entropy": 0.14432547613978386,
    "total_loss": -4956.982443995774
  },
  {
    "episode": 185,
    "avg_reward_per_step": 282.07099053763005,
    "episode_length": 71,
    "policy_loss": -10839.7470703125,
    "value_loss": 3.528669238090515,
    "entropy": 0.17800353467464447,
    "total_loss": -10836.28960248828
  },
  {
    "episode": 186,
    "avg_reward_per_step": 19.198968481977246,
    "episode_length": 637,
    "policy_loss": -1004.2160949707031,
    "value_loss": 0.5333271324634552,
    "entropy": 0.1756182461977005,
    "total_loss": -1003.7530151367188
  },
  {
    "episode": 187,
    "avg_reward_per_step": 235.79993503688937,
    "episode_length": 85,
    "policy_loss": -9771.479736328125,
    "value_loss": 2.6571192145347595,
    "entropy": 0.19253774732351303,
    "total_loss": -9768.89963221252
  },
  {
    "episode": 188,
    "avg_reward_per_step": 244.16459710666197,
    "episode_length": 82,
    "policy_loss": -9973.845458984375,
    "value_loss": 2.7890329360961914,
    "entropy": 0.13126190751791,
    "total_loss": -9971.108930811286
  },
  {
    "episode": 189,
    "avg_reward_per_step": 14.211510315297176,
    "episode_length": 747,
    "policy_loss": -755.3246765136719,
    "value_loss": 0.5213252902030945,
    "entropy": 0.17655202001333237,
    "total_loss": -754.8739720314741
  },
  {
    "episode": 190,
    "avg_reward_per_step": 219.89843366766308,
    "episode_length": 91,
    "policy_loss": -9353.535888671875,
    "value_loss": 2.380017042160034,
    "entropy": 0.1652318499982357,
    "total_loss": -9351.221964369714
  },
  {
    "episode": 191,
    "avg_reward_per_step": -14.156945640742293,
    "episode_length": 3000,
    "policy_loss": 671.4012145996094,
    "value_loss": 4.502643346786499,
    "entropy": 0.26477786153554916,
    "total_loss": 675.7979468017817
  },
  {
    "episode": 192,
    "avg_reward_per_step": 40.0086581802394,
    "episode_length": 401,
    "policy_loss": -2061.7105712890625,
    "value_loss": 0.6029575765132904,
    "entropy": 0.29504770785570145,
    "total_loss": -2061.2256327956916
  },
  {
    "episode": 193,
    "avg_reward_per_step": 202.1523200908335,
    "episode_length": 99,
    "policy_loss": -8836.195556640625,
    "value_loss": 2.100255787372589,
    "entropy": 0.20990780740976334,
    "total_loss": -8834.179263976217
  },
  {
    "episode": 194,
    "avg_reward_per_step": 260.1561393881609,
    "episode_length": 77,
    "policy_loss": -10378.011962890625,
    "value_loss": 3.0956664085388184,
    "entropy": 0.29312764108181,
    "total_loss": -10375.033547538518
  },
  {
    "episode": 195,
    "avg_reward_per_step": 52.45320787241019,
    "episode_length": 322,
    "policy_loss": -2693.054931640625,
    "value_loss": 0.6539921760559082,
    "entropy": 0.31618569046258926,
    "total_loss": -2692.527413740754
  },
  {
    "episode": 196,
    "avg_reward_per_step": 157.3251704550908,
    "episode_length": 127,
    "policy_loss": -7354.306884765625,
    "value_loss": 1.50090292096138,
    "entropy": 0.277775876224041,
    "total_loss": -7352.917092195154
  },
  {
    "episode": 197,
    "avg_reward_per_step": 465.7321249375495,
    "episode_length": 43,
    "policy_loss": -13706.9326171875,
    "value_loss": 8.546801328659058,
    "entropy": 0.2944401949644089,
    "total_loss": -13698.503591936827
  },
  {
    "episode": 198,
    "avg_reward_per_step": -14.338098008990649,
    "episode_length": 3000,
    "policy_loss": 676.2625427246094,
    "value_loss": 5.6088032722473145,
    "entropy": 0.2914234846830368,
    "total_loss": 681.7547766029835
  },
  {
    "episode": 199,
    "avg_reward_per_step": -14.570946823825256,
    "episode_length": 3000,
    "policy_loss": 688.7430419921875,
    "value_loss": 5.301295757293701,
    "entropy": 0.26371121406555176,
    "total_loss": 693.938853263855
  },
  {
    "episode": 200,
    "avg_reward_per_step": 282.0709905376674,
    "episode_length": 71,
    "policy_loss": -10859.90869140625,
    "value_loss": 3.532192349433899,
    "entropy": 0.19388865679502487,
    "total_loss": -10856.454054519534
  },
  {
    "episode": 201,
    "avg_reward_per_step": -14.646667453537418,
    "episode_length": 3000,
    "policy_loss": 696.5394592285156,
    "value_loss": 6.17588746547699,
    "entropy": 0.24899829551577568,
    "total_loss": 702.6157473757863
  },
  {
    "episode": 202,
    "avg_reward_per_step": 445.4146738044299,
    "episode_length": 45,
    "policy_loss": -13421.91259765625,
    "value_loss": 7.8889912366867065,
    "entropy": 0.2186463177204132,
    "total_loss": -13414.111064946652
  },
  {
    "episode": 203,
    "avg_reward_per_step": 489.1221794158454,
    "episode_length": 41,
    "policy_loss": -13988.74951171875,
    "value_loss": 9.395052671432495,
    "entropy": 0.22667305916547775,
    "total_loss": -13979.445128270983
  },
  {
    "episode": 204,
    "avg_reward_per_step": 121.09089845455902,
    "episode_length": 165,
    "policy_loss": -5916.8011474609375,
    "value_loss": 1.1367736160755157,
    "entropy": 0.08025303483009338,
    "total_loss": -5915.696475058794
  },
  {
    "episode": 205,
    "avg_reward_per_step": 312.97719262768334,
    "episode_length": 64,
    "policy_loss": -11449.723388671875,
    "value_loss": 4.206515908241272,
    "entropy": 0.1211929302662611,
    "total_loss": -11445.56534993574
  },
  {
    "episode": 206,
    "avg_reward_per_step": -17.945332951109634,
    "episode_length": 3000,
    "policy_loss": 853.6434783935547,
    "value_loss": 7.983726263046265,
    "entropy": 0.08905642293393612,
    "total_loss": 861.5915820874274
  },
  {
    "episode": 207,
    "avg_reward_per_step": 572.7374146542593,
    "episode_length": 35,
    "policy_loss": -14719.50830078125,
    "value_loss": 12.6253342628479,
    "entropy": 0.14439816400408745,
    "total_loss": -14706.940725784003
  },
  {
    "episode": 208,
    "avg_reward_per_step": 161.2950610791094,
    "episode_length": 124,
    "policy_loss": -7505.169189453125,
    "value_loss": 1.5542392432689667,
    "entropy": 0.11850255914032459,
    "total_loss": -7503.662351233512
  },
  {
    "episode": 209,
    "avg_reward_per_step": 303.43628429537756,
    "episode_length": 66,
    "policy_loss": -11299.501708984375,
    "value_loss": 3.9899942874908447,
    "entropy": 0.2394298017024994,
    "total_loss": -11295.607486617566
  },
  {
    "episode": 210,
    "avg_reward_per_step": 263.48023471011476,
    "episode_length": 76,
    "policy_loss": -10470.408447265625,
    "value_loss": 3.1565874814987183,
    "entropy": 0.19212375953793526,
    "total_loss": -10467.328709287942
  },
  {
    "episode": 211,
    "avg_reward_per_step": 290.2608294236754,
    "episode_length": 69,
    "policy_loss": -11043.78857421875,
    "value_loss": 3.702235221862793,
    "entropy": 0.18464381247758865,
    "total_loss": -11040.160196521878
  },
  {
    "episode": 212,
    "avg_reward_per_step": 126.47783699363475,
    "episode_length": 158,
    "policy_loss": -6152.9102783203125,
    "value_loss": 1.188602089881897,
    "entropy": 0.14303939044475555,
    "total_loss": -6151.778891986609
  },
  {
    "episode": 213,
    "avg_reward_per_step": 146.9518566029409,
    "episode_length": 136,
    "policy_loss": -6969.3468017578125,
    "value_loss": 1.3954027593135834,
    "entropy": 0.09160339087247849,
    "total_loss": -6967.988040354848
  },
  {
    "episode": 214,
    "avg_reward_per_step": 378.03849675796357,
    "episode_length": 53,
    "policy_loss": -12551.1455078125,
    "value_loss": 5.854442477226257,
    "entropy": 0.1737816110253334,
    "total_loss": -12545.360577979684
  },
  {
    "episode": 215,
    "avg_reward_per_step": 178.563275051774,
    "episode_length": 112,
    "policy_loss": -8121.22607421875,
    "value_loss": 1.7744089663028717,
    "entropy": 0.14585234224796295,
    "total_loss": -8119.510006189346
  },
  {
    "episode": 216,
    "avg_reward_per_step": 106.75271504492876,
    "episode_length": 187,
    "policy_loss": -5315.800048828125,
    "value_loss": 1.015174686908722,
    "entropy": 0.14466388523578644,
    "total_loss": -5314.84273969531
  },
  {
    "episode": 217,
    "avg_reward_per_step": 140.75415488123355,
    "episode_length": 142,
    "policy_loss": -6731.1322021484375,
    "value_loss": 1.3306288719177246,
    "entropy": 0.20268786698579788,
    "total_loss": -6729.882648423314
  },
  {
    "episode": 218,
    "avg_reward_per_step": 62.8482480982658,
    "episode_length": 279,
    "policy_loss": -3217.3700561523438,
    "value_loss": 0.7044452577829361,
    "entropy": 0.2836090624332428,
    "total_loss": -3216.779054519534
  },
  {
    "episode": 219,
    "avg_reward_per_step": 250.169331753267,
    "episode_length": 80,
    "policy_loss": -10187.55810546875,
    "value_loss": 2.9070032238960266,
    "entropy": 0.14851970225572586,
    "total_loss": -10184.710510125757
  },
  {
    "episode": 220,
    "avg_reward_per_step": 285.7690834569933,
    "episode_length": 70,
    "policy_loss": -10976.7607421875,
    "value_loss": 3.605694591999054,
    "entropy": 0.17651763185858727,
    "total_loss": -10973.225654648244
  },
  {
    "episode": 221,
    "avg_reward_per_step": 192.34783979441974,
    "episode_length": 104,
    "policy_loss": -8566.287109375,
    "value_loss": 1.963661253452301,
    "entropy": 0.17848902940750122,
    "total_loss": -8564.394843733311
  },
  {
    "episode": 222,
    "avg_reward_per_step": 9.119563205254746,
    "episode_length": 946,
    "policy_loss": -518.3089599609375,
    "value_loss": 0.5117834806442261,
    "entropy": 0.4181104525923729,
    "total_loss": -517.9644206613302
  },
  {
    "episode": 223,
    "avg_reward_per_step": -11.13719648398286,
    "episode_length": 3000,
    "policy_loss": 517.4130859375,
    "value_loss": 9.078564643859863,
    "entropy": 0.4959162697196007,
    "total_loss": 526.293284073472
  },
  {
    "episode": 224,
    "avg_reward_per_step": 77.91930494573762,
    "episode_length": 231,
    "policy_loss": -3961.6666259765625,
    "value_loss": 0.7871115654706955,
    "entropy": 0.4176177382469177,
    "total_loss": -3961.0465615063904
  },
  {
    "episode": 225,
    "avg_reward_per_step": 274.1916779306311,
    "episode_length": 73,
    "policy_loss": -10743.162841796875,
    "value_loss": 3.3705984950065613,
    "entropy": 0.23107538744807243,
    "total_loss": -10739.884673456847
  },
  {
    "episode": 226,
    "avg_reward_per_step": 150.35027594186883,
    "episode_length": 133,
    "policy_loss": -7083.5867919921875,
    "value_loss": 1.4328946769237518,
    "entropy": 0.1251047719269991,
    "total_loss": -7082.203939224035
  },
  {
    "episode": 227,
    "avg_reward_per_step": -12.639534989765954,
    "episode_length": 3000,
    "policy_loss": 587.8790435791016,
    "value_loss": 6.845066666603088,
    "entropy": 0.3596017435193062,
    "total_loss": 594.5802695482969
  },
  {
    "episode": 228,
    "avg_reward_per_step": 488.70027410588716,
    "episode_length": 41,
    "policy_loss": -13920.035400390625,
    "value_loss": 9.376542806625366,
    "entropy": 0.326419360935688,
    "total_loss": -13910.789425328374
  },
  {
    "episode": 229,
    "avg_reward_per_step": 489.08864896701067,
    "episode_length": 41,
    "policy_loss": -13894.515869140625,
    "value_loss": 9.390507698059082,
    "entropy": 0.31288009136915207,
    "total_loss": -13885.250513479114
  },
  {
    "episode": 230,
    "avg_reward_per_step": 345.39105469117237,
    "episode_length": 58,
    "policy_loss": -12050.159912109375,
    "value_loss": 5.000190496444702,
    "entropy": 0.29652606695890427,
    "total_loss": -12045.278332039714
  },
  {
    "episode": 231,
    "avg_reward_per_step": 318.1544334561091,
    "episode_length": 63,
    "policy_loss": -11635.20556640625,
    "value_loss": 4.323521375656128,
    "entropy": 0.2147086039185524,
    "total_loss": -11630.96792847216
  },
  {
    "episode": 232,
    "avg_reward_per_step": 232.7734193584685,
    "episode_length": 86,
    "policy_loss": -9739.23681640625,
    "value_loss": 2.604428231716156,
    "entropy": 0.23476729542016983,
    "total_loss": -9736.726295092702
  },
  {
    "episode": 233,
    "avg_reward_per_step": 364.48663054849027,
    "episode_length": 55,
    "policy_loss": -12375.711669921875,
    "value_loss": 5.495189070701599,
    "entropy": 0.24946428462862968,
    "total_loss": -12370.316266565025
  },
  {
    "episode": 234,
    "avg_reward_per_step": 364.63101358500995,
    "episode_length": 55,
    "policy_loss": -12468.581298828125,
    "value_loss": 5.4922484159469604,
    "entropy": 0.1819491758942604,
    "total_loss": -12463.161830082536
  },
  {
    "episode": 235,
    "avg_reward_per_step": -14.556040407751551,
    "episode_length": 3000,
    "policy_loss": 680.5822601318359,
    "value_loss": 5.739409327507019,
    "entropy": 0.19794490560889244,
    "total_loss": 686.2424914970994
  },
  {
    "episode": 236,
    "avg_reward_per_step": 128.1819326358077,
    "episode_length": 156,
    "policy_loss": -6222.1474609375,
    "value_loss": 1.2043233513832092,
    "entropy": 0.15253804624080658,
    "total_loss": -6221.004152804613
  },
  {
    "episode": 237,
    "avg_reward_per_step": 308.15380800657,
    "episode_length": 65,
    "policy_loss": -11374.553955078125,
    "value_loss": 4.0978028774261475,
    "entropy": 0.14958608150482178,
    "total_loss": -11370.515986633302
  },
  {
    "episode": 238,
    "avg_reward_per_step": 278.10078239703256,
    "episode_length": 72,
    "policy_loss": -10783.354736328125,
    "value_loss": 3.4583141803741455,
    "entropy": 0.14012812823057175,
    "total_loss": -10779.952473399044
  },
  {
    "episode": 239,
    "avg_reward_per_step": 256.6429144129981,
    "episode_length": 78,
    "policy_loss": -10307.94189453125,
    "value_loss": 3.027241349220276,
    "entropy": 0.22139565646648407,
    "total_loss": -10305.003211444617
  },
  {
    "episode": 240,
    "avg_reward_per_step": 9.092284406949048,
    "episode_length": 999,
    "policy_loss": -509.2939682006836,
    "value_loss": 0.5125983953475952,
    "entropy": 0.17191274091601372,
    "total_loss": -508.8501349017024
  },
  {
    "episode": 241,
    "avg_reward_per_step": 278.1086575109973,
    "episode_length": 72,
    "policy_loss": -10803.5546875,
    "value_loss": 3.451942265033722,
    "entropy": 0.2609565407037735,
    "total_loss": -10800.207127851249
  },
  {
    "episode": 242,
    "avg_reward_per_step": 328.1669772190102,
    "episode_length": 61,
    "policy_loss": -11760.56884765625,
    "value_loss": 4.564842343330383,
    "entropy": 0.18056680634617805,
    "total_loss": -11756.076232035459
  },
  {
    "episode": 243,
    "avg_reward_per_step": 351.4784982801253,
    "episode_length": 57,
    "policy_loss": -12226.16357421875,
    "value_loss": 5.152245879173279,
    "entropy": 0.28647611290216446,
    "total_loss": -12221.125918784737
  },
  {
    "episode": 244,
    "avg_reward_per_step": 556.9289322012917,
    "episode_length": 36,
    "policy_loss": -14610.050048828125,
    "value_loss": 11.98314380645752,
    "entropy": 0.2957756370306015,
    "total_loss": -14598.18521527648
  },
  {
    "episode": 245,
    "avg_reward_per_step": 426.1206428184517,
    "episode_length": 47,
    "policy_loss": -13261.24658203125,
    "value_loss": 7.2658079862594604,
    "entropy": 0.318095900118351,
    "total_loss": -13254.108012405039
  },
  {
    "episode": 246,
    "avg_reward_per_step": 626.4149172999988,
    "episode_length": 32,
    "policy_loss": -15113.720703125,
    "value_loss": 14.98761796951294,
    "entropy": 0.37645287066698074,
    "total_loss": -15098.883666303755
  },
  {
    "episode": 247,
    "avg_reward_per_step": 607.3535955903538,
    "episode_length": 33,
    "policy_loss": -14948.428955078125,
    "value_loss": 14.12242841720581,
    "entropy": 0.37815483659505844,
    "total_loss": -14934.457788595557
  },
  {
    "episode": 248,
    "avg_reward_per_step": 572.1111504979723,
    "episode_length": 35,
    "policy_loss": -14712.51123046875,
    "value_loss": 12.599844694137573,
    "entropy": 0.41631950438022614,
    "total_loss": -14700.077913576364
  },
  {
    "episode": 249,
    "avg_reward_per_step": 556.8297495215935,
    "episode_length": 36,
    "policy_loss": -14555.901611328125,
    "value_loss": 11.949111700057983,
    "entropy": 0.4249906614422798,
    "total_loss": -14544.122495892643
  },
  {
    "episode": 250,
    "avg_reward_per_step": -9.035048274458296,
    "episode_length": 3000,
    "policy_loss": 404.37547302246094,
    "value_loss": 4.873575448989868,
    "entropy": 0.5348030030727386,
    "total_loss": 409.0351272702217
  },
  {
    "episode": 251,
    "avg_reward_per_step": 590.3852244698528,
    "episode_length": 34,
    "policy_loss": -15062.944091796875,
    "value_loss": 13.362056016921997,
    "entropy": 0.4004916250705719,
    "total_loss": -15049.74223242998
  },
  {
    "episode": 252,
    "avg_reward_per_step": 589.7336385982028,
    "episode_length": 34,
    "policy_loss": -14647.98681640625,
    "value_loss": 13.363369703292847,
    "entropy": 0.2582338824868202,
    "total_loss": -14634.726740255952
  },
  {
    "episode": 253,
    "avg_reward_per_step": 466.6681513409416,
    "episode_length": 43,
    "policy_loss": -13661.256103515625,
    "value_loss": 8.625740051269531,
    "entropy": 0.27645212411880493,
    "total_loss": -13652.740944314002
  },
  {
    "episode": 254,
    "avg_reward_per_step": 466.7003353663916,
    "episode_length": 43,
    "policy_loss": -13718.229248046875,
    "value_loss": 8.643750429153442,
    "entropy": 0.2609819248318672,
    "total_loss": -13709.689890387654
  },
  {
    "episode": 255,
    "avg_reward_per_step": 489.49548128043625,
    "episode_length": 41,
    "policy_loss": -13851.653076171875,
    "value_loss": 9.440907955169678,
    "entropy": 0.20630766078829765,
    "total_loss": -13842.29469128102
  },
  {
    "episode": 256,
    "avg_reward_per_step": 400.52412991066535,
    "episode_length": 50,
    "policy_loss": -12911.448486328125,
    "value_loss": 6.489155173301697,
    "entropy": 0.24062679708003998,
    "total_loss": -12905.055581873656
  },
  {
    "episode": 257,
    "avg_reward_per_step": 572.888450233198,
    "episode_length": 35,
    "policy_loss": -14637.32568359375,
    "value_loss": 12.650916814804077,
    "entropy": 0.22550488635897636,
    "total_loss": -14624.764968733489
  },
  {
    "episode": 258,
    "avg_reward_per_step": 589.548065058704,
    "episode_length": 34,
    "policy_loss": -14805.743408203125,
    "value_loss": 13.34710144996643,
    "entropy": 0.25140197575092316,
    "total_loss": -14792.49686754346
  },
  {
    "episode": 259,
    "avg_reward_per_step": 338.5852077089731,
    "episode_length": 59,
    "policy_loss": -11924.147216796875,
    "value_loss": 4.780073046684265,
    "entropy": 0.37282031774520874,
    "total_loss": -11919.516271877288
  },
  {
    "episode": 260,
    "avg_reward_per_step": 542.3087381870515,
    "episode_length": 37,
    "policy_loss": -14470.711181640625,
    "value_loss": 11.396621465682983,
    "entropy": 0.2651595026254654,
    "total_loss": -14459.420623975991
  },
  {
    "episode": 261,
    "avg_reward_per_step": 541.9051829949992,
    "episode_length": 37,
    "policy_loss": -14358.375244140625,
    "value_loss": 11.38855266571045,
    "entropy": 0.33303939551115036,
    "total_loss": -14347.119907233118
  },
  {
    "episode": 262,
    "avg_reward_per_step": 607.3928474240926,
    "episode_length": 33,
    "policy_loss": -14898.0888671875,
    "value_loss": 14.11538553237915,
    "entropy": 0.27062440663576126,
    "total_loss": -14884.081731417775
  },
  {
    "episode": 263,
    "avg_reward_per_step": 500.73612795484394,
    "episode_length": 40,
    "policy_loss": -14027.56201171875,
    "value_loss": 9.783726930618286,
    "entropy": 0.3551517650485039,
    "total_loss": -14017.92034549415
  },
  {
    "episode": 264,
    "avg_reward_per_step": 626.4754650903134,
    "episode_length": 32,
    "policy_loss": -15033.78662109375,
    "value_loss": 14.96312141418457,
    "entropy": 0.33442454040050507,
    "total_loss": -15018.957269495726
  },
  {
    "episode": 265,
    "avg_reward_per_step": 541.6673928343155,
    "episode_length": 37,
    "policy_loss": -14452.6689453125,
    "value_loss": 11.368142127990723,
    "entropy": 0.3523288145661354,
    "total_loss": -14441.441734710335
  },
  {
    "episode": 266,
    "avg_reward_per_step": 626.7197204990481,
    "episode_length": 32,
    "policy_loss": -15006.865234375,
    "value_loss": 15.001250743865967,
    "entropy": 0.2292482741177082,
    "total_loss": -14991.955682940781
  },
  {
    "episode": 267,
    "avg_reward_per_step": 626.3359219695934,
    "episode_length": 32,
    "policy_loss": -15116.32568359375,
    "value_loss": 14.97352409362793,
    "entropy": 0.196690384298563,
    "total_loss": -15101.430835653842
  },
  {
    "episode": 268,
    "avg_reward_per_step": 514.17620230354,
    "episode_length": 39,
    "policy_loss": -14115.575927734375,
    "value_loss": 10.30443811416626,
    "entropy": 0.3035963103175163,
    "total_loss": -14105.392928144336
  },
  {
    "episode": 269,
    "avg_reward_per_step": 607.0858088164421,
    "episode_length": 33,
    "policy_loss": -14938.836181640625,
    "value_loss": 14.075704574584961,
    "entropy": 0.2851935550570488,
    "total_loss": -14924.874554488062
  },
  {
    "episode": 270,
    "avg_reward_per_step": 445.59920231863384,
    "episode_length": 45,
    "policy_loss": -13578.14404296875,
    "value_loss": 7.909332275390625,
    "entropy": 0.37799494713544846,
    "total_loss": -13570.385908672213
  },
  {
    "episode": 271,
    "avg_reward_per_step": 417.24977497817116,
    "episode_length": 48,
    "policy_loss": -13046.20849609375,
    "value_loss": 6.970376014709473,
    "entropy": 0.28585515171289444,
    "total_loss": -13039.352462139726
  },
  {
    "episode": 272,
    "avg_reward_per_step": 328.5718781906377,
    "episode_length": 61,
    "policy_loss": -11763.446533203125,
    "value_loss": 4.580649971961975,
    "entropy": 0.2410912998020649,
    "total_loss": -11758.962319751085
  },
  {
    "episode": 273,
    "avg_reward_per_step": 339.1277745851272,
    "episode_length": 59,
    "policy_loss": -11910.403564453125,
    "value_loss": 4.799166440963745,
    "entropy": 0.2082005776464939,
    "total_loss": -11905.68767824322
  },
  {
    "episode": 274,
    "avg_reward_per_step": 385.1616747910799,
    "episode_length": 52,
    "policy_loss": -12663.22509765625,
    "value_loss": 6.026563286781311,
    "entropy": 0.19508062303066254,
    "total_loss": -12657.27656661868
  },
  {
    "episode": 275,
    "avg_reward_per_step": 345.58952299040095,
    "episode_length": 58,
    "policy_loss": -12046.49609375,
    "value_loss": 5.004840612411499,
    "entropy": 0.18624621257185936,
    "total_loss": -12041.565751622617
  },
  {
    "episode": 276,
    "avg_reward_per_step": 436.53806154732837,
    "episode_length": 46,
    "policy_loss": -13332.62646484375,
    "value_loss": 7.651303291320801,
    "entropy": 0.18561610579490662,
    "total_loss": -13325.049407994748
  },
  {
    "episode": 277,
    "avg_reward_per_step": 488.98760423480337,
    "episode_length": 41,
    "policy_loss": -13856.020263671875,
    "value_loss": 9.3909273147583,
    "entropy": 0.20548591017723083,
    "total_loss": -13846.711530721188
  },
  {
    "episode": 278,
    "avg_reward_per_step": 528.0678141206351,
    "episode_length": 38,
    "policy_loss": -14254.921875,
    "value_loss": 10.869846820831299,
    "entropy": 0.20778940618038177,
    "total_loss": -14244.135143941641
  },
  {
    "episode": 279,
    "avg_reward_per_step": 488.52523576226577,
    "episode_length": 41,
    "policy_loss": -13888.055908203125,
    "value_loss": 9.32878851890564,
    "entropy": 0.24224193021655083,
    "total_loss": -13878.824016456307
  },
  {
    "episode": 280,
    "avg_reward_per_step": 626.3177847535134,
    "episode_length": 32,
    "policy_loss": -15086.115966796875,
    "value_loss": 14.930601835250854,
    "entropy": 0.20478307455778122,
    "total_loss": -15071.267278191448
  },
  {
    "episode": 281,
    "avg_reward_per_step": 488.4864824743251,
    "episode_length": 41,
    "policy_loss": -13864.04638671875,
    "value_loss": 9.329035520553589,
    "entropy": 0.32056816667318344,
    "total_loss": -13854.845578464865
  },
  {
    "episode": 282,
    "avg_reward_per_step": 607.897951601105,
    "episode_length": 33,
    "policy_loss": -14905.789794921875,
    "value_loss": 14.180114269256592,
    "entropy": 0.2312287837266922,
    "total_loss": -14891.70217216611
  },
  {
    "episode": 283,
    "avg_reward_per_step": 626.25550277749,
    "episode_length": 32,
    "policy_loss": -15251.5302734375,
    "value_loss": 14.947108507156372,
    "entropy": 0.24300754815340042,
    "total_loss": -15236.680367949604
  },
  {
    "episode": 284,
    "avg_reward_per_step": 384.7747986356959,
    "episode_length": 52,
    "policy_loss": -12760.453369140625,
    "value_loss": 6.007219552993774,
    "entropy": 0.42629795521497726,
    "total_loss": -12754.616668769717
  },
  {
    "episode": 285,
    "avg_reward_per_step": 589.3770936710526,
    "episode_length": 34,
    "policy_loss": -14718.272705078125,
    "value_loss": 13.29671573638916,
    "entropy": 0.23572614043951035,
    "total_loss": -14705.070279797912
  },
  {
    "episode": 286,
    "avg_reward_per_step": 351.09607937621496,
    "episode_length": 57,
    "policy_loss": -12129.649658203125,
    "value_loss": 5.106986999511719,
    "entropy": 0.3336304649710655,
    "total_loss": -12124.676123389601
  },
  {
    "episode": 287,
    "avg_reward_per_step": 74.39962066822909,
    "episode_length": 238,
    "policy_loss": -3804.9241333007812,
    "value_loss": 0.763338640332222,
    "entropy": 0.2566247954964638,
    "total_loss": -3804.2634445786475
  },
  {
    "episode": 288,
    "avg_reward_per_step": 590.2532747992449,
    "episode_length": 34,
    "policy_loss": -14775.309814453125,
    "value_loss": 13.42289423942566,
    "entropy": 0.27320025861263275,
    "total_loss": -14761.996200317144
  },
  {
    "episode": 289,
    "avg_reward_per_step": 607.5685848237234,
    "episode_length": 33,
    "policy_loss": -14879.216064453125,
    "value_loss": 14.116350889205933,
    "entropy": 0.2980503886938095,
    "total_loss": -14865.218933719396
  },
  {
    "episode": 290,
    "avg_reward_per_step": 514.0915425636684,
    "episode_length": 39,
    "policy_loss": -14140.799072265625,
    "value_loss": 10.311598062515259,
    "entropy": 0.302946075797081,
    "total_loss": -14130.60865263343
  },
  {
    "episode": 291,
    "avg_reward_per_step": 627.0182571769659,
    "episode_length": 32,
    "policy_loss": -15003.18701171875,
    "value_loss": 15.032657623291016,
    "entropy": 0.23211990296840668,
    "total_loss": -14988.247202056646
  },
  {
    "episode": 292,
    "avg_reward_per_step": 465.72133578233604,
    "episode_length": 43,
    "policy_loss": -13622.265625,
    "value_loss": 8.528335809707642,
    "entropy": 0.30016861110925674,
    "total_loss": -13613.857356634737
  },
  {
    "episode": 293,
    "avg_reward_per_step": 435.64305877776036,
    "episode_length": 46,
    "policy_loss": -13330.194580078125,
    "value_loss": 7.556973099708557,
    "entropy": 0.30991532653570175,
    "total_loss": -13322.76157310903
  },
  {
    "episode": 294,
    "avg_reward_per_step": 527.279737849253,
    "episode_length": 38,
    "policy_loss": -14190.77001953125,
    "value_loss": 10.786635398864746,
    "entropy": 0.215729258954525,
    "total_loss": -14180.069675835966
  },
  {
    "episode": 295,
    "avg_reward_per_step": 513.9262319766743,
    "episode_length": 39,
    "policy_loss": -14120.54052734375,
    "value_loss": 10.278804063796997,
    "entropy": 0.2025282233953476,
    "total_loss": -14110.34273456931
  },
  {
    "episode": 296,
    "avg_reward_per_step": 527.5636006763983,
    "episode_length": 38,
    "policy_loss": -14241.4365234375,
    "value_loss": 10.805526733398438,
    "entropy": 0.18503021448850632,
    "total_loss": -14230.705008789897
  },
  {
    "episode": 297,
    "avg_reward_per_step": 385.2880615651298,
    "episode_length": 52,
    "policy_loss": -12598.8076171875,
    "value_loss": 6.0529502630233765,
    "entropy": 0.23635200411081314,
    "total_loss": -12592.849207726122
  },
  {
    "episode": 298,
    "avg_reward_per_step": 607.5980352895018,
    "episode_length": 33,
    "policy_loss": -15000.99560546875,
    "value_loss": 14.123603582382202,
    "entropy": 0.1894460953772068,
    "total_loss": -14986.947780324519
  },
  {
    "episode": 299,
    "avg_reward_per_step": 426.1767027050261,
    "episode_length": 47,
    "policy_loss": -13125.2333984375,
    "value_loss": 7.246848940849304,
    "entropy": 0.30678050220012665,
    "total_loss": -13118.109261697531
  },
  {
    "episode": 300,
    "avg_reward_per_step": 572.4811355502851,
    "episode_length": 35,
    "policy_loss": -14626.6787109375,
    "value_loss": 12.587005853652954,
    "entropy": 0.24177346751093864,
    "total_loss": -14614.188414470851
  }
]