[
  {
    "episode": 1,
    "avg_reward_per_step": 12.22569270082457,
    "episode_length": 1447,
    "policy_loss": -212.94735717773438,
    "value_loss": 0.5086597502231598,
    "entropy": 1.3674003183841705,
    "total_loss": -212.50706744343043
  },
  {
    "episode": 2,
    "avg_reward_per_step": -2.207461849933435,
    "episode_length": 3000,
    "policy_loss": 36.78913879394531,
    "value_loss": 1.4984493851661682,
    "entropy": 1.3652366399765015,
    "total_loss": 38.219326347112656
  },
  {
    "episode": 3,
    "avg_reward_per_step": 99.65546599266102,
    "episode_length": 197,
    "policy_loss": -1700.35107421875,
    "value_loss": 0.592611238360405,
    "entropy": 1.3461385369300842,
    "total_loss": -1699.825769907236
  },
  {
    "episode": 4,
    "avg_reward_per_step": -2.288542070399157,
    "episode_length": 3000,
    "policy_loss": 38.2220344543457,
    "value_loss": 1.25418159365654,
    "entropy": 1.351107269525528,
    "total_loss": 39.40866068452597
  },
  {
    "episode": 5,
    "avg_reward_per_step": 12.387940462004803,
    "episode_length": 1390,
    "policy_loss": -209.88607788085938,
    "value_loss": 0.5085436999797821,
    "entropy": 1.2590758502483368,
    "total_loss": -209.440487973392
  },
  {
    "episode": 6,
    "avg_reward_per_step": 5.293025878912256,
    "episode_length": 2344,
    "policy_loss": -90.65117263793945,
    "value_loss": 0.5025116503238678,
    "entropy": 1.3137292563915253,
    "total_loss": -90.21434745043516
  },
  {
    "episode": 7,
    "avg_reward_per_step": 8.849813062768398,
    "episode_length": 1777,
    "policy_loss": -151.04996871948242,
    "value_loss": 0.5055004060268402,
    "entropy": 1.3145551681518555,
    "total_loss": -150.6101960718632
  },
  {
    "episode": 8,
    "avg_reward_per_step": 50.86527291991785,
    "episode_length": 369,
    "policy_loss": -878.6448364257812,
    "value_loss": 0.5411396026611328,
    "entropy": 1.3078671097755432,
    "total_loss": -878.1690901786089
  },
  {
    "episode": 9,
    "avg_reward_per_step": 22.552131099015245,
    "episode_length": 760,
    "policy_loss": -384.43370056152344,
    "value_loss": 0.5157204866409302,
    "entropy": 1.3146751821041107,
    "total_loss": -383.98371383398774
  },
  {
    "episode": 10,
    "avg_reward_per_step": 66.89667918339822,
    "episode_length": 282,
    "policy_loss": -1124.3171997070312,
    "value_loss": 0.5555957853794098,
    "entropy": 1.3023836612701416,
    "total_loss": -1123.8267231047153
  },
  {
    "episode": 11,
    "avg_reward_per_step": 7.3947380089264945,
    "episode_length": 1761,
    "policy_loss": -125.01778602600098,
    "value_loss": 0.5036919414997101,
    "entropy": 1.3171947300434113,
    "total_loss": -124.57995382100344
  },
  {
    "episode": 12,
    "avg_reward_per_step": 93.46015504790124,
    "episode_length": 211,
    "policy_loss": -1595.3843688964844,
    "value_loss": 0.5860093384981155,
    "entropy": 1.3117663264274597,
    "total_loss": -1594.8639478743075
  },
  {
    "episode": 13,
    "avg_reward_per_step": 27.033129540649707,
    "episode_length": 660,
    "policy_loss": -459.14888763427734,
    "value_loss": 0.5197559148073196,
    "entropy": 1.288789689540863,
    "total_loss": -458.69357120394704
  },
  {
    "episode": 14,
    "avg_reward_per_step": 42.25483679612885,
    "episode_length": 427,
    "policy_loss": -715.9446258544922,
    "value_loss": 0.5321165472269058,
    "entropy": 1.2402393817901611,
    "total_loss": -715.4745212763548
  },
  {
    "episode": 15,
    "avg_reward_per_step": -5.590675441579835,
    "episode_length": 3000,
    "policy_loss": 93.46726989746094,
    "value_loss": 1.9976839125156403,
    "entropy": 1.2093245089054108,
    "total_loss": 95.40448758453131
  },
  {
    "episode": 16,
    "avg_reward_per_step": 26.45011240453375,
    "episode_length": 647,
    "policy_loss": -454.2330627441406,
    "value_loss": 0.5184325724840164,
    "entropy": 1.1969064474105835,
    "total_loss": -453.7744754940271
  },
  {
    "episode": 17,
    "avg_reward_per_step": 133.3101444469437,
    "episode_length": 147,
    "policy_loss": -2270.70263671875,
    "value_loss": 0.6313542127609253,
    "entropy": 1.1905343234539032,
    "total_loss": -2270.1308092221616
  },
  {
    "episode": 18,
    "avg_reward_per_step": 78.51615731007962,
    "episode_length": 244,
    "policy_loss": -1335.9295654296875,
    "value_loss": 0.5680130571126938,
    "entropy": 1.1153934299945831,
    "total_loss": -1335.4173220440746
  },
  {
    "episode": 19,
    "avg_reward_per_step": 93.05448139946796,
    "episode_length": 212,
    "policy_loss": -1578.1778564453125,
    "value_loss": 0.5855150818824768,
    "entropy": 1.0601674616336823,
    "total_loss": -1577.6453497365117
  },
  {
    "episode": 20,
    "avg_reward_per_step": 118.09394945313055,
    "episode_length": 168,
    "policy_loss": -2004.7307434082031,
    "value_loss": 0.615060344338417,
    "entropy": 1.0178992599248886,
    "total_loss": -2004.1665780268609
  },
  {
    "episode": 21,
    "avg_reward_per_step": 17.344107098475817,
    "episode_length": 1008,
    "policy_loss": -293.55872344970703,
    "value_loss": 0.5122349113225937,
    "entropy": 0.9687977284193039,
    "total_loss": -293.0949284248054
  },
  {
    "episode": 22,
    "avg_reward_per_step": 11.753252702706323,
    "episode_length": 1315,
    "policy_loss": -199.0746841430664,
    "value_loss": 0.5071931034326553,
    "entropy": 0.9293458759784698,
    "total_loss": -198.61395833343266
  },
  {
    "episode": 23,
    "avg_reward_per_step": 69.42139032992442,
    "episode_length": 278,
    "policy_loss": -1175.1846618652344,
    "value_loss": 0.5596395283937454,
    "entropy": 0.9048994779586792,
    "total_loss": -1174.6702673107386
  },
  {
    "episode": 24,
    "avg_reward_per_step": 124.62112946456412,
    "episode_length": 158,
    "policy_loss": -2128.2093505859375,
    "value_loss": 0.6219812035560608,
    "entropy": 0.8822555691003799,
    "total_loss": -2127.6314821608366
  },
  {
    "episode": 25,
    "avg_reward_per_step": 22.730908244800048,
    "episode_length": 707,
    "policy_loss": -378.2248001098633,
    "value_loss": 0.5147126019001007,
    "entropy": 0.8274468183517456,
    "total_loss": -377.75145984888076
  },
  {
    "episode": 26,
    "avg_reward_per_step": 2.1365657411710766,
    "episode_length": 2459,
    "policy_loss": -36.40898513793945,
    "value_loss": 0.5002682358026505,
    "entropy": 0.7875262200832367,
    "total_loss": -35.948093213140965
  },
  {
    "episode": 27,
    "avg_reward_per_step": 34.520562145271455,
    "episode_length": 491,
    "policy_loss": -584.6458282470703,
    "value_loss": 0.5241357982158661,
    "entropy": 0.7723769545555115,
    "total_loss": -584.1603112965822
  },
  {
    "episode": 28,
    "avg_reward_per_step": 49.25537278528102,
    "episode_length": 362,
    "policy_loss": -835.3903961181641,
    "value_loss": 0.5372661352157593,
    "entropy": 0.7744305282831192,
    "total_loss": -834.8918515093625
  },
  {
    "episode": 29,
    "avg_reward_per_step": 21.218346853968015,
    "episode_length": 773,
    "policy_loss": -355.1359176635742,
    "value_loss": 0.5139568448066711,
    "entropy": 0.7974627465009689,
    "total_loss": -354.6618339560926
  },
  {
    "episode": 30,
    "avg_reward_per_step": 70.82704206110527,
    "episode_length": 269,
    "policy_loss": -1207.96484375,
    "value_loss": 0.5598842650651932,
    "entropy": 0.8157292604446411,
    "total_loss": -1207.445745947957
  },
  {
    "episode": 31,
    "avg_reward_per_step": 37.00017106231264,
    "episode_length": 487,
    "policy_loss": -634.7742767333984,
    "value_loss": 0.5278284102678299,
    "entropy": 0.8349737823009491,
    "total_loss": -634.2881970122456
  },
  {
    "episode": 32,
    "avg_reward_per_step": 35.99006378774912,
    "episode_length": 525,
    "policy_loss": -613.0694580078125,
    "value_loss": 0.5285340845584869,
    "entropy": 0.8266160637140274,
    "total_loss": -612.5822547264397
  },
  {
    "episode": 33,
    "avg_reward_per_step": 71.62220341699404,
    "episode_length": 275,
    "policy_loss": -1209.9800109863281,
    "value_loss": 0.5632750540971756,
    "entropy": 0.8270343989133835,
    "total_loss": -1209.4580876521766
  },
  {
    "episode": 34,
    "avg_reward_per_step": 58.0900207590307,
    "episode_length": 336,
    "policy_loss": -978.5811920166016,
    "value_loss": 0.5494313389062881,
    "entropy": 0.8515403866767883,
    "total_loss": -978.0743376970291
  },
  {
    "episode": 35,
    "avg_reward_per_step": 88.86759538124048,
    "episode_length": 221,
    "policy_loss": -1522.3849792480469,
    "value_loss": 0.5804741978645325,
    "entropy": 0.877657487988472,
    "total_loss": -1521.8483879245819
  },
  {
    "episode": 36,
    "avg_reward_per_step": 36.64759718154755,
    "episode_length": 514,
    "policy_loss": -617.7413635253906,
    "value_loss": 0.528900146484375,
    "entropy": 0.8998009860515594,
    "total_loss": -617.2574534282088
  },
  {
    "episode": 37,
    "avg_reward_per_step": 101.78362671688767,
    "episode_length": 192,
    "policy_loss": -1732.9939880371094,
    "value_loss": 0.5941639989614487,
    "entropy": 0.8724525719881058,
    "total_loss": -1732.4434466667474
  },
  {
    "episode": 38,
    "avg_reward_per_step": 90.18870750979906,
    "episode_length": 212,
    "policy_loss": -1522.4046630859375,
    "value_loss": 0.5795016884803772,
    "entropy": 0.8599564284086227,
    "total_loss": -1521.8681592188775
  },
  {
    "episode": 39,
    "avg_reward_per_step": 62.053248975620164,
    "episode_length": 301,
    "policy_loss": -1050.7570495605469,
    "value_loss": 0.55064857006073,
    "entropy": 0.8287031650543213,
    "total_loss": -1050.2478361487388
  },
  {
    "episode": 40,
    "avg_reward_per_step": 39.78220725986126,
    "episode_length": 444,
    "policy_loss": -670.5888214111328,
    "value_loss": 0.5292390137910843,
    "entropy": 0.8278492540121078,
    "total_loss": -670.1009748600424
  },
  {
    "episode": 41,
    "avg_reward_per_step": 31.965371708588073,
    "episode_length": 520,
    "policy_loss": -540.8947296142578,
    "value_loss": 0.5216310024261475,
    "entropy": 0.8292405009269714,
    "total_loss": -540.414560636878
  },
  {
    "episode": 42,
    "avg_reward_per_step": 128.62066624892952,
    "episode_length": 152,
    "policy_loss": -2179.1290283203125,
    "value_loss": 0.6248897314071655,
    "entropy": 0.791044756770134,
    "total_loss": -2178.543690826744
  },
  {
    "episode": 43,
    "avg_reward_per_step": 16.30367015884724,
    "episode_length": 848,
    "policy_loss": -274.5184020996094,
    "value_loss": 0.5087983906269073,
    "entropy": 0.7864061743021011,
    "total_loss": -274.0489240176976
  },
  {
    "episode": 44,
    "avg_reward_per_step": -1.4400449113519969,
    "episode_length": 2984,
    "policy_loss": 23.719300270080566,
    "value_loss": 0.5000633746385574,
    "entropy": 0.7597697675228119,
    "total_loss": 24.181375156342984
  },
  {
    "episode": 45,
    "avg_reward_per_step": -1.0023001737518171,
    "episode_length": 2503,
    "policy_loss": 16.03885793685913,
    "value_loss": 0.4998902156949043,
    "entropy": 0.7522816956043243,
    "total_loss": 16.50113406777382
  },
  {
    "episode": 46,
    "avg_reward_per_step": 8.18288506308056,
    "episode_length": 1153,
    "policy_loss": -138.47974395751953,
    "value_loss": 0.5027203112840652,
    "entropy": 0.7308931201696396,
    "total_loss": -138.01356830224395
  },
  {
    "episode": 47,
    "avg_reward_per_step": 0.31725776375061704,
    "episode_length": 1922,
    "policy_loss": -6.794061303138733,
    "value_loss": 0.4997420161962509,
    "entropy": 0.7107001096010208,
    "total_loss": -6.329854292422533
  },
  {
    "episode": 48,
    "avg_reward_per_step": 11.765095806744702,
    "episode_length": 988,
    "policy_loss": -198.96913146972656,
    "value_loss": 0.5051165670156479,
    "entropy": 0.8083793818950653,
    "total_loss": -198.50443387180567
  },
  {
    "episode": 49,
    "avg_reward_per_step": 53.00442786879241,
    "episode_length": 336,
    "policy_loss": -897.9228820800781,
    "value_loss": 0.5401172339916229,
    "entropy": 0.7612927556037903,
    "total_loss": -897.4208294838667
  },
  {
    "episode": 50,
    "avg_reward_per_step": -0.5217504176136515,
    "episode_length": 2049,
    "policy_loss": 8.453542232513428,
    "value_loss": 0.4997662901878357,
    "entropy": 0.6928797960281372,
    "total_loss": 8.918664532899857
  },
  {
    "episode": 51,
    "avg_reward_per_step": -10.604593142421036,
    "episode_length": 3000,
    "policy_loss": 177.8409309387207,
    "value_loss": 3.4865227341651917,
    "entropy": 0.6475846916437149,
    "total_loss": 181.29507443830371
  },
  {
    "episode": 52,
    "avg_reward_per_step": -1.7003343279927259,
    "episode_length": 2072,
    "policy_loss": 27.816953659057617,
    "value_loss": 0.49998433887958527,
    "entropy": 0.639648512005806,
    "total_loss": 28.284955572336912
  },
  {
    "episode": 53,
    "avg_reward_per_step": -10.888955867556472,
    "episode_length": 3000,
    "policy_loss": 182.3762664794922,
    "value_loss": 3.7889585494995117,
    "entropy": 0.6296149045228958,
    "total_loss": 186.13374428376557
  },
  {
    "episode": 54,
    "avg_reward_per_step": 148.0208296645607,
    "episode_length": 132,
    "policy_loss": -2503.1327514648438,
    "value_loss": 0.6509762704372406,
    "entropy": 0.6910201907157898,
    "total_loss": -2502.5163262039423
  },
  {
    "episode": 55,
    "avg_reward_per_step": 11.696894782394716,
    "episode_length": 955,
    "policy_loss": -198.32568359375,
    "value_loss": 0.5049100518226624,
    "entropy": 0.6786267310380936,
    "total_loss": -197.85470487847925
  },
  {
    "episode": 56,
    "avg_reward_per_step": 34.450246361547684,
    "episode_length": 493,
    "policy_loss": -581.2535705566406,
    "value_loss": 0.5239149630069733,
    "entropy": 0.625395268201828,
    "total_loss": -580.7609253570438
  },
  {
    "episode": 57,
    "avg_reward_per_step": 13.035186414419062,
    "episode_length": 908,
    "policy_loss": -221.49946212768555,
    "value_loss": 0.505912646651268,
    "entropy": 0.6818513721227646,
    "total_loss": -221.0276420496404
  },
  {
    "episode": 58,
    "avg_reward_per_step": 0.19459117592764,
    "episode_length": 2003,
    "policy_loss": -4.779488682746887,
    "value_loss": 0.49976224452257156,
    "entropy": 0.650546982884407,
    "total_loss": -4.312253787368536
  },
  {
    "episode": 59,
    "avg_reward_per_step": 63.28841802248822,
    "episode_length": 296,
    "policy_loss": -1068.7378234863281,
    "value_loss": 0.5515890866518021,
    "entropy": 0.715629830956459,
    "total_loss": -1068.2220158912241
  },
  {
    "episode": 60,
    "avg_reward_per_step": 8.696740228157438,
    "episode_length": 1125,
    "policy_loss": -152.66706466674805,
    "value_loss": 0.5030808299779892,
    "entropy": 0.709017738699913,
    "total_loss": -152.19943472370505
  },
  {
    "episode": 61,
    "avg_reward_per_step": 31.249295150259265,
    "episode_length": 552,
    "policy_loss": -530.0437469482422,
    "value_loss": 0.5221085399389267,
    "entropy": 0.8156499713659286,
    "total_loss": -529.5624209068716
  },
  {
    "episode": 62,
    "avg_reward_per_step": 4.116700650823946,
    "episode_length": 1786,
    "policy_loss": -70.30125427246094,
    "value_loss": 0.5009950995445251,
    "entropy": 0.8110879808664322,
    "total_loss": -69.84081357195973
  },
  {
    "episode": 63,
    "avg_reward_per_step": 188.62759357267572,
    "episode_length": 105,
    "policy_loss": -3228.5205078125,
    "value_loss": 0.7115775346755981,
    "entropy": 0.8410843312740326,
    "total_loss": -3227.8509844943883
  },
  {
    "episode": 64,
    "avg_reward_per_step": 131.74853522316147,
    "episode_length": 150,
    "policy_loss": -2233.257080078125,
    "value_loss": 0.631315678358078,
    "entropy": 0.8214289247989655,
    "total_loss": -2232.666835846007
  },
  {
    "episode": 65,
    "avg_reward_per_step": 131.14685189330385,
    "episode_length": 151,
    "policy_loss": -2240.3579711914062,
    "value_loss": 0.6305333226919174,
    "entropy": 0.85002601146698,
    "total_loss": -2239.7699391692877
  },
  {
    "episode": 66,
    "avg_reward_per_step": 135.44023603914417,
    "episode_length": 146,
    "policy_loss": -2329.6731567382812,
    "value_loss": 0.6363219618797302,
    "entropy": 0.8062050640583038,
    "total_loss": -2329.0771450296043
  },
  {
    "episode": 67,
    "avg_reward_per_step": 30.026451255882815,
    "episode_length": 543,
    "policy_loss": -505.71044921875,
    "value_loss": 0.5198676586151123,
    "entropy": 0.7273420840501785,
    "total_loss": -505.2269486643374
  },
  {
    "episode": 68,
    "avg_reward_per_step": 0.9106217220166437,
    "episode_length": 2210,
    "policy_loss": -16.64967966079712,
    "value_loss": 0.4998605027794838,
    "entropy": 0.6817084848880768,
    "total_loss": -16.183904582262038
  },
  {
    "episode": 69,
    "avg_reward_per_step": 40.612107909248714,
    "episode_length": 417,
    "policy_loss": -689.3846435546875,
    "value_loss": 0.5285966694355011,
    "entropy": 0.7039716243743896,
    "total_loss": -688.8912454664708
  },
  {
    "episode": 70,
    "avg_reward_per_step": 46.523970188311985,
    "episode_length": 390,
    "policy_loss": -787.6035919189453,
    "value_loss": 0.5355203449726105,
    "entropy": 0.6942639499902725,
    "total_loss": -787.1027847714722
  },
  {
    "episode": 71,
    "avg_reward_per_step": 61.02867752764888,
    "episode_length": 298,
    "policy_loss": -1033.02099609375,
    "value_loss": 0.5480034053325653,
    "entropy": 0.7380097061395645,
    "total_loss": -1032.5098931737243
  },
  {
    "episode": 72,
    "avg_reward_per_step": 48.04770242103697,
    "episode_length": 379,
    "policy_loss": -813.0591735839844,
    "value_loss": 0.5370414853096008,
    "entropy": 0.7298845499753952,
    "total_loss": -812.5586263261736
  },
  {
    "episode": 73,
    "avg_reward_per_step": 50.866418768985106,
    "episode_length": 374,
    "policy_loss": -866.3818359375,
    "value_loss": 0.5415641069412231,
    "entropy": 0.8138324469327927,
    "total_loss": -865.8809634529055
  },
  {
    "episode": 74,
    "avg_reward_per_step": 63.882240469863206,
    "episode_length": 291,
    "policy_loss": -1085.8684692382812,
    "value_loss": 0.551595002412796,
    "entropy": 0.7154279351234436,
    "total_loss": -1085.3526456326247
  },
  {
    "episode": 75,
    "avg_reward_per_step": 23.820247202813395,
    "episode_length": 658,
    "policy_loss": -400.3429718017578,
    "value_loss": 0.5149687081575394,
    "entropy": 0.7408654093742371,
    "total_loss": -399.865046364069
  },
  {
    "episode": 76,
    "avg_reward_per_step": 158.29641349843868,
    "episode_length": 125,
    "policy_loss": -2671.8056030273438,
    "value_loss": 0.6663172841072083,
    "entropy": 0.7946926206350327,
    "total_loss": -2671.1790203742685
  },
  {
    "episode": 77,
    "avg_reward_per_step": 3.118074269470133,
    "episode_length": 1593,
    "policy_loss": -53.826416015625,
    "value_loss": 0.5003205835819244,
    "entropy": 0.7010163962841034,
    "total_loss": -53.36114625185728
  },
  {
    "episode": 78,
    "avg_reward_per_step": 93.34173537248645,
    "episode_length": 205,
    "policy_loss": -1590.8055725097656,
    "value_loss": 0.5827036798000336,
    "entropy": 0.766646683216095,
    "total_loss": -1590.2612011641263
  },
  {
    "episode": 79,
    "avg_reward_per_step": 46.69820835501204,
    "episode_length": 395,
    "policy_loss": -808.7021331787109,
    "value_loss": 0.5365729182958603,
    "entropy": 0.8359064012765884,
    "total_loss": -808.2073555804789
  },
  {
    "episode": 80,
    "avg_reward_per_step": 127.56604145490294,
    "episode_length": 155,
    "policy_loss": -2183.2909545898438,
    "value_loss": 0.6263847947120667,
    "entropy": 0.8847483098506927,
    "total_loss": -2182.7088072106244
  },
  {
    "episode": 81,
    "avg_reward_per_step": 72.29757054971735,
    "episode_length": 259,
    "policy_loss": -1221.2418823242188,
    "value_loss": 0.5599692612886429,
    "entropy": 0.7215736210346222,
    "total_loss": -1220.7179917439819
  },
  {
    "episode": 82,
    "avg_reward_per_step": 99.45747124090457,
    "episode_length": 196,
    "policy_loss": -1698.4024963378906,
    "value_loss": 0.5911026895046234,
    "entropy": 0.8225520700216293,
    "total_loss": -1697.852521251887
  },
  {
    "episode": 83,
    "avg_reward_per_step": 17.97586543166318,
    "episode_length": 824,
    "policy_loss": -303.53902435302734,
    "value_loss": 0.5105512142181396,
    "entropy": 0.762991800904274,
    "total_loss": -303.06662272885444
  },
  {
    "episode": 84,
    "avg_reward_per_step": 75.97996774420903,
    "episode_length": 253,
    "policy_loss": -1282.890625,
    "value_loss": 0.5653354823589325,
    "entropy": 0.7508687227964401,
    "total_loss": -1282.362832953781
  },
  {
    "episode": 85,
    "avg_reward_per_step": 81.85738224480082,
    "episode_length": 238,
    "policy_loss": -1394.6603698730469,
    "value_loss": 0.5731052458286285,
    "entropy": 0.861425057053566,
    "total_loss": -1394.130335880071
  },
  {
    "episode": 86,
    "avg_reward_per_step": 62.81523200922417,
    "episode_length": 310,
    "policy_loss": -1065.8307189941406,
    "value_loss": 0.554063230752945,
    "entropy": 0.7726772576570511,
    "total_loss": -1065.3152896262704
  },
  {
    "episode": 87,
    "avg_reward_per_step": 14.148437886306935,
    "episode_length": 889,
    "policy_loss": -239.55379486083984,
    "value_loss": 0.5068327337503433,
    "entropy": 0.6064666211605072,
    "total_loss": -239.07728545814751
  },
  {
    "episode": 88,
    "avg_reward_per_step": 28.12247055274869,
    "episode_length": 521,
    "policy_loss": -474.3243408203125,
    "value_loss": 0.5164792239665985,
    "entropy": 0.5483626574277878,
    "total_loss": -473.8352797292173
  },
  {
    "episode": 89,
    "avg_reward_per_step": 29.31526265048921,
    "episode_length": 548,
    "policy_loss": -494.08815002441406,
    "value_loss": 0.5191519409418106,
    "entropy": 0.6308477520942688,
    "total_loss": -493.60054047107695
  },
  {
    "episode": 90,
    "avg_reward_per_step": -0.5614660410546053,
    "episode_length": 2345,
    "policy_loss": 8.54055118560791,
    "value_loss": 0.4998183399438858,
    "entropy": 0.6110249012708664,
    "total_loss": 9.009818280488252
  },
  {
    "episode": 91,
    "avg_reward_per_step": -9.85730983115496,
    "episode_length": 3000,
    "policy_loss": 164.9747428894043,
    "value_loss": 2.6149085760116577,
    "entropy": 0.5715703517198563,
    "total_loss": 167.56107294782996
  },
  {
    "episode": 92,
    "avg_reward_per_step": 70.96439118926551,
    "episode_length": 263,
    "policy_loss": -1199.1458435058594,
    "value_loss": 0.5582872480154037,
    "entropy": 0.6504725217819214,
    "total_loss": -1198.6200798839332
  },
  {
    "episode": 93,
    "avg_reward_per_step": 9.93031138008081,
    "episode_length": 1100,
    "policy_loss": -170.83989715576172,
    "value_loss": 0.5040334910154343,
    "entropy": 0.6659564524888992,
    "total_loss": -170.36916148737072
  },
  {
    "episode": 94,
    "avg_reward_per_step": 2.5031870963098997,
    "episode_length": 2045,
    "policy_loss": -42.95394802093506,
    "value_loss": 0.5002977401018143,
    "entropy": 0.6939012259244919,
    "total_loss": -42.48834534212947
  },
  {
    "episode": 95,
    "avg_reward_per_step": 22.233439146659297,
    "episode_length": 772,
    "policy_loss": -378.0230712890625,
    "value_loss": 0.5154638290405273,
    "entropy": 0.775051012635231,
    "total_loss": -377.54636001065376
  },
  {
    "episode": 96,
    "avg_reward_per_step": 167.51251100832192,
    "episode_length": 119,
    "policy_loss": -2856.100341796875,
    "value_loss": 0.6809539794921875,
    "entropy": 0.7266151756048203,
    "total_loss": -2855.4557185761632
  },
  {
    "episode": 97,
    "avg_reward_per_step": 9.169404855371404,
    "episode_length": 1478,
    "policy_loss": -156.52130508422852,
    "value_loss": 0.5048226863145828,
    "entropy": 0.7827191352844238,
    "total_loss": -156.05561835467816
  },
  {
    "episode": 98,
    "avg_reward_per_step": 15.945849755242085,
    "episode_length": 1066,
    "policy_loss": -270.69573974609375,
    "value_loss": 0.5108984857797623,
    "entropy": 0.8213617950677872,
    "total_loss": -270.22590935006735
  },
  {
    "episode": 99,
    "avg_reward_per_step": 213.9612622465273,
    "episode_length": 93,
    "policy_loss": -3613.6895751953125,
    "value_loss": 0.7558447271585464,
    "entropy": 0.8260252922773361,
    "total_loss": -3612.975031732768
  },
  {
    "episode": 100,
    "avg_reward_per_step": 27.682947172523388,
    "episode_length": 633,
    "policy_loss": -467.2454605102539,
    "value_loss": 0.5198912620544434,
    "entropy": 0.7987668961286545,
    "total_loss": -466.7655075930059
  },
  {
    "episode": 101,
    "avg_reward_per_step": 111.06227362823375,
    "episode_length": 179,
    "policy_loss": -1889.1749267578125,
    "value_loss": 0.6069062948226929,
    "entropy": 0.7709634602069855,
    "total_loss": -1888.6065686360002
  },
  {
    "episode": 102,
    "avg_reward_per_step": 93.8188924329051,
    "episode_length": 209,
    "policy_loss": -1573.2814025878906,
    "value_loss": 0.5857819765806198,
    "entropy": 0.7871910184621811,
    "total_loss": -1572.7349801622331
  },
  {
    "episode": 103,
    "avg_reward_per_step": 24.766441428609536,
    "episode_length": 662,
    "policy_loss": -416.9338073730469,
    "value_loss": 0.5163687765598297,
    "entropy": 0.7779880613088608,
    "total_loss": -416.4563379995525
  },
  {
    "episode": 104,
    "avg_reward_per_step": 38.35993323799772,
    "episode_length": 467,
    "policy_loss": -652.5519104003906,
    "value_loss": 0.5287652611732483,
    "entropy": 0.7943395674228668,
    "total_loss": -652.0628621175886
  },
  {
    "episode": 105,
    "avg_reward_per_step": 22.322132459601086,
    "episode_length": 715,
    "policy_loss": -382.7497024536133,
    "value_loss": 0.5143095403909683,
    "entropy": 0.7123101055622101,
    "total_loss": -382.2710084185004
  },
  {
    "episode": 106,
    "avg_reward_per_step": 109.04738996403768,
    "episode_length": 182,
    "policy_loss": -1838.1564025878906,
    "value_loss": 0.6041173487901688,
    "entropy": 0.7935461550951004,
    "total_loss": -1837.5919625468553
  },
  {
    "episode": 107,
    "avg_reward_per_step": 78.05011203066155,
    "episode_length": 246,
    "policy_loss": -1318.4144592285156,
    "value_loss": 0.568096250295639,
    "entropy": 0.8001997470855713,
    "total_loss": -1317.8863729655743
  },
  {
    "episode": 108,
    "avg_reward_per_step": 47.22490768503528,
    "episode_length": 376,
    "policy_loss": -798.078369140625,
    "value_loss": 0.5351864397525787,
    "entropy": 0.725788414478302,
    "total_loss": -797.5794721215964
  },
  {
    "episode": 109,
    "avg_reward_per_step": 0.6043826455303323,
    "episode_length": 2703,
    "policy_loss": -11.14905309677124,
    "value_loss": 0.49983973801136017,
    "entropy": 0.7260332852602005,
    "total_loss": -10.68551502302289
  },
  {
    "episode": 110,
    "avg_reward_per_step": 5.332912179042797,
    "episode_length": 1526,
    "policy_loss": -92.02853202819824,
    "value_loss": 0.501466765999794,
    "entropy": 0.6920287311077118,
    "total_loss": -91.56166669875384
  },
  {
    "episode": 111,
    "avg_reward_per_step": 19.124639704721012,
    "episode_length": 828,
    "policy_loss": -325.54615020751953,
    "value_loss": 0.5121115446090698,
    "entropy": 0.7736328542232513,
    "total_loss": -325.0727203056216
  },
  {
    "episode": 112,
    "avg_reward_per_step": 19.37171593546805,
    "episode_length": 884,
    "policy_loss": -328.85204315185547,
    "value_loss": 0.513440877199173,
    "entropy": 0.8387410938739777,
    "total_loss": -328.38053932935
  },
  {
    "episode": 113,
    "avg_reward_per_step": 134.58630254018829,
    "episode_length": 146,
    "policy_loss": -2305.136962890625,
    "value_loss": 0.6344383507966995,
    "entropy": 0.821422815322876,
    "total_loss": -2304.5435956805945
  },
  {
    "episode": 114,
    "avg_reward_per_step": 4.725651345631941,
    "episode_length": 1945,
    "policy_loss": -80.74118614196777,
    "value_loss": 0.501552939414978,
    "entropy": 0.7572456896305084,
    "total_loss": -80.27749548703432
  },
  {
    "episode": 115,
    "avg_reward_per_step": 238.17089223537673,
    "episode_length": 84,
    "policy_loss": -4054.2996826171875,
    "value_loss": 0.8019599765539169,
    "entropy": 0.7724254429340363,
    "total_loss": -4053.5363439127805
  },
  {
    "episode": 116,
    "avg_reward_per_step": 231.53321576977342,
    "episode_length": 86,
    "policy_loss": -3956.5321044921875,
    "value_loss": 0.7875372916460037,
    "entropy": 0.6909710168838501,
    "total_loss": -3955.7791157513857
  },
  {
    "episode": 117,
    "avg_reward_per_step": 10.105582868923419,
    "episode_length": 1394,
    "policy_loss": -171.23759078979492,
    "value_loss": 0.5055685490369797,
    "entropy": 0.727613240480423,
    "total_loss": -170.76840290278196
  },
  {
    "episode": 118,
    "avg_reward_per_step": 199.88081502572638,
    "episode_length": 100,
    "policy_loss": -3398.6060180664062,
    "value_loss": 0.7329370677471161,
    "entropy": 0.6810157746076584,
    "total_loss": -3397.9071317873895
  },
  {
    "episode": 119,
    "avg_reward_per_step": 93.28116918627232,
    "episode_length": 212,
    "policy_loss": -1580.0881042480469,
    "value_loss": 0.5858087092638016,
    "entropy": 0.7462839335203171,
    "total_loss": -1579.5396097354592
  },
  {
    "episode": 120,
    "avg_reward_per_step": 99.75866849023042,
    "episode_length": 198,
    "policy_loss": -1684.2836303710938,
    "value_loss": 0.5930477976799011,
    "entropy": 0.7546204626560211,
    "total_loss": -1683.7283135965467
  },
  {
    "episode": 121,
    "avg_reward_per_step": 16.746656453976396,
    "episode_length": 1028,
    "policy_loss": -283.3926086425781,
    "value_loss": 0.5115821361541748,
    "entropy": 0.7411845028400421,
    "total_loss": -282.91808573156595
  },
  {
    "episode": 122,
    "avg_reward_per_step": 32.5703213934053,
    "episode_length": 571,
    "policy_loss": -550.0076293945312,
    "value_loss": 0.5251588225364685,
    "entropy": 0.7302739918231964,
    "total_loss": -549.518984271586
  },
  {
    "episode": 123,
    "avg_reward_per_step": 23.3303344412682,
    "episode_length": 751,
    "policy_loss": -396.71666717529297,
    "value_loss": 0.5166080594062805,
    "entropy": 0.7261929661035538,
    "total_loss": -396.23636876419187
  },
  {
    "episode": 124,
    "avg_reward_per_step": 67.58475216876052,
    "episode_length": 289,
    "policy_loss": -1139.3912963867188,
    "value_loss": 0.5585098266601562,
    "entropy": 0.6990115493535995,
    "total_loss": -1138.8677371375263
  },
  {
    "episode": 125,
    "avg_reward_per_step": 160.23133616279287,
    "episode_length": 124,
    "policy_loss": -2730.7406005859375,
    "value_loss": 0.6705958992242813,
    "entropy": 0.6897183656692505,
    "total_loss": -2730.1044906049965
  },
  {
    "episode": 126,
    "avg_reward_per_step": 86.69881632825854,
    "episode_length": 228,
    "policy_loss": -1471.2233276367188,
    "value_loss": 0.5788620859384537,
    "entropy": 0.7372842878103256,
    "total_loss": -1470.6813297651709
  },
  {
    "episode": 127,
    "avg_reward_per_step": 164.16674480844554,
    "episode_length": 121,
    "policy_loss": -2786.6450805664062,
    "value_loss": 0.6759436875581741,
    "entropy": 0.7062248587608337,
    "total_loss": -2786.004448121786
  },
  {
    "episode": 128,
    "avg_reward_per_step": 12.616987623744258,
    "episode_length": 1328,
    "policy_loss": -215.34622955322266,
    "value_loss": 0.5084009915590286,
    "entropy": 0.7498374879360199,
    "total_loss": -214.87532043606043
  },
  {
    "episode": 129,
    "avg_reward_per_step": 243.18416013955593,
    "episode_length": 82,
    "policy_loss": -4124.8753662109375,
    "value_loss": 0.8105005919933319,
    "entropy": 0.7131492346525192,
    "total_loss": -4124.100523080677
  },
  {
    "episode": 130,
    "avg_reward_per_step": 154.02663625796987,
    "episode_length": 129,
    "policy_loss": -2617.1895141601562,
    "value_loss": 0.6616325080394745,
    "entropy": 0.6457994431257248,
    "total_loss": -2616.560171624273
  },
  {
    "episode": 131,
    "avg_reward_per_step": 262.9550873521737,
    "episode_length": 76,
    "policy_loss": -4468.5546875,
    "value_loss": 0.8516810387372971,
    "entropy": 0.5991864204406738,
    "total_loss": -4467.732965782285
  },
  {
    "episode": 132,
    "avg_reward_per_step": -5.120652550411338,
    "episode_length": 3000,
    "policy_loss": 85.63534355163574,
    "value_loss": 1.6589515209197998,
    "entropy": 0.571397602558136,
    "total_loss": 87.26572519242764
  },
  {
    "episode": 133,
    "avg_reward_per_step": 4.567810870654268,
    "episode_length": 1840,
    "policy_loss": -77.1218376159668,
    "value_loss": 0.5012824237346649,
    "entropy": 0.5310204774141312,
    "total_loss": -76.64710621610284
  },
  {
    "episode": 134,
    "avg_reward_per_step": -7.554705033850694,
    "episode_length": 3000,
    "policy_loss": 126.19784545898438,
    "value_loss": 1.7582255899906158,
    "entropy": 0.5090151876211166,
    "total_loss": 127.93062028959393
  },
  {
    "episode": 135,
    "avg_reward_per_step": -6.992185204562174,
    "episode_length": 3000,
    "policy_loss": 116.35012435913086,
    "value_loss": 1.5580777823925018,
    "entropy": 0.47450271993875504,
    "total_loss": 117.88447700552642
  },
  {
    "episode": 136,
    "avg_reward_per_step": 24.886458637541384,
    "episode_length": 690,
    "policy_loss": -423.68888092041016,
    "value_loss": 0.5172972232103348,
    "entropy": 0.49926286190748215,
    "total_loss": -423.1965468402952
  },
  {
    "episode": 137,
    "avg_reward_per_step": 17.89544461729339,
    "episode_length": 910,
    "policy_loss": -306.79036712646484,
    "value_loss": 0.5115978270769119,
    "entropy": 0.4915580078959465,
    "total_loss": -306.3033471997827
  },
  {
    "episode": 138,
    "avg_reward_per_step": -7.789221571694495,
    "episode_length": 3000,
    "policy_loss": 129.26836013793945,
    "value_loss": 1.7342584133148193,
    "entropy": 0.48659149557352066,
    "total_loss": 130.9782889764756
  },
  {
    "episode": 139,
    "avg_reward_per_step": -8.122862096801075,
    "episode_length": 3000,
    "policy_loss": 134.5916748046875,
    "value_loss": 1.6618030071258545,
    "entropy": 0.48380161076784134,
    "total_loss": 136.22928773127495
  },
  {
    "episode": 140,
    "avg_reward_per_step": -8.117950205322925,
    "episode_length": 3000,
    "policy_loss": 134.15056610107422,
    "value_loss": 1.6788290143013,
    "entropy": 0.4930110424757004,
    "total_loss": 135.80474456325175
  },
  {
    "episode": 141,
    "avg_reward_per_step": 54.70246070369105,
    "episode_length": 353,
    "policy_loss": -929.6870727539062,
    "value_loss": 0.5458291620016098,
    "entropy": 0.4757288247346878,
    "total_loss": -929.1650300331414
  },
  {
    "episode": 142,
    "avg_reward_per_step": -5.426762169381413,
    "episode_length": 3000,
    "policy_loss": 88.53998565673828,
    "value_loss": 1.476382464170456,
    "entropy": 0.5043676346540451,
    "total_loss": 89.99114973917604
  },
  {
    "episode": 143,
    "avg_reward_per_step": 152.97938877204626,
    "episode_length": 130,
    "policy_loss": -2594.4090576171875,
    "value_loss": 0.6605265438556671,
    "entropy": 0.48318250477313995,
    "total_loss": -2593.7726901985707
  },
  {
    "episode": 144,
    "avg_reward_per_step": 33.191949518359124,
    "episode_length": 541,
    "policy_loss": -549.3685455322266,
    "value_loss": 0.524886816740036,
    "entropy": 0.46842043101787567,
    "total_loss": -548.8670797370374
  },
  {
    "episode": 145,
    "avg_reward_per_step": 159.17024730131558,
    "episode_length": 125,
    "policy_loss": -2732.7227172851562,
    "value_loss": 0.6692754626274109,
    "entropy": 0.4331612214446068,
    "total_loss": -2732.075099883601
  },
  {
    "episode": 146,
    "avg_reward_per_step": -6.73620575449213,
    "episode_length": 3000,
    "policy_loss": 110.28884887695312,
    "value_loss": 1.4606244266033173,
    "entropy": 0.47107741236686707,
    "total_loss": 111.7259194329381
  },
  {
    "episode": 147,
    "avg_reward_per_step": -6.9584496968593035,
    "episode_length": 3000,
    "policy_loss": 113.41444206237793,
    "value_loss": 1.7210719287395477,
    "entropy": 0.4549459293484688,
    "total_loss": 115.11276669465005
  },
  {
    "episode": 148,
    "avg_reward_per_step": -7.667472808032492,
    "episode_length": 3000,
    "policy_loss": 124.89852905273438,
    "value_loss": 1.5629603862762451,
    "entropy": 0.4491061493754387,
    "total_loss": 126.43903413154185
  },
  {
    "episode": 149,
    "avg_reward_per_step": 59.29509124608754,
    "episode_length": 308,
    "policy_loss": -1005.6821899414062,
    "value_loss": 0.5475124269723892,
    "entropy": 0.38261236995458603,
    "total_loss": -1005.1538081329315
  },
  {
    "episode": 150,
    "avg_reward_per_step": 124.88620856403662,
    "episode_length": 157,
    "policy_loss": -2140.6583251953125,
    "value_loss": 0.6214527636766434,
    "entropy": 0.43619297444820404,
    "total_loss": -2140.0586820803583
  },
  {
    "episode": 151,
    "avg_reward_per_step": -5.729024195223425,
    "episode_length": 3000,
    "policy_loss": 91.6796817779541,
    "value_loss": 1.719650149345398,
    "entropy": 0.48892906308174133,
    "total_loss": 93.37488547414542
  },
  {
    "episode": 152,
    "avg_reward_per_step": 141.2149319876224,
    "episode_length": 141,
    "policy_loss": -2413.9920043945312,
    "value_loss": 0.6449047029018402,
    "entropy": 0.442732572555542,
    "total_loss": -2413.369236320257
  },
  {
    "episode": 153,
    "avg_reward_per_step": -4.662319526118191,
    "episode_length": 3000,
    "policy_loss": 73.14694786071777,
    "value_loss": 1.2930157482624054,
    "entropy": 0.4779784306883812,
    "total_loss": 74.41606468744575
  },
  {
    "episode": 154,
    "avg_reward_per_step": 73.18455913910684,
    "episode_length": 270,
    "policy_loss": -1245.02880859375,
    "value_loss": 0.5653630048036575,
    "entropy": 0.42331869900226593,
    "total_loss": -1244.4846115238965
  },
  {
    "episode": 155,
    "avg_reward_per_step": -5.489004330199814,
    "episode_length": 3000,
    "policy_loss": 86.55761528015137,
    "value_loss": 1.741498589515686,
    "entropy": 0.48881707340478897,
    "total_loss": 88.27467301599681
  },
  {
    "episode": 156,
    "avg_reward_per_step": 234.8731208706444,
    "episode_length": 85,
    "policy_loss": -3981.1968383789062,
    "value_loss": 0.796321377158165,
    "entropy": 0.3984576240181923,
    "total_loss": -3980.420439882949
  },
  {
    "episode": 157,
    "avg_reward_per_step": 243.66555127646097,
    "episode_length": 82,
    "policy_loss": -4172.0535888671875,
    "value_loss": 0.8135277628898621,
    "entropy": 0.3795512318611145,
    "total_loss": -4171.25903866589
  },
  {
    "episode": 158,
    "avg_reward_per_step": 76.52615574864186,
    "episode_length": 259,
    "policy_loss": -1300.2852172851562,
    "value_loss": 0.5689526796340942,
    "entropy": 0.35184917598962784,
    "total_loss": -1299.7338570643217
  },
  {
    "episode": 159,
    "avg_reward_per_step": 80.32896701688779,
    "episode_length": 247,
    "policy_loss": -1372.8351745605469,
    "value_loss": 0.5728755444288254,
    "entropy": 0.36254774779081345,
    "total_loss": -1372.2804264035076
  },
  {
    "episode": 160,
    "avg_reward_per_step": 166.5707168694235,
    "episode_length": 120,
    "policy_loss": -2834.4456787109375,
    "value_loss": 0.6808348298072815,
    "entropy": 0.3402269557118416,
    "total_loss": -2833.781855228916
  },
  {
    "episode": 161,
    "avg_reward_per_step": 263.2438305945949,
    "episode_length": 76,
    "policy_loss": -4467.287109375,
    "value_loss": 0.8535111993551254,
    "entropy": 0.3464617431163788,
    "total_loss": -4466.450921262801
  },
  {
    "episode": 162,
    "avg_reward_per_step": 161.3329353513019,
    "episode_length": 124,
    "policy_loss": -2737.6083984375,
    "value_loss": 0.6730809211730957,
    "entropy": 0.38822512328624725,
    "total_loss": -2736.9547287724913
  },
  {
    "episode": 163,
    "avg_reward_per_step": 102.61829244189866,
    "episode_length": 193,
    "policy_loss": -1762.8817138671875,
    "value_loss": 0.5967301428318024,
    "entropy": 0.3113068491220474,
    "total_loss": -1762.3005490668118
  },
  {
    "episode": 164,
    "avg_reward_per_step": 146.72319064585713,
    "episode_length": 136,
    "policy_loss": -2501.9860229492188,
    "value_loss": 0.6524326354265213,
    "entropy": 0.3578522652387619,
    "total_loss": -2501.3514829270543
  },
  {
    "episode": 165,
    "avg_reward_per_step": 142.28752224159481,
    "episode_length": 140,
    "policy_loss": -2431.2327880859375,
    "value_loss": 0.6465360075235367,
    "entropy": 0.30492765456438065,
    "total_loss": -2430.601498461142
  },
  {
    "episode": 166,
    "avg_reward_per_step": 253.04242043625672,
    "episode_length": 79,
    "policy_loss": -4310.88623046875,
    "value_loss": 0.8324891626834869,
    "entropy": 0.34435419738292694,
    "total_loss": -4310.070959015936
  },
  {
    "episode": 167,
    "avg_reward_per_step": 100.00088231058729,
    "episode_length": 199,
    "policy_loss": -1706.1133728027344,
    "value_loss": 0.5942088067531586,
    "entropy": 0.35291773825883865,
    "total_loss": -1705.5368098828942
  },
  {
    "episode": 168,
    "avg_reward_per_step": 256.65193597554816,
    "episode_length": 78,
    "policy_loss": -4391.8189697265625,
    "value_loss": 0.8398909866809845,
    "entropy": 0.33040179312229156,
    "total_loss": -4390.995598829538
  },
  {
    "episode": 169,
    "avg_reward_per_step": 263.02755252511537,
    "episode_length": 76,
    "policy_loss": -4481.5076904296875,
    "value_loss": 0.8527535647153854,
    "entropy": 0.3408634141087532,
    "total_loss": -4480.671980035678
  },
  {
    "episode": 170,
    "avg_reward_per_step": 263.52756693658046,
    "episode_length": 76,
    "policy_loss": -4431.3856201171875,
    "value_loss": 0.853835791349411,
    "entropy": 0.3417477086186409,
    "total_loss": -4430.548871711269
  },
  {
    "episode": 171,
    "avg_reward_per_step": 214.96325256077583,
    "episode_length": 93,
    "policy_loss": -3645.89990234375,
    "value_loss": 0.7592621892690659,
    "entropy": 0.34219442307949066,
    "total_loss": -3645.157749875635
  },
  {
    "episode": 172,
    "avg_reward_per_step": 274.411857390923,
    "episode_length": 73,
    "policy_loss": -4621.9228515625,
    "value_loss": 0.8780121952295303,
    "entropy": 0.3207286670804024,
    "total_loss": -4621.060875800625
  },
  {
    "episode": 173,
    "avg_reward_per_step": 270.80057157027363,
    "episode_length": 74,
    "policy_loss": -4578.130859375,
    "value_loss": 0.870277002453804,
    "entropy": 0.26079708710312843,
    "total_loss": -4577.273622226901
  },
  {
    "episode": 174,
    "avg_reward_per_step": 96.38298544598314,
    "episode_length": 205,
    "policy_loss": -1638.7186889648438,
    "value_loss": 0.5895287841558456,
    "entropy": 0.25768952816724777,
    "total_loss": -1638.1420446570962
  },
  {
    "episode": 175,
    "avg_reward_per_step": 263.4354116819068,
    "episode_length": 76,
    "policy_loss": -4436.66748046875,
    "value_loss": 0.8539881259202957,
    "entropy": 0.2192922718822956,
    "total_loss": -4435.824456956424
  },
  {
    "episode": 176,
    "avg_reward_per_step": 73.86280688143324,
    "episode_length": 268,
    "policy_loss": -1254.5663757324219,
    "value_loss": 0.5659658908843994,
    "entropy": 0.22393228858709335,
    "total_loss": -1254.0116064559668
  },
  {
    "episode": 177,
    "avg_reward_per_step": 270.41849389455393,
    "episode_length": 74,
    "policy_loss": -4525.7860107421875,
    "value_loss": 0.868881106376648,
    "entropy": 0.17222486436367035,
    "total_loss": -4524.925740879029
  },
  {
    "episode": 178,
    "avg_reward_per_step": 266.7810394471127,
    "episode_length": 75,
    "policy_loss": -4470.181396484375,
    "value_loss": 0.8610105514526367,
    "entropy": 0.16716071218252182,
    "total_loss": -4469.328743968532
  },
  {
    "episode": 179,
    "avg_reward_per_step": 266.62089808501236,
    "episode_length": 75,
    "policy_loss": -4516.8458251953125,
    "value_loss": 0.8607565760612488,
    "entropy": 0.15153906121850014,
    "total_loss": -4515.9926455723125
  },
  {
    "episode": 180,
    "avg_reward_per_step": 274.10380772907536,
    "episode_length": 73,
    "policy_loss": -4578.90625,
    "value_loss": 0.876966193318367,
    "entropy": 0.1409885287284851,
    "total_loss": -4578.036333233118
  },
  {
    "episode": 181,
    "avg_reward_per_step": 270.65365180825444,
    "episode_length": 74,
    "policy_loss": -4547.081787109375,
    "value_loss": 0.8696187287569046,
    "entropy": 0.13085802644491196,
    "total_loss": -4546.21871128194
  },
  {
    "episode": 182,
    "avg_reward_per_step": 286.3089905529992,
    "episode_length": 70,
    "policy_loss": -4794.47900390625,
    "value_loss": 0.9046857804059982,
    "entropy": 0.11910851113498211,
    "total_loss": -4793.580273551401
  },
  {
    "episode": 183,
    "avg_reward_per_step": 278.2436659728896,
    "episode_length": 72,
    "policy_loss": -4659.20458984375,
    "value_loss": 0.8865299969911575,
    "entropy": 0.1299312263727188,
    "total_loss": -4658.324556408077
  },
  {
    "episode": 184,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4780.1376953125,
    "value_loss": 0.9047164022922516,
    "entropy": 0.1441824957728386,
    "total_loss": -4779.240188034996
  },
  {
    "episode": 185,
    "avg_reward_per_step": 79.44247186146013,
    "episode_length": 250,
    "policy_loss": -1358.8480529785156,
    "value_loss": 0.5721001923084259,
    "entropy": 0.13102764077484608,
    "total_loss": -1358.2825041682459
  },
  {
    "episode": 186,
    "avg_reward_per_step": 282.5636853795732,
    "episode_length": 71,
    "policy_loss": -4724.838623046875,
    "value_loss": 0.8960983157157898,
    "entropy": 0.10960673168301582,
    "total_loss": -4723.948005067743
  },
  {
    "episode": 187,
    "avg_reward_per_step": 131.6242450824092,
    "episode_length": 149,
    "policy_loss": -2237.7571411132812,
    "value_loss": 0.6295778155326843,
    "entropy": 0.15214919671416283,
    "total_loss": -2237.135170757584
  },
  {
    "episode": 188,
    "avg_reward_per_step": 278.43979425069017,
    "episode_length": 72,
    "policy_loss": -4652.2998046875,
    "value_loss": 0.887033224105835,
    "entropy": 0.06927230022847652,
    "total_loss": -4651.416235078405
  },
  {
    "episode": 189,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4772.175048828125,
    "value_loss": 0.9046798050403595,
    "entropy": 0.06528786662966013,
    "total_loss": -4771.2736334164165
  },
  {
    "episode": 190,
    "avg_reward_per_step": 286.3484272360624,
    "episode_length": 70,
    "policy_loss": -4779.018310546875,
    "value_loss": 0.9046454876661301,
    "entropy": 0.06727247312664986,
    "total_loss": -4778.117028682866
  },
  {
    "episode": 191,
    "avg_reward_per_step": 270.48526485761994,
    "episode_length": 74,
    "policy_loss": -4558.04248046875,
    "value_loss": 0.8692589700222015,
    "entropy": 0.0883154422044754,
    "total_loss": -4557.177637270838
  },
  {
    "episode": 192,
    "avg_reward_per_step": 278.5133556893642,
    "episode_length": 72,
    "policy_loss": -4669.81884765625,
    "value_loss": 0.8873271346092224,
    "entropy": 0.08433347381651402,
    "total_loss": -4668.935737195332
  },
  {
    "episode": 193,
    "avg_reward_per_step": 278.43979425069017,
    "episode_length": 72,
    "policy_loss": -4643.16943359375,
    "value_loss": 0.886973962187767,
    "entropy": 0.046846505254507065,
    "total_loss": -4642.284801956825
  },
  {
    "episode": 194,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4767.2498779296875,
    "value_loss": 0.9046034961938858,
    "entropy": 0.047284986823797226,
    "total_loss": -4766.347638682835
  },
  {
    "episode": 195,
    "avg_reward_per_step": 146.05410829064996,
    "episode_length": 136,
    "policy_loss": -2474.880126953125,
    "value_loss": 0.650525838136673,
    "entropy": 0.11498209834098816,
    "total_loss": -2474.2353502199053
  },
  {
    "episode": 196,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4771.7625732421875,
    "value_loss": 0.9045633524656296,
    "entropy": 0.05026327073574066,
    "total_loss": -4770.8605230532585
  },
  {
    "episode": 197,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4772.0184326171875,
    "value_loss": 0.9045466333627701,
    "entropy": 0.0379792544990778,
    "total_loss": -4771.11578494655
  },
  {
    "episode": 198,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4767.25927734375,
    "value_loss": 0.9045359194278717,
    "entropy": 0.03189529664814472,
    "total_loss": -4766.356336189155
  },
  {
    "episode": 199,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4767.498046875,
    "value_loss": 0.904525488615036,
    "entropy": 0.030008043628185987,
    "total_loss": -4766.595021788567
  },
  {
    "episode": 200,
    "avg_reward_per_step": 282.0749516246424,
    "episode_length": 71,
    "policy_loss": -4706.6090087890625,
    "value_loss": 0.8944520652294159,
    "entropy": 0.04116269387304783,
    "total_loss": -4705.716614858527
  },
  {
    "episode": 201,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4768.0648193359375,
    "value_loss": 0.9045056402683258,
    "entropy": 0.02744973823428154,
    "total_loss": -4767.1616861825805
  },
  {
    "episode": 202,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4767.93603515625,
    "value_loss": 0.9044940173625946,
    "entropy": 0.02331900643184781,
    "total_loss": -4767.032707089209
  },
  {
    "episode": 203,
    "avg_reward_per_step": 282.3674401256895,
    "episode_length": 71,
    "policy_loss": -4748.4227294921875,
    "value_loss": 0.8953454196453094,
    "entropy": 0.025369691662490368,
    "total_loss": -4747.5286525571255
  },
  {
    "episode": 204,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4761.78955078125,
    "value_loss": 0.904348224401474,
    "entropy": 0.03480261377990246,
    "total_loss": -4760.886942687537
  },
  {
    "episode": 205,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4770.21337890625,
    "value_loss": 0.9043204486370087,
    "entropy": 0.02692938083782792,
    "total_loss": -4769.310404926655
  },
  {
    "episode": 206,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4765.9869384765625,
    "value_loss": 0.9043035805225372,
    "entropy": 0.027137957513332367,
    "total_loss": -4765.083991793916
  },
  {
    "episode": 207,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4765.7110595703125,
    "value_loss": 0.904294490814209,
    "entropy": 0.02933588158339262,
    "total_loss": -4764.808231873578
  },
  {
    "episode": 208,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4766.516357421875,
    "value_loss": 0.9042882025241852,
    "entropy": 0.027165806852281094,
    "total_loss": -4765.613427509694
  },
  {
    "episode": 209,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4766.4139404296875,
    "value_loss": 0.9042823910713196,
    "entropy": 0.022809761110693216,
    "total_loss": -4765.510798526671
  },
  {
    "episode": 210,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4765.9176025390625,
    "value_loss": 0.9042762368917465,
    "entropy": 0.020015620160847902,
    "total_loss": -4765.014327083179
  },
  {
    "episode": 211,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4765.576171875,
    "value_loss": 0.9042690396308899,
    "entropy": 0.018909613136202097,
    "total_loss": -4764.672848316026
  },
  {
    "episode": 212,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4765.3984375,
    "value_loss": 0.9042601734399796,
    "entropy": 0.018152129370719194,
    "total_loss": -4764.495084933029
  },
  {
    "episode": 213,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4765.2547607421875,
    "value_loss": 0.9042488783597946,
    "entropy": 0.01708474988117814,
    "total_loss": -4764.351366101322
  },
  {
    "episode": 214,
    "avg_reward_per_step": 151.2046483033205,
    "episode_length": 132,
    "policy_loss": -2564.8838500976562,
    "value_loss": 0.6581362038850784,
    "entropy": 0.06387011893093586,
    "total_loss": -2564.2289073997176
  },
  {
    "episode": 215,
    "avg_reward_per_step": 149.9496013162809,
    "episode_length": 133,
    "policy_loss": -2538.810791015625,
    "value_loss": 0.6561221927404404,
    "entropy": 0.07362887263298035,
    "total_loss": -2538.158350266516
  },
  {
    "episode": 216,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4764.16796875,
    "value_loss": 0.9042224735021591,
    "entropy": 0.019535440485924482,
    "total_loss": -4763.264723048522
  },
  {
    "episode": 217,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4764.8309326171875,
    "value_loss": 0.9042057693004608,
    "entropy": 0.01940778410062194,
    "total_loss": -4763.927697237092
  },
  {
    "episode": 218,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4764.855712890625,
    "value_loss": 0.9041889309883118,
    "entropy": 0.016974082682281733,
    "total_loss": -4763.952372663771
  },
  {
    "episode": 219,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4764.3670654296875,
    "value_loss": 0.9041722267866135,
    "entropy": 0.015140902251005173,
    "total_loss": -4763.463650248013
  },
  {
    "episode": 220,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4763.995849609375,
    "value_loss": 0.9041543155908585,
    "entropy": 0.014483837876468897,
    "total_loss": -4763.092419485678
  },
  {
    "episode": 221,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4763.762451171875,
    "value_loss": 0.9041358530521393,
    "entropy": 0.014164601918309927,
    "total_loss": -4762.859023548919
  },
  {
    "episode": 222,
    "avg_reward_per_step": 274.5010753243328,
    "episode_length": 73,
    "policy_loss": -4590.9708251953125,
    "value_loss": 0.8776169121265411,
    "entropy": 0.03834847640246153,
    "total_loss": -4590.095125707006
  },
  {
    "episode": 223,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4762.5361328125,
    "value_loss": 0.9041008651256561,
    "entropy": 0.015350345289334655,
    "total_loss": -4761.632799464639
  },
  {
    "episode": 224,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4763.0848388671875,
    "value_loss": 0.904076099395752,
    "entropy": 0.01644378202036023,
    "total_loss": -4762.181584956893
  },
  {
    "episode": 225,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4763.4876708984375,
    "value_loss": 0.9040524214506149,
    "entropy": 0.014967990340664983,
    "total_loss": -4762.584366876504
  },
  {
    "episode": 226,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4762.9744873046875,
    "value_loss": 0.9040294140577316,
    "entropy": 0.013757518492639065,
    "total_loss": -4762.071145766555
  },
  {
    "episode": 227,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4762.552490234375,
    "value_loss": 0.9040069431066513,
    "entropy": 0.013564315158873796,
    "total_loss": -4761.649161507026
  },
  {
    "episode": 228,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4762.2945556640625,
    "value_loss": 0.9039836674928665,
    "entropy": 0.013381890254095197,
    "total_loss": -4761.3912410910825
  },
  {
    "episode": 229,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4762.0731201171875,
    "value_loss": 0.9039600044488907,
    "entropy": 0.012744958745315671,
    "total_loss": -4761.169797360676
  },
  {
    "episode": 230,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4761.8160400390625,
    "value_loss": 0.9039354026317596,
    "entropy": 0.01183464308269322,
    "total_loss": -4760.912696368585
  },
  {
    "episode": 231,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4761.5289306640625,
    "value_loss": 0.9039103835821152,
    "entropy": 0.010978126898407936,
    "total_loss": -4760.6255691868255
  },
  {
    "episode": 232,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4761.2369384765625,
    "value_loss": 0.9038848429918289,
    "entropy": 0.010333178099244833,
    "total_loss": -4760.333570292476
  },
  {
    "episode": 233,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4760.9488525390625,
    "value_loss": 0.9038591980934143,
    "entropy": 0.009875553660094738,
    "total_loss": -4760.045487118652
  },
  {
    "episode": 234,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4760.6646728515625,
    "value_loss": 0.9038330763578415,
    "entropy": 0.00953182834200561,
    "total_loss": -4759.761316366622
  },
  {
    "episode": 235,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4760.378173828125,
    "value_loss": 0.9038066267967224,
    "entropy": 0.009242051746696234,
    "total_loss": -4759.474829303916
  },
  {
    "episode": 236,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4760.0899658203125,
    "value_loss": 0.9037798494100571,
    "entropy": 0.008976516779512167,
    "total_loss": -4759.186634796742
  },
  {
    "episode": 237,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4759.79638671875,
    "value_loss": 0.9037524312734604,
    "entropy": 0.008726856438443065,
    "total_loss": -4758.893070630298
  },
  {
    "episode": 238,
    "avg_reward_per_step": 151.30468563922983,
    "episode_length": 132,
    "policy_loss": -2558.6639404296875,
    "value_loss": 0.6579733192920685,
    "entropy": 0.05031828489154577,
    "total_loss": -2558.00848302464
  },
  {
    "episode": 239,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4758.6292724609375,
    "value_loss": 0.903705820441246,
    "entropy": 0.0131812640465796,
    "total_loss": -4757.726225703698
  },
  {
    "episode": 240,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4758.8953857421875,
    "value_loss": 0.9036784768104553,
    "entropy": 0.014843107666820288,
    "total_loss": -4757.992449420761
  },
  {
    "episode": 241,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4759.0770263671875,
    "value_loss": 0.903651237487793,
    "entropy": 0.012770099565386772,
    "total_loss": -4758.174013634678
  },
  {
    "episode": 242,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4758.6927490234375,
    "value_loss": 0.9036237001419067,
    "entropy": 0.010100095067173243,
    "total_loss": -4757.789630328049
  },
  {
    "episode": 243,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4758.21728515625,
    "value_loss": 0.903595507144928,
    "entropy": 0.008752071997150779,
    "total_loss": -4757.314127252705
  },
  {
    "episode": 244,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4757.8082275390625,
    "value_loss": 0.9035669714212418,
    "entropy": 0.008451233385130763,
    "total_loss": -4756.905083129311
  },
  {
    "episode": 245,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4757.4620361328125,
    "value_loss": 0.9035378247499466,
    "entropy": 0.008463495410978794,
    "total_loss": -4756.558921482833
  },
  {
    "episode": 246,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4757.1448974609375,
    "value_loss": 0.9035081714391708,
    "entropy": 0.00834755296818912,
    "total_loss": -4756.241806667147
  },
  {
    "episode": 247,
    "avg_reward_per_step": 282.0749516246424,
    "episode_length": 71,
    "policy_loss": -4690.512451171875,
    "value_loss": 0.8934221863746643,
    "entropy": 0.013970547122880816,
    "total_loss": -4689.619727512856
  },
  {
    "episode": 248,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4756.4573974609375,
    "value_loss": 0.9034505486488342,
    "entropy": 0.007372856372967362,
    "total_loss": -4755.554315555108
  },
  {
    "episode": 249,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4756.100830078125,
    "value_loss": 0.9034220427274704,
    "entropy": 0.007274191128090024,
    "total_loss": -4755.197771744954
  },
  {
    "episode": 250,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4755.747802734375,
    "value_loss": 0.9033922702074051,
    "entropy": 0.007199843763373792,
    "total_loss": -4754.844770456356
  },
  {
    "episode": 251,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4755.3941650390625,
    "value_loss": 0.9033617973327637,
    "entropy": 0.007087213220074773,
    "total_loss": -4754.491157602391
  },
  {
    "episode": 252,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4755.0362548828125,
    "value_loss": 0.9033304303884506,
    "entropy": 0.006931393640115857,
    "total_loss": -4754.133271022106
  },
  {
    "episode": 253,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4754.671630859375,
    "value_loss": 0.9032984972000122,
    "entropy": 0.006754052941687405,
    "total_loss": -4753.768670064822
  },
  {
    "episode": 254,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4754.2999267578125,
    "value_loss": 0.9032657444477081,
    "entropy": 0.006578430067747831,
    "total_loss": -4753.3969899348685
  },
  {
    "episode": 255,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4753.9237060546875,
    "value_loss": 0.9032327383756638,
    "entropy": 0.006412427988834679,
    "total_loss": -4753.0207939377115
  },
  {
    "episode": 256,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4753.5438232421875,
    "value_loss": 0.9031991213560104,
    "entropy": 0.00625817000400275,
    "total_loss": -4752.640937029331
  },
  {
    "episode": 257,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4753.1595458984375,
    "value_loss": 0.9031648337841034,
    "entropy": 0.0061158675234764814,
    "total_loss": -4752.25668685803
  },
  {
    "episode": 258,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4752.770751953125,
    "value_loss": 0.9031301587820053,
    "entropy": 0.005983165348879993,
    "total_loss": -4751.867920952611
  },
  {
    "episode": 259,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4752.376708984375,
    "value_loss": 0.9030951112508774,
    "entropy": 0.005858034361153841,
    "total_loss": -4751.473906774842
  },
  {
    "episode": 260,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4751.97998046875,
    "value_loss": 0.903059795498848,
    "entropy": 0.00573969422839582,
    "total_loss": -4751.077207657962
  },
  {
    "episode": 261,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4751.5765380859375,
    "value_loss": 0.9030237346887589,
    "entropy": 0.005628435057587922,
    "total_loss": -4750.673795773002
  },
  {
    "episode": 262,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4751.17138671875,
    "value_loss": 0.902987614274025,
    "entropy": 0.005523128900676966,
    "total_loss": -4750.268675260921
  },
  {
    "episode": 263,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4750.7596435546875,
    "value_loss": 0.9029506593942642,
    "entropy": 0.005422974471002817,
    "total_loss": -4749.856964044016
  },
  {
    "episode": 264,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4750.34375,
    "value_loss": 0.9029132425785065,
    "entropy": 0.005327516468241811,
    "total_loss": -4749.441103133245
  },
  {
    "episode": 265,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4749.923095703125,
    "value_loss": 0.902875691652298,
    "entropy": 0.005236234748736024,
    "total_loss": -4749.0204818232105
  },
  {
    "episode": 266,
    "avg_reward_per_step": 282.0578423443544,
    "episode_length": 71,
    "policy_loss": -4691.97119140625,
    "value_loss": 0.8929316401481628,
    "entropy": 0.009432879509404302,
    "total_loss": -4691.078731410077
  },
  {
    "episode": 267,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4749.24951171875,
    "value_loss": 0.9028574973344803,
    "entropy": 0.006042730296030641,
    "total_loss": -4748.34695635793
  },
  {
    "episode": 268,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4749.0426025390625,
    "value_loss": 0.90282242000103,
    "entropy": 0.006928676390089095,
    "total_loss": -4748.140126552881
  },
  {
    "episode": 269,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4748.7861328125,
    "value_loss": 0.902784913778305,
    "entropy": 0.007608052575960755,
    "total_loss": -4747.883728301351
  },
  {
    "episode": 270,
    "avg_reward_per_step": 151.3203444829916,
    "episode_length": 132,
    "policy_loss": -2543.4474487304688,
    "value_loss": 0.6572306603193283,
    "entropy": 0.04567553102970123,
    "total_loss": -2542.792501846701
  },
  {
    "episode": 271,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4748.1749267578125,
    "value_loss": 0.902715653181076,
    "entropy": 0.0076150905806571245,
    "total_loss": -4747.2725918591605
  },
  {
    "episode": 272,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4747.8046875,
    "value_loss": 0.9026731103658676,
    "entropy": 0.007599216420203447,
    "total_loss": -4746.902394350455
  },
  {
    "episode": 273,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4747.40625,
    "value_loss": 0.9026290029287338,
    "entropy": 0.007638036157004535,
    "total_loss": -4746.504002898879
  },
  {
    "episode": 274,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4746.981689453125,
    "value_loss": 0.9025844037532806,
    "entropy": 0.007598383468575776,
    "total_loss": -4746.079484968545
  },
  {
    "episode": 275,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4746.5333251953125,
    "value_loss": 0.9025390446186066,
    "entropy": 0.007454940467141569,
    "total_loss": -4745.631158897717
  },
  {
    "episode": 276,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4746.0655517578125,
    "value_loss": 0.9024933576583862,
    "entropy": 0.007236894802190363,
    "total_loss": -4745.163420244894
  },
  {
    "episode": 277,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4745.5791015625,
    "value_loss": 0.902446985244751,
    "entropy": 0.006989015848375857,
    "total_loss": -4744.677004028048
  },
  {
    "episode": 278,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4745.084716796875,
    "value_loss": 0.9024008810520172,
    "entropy": 0.0067437521647661924,
    "total_loss": -4744.182653103431
  },
  {
    "episode": 279,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4744.5828857421875,
    "value_loss": 0.9023543447256088,
    "entropy": 0.006516698515042663,
    "total_loss": -4743.680857232388
  },
  {
    "episode": 280,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4744.073486328125,
    "value_loss": 0.902307540178299,
    "entropy": 0.006311556440778077,
    "total_loss": -4743.171494365769
  },
  {
    "episode": 281,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4743.5594482421875,
    "value_loss": 0.9022605866193771,
    "entropy": 0.0061293598264455795,
    "total_loss": -4742.657494123559
  },
  {
    "episode": 282,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4743.042724609375,
    "value_loss": 0.9022136479616165,
    "entropy": 0.005964969634078443,
    "total_loss": -4742.140809209895
  },
  {
    "episode": 283,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4742.5233154296875,
    "value_loss": 0.9021665751934052,
    "entropy": 0.005814462201669812,
    "total_loss": -4741.621439577604
  },
  {
    "episode": 284,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4741.9996337890625,
    "value_loss": 0.902119442820549,
    "entropy": 0.0056748667266219854,
    "total_loss": -4741.097798089579
  },
  {
    "episode": 285,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4741.47314453125,
    "value_loss": 0.9020717889070511,
    "entropy": 0.0055442797020077705,
    "total_loss": -4740.571349956328
  },
  {
    "episode": 286,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4740.9443359375,
    "value_loss": 0.9020243138074875,
    "entropy": 0.005421775742433965,
    "total_loss": -4740.04258271248
  },
  {
    "episode": 287,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4740.410400390625,
    "value_loss": 0.9019761979579926,
    "entropy": 0.005306195002049208,
    "total_loss": -4739.508689502417
  },
  {
    "episode": 288,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4739.873291015625,
    "value_loss": 0.9019279778003693,
    "entropy": 0.0051969983614981174,
    "total_loss": -4738.971622887742
  },
  {
    "episode": 289,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4739.332275390625,
    "value_loss": 0.9018793851137161,
    "entropy": 0.00509345275349915,
    "total_loss": -4738.430650678149
  },
  {
    "episode": 290,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4738.7852783203125,
    "value_loss": 0.9018304497003555,
    "entropy": 0.004995050956495106,
    "total_loss": -4737.88369762316
  },
  {
    "episode": 291,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4738.2376708984375,
    "value_loss": 0.9017815738916397,
    "entropy": 0.00490166072268039,
    "total_loss": -4737.336134407582
  },
  {
    "episode": 292,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4737.6834716796875,
    "value_loss": 0.9017321169376373,
    "entropy": 0.004813737003132701,
    "total_loss": -4736.7819802496
  },
  {
    "episode": 293,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4737.126953125,
    "value_loss": 0.9016824662685394,
    "entropy": 0.004730247426778078,
    "total_loss": -4736.225507171102
  },
  {
    "episode": 294,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4736.5653076171875,
    "value_loss": 0.901632621884346,
    "entropy": 0.004650208866223693,
    "total_loss": -4735.6639075057465
  },
  {
    "episode": 295,
    "avg_reward_per_step": 282.0749516246424,
    "episode_length": 71,
    "policy_loss": -4670.187744140625,
    "value_loss": 0.8915339857339859,
    "entropy": 0.009109736885875463,
    "total_loss": -4669.296665641736
  },
  {
    "episode": 296,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4735.41064453125,
    "value_loss": 0.9015419036149979,
    "entropy": 0.004558282089419663,
    "total_loss": -4734.5093305417395
  },
  {
    "episode": 297,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4734.8631591796875,
    "value_loss": 0.9014927595853806,
    "entropy": 0.00453505024779588,
    "total_loss": -4733.9618931726145
  },
  {
    "episode": 298,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4734.304443359375,
    "value_loss": 0.9014425575733185,
    "entropy": 0.004528777091763914,
    "total_loss": -4733.403227240657
  },
  {
    "episode": 299,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4733.7357177734375,
    "value_loss": 0.9013915210962296,
    "entropy": 0.004503388772718608,
    "total_loss": -4732.83455142178
  },
  {
    "episode": 300,
    "avg_reward_per_step": 286.3575677161034,
    "episode_length": 70,
    "policy_loss": -4733.1563720703125,
    "value_loss": 0.9013398438692093,
    "entropy": 0.004453832283616066,
    "total_loss": -4732.255254918057
  }
]