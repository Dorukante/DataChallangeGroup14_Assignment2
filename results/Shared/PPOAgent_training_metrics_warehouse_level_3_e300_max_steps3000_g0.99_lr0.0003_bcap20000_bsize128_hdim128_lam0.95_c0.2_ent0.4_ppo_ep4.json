[
  {
    "episode": 1,
    "avg_reward_per_step": -1.9892874299894256,
    "episode_length": 3000,
    "policy_loss": 33.14401721954346,
    "value_loss": 1.5671105086803436,
    "entropy": 1.3814477920532227,
    "total_loss": 34.15854861140251
  },
  {
    "episode": 2,
    "avg_reward_per_step": 48.433085783430236,
    "episode_length": 406,
    "policy_loss": -831.1522827148438,
    "value_loss": 0.5409262478351593,
    "entropy": 1.3835003077983856,
    "total_loss": -831.1647565901279
  },
  {
    "episode": 3,
    "avg_reward_per_step": 6.226364278875176,
    "episode_length": 2567,
    "policy_loss": -106.3995246887207,
    "value_loss": 0.5038997083902359,
    "entropy": 1.3753397464752197,
    "total_loss": -106.44576087892055
  },
  {
    "episode": 4,
    "avg_reward_per_step": 5.664658866343363,
    "episode_length": 2846,
    "policy_loss": -94.56588554382324,
    "value_loss": 0.503578782081604,
    "entropy": 1.3636817932128906,
    "total_loss": -94.60777947902679
  },
  {
    "episode": 5,
    "avg_reward_per_step": -1.4284738663074146,
    "episode_length": 3000,
    "policy_loss": 23.81421184539795,
    "value_loss": 1.0996353924274445,
    "entropy": 1.3478034734725952,
    "total_loss": 24.374725848436356
  },
  {
    "episode": 6,
    "avg_reward_per_step": 19.70374509877194,
    "episode_length": 964,
    "policy_loss": -336.20741271972656,
    "value_loss": 0.5152113139629364,
    "entropy": 1.3400782942771912,
    "total_loss": -336.2282327234745
  },
  {
    "episode": 7,
    "avg_reward_per_step": -1.6376295194629211,
    "episode_length": 3000,
    "policy_loss": 27.328101634979248,
    "value_loss": 1.1085499823093414,
    "entropy": 1.3271110653877258,
    "total_loss": 27.905807191133498
  },
  {
    "episode": 8,
    "avg_reward_per_step": 6.776412158632133,
    "episode_length": 2460,
    "policy_loss": -114.99157905578613,
    "value_loss": 0.5044352561235428,
    "entropy": 1.2971383035182953,
    "total_loss": -115.0059991210699
  },
  {
    "episode": 9,
    "avg_reward_per_step": 39.5735837571347,
    "episode_length": 492,
    "policy_loss": -674.0406799316406,
    "value_loss": 0.5325313210487366,
    "entropy": 1.2800927758216858,
    "total_loss": -674.0201857209206
  },
  {
    "episode": 10,
    "avg_reward_per_step": 14.82107632633829,
    "episode_length": 1241,
    "policy_loss": -246.9467887878418,
    "value_loss": 0.5109235197305679,
    "entropy": 1.3017515242099762,
    "total_loss": -246.9565658777952
  },
  {
    "episode": 11,
    "avg_reward_per_step": 5.715477021327575,
    "episode_length": 2799,
    "policy_loss": -96.07021903991699,
    "value_loss": 0.5035849958658218,
    "entropy": 1.2929387390613556,
    "total_loss": -96.08380953967571
  },
  {
    "episode": 12,
    "avg_reward_per_step": 14.114204562465458,
    "episode_length": 1262,
    "policy_loss": -238.08698654174805,
    "value_loss": 0.5100300312042236,
    "entropy": 1.2885860204696655,
    "total_loss": -238.0923909187317
  },
  {
    "episode": 13,
    "avg_reward_per_step": 8.368211708846331,
    "episode_length": 1976,
    "policy_loss": -141.23392868041992,
    "value_loss": 0.5054541230201721,
    "entropy": 1.296793907880783,
    "total_loss": -141.24719212055206
  },
  {
    "episode": 14,
    "avg_reward_per_step": 15.035536204283233,
    "episode_length": 1215,
    "policy_loss": -253.94406509399414,
    "value_loss": 0.5110479891300201,
    "entropy": 1.271248698234558,
    "total_loss": -253.94151658415794
  },
  {
    "episode": 15,
    "avg_reward_per_step": 10.888364517126012,
    "episode_length": 1608,
    "policy_loss": -183.57271194458008,
    "value_loss": 0.5075847804546356,
    "entropy": 1.2712509632110596,
    "total_loss": -183.57362754940988
  },
  {
    "episode": 16,
    "avg_reward_per_step": 59.95942424930346,
    "episode_length": 327,
    "policy_loss": -1021.8767700195312,
    "value_loss": 0.5511849671602249,
    "entropy": 1.2660480439662933,
    "total_loss": -1021.8320042699576
  },
  {
    "episode": 17,
    "avg_reward_per_step": 13.11513703954901,
    "episode_length": 1332,
    "policy_loss": -221.29991912841797,
    "value_loss": 0.5091225653886795,
    "entropy": 1.1646726727485657,
    "total_loss": -221.25666563212872
  },
  {
    "episode": 18,
    "avg_reward_per_step": -1.755518105369184,
    "episode_length": 3000,
    "policy_loss": 29.340659141540527,
    "value_loss": 0.7679160535335541,
    "entropy": 1.0699559152126312,
    "total_loss": 29.680592828989028
  },
  {
    "episode": 19,
    "avg_reward_per_step": 36.94749103364199,
    "episode_length": 531,
    "policy_loss": -622.2704467773438,
    "value_loss": 0.5301691442728043,
    "entropy": 1.0197716355323792,
    "total_loss": -622.1481862872839
  },
  {
    "episode": 20,
    "avg_reward_per_step": 25.97163876875516,
    "episode_length": 737,
    "policy_loss": -441.7378692626953,
    "value_loss": 0.5203215032815933,
    "entropy": 1.0718902051448822,
    "total_loss": -441.64630384147165
  },
  {
    "episode": 21,
    "avg_reward_per_step": -1.6658620774275632,
    "episode_length": 3000,
    "policy_loss": 27.733699798583984,
    "value_loss": 0.6894276440143585,
    "entropy": 1.1311820149421692,
    "total_loss": 27.970654636621475
  },
  {
    "episode": 22,
    "avg_reward_per_step": -1.6428483022790479,
    "episode_length": 3000,
    "policy_loss": 27.588898181915283,
    "value_loss": 0.7060983628034592,
    "entropy": 1.1625052392482758,
    "total_loss": 27.82999444901943
  },
  {
    "episode": 23,
    "avg_reward_per_step": 6.52504389860274,
    "episode_length": 2483,
    "policy_loss": -110.5567512512207,
    "value_loss": 0.5041554123163223,
    "entropy": 1.1667978167533875,
    "total_loss": -110.51931496560573
  },
  {
    "episode": 24,
    "avg_reward_per_step": 84.71768254102797,
    "episode_length": 235,
    "policy_loss": -1445.186767578125,
    "value_loss": 0.5772468745708466,
    "entropy": 1.194296419620514,
    "total_loss": -1445.0872392714023
  },
  {
    "episode": 25,
    "avg_reward_per_step": 37.501321993604186,
    "episode_length": 519,
    "policy_loss": -636.7976226806641,
    "value_loss": 0.5306549221277237,
    "entropy": 1.240819662809372,
    "total_loss": -636.76329562366
  },
  {
    "episode": 26,
    "avg_reward_per_step": -1.6440016197627327,
    "episode_length": 3000,
    "policy_loss": 27.119967937469482,
    "value_loss": 0.8574252724647522,
    "entropy": 1.2747054994106293,
    "total_loss": 27.467511010169982
  },
  {
    "episode": 27,
    "avg_reward_per_step": 12.250094002502506,
    "episode_length": 1498,
    "policy_loss": -207.42726516723633,
    "value_loss": 0.5090144276618958,
    "entropy": 1.2836267352104187,
    "total_loss": -207.4317014336586
  },
  {
    "episode": 28,
    "avg_reward_per_step": -1.2717879603691746,
    "episode_length": 3000,
    "policy_loss": 20.7844557762146,
    "value_loss": 0.8339613974094391,
    "entropy": 1.2750139236450195,
    "total_loss": 21.10841160416603
  },
  {
    "episode": 29,
    "avg_reward_per_step": 17.322969428816492,
    "episode_length": 1084,
    "policy_loss": -292.8491439819336,
    "value_loss": 0.5131940096616745,
    "entropy": 1.2926050126552582,
    "total_loss": -292.852991977334
  },
  {
    "episode": 30,
    "avg_reward_per_step": -1.2254623892875427,
    "episode_length": 3000,
    "policy_loss": 19.93067741394043,
    "value_loss": 0.9351281374692917,
    "entropy": 1.2388253211975098,
    "total_loss": 20.370275422930717
  },
  {
    "episode": 31,
    "avg_reward_per_step": -1.1158131208000819,
    "episode_length": 3000,
    "policy_loss": 18.05455493927002,
    "value_loss": 0.9953957498073578,
    "entropy": 1.2297234237194061,
    "total_loss": 18.558061319589616
  },
  {
    "episode": 32,
    "avg_reward_per_step": -1.0794554317773823,
    "episode_length": 3000,
    "policy_loss": 17.4180006980896,
    "value_loss": 1.058864176273346,
    "entropy": 1.2291873693466187,
    "total_loss": 17.985189926624297
  },
  {
    "episode": 33,
    "avg_reward_per_step": -1.137931280269946,
    "episode_length": 3000,
    "policy_loss": 18.35444736480713,
    "value_loss": 0.9422075599431992,
    "entropy": 1.2332823276519775,
    "total_loss": 18.803341993689536
  },
  {
    "episode": 34,
    "avg_reward_per_step": 7.839561518254394,
    "episode_length": 2266,
    "policy_loss": -133.070556640625,
    "value_loss": 0.5056224167346954,
    "entropy": 1.2358815371990204,
    "total_loss": -133.0592868387699
  },
  {
    "episode": 35,
    "avg_reward_per_step": -1.0944240554510936,
    "episode_length": 3000,
    "policy_loss": 17.291646003723145,
    "value_loss": 1.1389762163162231,
    "entropy": 1.2381280064582825,
    "total_loss": 17.935371017456056
  },
  {
    "episode": 36,
    "avg_reward_per_step": 8.40780601772623,
    "episode_length": 2105,
    "policy_loss": -143.47775650024414,
    "value_loss": 0.5060107260942459,
    "entropy": 1.2862783372402191,
    "total_loss": -143.486257109046
  },
  {
    "episode": 37,
    "avg_reward_per_step": 6.370364556967107,
    "episode_length": 2679,
    "policy_loss": -109.45623779296875,
    "value_loss": 0.5043744742870331,
    "entropy": 1.3143694698810577,
    "total_loss": -109.47761110663414
  },
  {
    "episode": 38,
    "avg_reward_per_step": 31.779865328147853,
    "episode_length": 614,
    "policy_loss": -544.6397552490234,
    "value_loss": 0.5259474813938141,
    "entropy": 1.2969613075256348,
    "total_loss": -544.6325922906399
  },
  {
    "episode": 39,
    "avg_reward_per_step": 5.90843811901164,
    "episode_length": 2794,
    "policy_loss": -100.52740859985352,
    "value_loss": 0.5039403587579727,
    "entropy": 1.3142680823802948,
    "total_loss": -100.54917547404766
  },
  {
    "episode": 40,
    "avg_reward_per_step": 9.909572019030925,
    "episode_length": 1768,
    "policy_loss": -168.06625366210938,
    "value_loss": 0.5069935321807861,
    "entropy": 1.3294084966182709,
    "total_loss": -168.0910235285759
  },
  {
    "episode": 41,
    "avg_reward_per_step": 12.136545327261736,
    "episode_length": 1461,
    "policy_loss": -206.6498031616211,
    "value_loss": 0.5087255239486694,
    "entropy": 1.3291609585285187,
    "total_loss": -206.67274202108382
  },
  {
    "episode": 42,
    "avg_reward_per_step": 5.0705991397324,
    "episode_length": 2963,
    "policy_loss": -87.49509048461914,
    "value_loss": 0.5030562579631805,
    "entropy": 1.3330412805080414,
    "total_loss": -87.52525073885917
  },
  {
    "episode": 43,
    "avg_reward_per_step": 7.99102045891322,
    "episode_length": 2137,
    "policy_loss": -136.04222869873047,
    "value_loss": 0.5055015087127686,
    "entropy": 1.3269271850585938,
    "total_loss": -136.06749806404113
  },
  {
    "episode": 44,
    "avg_reward_per_step": 37.22187968035649,
    "episode_length": 520,
    "policy_loss": -629.3039093017578,
    "value_loss": 0.5303308218717575,
    "entropy": 1.3102460205554962,
    "total_loss": -629.2976768881083
  },
  {
    "episode": 45,
    "avg_reward_per_step": 114.24268634347663,
    "episode_length": 175,
    "policy_loss": -1950.885009765625,
    "value_loss": 0.6102553457021713,
    "entropy": 1.2768271565437317,
    "total_loss": -1950.7854852825403
  },
  {
    "episode": 46,
    "avg_reward_per_step": 10.211602774846066,
    "episode_length": 1628,
    "policy_loss": -177.40765380859375,
    "value_loss": 0.5068112909793854,
    "entropy": 1.2516783475875854,
    "total_loss": -177.4015138566494
  },
  {
    "episode": 47,
    "avg_reward_per_step": -1.8286754299252412,
    "episode_length": 3000,
    "policy_loss": 29.536333560943604,
    "value_loss": 0.7554121166467667,
    "entropy": 1.20185124874115,
    "total_loss": 29.81100517809391
  },
  {
    "episode": 48,
    "avg_reward_per_step": 16.37142103829776,
    "episode_length": 1125,
    "policy_loss": -276.93402099609375,
    "value_loss": 0.5121936202049255,
    "entropy": 1.1630595028400421,
    "total_loss": -276.88705117702483
  },
  {
    "episode": 49,
    "avg_reward_per_step": 5.5459997394943965,
    "episode_length": 2872,
    "policy_loss": -95.09969711303711,
    "value_loss": 0.5035670399665833,
    "entropy": 1.1424015760421753,
    "total_loss": -95.0530907034874
  },
  {
    "episode": 50,
    "avg_reward_per_step": -1.542701572692989,
    "episode_length": 3000,
    "policy_loss": 24.4786057472229,
    "value_loss": 0.7339058220386505,
    "entropy": 1.126823365688324,
    "total_loss": 24.76178222298622
  },
  {
    "episode": 51,
    "avg_reward_per_step": 5.326978640965427,
    "episode_length": 2999,
    "policy_loss": -91.15816688537598,
    "value_loss": 0.5034185945987701,
    "entropy": 1.1065595149993896,
    "total_loss": -91.09737209677697
  },
  {
    "episode": 52,
    "avg_reward_per_step": -1.634776509387334,
    "episode_length": 3000,
    "policy_loss": 25.85311794281006,
    "value_loss": 0.736657902598381,
    "entropy": 1.0999828279018402,
    "total_loss": 26.149782714247703
  },
  {
    "episode": 53,
    "avg_reward_per_step": 17.240654234177388,
    "episode_length": 1069,
    "policy_loss": -291.24132537841797,
    "value_loss": 0.512888953089714,
    "entropy": 1.1046994626522064,
    "total_loss": -291.17031621038916
  },
  {
    "episode": 54,
    "avg_reward_per_step": 17.968059022965853,
    "episode_length": 1042,
    "policy_loss": -304.55704498291016,
    "value_loss": 0.5136971026659012,
    "entropy": 1.0814352631568909,
    "total_loss": -304.475921985507
  },
  {
    "episode": 55,
    "avg_reward_per_step": 13.34893263326698,
    "episode_length": 1347,
    "policy_loss": -227.07497787475586,
    "value_loss": 0.5097555220127106,
    "entropy": 1.0734643936157227,
    "total_loss": -226.99460811018943
  },
  {
    "episode": 56,
    "avg_reward_per_step": 86.79753019621616,
    "episode_length": 230,
    "policy_loss": -1484.8873291015625,
    "value_loss": 0.5798645168542862,
    "entropy": 1.0277419686317444,
    "total_loss": -1484.7185613721608
  },
  {
    "episode": 57,
    "avg_reward_per_step": 24.088859591072442,
    "episode_length": 798,
    "policy_loss": -417.4452667236328,
    "value_loss": 0.5190632790327072,
    "entropy": 0.9907886832952499,
    "total_loss": -417.3225189179182
  },
  {
    "episode": 58,
    "avg_reward_per_step": 5.68379066196943,
    "episode_length": 2853,
    "policy_loss": -96.8746566772461,
    "value_loss": 0.503729373216629,
    "entropy": 0.8559713214635849,
    "total_loss": -96.7133158326149
  },
  {
    "episode": 59,
    "avg_reward_per_step": 21.994488324058878,
    "episode_length": 889,
    "policy_loss": -370.57794189453125,
    "value_loss": 0.5176564157009125,
    "entropy": 0.7408377528190613,
    "total_loss": -370.35662057995796
  },
  {
    "episode": 60,
    "avg_reward_per_step": 11.142529023109212,
    "episode_length": 1679,
    "policy_loss": -189.4477653503418,
    "value_loss": 0.5084396004676819,
    "entropy": 0.762024775147438,
    "total_loss": -189.24413565993308
  },
  {
    "episode": 61,
    "avg_reward_per_step": 7.699239083484243,
    "episode_length": 2349,
    "policy_loss": -130.8702163696289,
    "value_loss": 0.5056252330541611,
    "entropy": 0.7196293622255325,
    "total_loss": -130.65244288146496
  },
  {
    "episode": 62,
    "avg_reward_per_step": -1.2168148179577598,
    "episode_length": 3000,
    "policy_loss": 18.641316413879395,
    "value_loss": 0.5697270929813385,
    "entropy": 0.7576296776533127,
    "total_loss": 18.90799163579941
  },
  {
    "episode": 63,
    "avg_reward_per_step": 23.673244333100474,
    "episode_length": 827,
    "policy_loss": -400.31211853027344,
    "value_loss": 0.5190111100673676,
    "entropy": 0.7480960488319397,
    "total_loss": -400.09234583973887
  },
  {
    "episode": 64,
    "avg_reward_per_step": -1.1850765218688182,
    "episode_length": 3000,
    "policy_loss": 18.273322105407715,
    "value_loss": 0.5892482399940491,
    "entropy": 0.7745367735624313,
    "total_loss": 18.55275563597679
  },
  {
    "episode": 65,
    "avg_reward_per_step": 9.701425283529515,
    "episode_length": 1884,
    "policy_loss": -165.33588409423828,
    "value_loss": 0.5071840286254883,
    "entropy": 0.7963965386152267,
    "total_loss": -165.14725868105887
  },
  {
    "episode": 66,
    "avg_reward_per_step": 5.376489725193497,
    "episode_length": 2995,
    "policy_loss": -92.84923362731934,
    "value_loss": 0.5035199820995331,
    "entropy": 0.8449909389019012,
    "total_loss": -92.68371002078057
  },
  {
    "episode": 67,
    "avg_reward_per_step": -1.3506399428127174,
    "episode_length": 3000,
    "policy_loss": 20.916480541229248,
    "value_loss": 0.6026350855827332,
    "entropy": 0.8781242817640305,
    "total_loss": 21.16786591410637
  },
  {
    "episode": 68,
    "avg_reward_per_step": 7.391973881799882,
    "episode_length": 2305,
    "policy_loss": -126.61685562133789,
    "value_loss": 0.505110114812851,
    "entropy": 0.8991589099168777,
    "total_loss": -126.47140907049179
  },
  {
    "episode": 69,
    "avg_reward_per_step": 19.536904622179787,
    "episode_length": 967,
    "policy_loss": -332.00919342041016,
    "value_loss": 0.5150974094867706,
    "entropy": 0.9290793985128403,
    "total_loss": -331.86572777032853
  },
  {
    "episode": 70,
    "avg_reward_per_step": -1.612168367455949,
    "episode_length": 3000,
    "policy_loss": 25.351406574249268,
    "value_loss": 0.6570953875780106,
    "entropy": 0.9908117949962616,
    "total_loss": 25.612177243828775
  },
  {
    "episode": 71,
    "avg_reward_per_step": 86.93182711435142,
    "episode_length": 229,
    "policy_loss": -1487.4742736816406,
    "value_loss": 0.5795644968748093,
    "entropy": 1.04295814037323,
    "total_loss": -1487.311892440915
  },
  {
    "episode": 72,
    "avg_reward_per_step": 11.899029532152186,
    "episode_length": 1512,
    "policy_loss": -201.76346588134766,
    "value_loss": 0.5086816698312759,
    "entropy": 1.0576573610305786,
    "total_loss": -201.67784715592862
  },
  {
    "episode": 73,
    "avg_reward_per_step": 14.114899124408986,
    "episode_length": 1277,
    "policy_loss": -238.85813903808594,
    "value_loss": 0.5103399604558945,
    "entropy": 1.0655106604099274,
    "total_loss": -238.774003341794
  },
  {
    "episode": 74,
    "avg_reward_per_step": 18.27056260291443,
    "episode_length": 1031,
    "policy_loss": -310.16619873046875,
    "value_loss": 0.514070525765419,
    "entropy": 1.0694331526756287,
    "total_loss": -310.07990146577356
  },
  {
    "episode": 75,
    "avg_reward_per_step": 26.02779825767432,
    "episode_length": 725,
    "policy_loss": -450.79125213623047,
    "value_loss": 0.520354226231575,
    "entropy": 1.099126547574997,
    "total_loss": -450.71054852902887
  },
  {
    "episode": 76,
    "avg_reward_per_step": 19.33532536780399,
    "episode_length": 970,
    "policy_loss": -326.4895935058594,
    "value_loss": 0.5148543119430542,
    "entropy": 1.16342294216156,
    "total_loss": -326.44010837078093
  },
  {
    "episode": 77,
    "avg_reward_per_step": 37.63899242159272,
    "episode_length": 520,
    "policy_loss": -638.5990447998047,
    "value_loss": 0.5310625433921814,
    "entropy": 1.1609908938407898,
    "total_loss": -638.5323786139488
  },
  {
    "episode": 78,
    "avg_reward_per_step": 47.431135919336846,
    "episode_length": 413,
    "policy_loss": -799.4975738525391,
    "value_loss": 0.5399181544780731,
    "entropy": 1.1944864094257355,
    "total_loss": -799.4354502618313
  },
  {
    "episode": 79,
    "avg_reward_per_step": 41.12440594561509,
    "episode_length": 475,
    "policy_loss": -697.5560302734375,
    "value_loss": 0.5339332520961761,
    "entropy": 1.1740992069244385,
    "total_loss": -697.4917367041111
  },
  {
    "episode": 80,
    "avg_reward_per_step": 35.426561565059714,
    "episode_length": 544,
    "policy_loss": -604.6582489013672,
    "value_loss": 0.5287054628133774,
    "entropy": 1.1914561688899994,
    "total_loss": -604.6061259061098
  },
  {
    "episode": 81,
    "avg_reward_per_step": 24.02137676892913,
    "episode_length": 790,
    "policy_loss": -404.0122375488281,
    "value_loss": 0.5188048183917999,
    "entropy": 1.15624138712883,
    "total_loss": -403.9559292852879
  },
  {
    "episode": 82,
    "avg_reward_per_step": 102.68770307769927,
    "episode_length": 194,
    "policy_loss": -1739.9348754882812,
    "value_loss": 0.5970879942178726,
    "entropy": 1.115582525730133,
    "total_loss": -1739.7840205043553
  },
  {
    "episode": 83,
    "avg_reward_per_step": 23.273167333215664,
    "episode_length": 815,
    "policy_loss": -394.7552795410156,
    "value_loss": 0.5182466208934784,
    "entropy": 1.1531065106391907,
    "total_loss": -394.69827552437783
  },
  {
    "episode": 84,
    "avg_reward_per_step": 5.796518898268136,
    "episode_length": 2715,
    "policy_loss": -99.42730903625488,
    "value_loss": 0.5037192702293396,
    "entropy": 1.1644160747528076,
    "total_loss": -99.38935619592667
  },
  {
    "episode": 85,
    "avg_reward_per_step": 37.10086908877874,
    "episode_length": 516,
    "policy_loss": -627.0550842285156,
    "value_loss": 0.5298878699541092,
    "entropy": 1.192257821559906,
    "total_loss": -627.0020994871854
  },
  {
    "episode": 86,
    "avg_reward_per_step": 9.249239793986652,
    "episode_length": 1823,
    "policy_loss": -157.48615264892578,
    "value_loss": 0.5063161998987198,
    "entropy": 1.2039851546287537,
    "total_loss": -157.46143051087856
  },
  {
    "episode": 87,
    "avg_reward_per_step": 44.32797324291734,
    "episode_length": 436,
    "policy_loss": -748.0151519775391,
    "value_loss": 0.536420002579689,
    "entropy": 1.227951556444168,
    "total_loss": -747.969912597537
  },
  {
    "episode": 88,
    "avg_reward_per_step": 74.89945400447594,
    "episode_length": 263,
    "policy_loss": -1272.4996337890625,
    "value_loss": 0.566581130027771,
    "entropy": 1.1708787381649017,
    "total_loss": -1272.4014041543007
  },
  {
    "episode": 89,
    "avg_reward_per_step": 28.271740466241944,
    "episode_length": 668,
    "policy_loss": -486.1510009765625,
    "value_loss": 0.5223210901021957,
    "entropy": 1.186345487833023,
    "total_loss": -486.1032180815935
  },
  {
    "episode": 90,
    "avg_reward_per_step": 29.817134887141044,
    "episode_length": 632,
    "policy_loss": -504.63246154785156,
    "value_loss": 0.523456484079361,
    "entropy": 1.1625312268733978,
    "total_loss": -504.57401755452156
  },
  {
    "episode": 91,
    "avg_reward_per_step": 10.168320718888529,
    "episode_length": 1743,
    "policy_loss": -174.37397384643555,
    "value_loss": 0.5073849409818649,
    "entropy": 1.124145746231079,
    "total_loss": -174.31624720394612
  },
  {
    "episode": 92,
    "avg_reward_per_step": 22.22027482770782,
    "episode_length": 867,
    "policy_loss": -375.74877166748047,
    "value_loss": 0.5177808701992035,
    "entropy": 1.0621987283229828,
    "total_loss": -375.65587028861046
  },
  {
    "episode": 93,
    "avg_reward_per_step": 34.57520614333039,
    "episode_length": 553,
    "policy_loss": -584.1979064941406,
    "value_loss": 0.527907595038414,
    "entropy": 1.0649567544460297,
    "total_loss": -584.0959816008806
  },
  {
    "episode": 94,
    "avg_reward_per_step": 11.11069528847008,
    "episode_length": 1584,
    "policy_loss": -189.19009399414062,
    "value_loss": 0.5079668462276459,
    "entropy": 1.055623173713684,
    "total_loss": -189.10437641739844
  },
  {
    "episode": 95,
    "avg_reward_per_step": 24.238048840354267,
    "episode_length": 760,
    "policy_loss": -411.3926010131836,
    "value_loss": 0.5184408873319626,
    "entropy": 1.069202035665512,
    "total_loss": -411.3018409401178
  },
  {
    "episode": 96,
    "avg_reward_per_step": 28.48975518796956,
    "episode_length": 659,
    "policy_loss": -494.00536346435547,
    "value_loss": 0.5222757905721664,
    "entropy": 1.068833202123642,
    "total_loss": -493.91062095463275
  },
  {
    "episode": 97,
    "avg_reward_per_step": 11.493199235020775,
    "episode_length": 1488,
    "policy_loss": -197.41962432861328,
    "value_loss": 0.507972463965416,
    "entropy": 1.0517971217632294,
    "total_loss": -197.33237071335316
  },
  {
    "episode": 98,
    "avg_reward_per_step": 108.3156746458459,
    "episode_length": 183,
    "policy_loss": -1826.4903869628906,
    "value_loss": 0.6034491062164307,
    "entropy": 0.956260085105896,
    "total_loss": -1826.2694418907165
  },
  {
    "episode": 99,
    "avg_reward_per_step": 180.60115257881728,
    "episode_length": 111,
    "policy_loss": -3117.4884033203125,
    "value_loss": 0.70327028632164,
    "entropy": 0.8142846971750259,
    "total_loss": -3117.110846912861
  },
  {
    "episode": 100,
    "avg_reward_per_step": 6.4051636876283835,
    "episode_length": 2155,
    "policy_loss": -111.42543029785156,
    "value_loss": 0.5035362541675568,
    "entropy": 0.806957945227623,
    "total_loss": -111.24467722177505
  },
  {
    "episode": 101,
    "avg_reward_per_step": -3.3022209197457904,
    "episode_length": 3000,
    "policy_loss": 53.630677223205566,
    "value_loss": 1.8920352458953857,
    "entropy": 0.6724981516599655,
    "total_loss": 55.25371320843696
  },
  {
    "episode": 102,
    "avg_reward_per_step": 6.058654299393614,
    "episode_length": 2264,
    "policy_loss": -104.00453567504883,
    "value_loss": 0.5033634155988693,
    "entropy": 0.6557974964380264,
    "total_loss": -103.76349125802517
  },
  {
    "episode": 103,
    "avg_reward_per_step": -2.8970686026917827,
    "episode_length": 3000,
    "policy_loss": 46.74944019317627,
    "value_loss": 1.3122696280479431,
    "entropy": 0.6546815186738968,
    "total_loss": 47.79983721375466
  },
  {
    "episode": 104,
    "avg_reward_per_step": -2.892144369800124,
    "episode_length": 3000,
    "policy_loss": 46.42385387420654,
    "value_loss": 1.6356819868087769,
    "entropy": 0.6007706522941589,
    "total_loss": 47.819227600097655
  },
  {
    "episode": 105,
    "avg_reward_per_step": -2.6937537140323684,
    "episode_length": 3000,
    "policy_loss": 42.69556713104248,
    "value_loss": 1.2700371444225311,
    "entropy": 0.5936464965343475,
    "total_loss": 43.72814567685127
  },
  {
    "episode": 106,
    "avg_reward_per_step": -2.9872877815566006,
    "episode_length": 3000,
    "policy_loss": 47.78879451751709,
    "value_loss": 1.559868484735489,
    "entropy": 0.6465582102537155,
    "total_loss": 49.09003971815109
  },
  {
    "episode": 107,
    "avg_reward_per_step": 61.572653834037794,
    "episode_length": 319,
    "policy_loss": -1042.4137878417969,
    "value_loss": 0.5532226264476776,
    "entropy": 0.4840651601552963,
    "total_loss": -1042.0541912794113
  },
  {
    "episode": 108,
    "avg_reward_per_step": -2.551881015002258,
    "episode_length": 3000,
    "policy_loss": 39.57305145263672,
    "value_loss": 1.1853032112121582,
    "entropy": 0.5713620483875275,
    "total_loss": 40.52980984449387
  },
  {
    "episode": 109,
    "avg_reward_per_step": 52.77948358191859,
    "episode_length": 368,
    "policy_loss": -899.295654296875,
    "value_loss": 0.5446034669876099,
    "entropy": 0.5535860359668732,
    "total_loss": -898.9724852442741
  },
  {
    "episode": 110,
    "avg_reward_per_step": 7.976817263163758,
    "episode_length": 1795,
    "policy_loss": -138.69439697265625,
    "value_loss": 0.5047734975814819,
    "entropy": 0.7335084229707718,
    "total_loss": -138.48302684426307
  },
  {
    "episode": 111,
    "avg_reward_per_step": 9.226492048409995,
    "episode_length": 1614,
    "policy_loss": -160.54478454589844,
    "value_loss": 0.5056912750005722,
    "entropy": 0.7451479136943817,
    "total_loss": -160.33715243637562
  },
  {
    "episode": 112,
    "avg_reward_per_step": 31.513702223968565,
    "episode_length": 585,
    "policy_loss": -534.7487487792969,
    "value_loss": 0.5244443416595459,
    "entropy": 0.7351101040840149,
    "total_loss": -534.5183484792709
  },
  {
    "episode": 113,
    "avg_reward_per_step": 3.027112135031392,
    "episode_length": 2989,
    "policy_loss": -55.027469635009766,
    "value_loss": 0.5011892914772034,
    "entropy": 0.7987940758466721,
    "total_loss": -54.84579797387123
  },
  {
    "episode": 114,
    "avg_reward_per_step": 14.108844630472289,
    "episode_length": 1158,
    "policy_loss": -242.64325332641602,
    "value_loss": 0.5095703452825546,
    "entropy": 0.8102464824914932,
    "total_loss": -242.45778157413005
  },
  {
    "episode": 115,
    "avg_reward_per_step": 26.91398539736639,
    "episode_length": 691,
    "policy_loss": -457.3648452758789,
    "value_loss": 0.5210871994495392,
    "entropy": 0.8250934928655624,
    "total_loss": -457.1737954735756
  },
  {
    "episode": 116,
    "avg_reward_per_step": 14.515520204009484,
    "episode_length": 1154,
    "policy_loss": -249.02943801879883,
    "value_loss": 0.5101321935653687,
    "entropy": 0.8307396024465561,
    "total_loss": -248.85160166621208
  },
  {
    "episode": 117,
    "avg_reward_per_step": 13.611998499700187,
    "episode_length": 1201,
    "policy_loss": -233.2346076965332,
    "value_loss": 0.5092320740222931,
    "entropy": 0.8425371944904327,
    "total_loss": -233.0623905003071
  },
  {
    "episode": 118,
    "avg_reward_per_step": 8.529665785329534,
    "episode_length": 1756,
    "policy_loss": -148.87712478637695,
    "value_loss": 0.5053681880235672,
    "entropy": 0.8368481993675232,
    "total_loss": -148.70649587810038
  },
  {
    "episode": 119,
    "avg_reward_per_step": 21.61291160302677,
    "episode_length": 827,
    "policy_loss": -367.89046478271484,
    "value_loss": 0.5161084532737732,
    "entropy": 0.867464542388916,
    "total_loss": -367.72134214639664
  },
  {
    "episode": 120,
    "avg_reward_per_step": 21.08423330037906,
    "episode_length": 838,
    "policy_loss": -360.2415771484375,
    "value_loss": 0.5154717564582825,
    "entropy": 0.8715057820081711,
    "total_loss": -360.0747077047825
  },
  {
    "episode": 121,
    "avg_reward_per_step": 10.646081596953895,
    "episode_length": 1509,
    "policy_loss": -183.86993408203125,
    "value_loss": 0.5071323215961456,
    "entropy": 0.8923905193805695,
    "total_loss": -183.71975796818734
  },
  {
    "episode": 122,
    "avg_reward_per_step": 36.3361738664162,
    "episode_length": 523,
    "policy_loss": -619.2190856933594,
    "value_loss": 0.5292332917451859,
    "entropy": 0.9152336865663528,
    "total_loss": -619.0559458762407
  },
  {
    "episode": 123,
    "avg_reward_per_step": 9.896671640222266,
    "episode_length": 1691,
    "policy_loss": -173.54610061645508,
    "value_loss": 0.5069193989038467,
    "entropy": 0.9292443543672562,
    "total_loss": -173.41087895929815
  },
  {
    "episode": 124,
    "avg_reward_per_step": 29.787161564574433,
    "episode_length": 632,
    "policy_loss": -510.8919219970703,
    "value_loss": 0.5236230939626694,
    "entropy": 0.9278827756643295,
    "total_loss": -510.73945201337335
  },
  {
    "episode": 125,
    "avg_reward_per_step": 63.69131639061704,
    "episode_length": 310,
    "policy_loss": -1082.2390441894531,
    "value_loss": 0.5559936761856079,
    "entropy": 0.9615246504545212,
    "total_loss": -1082.0676603734494
  },
  {
    "episode": 126,
    "avg_reward_per_step": 44.59530854538058,
    "episode_length": 436,
    "policy_loss": -774.8758697509766,
    "value_loss": 0.5373138338327408,
    "entropy": 0.9949071407318115,
    "total_loss": -774.7365187734365
  },
  {
    "episode": 127,
    "avg_reward_per_step": 68.87766872389348,
    "episode_length": 286,
    "policy_loss": -1164.6998901367188,
    "value_loss": 0.5608016699552536,
    "entropy": 0.9964697957038879,
    "total_loss": -1164.537676385045
  },
  {
    "episode": 128,
    "avg_reward_per_step": 44.70352153670894,
    "episode_length": 431,
    "policy_loss": -759.9740753173828,
    "value_loss": 0.5367688238620758,
    "entropy": 1.0114116370677948,
    "total_loss": -759.8418711483479
  },
  {
    "episode": 129,
    "avg_reward_per_step": 12.003436869199733,
    "episode_length": 1464,
    "policy_loss": -205.18752670288086,
    "value_loss": 0.5088701397180557,
    "entropy": 1.0173591673374176,
    "total_loss": -205.08560023009778
  },
  {
    "episode": 130,
    "avg_reward_per_step": 20.714253002056722,
    "episode_length": 913,
    "policy_loss": -352.2905502319336,
    "value_loss": 0.5162993371486664,
    "entropy": 1.0743879079818726,
    "total_loss": -352.20400605797767
  },
  {
    "episode": 131,
    "avg_reward_per_step": 12.512240424184505,
    "episode_length": 1443,
    "policy_loss": -214.38321685791016,
    "value_loss": 0.5094099789857864,
    "entropy": 1.0380145013332367,
    "total_loss": -214.28901267945767
  },
  {
    "episode": 132,
    "avg_reward_per_step": 8.18669870356973,
    "episode_length": 1972,
    "policy_loss": -141.7347068786621,
    "value_loss": 0.50553859770298,
    "entropy": 1.0543540716171265,
    "total_loss": -141.65090990960599
  },
  {
    "episode": 133,
    "avg_reward_per_step": 25.81078288371591,
    "episode_length": 736,
    "policy_loss": -437.83841705322266,
    "value_loss": 0.5204291939735413,
    "entropy": 1.0041675120592117,
    "total_loss": -437.7196548640728
  },
  {
    "episode": 134,
    "avg_reward_per_step": 32.0013129037466,
    "episode_length": 603,
    "policy_loss": -543.8298950195312,
    "value_loss": 0.5259421467781067,
    "entropy": 1.0109392702579498,
    "total_loss": -543.7083285808563
  },
  {
    "episode": 135,
    "avg_reward_per_step": 45.74456649022051,
    "episode_length": 428,
    "policy_loss": -776.1728973388672,
    "value_loss": 0.5383623838424683,
    "entropy": 1.0261729061603546,
    "total_loss": -776.0450041174888
  },
  {
    "episode": 136,
    "avg_reward_per_step": 22.029926225577885,
    "episode_length": 839,
    "policy_loss": -374.2815704345703,
    "value_loss": 0.5168907642364502,
    "entropy": 1.0927525758743286,
    "total_loss": -374.20178070068357
  },
  {
    "episode": 137,
    "avg_reward_per_step": 31.065787859298823,
    "episode_length": 615,
    "policy_loss": -526.2968902587891,
    "value_loss": 0.5249851644039154,
    "entropy": 1.0589849352836609,
    "total_loss": -526.1954990684986
  },
  {
    "episode": 138,
    "avg_reward_per_step": 23.659787892516412,
    "episode_length": 792,
    "policy_loss": -403.0713195800781,
    "value_loss": 0.5184821039438248,
    "entropy": 1.0484257340431213,
    "total_loss": -402.97220776975155
  },
  {
    "episode": 139,
    "avg_reward_per_step": 32.7568796362108,
    "episode_length": 590,
    "policy_loss": -557.409912109375,
    "value_loss": 0.5267997831106186,
    "entropy": 1.0264230370521545,
    "total_loss": -557.2936815410852
  },
  {
    "episode": 140,
    "avg_reward_per_step": 5.406855986141899,
    "episode_length": 2784,
    "policy_loss": -94.60129165649414,
    "value_loss": 0.5035325139760971,
    "entropy": 1.0230014026165009,
    "total_loss": -94.50695970356465
  },
  {
    "episode": 141,
    "avg_reward_per_step": 8.911020569737829,
    "episode_length": 1919,
    "policy_loss": -153.91269302368164,
    "value_loss": 0.5064168870449066,
    "entropy": 1.010215848684311,
    "total_loss": -153.81036247611047
  },
  {
    "episode": 142,
    "avg_reward_per_step": 28.069541540229743,
    "episode_length": 679,
    "policy_loss": -477.2828369140625,
    "value_loss": 0.5222611874341965,
    "entropy": 0.9854978173971176,
    "total_loss": -477.1547748535871
  },
  {
    "episode": 143,
    "avg_reward_per_step": 23.058765480718684,
    "episode_length": 800,
    "policy_loss": -395.7832946777344,
    "value_loss": 0.5177345722913742,
    "entropy": 0.9566648155450821,
    "total_loss": -395.648226031661
  },
  {
    "episode": 144,
    "avg_reward_per_step": 6.7428894118747715,
    "episode_length": 2294,
    "policy_loss": -118.09920120239258,
    "value_loss": 0.5044101178646088,
    "entropy": 1.002503290772438,
    "total_loss": -117.99579240083695
  },
  {
    "episode": 145,
    "avg_reward_per_step": 13.312940009720483,
    "episode_length": 1263,
    "policy_loss": -227.73933029174805,
    "value_loss": 0.5092756301164627,
    "entropy": 1.0133334696292877,
    "total_loss": -227.6353880494833
  },
  {
    "episode": 146,
    "avg_reward_per_step": 55.1549172548641,
    "episode_length": 359,
    "policy_loss": -932.0981292724609,
    "value_loss": 0.5476922541856766,
    "entropy": 0.8778985291719437,
    "total_loss": -931.901596429944
  },
  {
    "episode": 147,
    "avg_reward_per_step": 16.75885930933512,
    "episode_length": 1101,
    "policy_loss": -286.1204605102539,
    "value_loss": 0.5129046589136124,
    "entropy": 0.8939802497625351,
    "total_loss": -285.9651479512453
  },
  {
    "episode": 148,
    "avg_reward_per_step": 16.9903844472385,
    "episode_length": 1063,
    "policy_loss": -290.0193328857422,
    "value_loss": 0.5127280652523041,
    "entropy": 0.9256805330514908,
    "total_loss": -289.87687703371046
  },
  {
    "episode": 149,
    "avg_reward_per_step": 33.03451960558552,
    "episode_length": 596,
    "policy_loss": -561.9374847412109,
    "value_loss": 0.5274623781442642,
    "entropy": 0.9214880615472794,
    "total_loss": -561.7786175876856
  },
  {
    "episode": 150,
    "avg_reward_per_step": 11.100360657102621,
    "episode_length": 1664,
    "policy_loss": -191.1411476135254,
    "value_loss": 0.5086035579442978,
    "entropy": 0.9431933164596558,
    "total_loss": -191.00982138216494
  },
  {
    "episode": 151,
    "avg_reward_per_step": 19.954492740507835,
    "episode_length": 959,
    "policy_loss": -341.03072357177734,
    "value_loss": 0.5160306394100189,
    "entropy": 0.9446185231208801,
    "total_loss": -340.8925403416157
  },
  {
    "episode": 152,
    "avg_reward_per_step": 8.018709398058578,
    "episode_length": 2257,
    "policy_loss": -139.07658004760742,
    "value_loss": 0.5062049478292465,
    "entropy": 0.925899088382721,
    "total_loss": -138.94073473513126
  },
  {
    "episode": 153,
    "avg_reward_per_step": 27.75576934781283,
    "episode_length": 738,
    "policy_loss": -469.7935333251953,
    "value_loss": 0.5240310728549957,
    "entropy": 0.8839862495660782,
    "total_loss": -469.62309675216676
  },
  {
    "episode": 154,
    "avg_reward_per_step": 13.87408843439488,
    "episode_length": 1432,
    "policy_loss": -237.3180160522461,
    "value_loss": 0.5115689188241959,
    "entropy": 0.891721099615097,
    "total_loss": -237.16313557326794
  },
  {
    "episode": 155,
    "avg_reward_per_step": 9.874328225371517,
    "episode_length": 2076,
    "policy_loss": -169.55933380126953,
    "value_loss": 0.5085683166980743,
    "entropy": 0.8844532370567322,
    "total_loss": -169.40454677939414
  },
  {
    "episode": 156,
    "avg_reward_per_step": 13.584041866761316,
    "episode_length": 1419,
    "policy_loss": -232.75287628173828,
    "value_loss": 0.5109455287456512,
    "entropy": 0.8750335574150085,
    "total_loss": -232.59194417595864
  },
  {
    "episode": 157,
    "avg_reward_per_step": 9.289568382989765,
    "episode_length": 2048,
    "policy_loss": -159.82123947143555,
    "value_loss": 0.5074810683727264,
    "entropy": 0.82247194647789,
    "total_loss": -159.642747181654
  },
  {
    "episode": 158,
    "avg_reward_per_step": 150.1007656450927,
    "episode_length": 133,
    "policy_loss": -2539.377685546875,
    "value_loss": 0.6572370678186417,
    "entropy": 0.9115461707115173,
    "total_loss": -2539.085066947341
  },
  {
    "episode": 159,
    "avg_reward_per_step": 21.709088310086592,
    "episode_length": 871,
    "policy_loss": -366.8466567993164,
    "value_loss": 0.5171752274036407,
    "entropy": 0.8538156449794769,
    "total_loss": -366.67100782990457
  },
  {
    "episode": 160,
    "avg_reward_per_step": 17.298265390674835,
    "episode_length": 1110,
    "policy_loss": -294.10318756103516,
    "value_loss": 0.5138668268918991,
    "entropy": 0.8050857335329056,
    "total_loss": -293.9113550275564
  },
  {
    "episode": 161,
    "avg_reward_per_step": 7.665647402856558,
    "episode_length": 2916,
    "policy_loss": -132.58603286743164,
    "value_loss": 0.5074490457773209,
    "entropy": 0.7405647486448288,
    "total_loss": -132.37480972111226
  },
  {
    "episode": 162,
    "avg_reward_per_step": 8.198771555217881,
    "episode_length": 2359,
    "policy_loss": -141.7925910949707,
    "value_loss": 0.5068257451057434,
    "entropy": 0.7633599191904068,
    "total_loss": -141.5911093175411
  },
  {
    "episode": 163,
    "avg_reward_per_step": 10.859696341801909,
    "episode_length": 1866,
    "policy_loss": -186.49990463256836,
    "value_loss": 0.5093766450881958,
    "entropy": 0.7181443423032761,
    "total_loss": -186.27778572440147
  },
  {
    "episode": 164,
    "avg_reward_per_step": 0.32378707825378833,
    "episode_length": 3000,
    "policy_loss": -9.023670196533203,
    "value_loss": 0.5433149188756943,
    "entropy": 0.6965339183807373,
    "total_loss": -8.758968845009804
  },
  {
    "episode": 165,
    "avg_reward_per_step": 13.153847072028103,
    "episode_length": 1530,
    "policy_loss": -225.50440216064453,
    "value_loss": 0.5111911594867706,
    "entropy": 0.7233841717243195,
    "total_loss": -225.2825646698475
  },
  {
    "episode": 166,
    "avg_reward_per_step": 11.396173827703855,
    "episode_length": 1818,
    "policy_loss": -195.57437133789062,
    "value_loss": 0.510034516453743,
    "entropy": 0.6727191805839539,
    "total_loss": -195.33342449367046
  },
  {
    "episode": 167,
    "avg_reward_per_step": 15.379709098542437,
    "episode_length": 1148,
    "policy_loss": -262.33558654785156,
    "value_loss": 0.5113353580236435,
    "entropy": 0.7140475064516068,
    "total_loss": -262.10987019240855
  },
  {
    "episode": 168,
    "avg_reward_per_step": 15.587992384208949,
    "episode_length": 1174,
    "policy_loss": -271.3240966796875,
    "value_loss": 0.51182422041893,
    "entropy": 0.7491346746683121,
    "total_loss": -271.1119263291359
  },
  {
    "episode": 169,
    "avg_reward_per_step": 1.2583224712298806,
    "episode_length": 3000,
    "policy_loss": -24.36268424987793,
    "value_loss": 1.261521190404892,
    "entropy": 0.7271521836519241,
    "total_loss": -23.392023932933807
  },
  {
    "episode": 170,
    "avg_reward_per_step": 50.34543425898021,
    "episode_length": 386,
    "policy_loss": -851.1965637207031,
    "value_loss": 0.5422042608261108,
    "entropy": 0.8007070571184158,
    "total_loss": -850.9746422827244
  },
  {
    "episode": 171,
    "avg_reward_per_step": 7.7628054170370575,
    "episode_length": 2530,
    "policy_loss": -133.40509796142578,
    "value_loss": 0.50652214884758,
    "entropy": 0.7599260360002518,
    "total_loss": -133.2025462269783
  },
  {
    "episode": 172,
    "avg_reward_per_step": 12.448364573217635,
    "episode_length": 1616,
    "policy_loss": -212.86728286743164,
    "value_loss": 0.5105789452791214,
    "entropy": 0.7896229922771454,
    "total_loss": -212.67255311906337
  },
  {
    "episode": 173,
    "avg_reward_per_step": 24.912072678552732,
    "episode_length": 820,
    "policy_loss": -428.90242767333984,
    "value_loss": 0.521464928984642,
    "entropy": 0.7500291019678116,
    "total_loss": -428.68097438514235
  },
  {
    "episode": 174,
    "avg_reward_per_step": 8.294168892882267,
    "episode_length": 2457,
    "policy_loss": -141.08827209472656,
    "value_loss": 0.5072056800127029,
    "entropy": 0.7408613115549088,
    "total_loss": -140.87741093933582
  },
  {
    "episode": 175,
    "avg_reward_per_step": 26.0429714896826,
    "episode_length": 755,
    "policy_loss": -447.4140930175781,
    "value_loss": 0.5215252041816711,
    "entropy": 0.7718514949083328,
    "total_loss": -447.2013084113598
  },
  {
    "episode": 176,
    "avg_reward_per_step": 9.7256132442632,
    "episode_length": 1847,
    "policy_loss": -165.06287384033203,
    "value_loss": 0.507248729467392,
    "entropy": 0.6737473160028458,
    "total_loss": -164.82512403726577
  },
  {
    "episode": 177,
    "avg_reward_per_step": 26.708102476490478,
    "episode_length": 736,
    "policy_loss": -458.1532516479492,
    "value_loss": 0.5221958607435226,
    "entropy": 0.6285212635993958,
    "total_loss": -457.88246429264547
  },
  {
    "episode": 178,
    "avg_reward_per_step": 8.820143124167865,
    "episode_length": 2465,
    "policy_loss": -151.18783950805664,
    "value_loss": 0.5082058757543564,
    "entropy": 0.744178369641304,
    "total_loss": -150.9773049801588
  },
  {
    "episode": 179,
    "avg_reward_per_step": 35.95005376058195,
    "episode_length": 553,
    "policy_loss": -619.9299011230469,
    "value_loss": 0.5306021720170975,
    "entropy": 0.7630181461572647,
    "total_loss": -619.7045062094927
  },
  {
    "episode": 180,
    "avg_reward_per_step": 21.350774441755895,
    "episode_length": 947,
    "policy_loss": -367.0145568847656,
    "value_loss": 0.5181002914905548,
    "entropy": 0.7909501194953918,
    "total_loss": -366.8128366410732
  },
  {
    "episode": 181,
    "avg_reward_per_step": 13.968569059854493,
    "episode_length": 1389,
    "policy_loss": -240.50864028930664,
    "value_loss": 0.5113740265369415,
    "entropy": 0.8389002531766891,
    "total_loss": -240.3328263640404
  },
  {
    "episode": 182,
    "avg_reward_per_step": 31.280534862582087,
    "episode_length": 649,
    "policy_loss": -532.9135437011719,
    "value_loss": 0.5268421024084091,
    "entropy": 0.8287992775440216,
    "total_loss": -532.718221309781
  },
  {
    "episode": 183,
    "avg_reward_per_step": 16.04665011878274,
    "episode_length": 1257,
    "policy_loss": -273.4310073852539,
    "value_loss": 0.5135856717824936,
    "entropy": 0.8132060021162033,
    "total_loss": -273.2427041143179
  },
  {
    "episode": 184,
    "avg_reward_per_step": 12.57874827903013,
    "episode_length": 1543,
    "policy_loss": -213.67604064941406,
    "value_loss": 0.510218158364296,
    "entropy": 0.8294091373682022,
    "total_loss": -213.49758614599705
  },
  {
    "episode": 185,
    "avg_reward_per_step": 38.36056878074953,
    "episode_length": 525,
    "policy_loss": -657.5594329833984,
    "value_loss": 0.5330223441123962,
    "entropy": 0.759535402059555,
    "total_loss": -657.3302248001098
  },
  {
    "episode": 186,
    "avg_reward_per_step": 18.206723468664052,
    "episode_length": 1094,
    "policy_loss": -306.6905517578125,
    "value_loss": 0.5152204781770706,
    "entropy": 0.8571983724832535,
    "total_loss": -306.5182106286287
  },
  {
    "episode": 187,
    "avg_reward_per_step": 45.221839582049846,
    "episode_length": 445,
    "policy_loss": -774.3752899169922,
    "value_loss": 0.5393229722976685,
    "entropy": 0.8231326937675476,
    "total_loss": -774.1652200222015
  },
  {
    "episode": 188,
    "avg_reward_per_step": 42.39358867289866,
    "episode_length": 475,
    "policy_loss": -733.8542938232422,
    "value_loss": 0.5368101447820663,
    "entropy": 0.800945445895195,
    "total_loss": -733.6378618568182
  },
  {
    "episode": 189,
    "avg_reward_per_step": 21.275038638418014,
    "episode_length": 925,
    "policy_loss": -361.4773406982422,
    "value_loss": 0.5176102817058563,
    "entropy": 0.8522710502147675,
    "total_loss": -361.3006388366222
  },
  {
    "episode": 190,
    "avg_reward_per_step": -0.7517256011010888,
    "episode_length": 3000,
    "policy_loss": 10.329659461975098,
    "value_loss": 0.5703844726085663,
    "entropy": 0.830053448677063,
    "total_loss": 10.568022555112838
  },
  {
    "episode": 191,
    "avg_reward_per_step": 11.24228262635582,
    "episode_length": 1688,
    "policy_loss": -191.76166915893555,
    "value_loss": 0.5089740008115768,
    "entropy": 0.779157966375351,
    "total_loss": -191.5643583446741
  },
  {
    "episode": 192,
    "avg_reward_per_step": 36.00541097273569,
    "episode_length": 552,
    "policy_loss": -616.3012847900391,
    "value_loss": 0.5304806679487228,
    "entropy": 0.9398037195205688,
    "total_loss": -616.1467256098986
  },
  {
    "episode": 193,
    "avg_reward_per_step": -0.7069251139404726,
    "episode_length": 3000,
    "policy_loss": 9.740374565124512,
    "value_loss": 0.7839412987232208,
    "entropy": 0.5165795981884003,
    "total_loss": 10.317684024572372
  },
  {
    "episode": 194,
    "avg_reward_per_step": -0.9690242767720318,
    "episode_length": 3000,
    "policy_loss": 13.868044376373291,
    "value_loss": 0.7276022136211395,
    "entropy": 0.8092106729745865,
    "total_loss": 14.271962320804596
  },
  {
    "episode": 195,
    "avg_reward_per_step": -0.6398274912011502,
    "episode_length": 3000,
    "policy_loss": 8.317768096923828,
    "value_loss": 0.7878803461790085,
    "entropy": 0.4154457524418831,
    "total_loss": 8.939470142126083
  },
  {
    "episode": 196,
    "avg_reward_per_step": -0.6157326010056463,
    "episode_length": 3000,
    "policy_loss": 7.718545198440552,
    "value_loss": 0.8759065717458725,
    "entropy": 0.42044395208358765,
    "total_loss": 8.42627418935299
  },
  {
    "episode": 197,
    "avg_reward_per_step": -0.6710145079804204,
    "episode_length": 3000,
    "policy_loss": 8.346647500991821,
    "value_loss": 0.7532982677221298,
    "entropy": 0.5226268172264099,
    "total_loss": 8.890895041823388
  },
  {
    "episode": 198,
    "avg_reward_per_step": -0.566353387311989,
    "episode_length": 3000,
    "policy_loss": 6.149191617965698,
    "value_loss": 0.8146131783723831,
    "entropy": 0.4528810977935791,
    "total_loss": 6.78265235722065
  },
  {
    "episode": 199,
    "avg_reward_per_step": 16.790166352915943,
    "episode_length": 1148,
    "policy_loss": -289.8319396972656,
    "value_loss": 0.5137051492929459,
    "entropy": 0.6701446175575256,
    "total_loss": -289.58629239499567
  },
  {
    "episode": 200,
    "avg_reward_per_step": -0.6187719204979113,
    "episode_length": 3000,
    "policy_loss": 6.335182428359985,
    "value_loss": 0.8061514049768448,
    "entropy": 0.5105143487453461,
    "total_loss": 6.937128093838692
  },
  {
    "episode": 201,
    "avg_reward_per_step": -0.7694048664963413,
    "episode_length": 3000,
    "policy_loss": 8.478608131408691,
    "value_loss": 0.7528274953365326,
    "entropy": 0.6131500452756882,
    "total_loss": 8.986175608634948
  },
  {
    "episode": 202,
    "avg_reward_per_step": 6.405886549405861,
    "episode_length": 2777,
    "policy_loss": -113.07695388793945,
    "value_loss": 0.5051576793193817,
    "entropy": 0.8909473270177841,
    "total_loss": -112.92817513942718
  },
  {
    "episode": 203,
    "avg_reward_per_step": 9.157446695824277,
    "episode_length": 2017,
    "policy_loss": -159.3731689453125,
    "value_loss": 0.5073745101690292,
    "entropy": 0.8536409735679626,
    "total_loss": -159.20725082457065
  },
  {
    "episode": 204,
    "avg_reward_per_step": 15.713826127222774,
    "episode_length": 1234,
    "policy_loss": -272.83643341064453,
    "value_loss": 0.5128983855247498,
    "entropy": 0.8813031911849976,
    "total_loss": -272.6760563015938
  },
  {
    "episode": 205,
    "avg_reward_per_step": 9.325335586183446,
    "episode_length": 2043,
    "policy_loss": -163.88556671142578,
    "value_loss": 0.5075288861989975,
    "entropy": 0.889546737074852,
    "total_loss": -163.73385652005672
  },
  {
    "episode": 206,
    "avg_reward_per_step": 20.098587230514056,
    "episode_length": 966,
    "policy_loss": -343.5260467529297,
    "value_loss": 0.5167151242494583,
    "entropy": 0.8131774365901947,
    "total_loss": -343.3346026033163
  },
  {
    "episode": 207,
    "avg_reward_per_step": 15.667002667175366,
    "episode_length": 1238,
    "policy_loss": -270.064208984375,
    "value_loss": 0.5130544602870941,
    "entropy": 0.786922350525856,
    "total_loss": -269.86592346429825
  },
  {
    "episode": 208,
    "avg_reward_per_step": 35.208284873696364,
    "episode_length": 568,
    "policy_loss": -606.4816436767578,
    "value_loss": 0.5302561968564987,
    "entropy": 0.8688016980886459,
    "total_loss": -606.2989081591368
  },
  {
    "episode": 209,
    "avg_reward_per_step": 12.592380134887888,
    "episode_length": 1592,
    "policy_loss": -216.92690658569336,
    "value_loss": 0.5109772831201553,
    "entropy": 0.905371904373169,
    "total_loss": -216.77807806432247
  },
  {
    "episode": 210,
    "avg_reward_per_step": 17.450885996125415,
    "episode_length": 1131,
    "policy_loss": -300.41902923583984,
    "value_loss": 0.5147363692522049,
    "entropy": 0.8712853640317917,
    "total_loss": -300.2528070122004
  },
  {
    "episode": 211,
    "avg_reward_per_step": 64.61290123687883,
    "episode_length": 308,
    "policy_loss": -1100.2332763671875,
    "value_loss": 0.5576494187116623,
    "entropy": 0.9229135662317276,
    "total_loss": -1100.0447923749684
  },
  {
    "episode": 212,
    "avg_reward_per_step": 27.98343420051059,
    "episode_length": 712,
    "policy_loss": -482.6246643066406,
    "value_loss": 0.5236557275056839,
    "entropy": 0.7979054301977158,
    "total_loss": -482.420170751214
  },
  {
    "episode": 213,
    "avg_reward_per_step": 16.800415114770306,
    "episode_length": 1167,
    "policy_loss": -292.5644760131836,
    "value_loss": 0.5140621364116669,
    "entropy": 0.909038707613945,
    "total_loss": -292.4140293598175
  },
  {
    "episode": 214,
    "avg_reward_per_step": 11.867583093479238,
    "episode_length": 1598,
    "policy_loss": -207.3834686279297,
    "value_loss": 0.5096599757671356,
    "entropy": 0.9199074059724808,
    "total_loss": -207.24177161455154
  },
  {
    "episode": 215,
    "avg_reward_per_step": -0.6879890218287481,
    "episode_length": 3000,
    "policy_loss": 5.73888885974884,
    "value_loss": 0.5216269493103027,
    "entropy": 0.847969263792038,
    "total_loss": 5.9213281035423275
  },
  {
    "episode": 216,
    "avg_reward_per_step": -1.0013104006570293,
    "episode_length": 3000,
    "policy_loss": 11.083099842071533,
    "value_loss": 0.6006570756435394,
    "entropy": 0.8129075318574905,
    "total_loss": 11.358593904972077
  },
  {
    "episode": 217,
    "avg_reward_per_step": 17.71522494161051,
    "episode_length": 1077,
    "policy_loss": -306.4068374633789,
    "value_loss": 0.5144198834896088,
    "entropy": 0.8436649143695831,
    "total_loss": -306.2298835456371
  },
  {
    "episode": 218,
    "avg_reward_per_step": -0.9017914912702446,
    "episode_length": 3000,
    "policy_loss": 9.082204103469849,
    "value_loss": 0.6043312400579453,
    "entropy": 0.7894802093505859,
    "total_loss": 9.37074325978756
  },
  {
    "episode": 219,
    "avg_reward_per_step": 9.366836405546776,
    "episode_length": 1946,
    "policy_loss": -164.7153205871582,
    "value_loss": 0.5075148791074753,
    "entropy": 0.8313685655593872,
    "total_loss": -164.54035313427448
  },
  {
    "episode": 220,
    "avg_reward_per_step": -0.921755002024351,
    "episode_length": 3000,
    "policy_loss": 9.359330892562866,
    "value_loss": 0.569437101483345,
    "entropy": 0.8108967244625092,
    "total_loss": 9.604409304261207
  },
  {
    "episode": 221,
    "avg_reward_per_step": -1.0229994836526675,
    "episode_length": 3000,
    "policy_loss": 10.883694887161255,
    "value_loss": 0.5819807201623917,
    "entropy": 0.8835952877998352,
    "total_loss": 11.112237492203713
  },
  {
    "episode": 222,
    "avg_reward_per_step": 7.058780135662687,
    "episode_length": 2477,
    "policy_loss": -126.12294006347656,
    "value_loss": 0.5055238604545593,
    "entropy": 0.8888648450374603,
    "total_loss": -125.97296214103699
  },
  {
    "episode": 223,
    "avg_reward_per_step": 15.315088483629326,
    "episode_length": 1251,
    "policy_loss": -265.0969696044922,
    "value_loss": 0.5125556290149689,
    "entropy": 0.9096534550189972,
    "total_loss": -264.9482753574848
  },
  {
    "episode": 224,
    "avg_reward_per_step": 7.876951725038801,
    "episode_length": 2389,
    "policy_loss": -141.2872772216797,
    "value_loss": 0.5065775662660599,
    "entropy": 0.8776660114526749,
    "total_loss": -141.1317660599947
  },
  {
    "episode": 225,
    "avg_reward_per_step": 26.711167286527726,
    "episode_length": 736,
    "policy_loss": -457.6263961791992,
    "value_loss": 0.5224501192569733,
    "entropy": 0.9544792324304581,
    "total_loss": -457.4857377529144
  },
  {
    "episode": 226,
    "avg_reward_per_step": 30.98638677147562,
    "episode_length": 648,
    "policy_loss": -533.5128479003906,
    "value_loss": 0.526825949549675,
    "entropy": 0.8358045071363449,
    "total_loss": -533.3203437536955
  },
  {
    "episode": 227,
    "avg_reward_per_step": 49.57786389326049,
    "episode_length": 398,
    "policy_loss": -855.0183715820312,
    "value_loss": 0.5429394245147705,
    "entropy": 0.8421921581029892,
    "total_loss": -854.8123090207577
  },
  {
    "episode": 228,
    "avg_reward_per_step": 34.89630573655758,
    "episode_length": 577,
    "policy_loss": -607.5780334472656,
    "value_loss": 0.530130535364151,
    "entropy": 0.7417540848255157,
    "total_loss": -607.3446045458317
  },
  {
    "episode": 229,
    "avg_reward_per_step": 43.6176555113109,
    "episode_length": 461,
    "policy_loss": -750.4395294189453,
    "value_loss": 0.5380786657333374,
    "entropy": 0.728890597820282,
    "total_loss": -750.1930069923401
  },
  {
    "episode": 230,
    "avg_reward_per_step": 19.849114346176442,
    "episode_length": 984,
    "policy_loss": -342.4061279296875,
    "value_loss": 0.5166871249675751,
    "entropy": 0.6833154410123825,
    "total_loss": -342.1627669811249
  },
  {
    "episode": 231,
    "avg_reward_per_step": 36.135518502646086,
    "episode_length": 542,
    "policy_loss": -614.6497955322266,
    "value_loss": 0.5305263996124268,
    "entropy": 0.5383710265159607,
    "total_loss": -614.3346175432205
  },
  {
    "episode": 232,
    "avg_reward_per_step": 14.967701512691145,
    "episode_length": 1287,
    "policy_loss": -258.5013885498047,
    "value_loss": 0.5124021619558334,
    "entropy": 0.6696629971265793,
    "total_loss": -258.2568515866995
  },
  {
    "episode": 233,
    "avg_reward_per_step": 10.561260489200114,
    "episode_length": 1827,
    "policy_loss": -188.50207138061523,
    "value_loss": 0.5089021921157837,
    "entropy": 0.5999862849712372,
    "total_loss": -188.23316370248796
  },
  {
    "episode": 234,
    "avg_reward_per_step": 8.796308809430103,
    "episode_length": 2092,
    "policy_loss": -156.46892166137695,
    "value_loss": 0.5071880221366882,
    "entropy": 0.6057166904211044,
    "total_loss": -156.2040203154087
  },
  {
    "episode": 235,
    "avg_reward_per_step": 14.897934993064146,
    "episode_length": 1284,
    "policy_loss": -259.85758209228516,
    "value_loss": 0.5122581273317337,
    "entropy": 0.593521237373352,
    "total_loss": -259.5827324599028
  },
  {
    "episode": 236,
    "avg_reward_per_step": 8.71586041475225,
    "episode_length": 2109,
    "policy_loss": -155.1851043701172,
    "value_loss": 0.5072030574083328,
    "entropy": 0.616425409913063,
    "total_loss": -154.92447147667409
  },
  {
    "episode": 237,
    "avg_reward_per_step": 7.836313895946914,
    "episode_length": 2395,
    "policy_loss": -141.31183624267578,
    "value_loss": 0.5066713839769363,
    "entropy": 0.6366635859012604,
    "total_loss": -141.05983029305935
  },
  {
    "episode": 238,
    "avg_reward_per_step": 14.08918886809866,
    "episode_length": 1322,
    "policy_loss": -246.2944107055664,
    "value_loss": 0.5112528502941132,
    "entropy": 0.6358115524053574,
    "total_loss": -246.03748247623443
  },
  {
    "episode": 239,
    "avg_reward_per_step": -1.0912565830951657,
    "episode_length": 3000,
    "policy_loss": 11.76434588432312,
    "value_loss": 0.5808284282684326,
    "entropy": 0.6124377548694611,
    "total_loss": 12.100199210643769
  },
  {
    "episode": 240,
    "avg_reward_per_step": -0.9929245809717407,
    "episode_length": 3000,
    "policy_loss": 10.16446852684021,
    "value_loss": 0.5540168285369873,
    "entropy": 0.6134257912635803,
    "total_loss": 10.473115038871764
  },
  {
    "episode": 241,
    "avg_reward_per_step": 13.813884609959626,
    "episode_length": 1361,
    "policy_loss": -240.88628768920898,
    "value_loss": 0.5113435834646225,
    "entropy": 0.6631987392902374,
    "total_loss": -240.64022360146046
  },
  {
    "episode": 242,
    "avg_reward_per_step": 33.09608676177285,
    "episode_length": 603,
    "policy_loss": -571.0650634765625,
    "value_loss": 0.5285002887248993,
    "entropy": 0.6492992639541626,
    "total_loss": -570.7962828934193
  },
  {
    "episode": 243,
    "avg_reward_per_step": 14.24586647674226,
    "episode_length": 1354,
    "policy_loss": -249.6565055847168,
    "value_loss": 0.5118115097284317,
    "entropy": 0.6803508400917053,
    "total_loss": -249.41683441102504
  },
  {
    "episode": 244,
    "avg_reward_per_step": 32.78147944209422,
    "episode_length": 606,
    "policy_loss": -571.3890228271484,
    "value_loss": 0.5281554758548737,
    "entropy": 0.5049067661166191,
    "total_loss": -571.0628300577403
  },
  {
    "episode": 245,
    "avg_reward_per_step": 63.66388627992852,
    "episode_length": 314,
    "policy_loss": -1088.9496154785156,
    "value_loss": 0.557034507393837,
    "entropy": 0.6066141724586487,
    "total_loss": -1088.6352266401052
  },
  {
    "episode": 246,
    "avg_reward_per_step": 10.193539021391317,
    "episode_length": 1869,
    "policy_loss": -178.09860229492188,
    "value_loss": 0.5086463540792465,
    "entropy": 0.5003127902746201,
    "total_loss": -177.7900810569525
  },
  {
    "episode": 247,
    "avg_reward_per_step": 24.990757408269552,
    "episode_length": 792,
    "policy_loss": -430.13035583496094,
    "value_loss": 0.5212316364049911,
    "entropy": 0.5983240306377411,
    "total_loss": -429.84845381081107
  },
  {
    "episode": 248,
    "avg_reward_per_step": 19.65794723080643,
    "episode_length": 994,
    "policy_loss": -340.2368469238281,
    "value_loss": 0.5165518224239349,
    "entropy": 0.4279121682047844,
    "total_loss": -339.8914599686861
  },
  {
    "episode": 249,
    "avg_reward_per_step": 13.068969057524296,
    "episode_length": 1476,
    "policy_loss": -227.46196365356445,
    "value_loss": 0.510976642370224,
    "entropy": 0.4963369593024254,
    "total_loss": -227.1495217949152
  },
  {
    "episode": 250,
    "avg_reward_per_step": 19.57402034106304,
    "episode_length": 994,
    "policy_loss": -339.22071838378906,
    "value_loss": 0.5164079964160919,
    "entropy": 0.45633238554000854,
    "total_loss": -338.886843341589
  },
  {
    "episode": 251,
    "avg_reward_per_step": 8.826318993230547,
    "episode_length": 2123,
    "policy_loss": -156.04948043823242,
    "value_loss": 0.5073890388011932,
    "entropy": 0.4457928463816643,
    "total_loss": -155.7204085379839
  },
  {
    "episode": 252,
    "avg_reward_per_step": 9.940430201138746,
    "episode_length": 1901,
    "policy_loss": -175.04860305786133,
    "value_loss": 0.5083208233118057,
    "entropy": 0.4350249394774437,
    "total_loss": -174.7142922103405
  },
  {
    "episode": 253,
    "avg_reward_per_step": 62.27204719327097,
    "episode_length": 322,
    "policy_loss": -1070.67041015625,
    "value_loss": 0.556028813123703,
    "entropy": 0.3468541353940964,
    "total_loss": -1070.253122997284
  },
  {
    "episode": 254,
    "avg_reward_per_step": 39.25394009666116,
    "episode_length": 506,
    "policy_loss": -679.7108306884766,
    "value_loss": 0.5338693112134933,
    "entropy": 0.3856268599629402,
    "total_loss": -679.3312121212482
  },
  {
    "episode": 255,
    "avg_reward_per_step": 48.48053600369671,
    "episode_length": 412,
    "policy_loss": -821.9687652587891,
    "value_loss": 0.5424653589725494,
    "entropy": 0.33128830790519714,
    "total_loss": -821.5588152229786
  },
  {
    "episode": 256,
    "avg_reward_per_step": 46.825051773684905,
    "episode_length": 423,
    "policy_loss": -798.8598327636719,
    "value_loss": 0.5404534786939621,
    "entropy": 0.40170811116695404,
    "total_loss": -798.4800625294447
  },
  {
    "episode": 257,
    "avg_reward_per_step": 129.8679014465389,
    "episode_length": 155,
    "policy_loss": -2214.1497802734375,
    "value_loss": 0.6319025605916977,
    "entropy": 0.39302289485931396,
    "total_loss": -2213.6750868707895
  },
  {
    "episode": 258,
    "avg_reward_per_step": 89.19452360729632,
    "episode_length": 224,
    "policy_loss": -1526.970703125,
    "value_loss": 0.5833180993795395,
    "entropy": 0.3801098093390465,
    "total_loss": -1526.539428949356
  },
  {
    "episode": 259,
    "avg_reward_per_step": 97.42177814782713,
    "episode_length": 206,
    "policy_loss": -1679.3998413085938,
    "value_loss": 0.5928316563367844,
    "entropy": 0.30340027064085007,
    "total_loss": -1678.9283697605133
  },
  {
    "episode": 260,
    "avg_reward_per_step": 93.9448444949658,
    "episode_length": 214,
    "policy_loss": -1607.3524780273438,
    "value_loss": 0.5891268700361252,
    "entropy": 0.2772696018218994,
    "total_loss": -1606.8742589980363
  },
  {
    "episode": 261,
    "avg_reward_per_step": 55.06951986486025,
    "episode_length": 362,
    "policy_loss": -941.2457885742188,
    "value_loss": 0.5481345802545547,
    "entropy": 0.24299794808030128,
    "total_loss": -940.7948531731963
  },
  {
    "episode": 262,
    "avg_reward_per_step": 119.53312354488556,
    "episode_length": 168,
    "policy_loss": -2044.9818420410156,
    "value_loss": 0.6184485852718353,
    "entropy": 0.251948494464159,
    "total_loss": -2044.4641728535294
  },
  {
    "episode": 263,
    "avg_reward_per_step": 112.41050350900844,
    "episode_length": 179,
    "policy_loss": -1913.1157531738281,
    "value_loss": 0.6092263460159302,
    "entropy": 0.2433459684252739,
    "total_loss": -1912.6038652151824
  },
  {
    "episode": 264,
    "avg_reward_per_step": 128.02190352949896,
    "episode_length": 157,
    "policy_loss": -2136.2655029296875,
    "value_loss": 0.6296308189630508,
    "entropy": 0.20196342840790749,
    "total_loss": -2135.7166574820876
  },
  {
    "episode": 265,
    "avg_reward_per_step": 183.38939849117688,
    "episode_length": 110,
    "policy_loss": -3112.9189453125,
    "value_loss": 0.7070320546627045,
    "entropy": 0.22495496273040771,
    "total_loss": -3112.3018952429293
  },
  {
    "episode": 266,
    "avg_reward_per_step": 168.30142438009787,
    "episode_length": 120,
    "policy_loss": -2848.5450439453125,
    "value_loss": 0.684153363108635,
    "entropy": 0.19625023379921913,
    "total_loss": -2847.9393906757236
  },
  {
    "episode": 267,
    "avg_reward_per_step": 125.33509772965117,
    "episode_length": 161,
    "policy_loss": -2128.6299438476562,
    "value_loss": 0.6259194612503052,
    "entropy": 0.1919114552438259,
    "total_loss": -2128.0807889685034
  },
  {
    "episode": 268,
    "avg_reward_per_step": 129.19623926572675,
    "episode_length": 156,
    "policy_loss": -2171.8058471679688,
    "value_loss": 0.6308821588754654,
    "entropy": 0.17663271352648735,
    "total_loss": -2171.2456180945037
  },
  {
    "episode": 269,
    "avg_reward_per_step": 172.51705553658513,
    "episode_length": 117,
    "policy_loss": -2942.5584716796875,
    "value_loss": 0.6903087645769119,
    "entropy": 0.20471786707639694,
    "total_loss": -2941.950050061941
  },
  {
    "episode": 270,
    "avg_reward_per_step": 183.87477411163468,
    "episode_length": 110,
    "policy_loss": -3112.5574340820312,
    "value_loss": 0.7078041732311249,
    "entropy": 0.15946455672383308,
    "total_loss": -3111.9134157314897
  },
  {
    "episode": 271,
    "avg_reward_per_step": 171.14066307396635,
    "episode_length": 118,
    "policy_loss": -2919.7547607421875,
    "value_loss": 0.68807353079319,
    "entropy": 0.1578228585422039,
    "total_loss": -2919.1298163548113
  },
  {
    "episode": 272,
    "avg_reward_per_step": 159.7694234442732,
    "episode_length": 127,
    "policy_loss": -2707.0256958007812,
    "value_loss": 0.6723015606403351,
    "entropy": 0.17294885963201523,
    "total_loss": -2706.422573783994
  },
  {
    "episode": 273,
    "avg_reward_per_step": 165.80462930835603,
    "episode_length": 122,
    "policy_loss": -2788.7247924804688,
    "value_loss": 0.6805189102888107,
    "entropy": 0.16788353398442268,
    "total_loss": -2788.1114269837735
  },
  {
    "episode": 274,
    "avg_reward_per_step": 177.39199512127635,
    "episode_length": 114,
    "policy_loss": -2995.5031127929688,
    "value_loss": 0.6978333443403244,
    "entropy": 0.1459612362086773,
    "total_loss": -2994.863663943112
  },
  {
    "episode": 275,
    "avg_reward_per_step": 183.86462774731382,
    "episode_length": 110,
    "policy_loss": -3106.6771850585938,
    "value_loss": 0.7078424394130707,
    "entropy": 0.14083537831902504,
    "total_loss": -3106.025676770508
  },
  {
    "episode": 276,
    "avg_reward_per_step": 170.9808317811397,
    "episode_length": 118,
    "policy_loss": -2885.9376220703125,
    "value_loss": 0.6875342279672623,
    "entropy": 0.13547498360276222,
    "total_loss": -2885.3042778357863
  },
  {
    "episode": 277,
    "avg_reward_per_step": 177.5833138753649,
    "episode_length": 114,
    "policy_loss": -3005.3008422851562,
    "value_loss": 0.6982664465904236,
    "entropy": 0.17580250278115273,
    "total_loss": -3004.6728968396783
  },
  {
    "episode": 278,
    "avg_reward_per_step": 170.04398694651766,
    "episode_length": 119,
    "policy_loss": -2855.5107421875,
    "value_loss": 0.6868337988853455,
    "entropy": 0.12459130398929119,
    "total_loss": -2854.8737449102105
  },
  {
    "episode": 279,
    "avg_reward_per_step": 171.44436284271603,
    "episode_length": 118,
    "policy_loss": -2886.5883178710938,
    "value_loss": 0.6888819336891174,
    "entropy": 0.11066355369985104,
    "total_loss": -2885.9437013588845
  },
  {
    "episode": 280,
    "avg_reward_per_step": 168.50503017712646,
    "episode_length": 120,
    "policy_loss": -2838.4960327148438,
    "value_loss": 0.6843146234750748,
    "entropy": 0.1312052682042122,
    "total_loss": -2837.8642001986505
  },
  {
    "episode": 281,
    "avg_reward_per_step": 177.41777530426543,
    "episode_length": 114,
    "policy_loss": -2989.4119873046875,
    "value_loss": 0.6978284120559692,
    "entropy": 0.11382847465574741,
    "total_loss": -2988.759690282494
  },
  {
    "episode": 282,
    "avg_reward_per_step": 159.38464424769964,
    "episode_length": 127,
    "policy_loss": -2691.3465576171875,
    "value_loss": 0.671699121594429,
    "entropy": 0.12763093039393425,
    "total_loss": -2690.725910867751
  },
  {
    "episode": 283,
    "avg_reward_per_step": 168.44265231185722,
    "episode_length": 120,
    "policy_loss": -2845.4989624023438,
    "value_loss": 0.6844493597745895,
    "entropy": 0.10219458676874638,
    "total_loss": -2844.8553908772765
  },
  {
    "episode": 284,
    "avg_reward_per_step": 164.54932541132817,
    "episode_length": 123,
    "policy_loss": -2775.0523681640625,
    "value_loss": 0.6786639243364334,
    "entropy": 0.11982428096234798,
    "total_loss": -2774.421633952111
  },
  {
    "episode": 285,
    "avg_reward_per_step": 167.32927807761828,
    "episode_length": 121,
    "policy_loss": -2823.0994262695312,
    "value_loss": 0.6827506273984909,
    "entropy": 0.1074922364205122,
    "total_loss": -2822.459672536701
  },
  {
    "episode": 286,
    "avg_reward_per_step": 171.4418291924455,
    "episode_length": 118,
    "policy_loss": -2888.4422607421875,
    "value_loss": 0.6886265128850937,
    "entropy": 0.11675239913165569,
    "total_loss": -2887.800335188955
  },
  {
    "episode": 287,
    "avg_reward_per_step": 170.0414726381307,
    "episode_length": 119,
    "policy_loss": -2861.1017456054688,
    "value_loss": 0.6866739839315414,
    "entropy": 0.10737023875117302,
    "total_loss": -2860.4580197170376
  },
  {
    "episode": 288,
    "avg_reward_per_step": 174.36838674867673,
    "episode_length": 116,
    "policy_loss": -2934.938232421875,
    "value_loss": 0.6930605620145798,
    "entropy": 0.1036452203989029,
    "total_loss": -2934.28662994802
  },
  {
    "episode": 289,
    "avg_reward_per_step": 163.31099721111687,
    "episode_length": 124,
    "policy_loss": -2757.5650024414062,
    "value_loss": 0.6768461167812347,
    "entropy": 0.08674979209899902,
    "total_loss": -2756.9228562414646
  },
  {
    "episode": 290,
    "avg_reward_per_step": 155.58265837087868,
    "episode_length": 130,
    "policy_loss": -2632.5545654296875,
    "value_loss": 0.666516438126564,
    "entropy": 0.108375059440732,
    "total_loss": -2631.9313990153373
  },
  {
    "episode": 291,
    "avg_reward_per_step": 159.4420959315223,
    "episode_length": 127,
    "policy_loss": -2698.0082397460938,
    "value_loss": 0.6717865616083145,
    "entropy": 0.08549751900136471,
    "total_loss": -2697.370652192086
  },
  {
    "episode": 292,
    "avg_reward_per_step": 164.3548808588299,
    "episode_length": 123,
    "policy_loss": -2771.436279296875,
    "value_loss": 0.6789326667785645,
    "entropy": 0.09442010894417763,
    "total_loss": -2770.795114673674
  },
  {
    "episode": 293,
    "avg_reward_per_step": 174.40101330079963,
    "episode_length": 116,
    "policy_loss": -2937.0582885742188,
    "value_loss": 0.692839041352272,
    "entropy": 0.10143694467842579,
    "total_loss": -2936.406024310738
  },
  {
    "episode": 294,
    "avg_reward_per_step": 158.24025582201958,
    "episode_length": 128,
    "policy_loss": -2667.2272338867188,
    "value_loss": 0.6701086014509201,
    "entropy": 0.08080547861754894,
    "total_loss": -2666.5894474767147
  },
  {
    "episode": 295,
    "avg_reward_per_step": 162.98552492602647,
    "episode_length": 124,
    "policy_loss": -2744.1743774414062,
    "value_loss": 0.6768489331007004,
    "entropy": 0.07565129734575748,
    "total_loss": -2743.5277890272437
  },
  {
    "episode": 296,
    "avg_reward_per_step": 163.28777494712725,
    "episode_length": 124,
    "policy_loss": -2764.6436157226562,
    "value_loss": 0.6768173575401306,
    "entropy": 0.11603125743567944,
    "total_loss": -2764.0132108680905
  },
  {
    "episode": 297,
    "avg_reward_per_step": 170.21902107021606,
    "episode_length": 119,
    "policy_loss": -2878.976806640625,
    "value_loss": 0.6871110200881958,
    "entropy": 0.09480858966708183,
    "total_loss": -2878.327619056404
  },
  {
    "episode": 298,
    "avg_reward_per_step": 160.77127037941466,
    "episode_length": 126,
    "policy_loss": -2716.019287109375,
    "value_loss": 0.6732585728168488,
    "entropy": 0.12878667563199997,
    "total_loss": -2715.397543206811
  },
  {
    "episode": 299,
    "avg_reward_per_step": 154.34384562844986,
    "episode_length": 131,
    "policy_loss": -2600.85205078125,
    "value_loss": 0.6638321876525879,
    "entropy": 0.11815183609724045,
    "total_loss": -2600.2354793280365
  },
  {
    "episode": 300,
    "avg_reward_per_step": 172.8214574414973,
    "episode_length": 117,
    "policy_loss": -2911.1592407226562,
    "value_loss": 0.6906352490186691,
    "entropy": 0.08643297851085663,
    "total_loss": -2910.503178665042
  }
]